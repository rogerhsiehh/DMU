{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8173246-62e5-4cbc-8009-5f0919c18057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, date, timedelta\n",
    "import ta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from sb3_contrib import RecurrentPPO\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import gym_anytrading\n",
    "from gym_anytrading.envs import StocksEnv,Actions,Positions\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8120e4f-912e-4b28-a4e7-ddbbaafd5f42",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba343558-04ec-47ee-a3ab-a0ca7245f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change these variables if necessary\n",
    "window_size = 5\n",
    "start_date = '2020-01-01' \n",
    "today = datetime.today().date()\n",
    "end_date = today.strftime(\"%Y-%m-%d\") #today is the end\n",
    "ticker = \"NVDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645d7b65-3bf8-4e13-9070-a4e089e1a7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['stoch'].replace([-float('inf'), float('inf')], np.nan, inplace=True)\n",
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['adi'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['williams_r'].replace([-float('inf'), float('inf')], np.nan, inplace=True)\n",
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['Dividends','Stock Splits'],axis=1, inplace=True)\n",
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[columns_to_scale] = scaler.fit_transform(train_df[columns_to_scale])\n",
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df[columns_to_scale] = scaler.transform(val_df[columns_to_scale])\n",
      "/var/folders/yf/0wv1c8p96x15nmycpl2csp9m0000gn/T/ipykernel_95122/1715772872.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[columns_to_scale] = scaler.transform(test_df[columns_to_scale])\n"
     ]
    }
   ],
   "source": [
    "#SEED = 99\n",
    "#np.random.seed(SEED)\n",
    "#random.seed(SEED))\n",
    "\n",
    "stock_data = yf.Ticker(ticker).history(start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "df = stock_data.reset_index()#[['Date','Close']]\n",
    "\n",
    "df.sort_values(by=['Date'], inplace=True)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "# Calculate Simple Moving Average (SMA)\n",
    "data['sma'] = ta.trend.sma_indicator(data['Close'], window=10)\n",
    "\n",
    "# Calculate Exponential Moving Average (EMA)\n",
    "data['ema'] = ta.trend.ema_indicator(data['Close'], window=10)\n",
    "\n",
    "# Calculate Moving Average Convergence Divergence (MACD)\n",
    "macd = ta.trend.MACD(data['Close'])\n",
    "data['macd'] = macd.macd()\n",
    "data['macd_signal'] = macd.macd_signal()\n",
    "data['macd_diff'] = macd.macd_diff()\n",
    "\n",
    "# Calculate Stochastic Oscillator\n",
    "stochastic_osc = ta.momentum.StochasticOscillator(data['High'], data['Low'], data['Close'], window=10, smooth_window=3)\n",
    "data['stoch'] = stochastic_osc.stoch()\n",
    "data['stoch'].replace([-float('inf'), float('inf')], np.nan, inplace=True)\n",
    "data['stoch_signal'] = stochastic_osc.stoch_signal()\n",
    "\n",
    "# Calculate Relative Strength Index (RSI)\n",
    "data['rsi'] = ta.momentum.rsi(data['Close'], window=10)\n",
    "\n",
    "# Calculate Average True Range (ATR)\n",
    "data['atr'] = ta.volatility.average_true_range(data['High'], data['Low'], data['Close'], window=10)\n",
    "\n",
    "# Calculate Accumulation Distribution Index (ADI)\n",
    "data['adi'] = ta.volume.acc_dist_index(data['High'], data['Low'], data['Close'], data['Volume'])\n",
    "data['adi'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "bollinger = ta.volatility.BollingerBands(data['Close'], window=20, window_dev=2)\n",
    "data['bollinger_hband'] = bollinger.bollinger_hband()\n",
    "data['bollinger_lband'] = bollinger.bollinger_lband()\n",
    "data['bollinger_mavg'] = bollinger.bollinger_mavg()\n",
    "\n",
    "#Commodity Channel Index (CCI)\n",
    "data['cci'] = ta.trend.cci(data['High'], data['Low'], data['Close'], window=20)\n",
    "\n",
    "# Aroon Indicator\n",
    "aroon = ta.trend.AroonIndicator(high=data['High'], low=data['Low'], window=25)\n",
    "data['aroon_up'] = aroon.aroon_up()\n",
    "data['aroon_down'] = aroon.aroon_down()\n",
    "\n",
    "# Williams %R\n",
    "data['williams_r'] = ta.momentum.williams_r(data['High'], data['Low'], data['Close'], lbp=10)\n",
    "data['williams_r'].replace([-float('inf'), float('inf')], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# Money Flow Index (MFI)\n",
    "data['mfi'] = ta.volume.money_flow_index(data['High'], data['Low'], data['Close'], data['Volume'], window=10)\n",
    "\n",
    "# Rate of Change (ROC)\n",
    "data['roc'] = ta.momentum.roc(data['Close'], window=10)\n",
    "\n",
    "# Chaikin A/D Line\n",
    "data['chaikin_ad'] = ta.volume.ChaikinMoneyFlowIndicator(data['High'], data['Low'], data['Close'], data['Volume'], window=20).chaikin_money_flow()\n",
    "\n",
    "# On-Balance Volume (OBV)\n",
    "data['obv'] = ta.volume.on_balance_volume(data['Close'], data['Volume'])\n",
    "\n",
    "\n",
    "df = data.dropna() ## <- Might need to change this if more variables are added\n",
    "df.drop(['Dividends','Stock Splits'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34489cd0-561c-44da-8c48-50f2d32ce3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['Date']<'2023-12-01']\n",
    "val_df = df[(df['Date']>='2023-12-01') & (df['Date']<'2024-12-01')]\n",
    "test_df = df[df['Date']>='2024-12-01']\n",
    "\n",
    "columns_to_scale = [col for col in df.columns if col not in [\"Date\"]]\n",
    "scaler = StandardScaler()\n",
    "train_df[columns_to_scale] = scaler.fit_transform(train_df[columns_to_scale]) \n",
    "val_df[columns_to_scale] = scaler.transform(val_df[columns_to_scale])\n",
    "test_df[columns_to_scale] = scaler.transform(test_df[columns_to_scale])\n",
    "\n",
    "train_df.set_index('Date', inplace=True)\n",
    "val_df.set_index('Date', inplace=True)\n",
    "test_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae43dfc-35d8-4961-b30a-f1979730ea83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e27d3c1-0e2e-4382-a198-20b6ee949389",
   "metadata": {},
   "source": [
    "# 2. Customize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f97672-40e6-49f5-b832-bad7a97f0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStocksEnv(StocksEnv):\n",
    "    def __init__(self, df, window_size, frame_bound, render_mode=None):\n",
    "        super().__init__(df, window_size, frame_bound, render_mode)\n",
    "\n",
    "        self.trade_fee_bid_percent = 0.001  # unit\n",
    "        self.trade_fee_ask_percent = 0.001 \n",
    "    \n",
    "    def _process_data(self):\n",
    "        start = self.frame_bound[0] - self.window_size\n",
    "        end = self.frame_bound[1]\n",
    "        prices = self.df.loc[:, 'Close'].to_numpy()[start:end]\n",
    "        signal_features = self.df.drop(['Close'],axis=1).to_numpy()[start:end]\n",
    "    \n",
    "        diff = np.insert(np.diff(prices), 0, 0)\n",
    "        signal_features = np.column_stack((prices, diff, signal_features))\n",
    "    \n",
    "        close_col_idx = self.df.columns.get_loc('Close')\n",
    "        close_mean = scaler.mean_[close_col_idx]\n",
    "        close_scale = scaler.scale_[close_col_idx]\n",
    "        # invert scaling\n",
    "        prices = prices * close_scale + close_mean\n",
    "        \n",
    "        return prices.astype(np.float32), signal_features.astype(np.float32)\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        trade = False\n",
    "        if (\n",
    "            (action == Actions.Buy.value and self._position == Positions.Short) or\n",
    "            (action == Actions.Sell.value and self._position == Positions.Long)\n",
    "        ):\n",
    "            trade = True\n",
    "\n",
    "        if trade or self._truncated:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "\n",
    "            if self._position == Positions.Long:\n",
    "                shares = (self._total_profit * (1 - self.trade_fee_ask_percent)) / last_trade_price\n",
    "                self._total_profit = (shares * (1 - self.trade_fee_bid_percent)) * current_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee5f22-4cd1-4aa5-8e4e-896406a2b560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c14a2-947d-4463-adb4-fb2dee47a790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09889c4-5d16-4b13-8add-a9edd7c8f311",
   "metadata": {},
   "source": [
    "# 3. PPO Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb597cfb-a0ba-4464-9632-f239b36891a1",
   "metadata": {},
   "source": [
    "## a. Fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775e85ba-22ec-4e3d-98f3-cc82dcced125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Fine tuning using Bayesian Optimization from optuna\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Sample hyperparameters from ranges ---\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2,log=True)\n",
    "    n_steps       = trial.suggest_int(\"n_steps\", 128, 2048, step=128)\n",
    "    gamma         = trial.suggest_float(\"gamma\", 0.90, 0.99, step=0.01)\n",
    "    ent_coef      = trial.suggest_float(\"ent_coef\", 1e-8, 0.1, log=True)\n",
    "    clip_range    = trial.suggest_float(\"clip_range\", 0.1, 0.4, step=0.05)\n",
    "\n",
    "    #Less important hyperparameters:\n",
    "    batch_size       = trial.suggest_categorical(\"batch_size\", [32,64])\n",
    "    gae_lambda       = trial.suggest_float(\"gae_lambda\", 0.8, 0.98)\n",
    "    n_epochs       = trial.suggest_int(\"n_epochs\", 5, 20)\n",
    "\n",
    "\n",
    "    # --- Create the environment ---\n",
    "    train_env = CustomStocksEnv(df=train_df, window_size=window_size, frame_bound=(window_size, len(train_df)))\n",
    "    val_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "    val_env = Monitor(val_env)\n",
    "\n",
    "    eval_callback_ft = EvalCallback(\n",
    "        val_env,\n",
    "        best_model_save_path='./logs/best_model_ft/',\n",
    "        log_path='./logs/results_ft/',\n",
    "        eval_freq=500,  # Evaluate every 500 timesteps.\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Build the PPO model\n",
    "    model = PPO( \n",
    "        policy=\"MlpPolicy\", \n",
    "        env=train_env, \n",
    "        verbose=0, \n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=batch_size,\n",
    "        gae_lambda=gae_lambda,\n",
    "        gamma=gamma,\n",
    "        n_epochs=n_epochs, \n",
    "        ent_coef=ent_coef,\n",
    "        clip_range=clip_range\n",
    "    )\n",
    "\n",
    "    #Keep it short - 50,000 steps also make sense\n",
    "    model.learn(total_timesteps=100_000, callback=eval_callback_ft)\n",
    "\n",
    "    model = PPO.load(\"./logs/best_model_ft/best_model.zip\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, val_env, n_eval_episodes=10, deterministic=False)\n",
    "\n",
    "    # Cleanup the environments\n",
    "    train_env.close()\n",
    "    val_env.close()\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "def run_optimization():\n",
    "    study = optuna.create_study(direction=\"maximize\")  \n",
    "    study.optimize(objective, n_trials=300)\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best value (objective):\", study.best_value)\n",
    "\n",
    "    return study\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e94868-7eba-4c34-b392-9f5404f0e22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-03 05:09:22,595] A new study created in memory with name: no-name-bf851207-ec5a-40ac-83e2-fb7588b7a062\n",
      "[I 2025-02-03 05:10:37,647] Trial 0 finished with value: 52.8174848 and parameters: {'learning_rate': 2.8120532392347434e-05, 'n_steps': 1024, 'gamma': 0.96, 'ent_coef': 1.863783370879267e-08, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9560105707026503, 'n_epochs': 14}. Best is trial 0 with value: 52.8174848.\n",
      "[I 2025-02-03 05:11:39,745] Trial 1 finished with value: 29.588680599999996 and parameters: {'learning_rate': 0.0007452181302411, 'n_steps': 1792, 'gamma': 0.97, 'ent_coef': 0.00012620637341360266, 'clip_range': 0.15000000000000002, 'batch_size': 64, 'gae_lambda': 0.8043218035307864, 'n_epochs': 9}. Best is trial 0 with value: 52.8174848.\n",
      "[I 2025-02-03 05:13:09,236] Trial 2 finished with value: 66.06046220000002 and parameters: {'learning_rate': 0.0004959920369242631, 'n_steps': 512, 'gamma': 0.96, 'ent_coef': 0.00020215087835153707, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9491571426344162, 'n_epochs': 13}. Best is trial 2 with value: 66.06046220000002.\n",
      "[I 2025-02-03 05:14:12,036] Trial 3 finished with value: 90.5516209 and parameters: {'learning_rate': 0.0019513992154087181, 'n_steps': 768, 'gamma': 0.96, 'ent_coef': 4.6152866642769675e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9733999997134015, 'n_epochs': 5}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:15:25,817] Trial 4 finished with value: 56.87091769999999 and parameters: {'learning_rate': 0.0008876333522562535, 'n_steps': 1408, 'gamma': 0.97, 'ent_coef': 0.032813857823428536, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9710138502149582, 'n_epochs': 15}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:16:47,420] Trial 5 finished with value: 39.9067247 and parameters: {'learning_rate': 4.232867025083702e-05, 'n_steps': 1408, 'gamma': 0.98, 'ent_coef': 3.9534016539738665e-08, 'clip_range': 0.1, 'batch_size': 64, 'gae_lambda': 0.8863004560807828, 'n_epochs': 19}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:18:03,109] Trial 6 finished with value: 57.6173166 and parameters: {'learning_rate': 0.004529843916406724, 'n_steps': 1664, 'gamma': 0.93, 'ent_coef': 0.07583302279732732, 'clip_range': 0.1, 'batch_size': 32, 'gae_lambda': 0.8912594557601929, 'n_epochs': 9}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:19:23,430] Trial 7 finished with value: 63.695956100000004 and parameters: {'learning_rate': 3.215824029172046e-05, 'n_steps': 1664, 'gamma': 0.92, 'ent_coef': 3.076901963097737e-05, 'clip_range': 0.15000000000000002, 'batch_size': 64, 'gae_lambda': 0.9401983234379745, 'n_epochs': 19}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:20:53,001] Trial 8 finished with value: 70.66552200000001 and parameters: {'learning_rate': 0.0035180777551623993, 'n_steps': 1024, 'gamma': 0.9, 'ent_coef': 0.05572305783490018, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8383400772743699, 'n_epochs': 13}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:22:16,095] Trial 9 finished with value: 53.23281519999999 and parameters: {'learning_rate': 3.576769581747061e-05, 'n_steps': 768, 'gamma': 0.97, 'ent_coef': 0.008443259712372805, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.9525685229717039, 'n_epochs': 11}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:23:20,803] Trial 10 finished with value: 82.721275 and parameters: {'learning_rate': 0.00012089987757350172, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 2.351271003861705e-06, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.9124601082444661, 'n_epochs': 5}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:24:25,423] Trial 11 finished with value: 78.23648599999999 and parameters: {'learning_rate': 0.00015430579657403493, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 1.4385098608292671e-06, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.9031579867702452, 'n_epochs': 5}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:25:29,460] Trial 12 finished with value: 50.1802491 and parameters: {'learning_rate': 0.0001491028570713255, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 2.4064459115573114e-06, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.9186547324654587, 'n_epochs': 5}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:26:44,442] Trial 13 finished with value: 89.1223764 and parameters: {'learning_rate': 0.009453506099012899, 'n_steps': 512, 'gamma': 0.9400000000000001, 'ent_coef': 1.5136960986799403e-06, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8572342658312779, 'n_epochs': 7}. Best is trial 3 with value: 90.5516209.\n",
      "[I 2025-02-03 05:27:57,503] Trial 14 finished with value: 99.2107645 and parameters: {'learning_rate': 0.00999444216216076, 'n_steps': 512, 'gamma': 0.9400000000000001, 'ent_coef': 2.2676036406045928e-07, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8630147767066377, 'n_epochs': 8}. Best is trial 14 with value: 99.2107645.\n",
      "[I 2025-02-03 05:29:11,008] Trial 15 finished with value: 84.80558810000001 and parameters: {'learning_rate': 0.0019583708846187048, 'n_steps': 640, 'gamma': 0.9500000000000001, 'ent_coef': 1.7128390103413556e-07, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8537290773276416, 'n_epochs': 8}. Best is trial 14 with value: 99.2107645.\n",
      "[I 2025-02-03 05:30:35,887] Trial 16 finished with value: 91.51800469999999 and parameters: {'learning_rate': 0.008316683790543837, 'n_steps': 768, 'gamma': 0.92, 'ent_coef': 0.0013215537067234706, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8739951052377891, 'n_epochs': 11}. Best is trial 14 with value: 99.2107645.\n",
      "[I 2025-02-03 05:32:15,478] Trial 17 finished with value: 99.2482012 and parameters: {'learning_rate': 0.009963864595679444, 'n_steps': 384, 'gamma': 0.91, 'ent_coef': 0.0010604840403453072, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8705342128425343, 'n_epochs': 16}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:33:56,137] Trial 18 finished with value: 44.454735899999996 and parameters: {'learning_rate': 1.0975360381466033e-05, 'n_steps': 384, 'gamma': 0.91, 'ent_coef': 0.0013158671528977958, 'clip_range': 0.2, 'batch_size': 32, 'gae_lambda': 0.8218978694736044, 'n_epochs': 16}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:35:40,621] Trial 19 finished with value: 84.6151595 and parameters: {'learning_rate': 0.003812067069951079, 'n_steps': 384, 'gamma': 0.9, 'ent_coef': 1.298972992097235e-05, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8653723457614901, 'n_epochs': 17}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:37:04,604] Trial 20 finished with value: 50.0288326 and parameters: {'learning_rate': 0.0016168493300310544, 'n_steps': 1280, 'gamma': 0.9400000000000001, 'ent_coef': 1.1108338446167878e-07, 'clip_range': 0.2, 'batch_size': 32, 'gae_lambda': 0.8387183037467548, 'n_epochs': 11}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:38:27,666] Trial 21 finished with value: 93.84244880000001 and parameters: {'learning_rate': 0.009365373752666764, 'n_steps': 896, 'gamma': 0.92, 'ent_coef': 0.0019197032916140396, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8737073961593689, 'n_epochs': 11}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:40:11,086] Trial 22 finished with value: 72.5647262 and parameters: {'learning_rate': 0.009950787103951898, 'n_steps': 896, 'gamma': 0.92, 'ent_coef': 0.0010683631402477651, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8792050186342681, 'n_epochs': 17}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:41:30,965] Trial 23 finished with value: 82.0721492 and parameters: {'learning_rate': 0.005012571550176154, 'n_steps': 384, 'gamma': 0.93, 'ent_coef': 0.003883778019887912, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8408700494306118, 'n_epochs': 10}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:42:39,625] Trial 24 finished with value: 62.71365270000001 and parameters: {'learning_rate': 0.005999148803063511, 'n_steps': 2048, 'gamma': 0.91, 'ent_coef': 0.00031930660493671107, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8991828896819428, 'n_epochs': 7}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:44:05,248] Trial 25 finished with value: 82.8532901 and parameters: {'learning_rate': 0.002605847311993154, 'n_steps': 1152, 'gamma': 0.93, 'ent_coef': 0.010454416447227942, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8675670633163242, 'n_epochs': 12}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:45:28,428] Trial 26 finished with value: 71.66218760000001 and parameters: {'learning_rate': 0.001055282764818865, 'n_steps': 640, 'gamma': 0.91, 'ent_coef': 8.242478539590089e-06, 'clip_range': 0.2, 'batch_size': 64, 'gae_lambda': 0.9252214780559993, 'n_epochs': 20}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:47:06,952] Trial 27 finished with value: 77.8378364 and parameters: {'learning_rate': 0.006101146589952368, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 4.4973104132000466e-07, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8519066666395052, 'n_epochs': 15}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:48:17,400] Trial 28 finished with value: 65.0296431 and parameters: {'learning_rate': 0.0003296269460388207, 'n_steps': 512, 'gamma': 0.92, 'ent_coef': 0.0004143442131674331, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.8173362767953533, 'n_epochs': 7}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:49:28,805] Trial 29 finished with value: 73.6409618 and parameters: {'learning_rate': 0.0028822666279226415, 'n_steps': 896, 'gamma': 0.9500000000000001, 'ent_coef': 7.553932717873983e-05, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.888453494590796, 'n_epochs': 14}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:50:44,421] Trial 30 finished with value: 79.7178867 and parameters: {'learning_rate': 0.0012392097386838383, 'n_steps': 1152, 'gamma': 0.9, 'ent_coef': 1.2482667076710632e-08, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8254834288808932, 'n_epochs': 9}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:52:07,625] Trial 31 finished with value: 76.74465599999999 and parameters: {'learning_rate': 0.008104010578932173, 'n_steps': 768, 'gamma': 0.92, 'ent_coef': 0.002254760169450408, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8713731260926418, 'n_epochs': 11}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:53:34,349] Trial 32 finished with value: 84.8742247 and parameters: {'learning_rate': 0.0069978909187592715, 'n_steps': 896, 'gamma': 0.91, 'ent_coef': 0.0007428356400089088, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8774953235334187, 'n_epochs': 12}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:54:54,464] Trial 33 finished with value: 76.19051060000001 and parameters: {'learning_rate': 0.009877253560890269, 'n_steps': 640, 'gamma': 0.93, 'ent_coef': 0.016422606043885474, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8578930413551151, 'n_epochs': 10}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:56:29,811] Trial 34 finished with value: 81.70099830000001 and parameters: {'learning_rate': 0.005037553616833421, 'n_steps': 256, 'gamma': 0.92, 'ent_coef': 0.00014748376087662883, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8994359566191381, 'n_epochs': 14}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:57:34,456] Trial 35 finished with value: 49.327606200000005 and parameters: {'learning_rate': 0.0005921106148627136, 'n_steps': 768, 'gamma': 0.91, 'ent_coef': 0.0035295577352954803, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.846285842338484, 'n_epochs': 10}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 05:58:48,736] Trial 36 finished with value: 68.50102619999998 and parameters: {'learning_rate': 0.0025817438602519023, 'n_steps': 512, 'gamma': 0.9500000000000001, 'ent_coef': 0.00047036941174979956, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8011685197116487, 'n_epochs': 8}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 06:00:18,338] Trial 37 finished with value: 64.34737080000001 and parameters: {'learning_rate': 0.006579151974347798, 'n_steps': 1024, 'gamma': 0.93, 'ent_coef': 1.9024041466668267e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8764185677824855, 'n_epochs': 13}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 06:01:32,340] Trial 38 finished with value: 63.809945600000006 and parameters: {'learning_rate': 0.00414283426018634, 'n_steps': 640, 'gamma': 0.96, 'ent_coef': 9.903172309369627e-05, 'clip_range': 0.25, 'batch_size': 64, 'gae_lambda': 0.8866184122927656, 'n_epochs': 15}. Best is trial 17 with value: 99.2482012.\n",
      "[I 2025-02-03 06:03:00,640] Trial 39 finished with value: 104.30111380000001 and parameters: {'learning_rate': 0.0015857499194644805, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.005936265348171829, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8640299066558694, 'n_epochs': 12}. Best is trial 39 with value: 104.30111380000001.\n",
      "[I 2025-02-03 06:04:21,561] Trial 40 finished with value: 87.3765469 and parameters: {'learning_rate': 0.0018737914098041352, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.02093554941567401, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.8619751588720289, 'n_epochs': 18}. Best is trial 39 with value: 104.30111380000001.\n",
      "[I 2025-02-03 06:05:49,119] Trial 41 finished with value: 92.76596989999999 and parameters: {'learning_rate': 0.0033880876544932267, 'n_steps': 384, 'gamma': 0.92, 'ent_coef': 0.006139636169263088, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8719732754487579, 'n_epochs': 12}. Best is trial 39 with value: 104.30111380000001.\n",
      "[I 2025-02-03 06:07:19,581] Trial 42 finished with value: 87.1108195 and parameters: {'learning_rate': 0.0037544891311385767, 'n_steps': 384, 'gamma': 0.93, 'ent_coef': 0.0057301156516086135, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8328958181770542, 'n_epochs': 13}. Best is trial 39 with value: 104.30111380000001.\n",
      "[I 2025-02-03 06:08:48,259] Trial 43 finished with value: 60.61434929999999 and parameters: {'learning_rate': 0.002661670129163667, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.0468521973691113, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8842538125346268, 'n_epochs': 12}. Best is trial 39 with value: 104.30111380000001.\n",
      "[I 2025-02-03 06:10:21,383] Trial 44 finished with value: 108.41462770000001 and parameters: {'learning_rate': 0.005330648597957834, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 0.0022509839075321855, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8665178668576276, 'n_epochs': 14}. Best is trial 44 with value: 108.41462770000001.\n",
      "[I 2025-02-03 06:11:57,605] Trial 45 finished with value: 85.945015 and parameters: {'learning_rate': 0.005619937479025732, 'n_steps': 512, 'gamma': 0.96, 'ent_coef': 0.0027223516804059855, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8460079944352915, 'n_epochs': 15}. Best is trial 44 with value: 108.41462770000001.\n",
      "[I 2025-02-03 06:13:40,719] Trial 46 finished with value: 108.5218999 and parameters: {'learning_rate': 0.0007247362400157931, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.0002157313124265443, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8938328818503785, 'n_epochs': 16}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:15:22,662] Trial 47 finished with value: 107.1694694 and parameters: {'learning_rate': 0.0004090225314892523, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 5.037984136439209e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8940263671535805, 'n_epochs': 16}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:17:04,397] Trial 48 finished with value: 77.544252 and parameters: {'learning_rate': 0.00036045348695340956, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.0002539213614138212, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9350379504811006, 'n_epochs': 16}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:18:45,373] Trial 49 finished with value: 93.1937121 and parameters: {'learning_rate': 0.00024006958698365947, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 0.0006210514366083308, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9068584842452788, 'n_epochs': 16}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:20:31,534] Trial 50 finished with value: 105.7766674 and parameters: {'learning_rate': 0.0006880192711800731, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 4.721625893496202e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9174252714342913, 'n_epochs': 17}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:22:16,740] Trial 51 finished with value: 98.2239877 and parameters: {'learning_rate': 0.0006905313767511323, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 6.009724209497593e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8943731075107305, 'n_epochs': 17}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:23:51,981] Trial 52 finished with value: 81.20448719999999 and parameters: {'learning_rate': 0.0004478982254162948, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 3.0827766704160956e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9662001805630449, 'n_epochs': 14}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:25:40,529] Trial 53 finished with value: 79.16269700000001 and parameters: {'learning_rate': 0.0013441887366497634, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 6.628456173804468e-06, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9177033210193469, 'n_epochs': 18}. Best is trial 46 with value: 108.5218999.\n",
      "[I 2025-02-03 06:27:28,860] Trial 54 finished with value: 110.27464769999999 and parameters: {'learning_rate': 0.0008440488841294522, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.00016881303687629366, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9101110248233725, 'n_epochs': 18}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:29:17,428] Trial 55 finished with value: 94.6072781 and parameters: {'learning_rate': 0.0009215813553059425, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 4.064063191854092e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9093402650214285, 'n_epochs': 18}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:31:10,346] Trial 56 finished with value: 91.27456509999999 and parameters: {'learning_rate': 0.00023856884999823657, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00017240742360124785, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9247007683079694, 'n_epochs': 19}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:33:06,391] Trial 57 finished with value: 97.0946662 and parameters: {'learning_rate': 0.000541063482221977, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 1.7192620621455534e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8944315009211763, 'n_epochs': 20}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:34:56,879] Trial 58 finished with value: 68.85746689999999 and parameters: {'learning_rate': 9.232896307314031e-05, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 0.00013558004845430394, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9358756464254799, 'n_epochs': 19}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:36:15,365] Trial 59 finished with value: 94.6930251 and parameters: {'learning_rate': 0.0008059988258620021, 'n_steps': 384, 'gamma': 0.96, 'ent_coef': 3.611527552194515e-06, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9031030315333348, 'n_epochs': 17}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:37:53,595] Trial 60 finished with value: 108.86996730000001 and parameters: {'learning_rate': 0.0004222432297584129, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00024008661052592764, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9159053079041433, 'n_epochs': 15}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:39:32,586] Trial 61 finished with value: 87.5206839 and parameters: {'learning_rate': 0.00027198210560777636, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00022534206214411043, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9243203054778614, 'n_epochs': 15}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:41:13,614] Trial 62 finished with value: 95.05663039999999 and parameters: {'learning_rate': 0.00043596342416495835, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 7.75965185768249e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.916515452496607, 'n_epochs': 16}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:42:48,962] Trial 63 finished with value: 51.729767200000005 and parameters: {'learning_rate': 0.00019321891606905733, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 5.2309399110338606e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9451680748744927, 'n_epochs': 14}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:44:33,653] Trial 64 finished with value: 93.18929290000001 and parameters: {'learning_rate': 0.000615813867814353, 'n_steps': 384, 'gamma': 0.99, 'ent_coef': 2.4764349638830206e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.915002250904549, 'n_epochs': 17}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:46:13,839] Trial 65 finished with value: 80.9576566 and parameters: {'learning_rate': 0.0010595021504758075, 'n_steps': 512, 'gamma': 0.99, 'ent_coef': 0.0007938284330585188, 'clip_range': 0.1, 'batch_size': 32, 'gae_lambda': 0.9060372285260926, 'n_epochs': 16}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:47:44,584] Trial 66 finished with value: 91.0050308 and parameters: {'learning_rate': 0.0003869940751606737, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 0.00034199219392542, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8822261101394204, 'n_epochs': 13}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:49:22,947] Trial 67 finished with value: 82.5203884 and parameters: {'learning_rate': 0.001555091887973426, 'n_steps': 1536, 'gamma': 0.98, 'ent_coef': 0.0018705630456076602, 'clip_range': 0.15000000000000002, 'batch_size': 32, 'gae_lambda': 0.893127236115327, 'n_epochs': 15}. Best is trial 54 with value: 110.27464769999999.\n",
      "[I 2025-02-03 06:51:12,990] Trial 68 finished with value: 111.4069559 and parameters: {'learning_rate': 0.000787263622769742, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 0.011697145534919752, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9283682946222443, 'n_epochs': 18}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 06:53:01,361] Trial 69 finished with value: 90.0857609 and parameters: {'learning_rate': 8.423173025732838e-05, 'n_steps': 128, 'gamma': 0.93, 'ent_coef': 0.01640960727653701, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9329833656785836, 'n_epochs': 18}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 06:54:46,030] Trial 70 finished with value: 68.5839189 and parameters: {'learning_rate': 0.000774383368790639, 'n_steps': 1920, 'gamma': 0.93, 'ent_coef': 0.00012371317639953632, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9292648109831548, 'n_epochs': 17}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 06:56:34,769] Trial 71 finished with value: 61.7028385 and parameters: {'learning_rate': 0.0005151967526088627, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.004612799612002902, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9121019999652575, 'n_epochs': 18}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 06:58:13,367] Trial 72 finished with value: 88.89727440000001 and parameters: {'learning_rate': 0.0010133284940169352, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.008323032260129407, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9009520145189107, 'n_epochs': 15}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:00:00,155] Trial 73 finished with value: 61.794971200000006 and parameters: {'learning_rate': 0.0007254001266984555, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.027455129175543463, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9216205731749991, 'n_epochs': 17}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:01:42,452] Trial 74 finished with value: 72.3513287 and parameters: {'learning_rate': 0.0014197908228223118, 'n_steps': 384, 'gamma': 0.93, 'ent_coef': 0.009733270878043319, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9107941118070456, 'n_epochs': 16}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:03:35,933] Trial 75 finished with value: 98.6572107 and parameters: {'learning_rate': 0.0019604803642138046, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 9.39581527902798e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9467769803793611, 'n_epochs': 19}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:04:51,328] Trial 76 finished with value: 85.4563874 and parameters: {'learning_rate': 0.0006208039286440102, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.0013951642760905135, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9553673553222103, 'n_epochs': 14}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:06:42,612] Trial 77 finished with value: 97.78448139999999 and parameters: {'learning_rate': 0.0012380625559803647, 'n_steps': 512, 'gamma': 0.9400000000000001, 'ent_coef': 0.04603624535201793, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8967137351803101, 'n_epochs': 19}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:08:24,035] Trial 78 finished with value: 91.0040573 and parameters: {'learning_rate': 0.000298534653143019, 'n_steps': 384, 'gamma': 0.97, 'ent_coef': 0.0005666713389131299, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8889556645498983, 'n_epochs': 16}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:10:02,698] Trial 79 finished with value: 81.1270633 and parameters: {'learning_rate': 0.00043427551124816725, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 8.351856663684227e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9381422892418019, 'n_epochs': 15}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:11:51,118] Trial 80 finished with value: 48.6618428 and parameters: {'learning_rate': 1.1153020355373269e-05, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.00037299836589371147, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9292067653511764, 'n_epochs': 18}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:13:35,905] Trial 81 finished with value: 67.5941197 and parameters: {'learning_rate': 0.0008903528612012888, 'n_steps': 384, 'gamma': 0.9, 'ent_coef': 0.0009388620270026304, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8686258375600767, 'n_epochs': 17}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:15:16,340] Trial 82 finished with value: 98.25769009999999 and parameters: {'learning_rate': 0.0011307059093252699, 'n_steps': 512, 'gamma': 0.9400000000000001, 'ent_coef': 0.08868418328306103, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8803797016639022, 'n_epochs': 16}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:16:52,799] Trial 83 finished with value: 89.63887299999999 and parameters: {'learning_rate': 0.007921288861195204, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.0002216319073638046, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8630969402422884, 'n_epochs': 14}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:18:40,796] Trial 84 finished with value: 95.825839 and parameters: {'learning_rate': 0.0004825935995606158, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 0.0027210556326334383, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.855206518557909, 'n_epochs': 17}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:20:37,913] Trial 85 finished with value: 68.943895 and parameters: {'learning_rate': 0.002139371981269609, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.0013662634392141446, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.9054308205484288, 'n_epochs': 20}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:22:18,964] Trial 86 finished with value: 92.56451709999999 and parameters: {'learning_rate': 0.0006444808110866564, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 5.0702837677833637e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.859225863369349, 'n_epochs': 16}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:23:57,015] Trial 87 finished with value: 56.87394830000001 and parameters: {'learning_rate': 0.0003639278599138951, 'n_steps': 640, 'gamma': 0.97, 'ent_coef': 0.015104130321939177, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8488692674528188, 'n_epochs': 15}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:25:05,914] Trial 88 finished with value: 87.05285549999999 and parameters: {'learning_rate': 0.00016335328579406683, 'n_steps': 1280, 'gamma': 0.9500000000000001, 'ent_coef': 0.00010715270081919104, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9205790323644589, 'n_epochs': 12}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:26:55,479] Trial 89 finished with value: 81.600644 and parameters: {'learning_rate': 0.0032356133384082, 'n_steps': 384, 'gamma': 0.91, 'ent_coef': 3.566090545666257e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8851577021205715, 'n_epochs': 18}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:28:28,294] Trial 90 finished with value: 90.2670173 and parameters: {'learning_rate': 0.0008071600750434704, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.00688571557208453, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.874768992744137, 'n_epochs': 13}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:29:39,781] Trial 91 finished with value: 94.03768729999999 and parameters: {'learning_rate': 0.004665452113922394, 'n_steps': 512, 'gamma': 0.9400000000000001, 'ent_coef': 7.392805710809286e-08, 'clip_range': 0.2, 'batch_size': 32, 'gae_lambda': 0.8714309149735325, 'n_epochs': 7}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:30:48,940] Trial 92 finished with value: 76.5033244 and parameters: {'learning_rate': 0.007977971231633827, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 3.1727018724524636e-08, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8631354884438107, 'n_epochs': 6}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:32:04,864] Trial 93 finished with value: 71.85336629999999 and parameters: {'learning_rate': 0.005816112219806867, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 2.1289830973991418e-07, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.8906449880872156, 'n_epochs': 8}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:33:46,088] Trial 94 finished with value: 86.51641670000001 and parameters: {'learning_rate': 0.006726530248275367, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 0.003577613345096167, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.850870748515479, 'n_epochs': 16}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:35:03,714] Trial 95 finished with value: 92.48546780000001 and parameters: {'learning_rate': 0.009043747221156273, 'n_steps': 512, 'gamma': 0.92, 'ent_coef': 1.133885804125152e-06, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8651840719168917, 'n_epochs': 9}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:36:12,591] Trial 96 finished with value: 62.569792099999994 and parameters: {'learning_rate': 0.0005507656778997298, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.00027291839644877835, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8977963324188208, 'n_epochs': 6}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:37:34,872] Trial 97 finished with value: 84.87253729999999 and parameters: {'learning_rate': 0.0008898930861714101, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.00017434182237813665, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9416438837212605, 'n_epochs': 10}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:39:21,081] Trial 98 finished with value: 69.9867595 and parameters: {'learning_rate': 0.0022896906123880787, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 2.058619546465213e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.841949540269663, 'n_epochs': 17}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:40:34,994] Trial 99 finished with value: 72.068654 and parameters: {'learning_rate': 0.007194487695316363, 'n_steps': 640, 'gamma': 0.96, 'ent_coef': 0.0004764545450748207, 'clip_range': 0.25, 'batch_size': 64, 'gae_lambda': 0.8774268510220887, 'n_epochs': 15}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:42:10,563] Trial 100 finished with value: 86.10809900000001 and parameters: {'learning_rate': 0.004223494526717871, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 1.2382563268788182e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9146869864955715, 'n_epochs': 14}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:43:59,677] Trial 101 finished with value: 89.180212 and parameters: {'learning_rate': 0.0019188583729325152, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 8.267942662127185e-07, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9300125535322948, 'n_epochs': 18}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:45:53,063] Trial 102 finished with value: 86.4274564 and parameters: {'learning_rate': 0.0016319158557261129, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 4.925349766825848e-07, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.9724828147590965, 'n_epochs': 19}. Best is trial 68 with value: 111.4069559.\n",
      "[I 2025-02-03 07:47:45,964] Trial 103 finished with value: 120.2537948 and parameters: {'learning_rate': 0.0007298100298214147, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 7.21321235424911e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8672255304849467, 'n_epochs': 19}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 07:49:34,073] Trial 104 finished with value: 93.8854167 and parameters: {'learning_rate': 0.00031302588778533725, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 5.835459019380501e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8592386640838697, 'n_epochs': 18}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 07:51:27,209] Trial 105 finished with value: 68.6539097 and parameters: {'learning_rate': 0.000706667140358026, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 8.224312968900523e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8706420152611652, 'n_epochs': 19}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 07:53:18,053] Trial 106 finished with value: 83.1316032 and parameters: {'learning_rate': 0.009969538157653572, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 2.7909388139957234e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8676328196116789, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 07:55:14,921] Trial 107 finished with value: 81.1620132 and parameters: {'learning_rate': 0.0005169067978211434, 'n_steps': 128, 'gamma': 0.91, 'ent_coef': 0.0018350281503010165, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8555695400334001, 'n_epochs': 20}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 07:56:58,880] Trial 108 finished with value: 106.54212600000001 and parameters: {'learning_rate': 0.0004207465662713652, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00018980380202960896, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8817933233780266, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 07:58:43,329] Trial 109 finished with value: 66.60951960000001 and parameters: {'learning_rate': 0.00022009844708039168, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00015583631707963584, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8830516026370818, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:00:27,015] Trial 110 finished with value: 86.036062 and parameters: {'learning_rate': 0.00039290570318471703, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.0006258487935082805, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9015035660945112, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:02:07,222] Trial 111 finished with value: 78.80728269999999 and parameters: {'learning_rate': 0.00043125632046702334, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.0003123052533906136, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.878994263015681, 'n_epochs': 15}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:03:53,591] Trial 112 finished with value: 72.75183640000002 and parameters: {'learning_rate': 0.0006195776178454883, 'n_steps': 384, 'gamma': 0.96, 'ent_coef': 3.9793410984866456e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8751849189498855, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:05:37,240] Trial 113 finished with value: 108.92299779999999 and parameters: {'learning_rate': 0.0009813715272535524, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.0001238132902706011, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8879698251985079, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:07:21,388] Trial 114 finished with value: 90.63738959999999 and parameters: {'learning_rate': 0.0011113810694600276, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00011373326108196132, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9086135857694332, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:09:00,801] Trial 115 finished with value: 98.488873 and parameters: {'learning_rate': 0.0009380538939388298, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 7.687394694586704e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8876438808709485, 'n_epochs': 15}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:10:48,144] Trial 116 finished with value: 84.21245619999999 and parameters: {'learning_rate': 0.0007989746502598727, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.0002256927988089582, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9211056806150872, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:12:31,116] Trial 117 finished with value: 88.219212 and parameters: {'learning_rate': 0.001328066015737667, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.0010766148765268349, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8927475969392129, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:14:19,621] Trial 118 finished with value: 66.893817 and parameters: {'learning_rate': 0.0004923094512510254, 'n_steps': 1664, 'gamma': 0.9, 'ent_coef': 0.0001490460703928234, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8827114709079164, 'n_epochs': 18}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:15:37,217] Trial 119 finished with value: 73.0899909 and parameters: {'learning_rate': 0.0006906676567708222, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 0.00439282811085266, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9039110284969755, 'n_epochs': 15}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:17:11,475] Trial 120 finished with value: 96.90167879999998 and parameters: {'learning_rate': 0.0005669276775725718, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.013763930785031804, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.913783981091813, 'n_epochs': 13}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:18:56,982] Trial 121 finished with value: 67.6754959 and parameters: {'learning_rate': 0.00033240648738258637, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 0.00011104381918436683, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8662853020087552, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:20:42,538] Trial 122 finished with value: 68.9429199 and parameters: {'learning_rate': 0.00027488655688752715, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 6.245815137012911e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8605032613284788, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:22:24,682] Trial 123 finished with value: 103.0243381 and parameters: {'learning_rate': 0.0051011139665658786, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 3.924252155706255e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8731909349492849, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:24:06,040] Trial 124 finished with value: 103.5264804 and parameters: {'learning_rate': 0.0009896793362946968, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 0.00043719137499812914, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8732675951584522, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:25:48,959] Trial 125 finished with value: 104.26006939999999 and parameters: {'learning_rate': 0.0007960211892101494, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 6.280042479499252e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8737987094212725, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:27:25,864] Trial 126 finished with value: 58.885381599999995 and parameters: {'learning_rate': 0.001005800196460513, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00043447881908041566, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8865418935654124, 'n_epochs': 14}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:29:05,780] Trial 127 finished with value: 96.4050639 and parameters: {'learning_rate': 0.0012014894305577303, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.000242415352030339, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8789259533418958, 'n_epochs': 15}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:30:53,872] Trial 128 finished with value: 106.2657103 and parameters: {'learning_rate': 0.0015238750892104832, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 0.00017357725876069002, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8911271452235987, 'n_epochs': 18}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:32:47,288] Trial 129 finished with value: 88.6843954 and parameters: {'learning_rate': 0.0014818361849828902, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 1.4013288700900474e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8949847516595995, 'n_epochs': 19}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:34:37,548] Trial 130 finished with value: 71.45114650000002 and parameters: {'learning_rate': 0.0007889813839793461, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 0.02842938655956834, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8914463698628257, 'n_epochs': 18}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:36:24,402] Trial 131 finished with value: 89.52870440000001 and parameters: {'learning_rate': 0.0016678899568875487, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.0001931354767740073, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9250898343219086, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:38:14,185] Trial 132 finished with value: 63.9924227 and parameters: {'learning_rate': 0.000940623396905937, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 4.514333833845801e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8994426738463215, 'n_epochs': 18}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:40:01,929] Trial 133 finished with value: 97.095395 and parameters: {'learning_rate': 0.0006928462240106043, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.00010377151368758568, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9176828571618197, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:41:45,649] Trial 134 finished with value: 95.8154289 and parameters: {'learning_rate': 0.0008351523550321862, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 0.00014515242440081913, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8896009060523953, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:43:28,571] Trial 135 finished with value: 99.26564440000001 and parameters: {'learning_rate': 0.0010639141014874222, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 3.1035596594516644e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8824119438766994, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:44:57,624] Trial 136 finished with value: 88.80731149999998 and parameters: {'learning_rate': 0.0012786391677193937, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.0003147674874423449, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9107124077491765, 'n_epochs': 12}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:46:23,439] Trial 137 finished with value: 93.3120987 and parameters: {'learning_rate': 0.000605122048733568, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 6.51962930453105e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8745070277213525, 'n_epochs': 11}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:48:16,122] Trial 138 finished with value: 58.7933213 and parameters: {'learning_rate': 0.000404940898488681, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00018934312040772293, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8693931808285352, 'n_epochs': 19}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:49:57,655] Trial 139 finished with value: 96.8024017 and parameters: {'learning_rate': 0.0005166620434219693, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.0007584287268008044, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8965930431671487, 'n_epochs': 15}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:51:43,062] Trial 140 finished with value: 88.22619549999999 and parameters: {'learning_rate': 0.0009036483410601159, 'n_steps': 384, 'gamma': 0.93, 'ent_coef': 0.010442813649158585, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8801810460663697, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:53:24,718] Trial 141 finished with value: 87.46656180000001 and parameters: {'learning_rate': 0.0007220568917794432, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 2.168768680653626e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8739867003106023, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:55:06,293] Trial 142 finished with value: 83.5518227 and parameters: {'learning_rate': 0.0011081897128644455, 'n_steps': 512, 'gamma': 0.9500000000000001, 'ent_coef': 4.125820547009766e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8670110070021533, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:56:52,309] Trial 143 finished with value: 65.56025809999998 and parameters: {'learning_rate': 0.0006409347306437858, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 4.953071703579881e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8723808087427755, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 08:58:43,136] Trial 144 finished with value: 101.7649031 and parameters: {'learning_rate': 0.0004747959198377393, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 2.1928181662239e-06, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8637139824999208, 'n_epochs': 18}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 09:00:21,951] Trial 145 finished with value: 88.77277489999999 and parameters: {'learning_rate': 0.005352314933812796, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 2.129684625467663e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8856286144622239, 'n_epochs': 15}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 09:01:41,239] Trial 146 finished with value: 72.2170318 and parameters: {'learning_rate': 0.002972820640735396, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 5.91995864381719e-06, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.8710981381338379, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 09:03:23,187] Trial 147 finished with value: 114.6805844 and parameters: {'learning_rate': 0.0005671281315380626, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 2.9993119401864687e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9280972112528887, 'n_epochs': 16}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 09:05:10,401] Trial 148 finished with value: 84.9374847 and parameters: {'learning_rate': 0.0005512896357491341, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 8.99356847089842e-05, 'clip_range': 0.15000000000000002, 'batch_size': 32, 'gae_lambda': 0.9264193508101927, 'n_epochs': 17}. Best is trial 103 with value: 120.2537948.\n",
      "[I 2025-02-03 09:07:02,475] Trial 149 finished with value: 120.9218599 and parameters: {'learning_rate': 0.0007826578697168138, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.000343537780202953, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9316868937844326, 'n_epochs': 18}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:08:53,268] Trial 150 finished with value: 69.917626 and parameters: {'learning_rate': 0.00033898394925695283, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.00013583666058428917, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9334382397613679, 'n_epochs': 18}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:10:42,737] Trial 151 finished with value: 100.8282887 and parameters: {'learning_rate': 0.0007749951803405371, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.00039987652160262374, 'clip_range': 0.1, 'batch_size': 32, 'gae_lambda': 0.9396774119251999, 'n_epochs': 18}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:12:35,999] Trial 152 finished with value: 100.4160434 and parameters: {'learning_rate': 0.0009671501822599922, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.00047109485355694775, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9289115371018342, 'n_epochs': 19}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:14:23,958] Trial 153 finished with value: 99.3749563 and parameters: {'learning_rate': 0.0006709265624272015, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.00028794775508213515, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9226840041984986, 'n_epochs': 17}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:16:05,516] Trial 154 finished with value: 70.09870729999999 and parameters: {'learning_rate': 0.0008613030973799637, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 0.00019074177803512078, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9327360301347413, 'n_epochs': 15}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:17:48,994] Trial 155 finished with value: 97.90191209999999 and parameters: {'learning_rate': 0.0004555074772096802, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 8.242890582954288e-06, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9185546889405319, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:19:39,173] Trial 156 finished with value: 95.0631087 and parameters: {'learning_rate': 0.0006028575476508403, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.00640094287752714, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9268063273824598, 'n_epochs': 18}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:21:24,427] Trial 157 finished with value: 85.25726230000001 and parameters: {'learning_rate': 0.0007478462508940693, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 5.9553898664468386e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9074252609094899, 'n_epochs': 17}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:23:08,587] Trial 158 finished with value: 85.7167845 and parameters: {'learning_rate': 0.0013728520299749738, 'n_steps': 256, 'gamma': 0.97, 'ent_coef': 4.079753417500347e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8780637639203039, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:25:01,103] Trial 159 finished with value: 75.82161289999999 and parameters: {'learning_rate': 0.0003802445728260311, 'n_steps': 384, 'gamma': 0.9400000000000001, 'ent_coef': 0.00010618795856552352, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9369798744755421, 'n_epochs': 19}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:26:44,842] Trial 160 finished with value: 100.1088258 and parameters: {'learning_rate': 0.0005358239217284874, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.0026461380725889584, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9429688160348857, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:28:26,746] Trial 161 finished with value: 78.3711501 and parameters: {'learning_rate': 0.0017490623374104546, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 2.710511897287615e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8759455205756216, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:30:09,235] Trial 162 finished with value: 99.4487892 and parameters: {'learning_rate': 0.0011883530307742886, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 1.427861813235661e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8847675850770658, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:31:48,032] Trial 163 finished with value: 73.0374021 and parameters: {'learning_rate': 0.003829461568903396, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 1.1280624356753554e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8913859203454007, 'n_epochs': 15}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:33:27,340] Trial 164 finished with value: 83.09181370000002 and parameters: {'learning_rate': 0.00242488750477567, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.0002468578327774745, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8679759024043289, 'n_epochs': 15}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:35:09,178] Trial 165 finished with value: 84.3637409 and parameters: {'learning_rate': 0.0008619126446905679, 'n_steps': 384, 'gamma': 0.9500000000000001, 'ent_coef': 0.00013049103561229523, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8642492050989907, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:36:56,318] Trial 166 finished with value: 55.4349304 and parameters: {'learning_rate': 5.072216374253717e-05, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 2.8771274917294883e-06, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9314084348217015, 'n_epochs': 17}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:38:43,938] Trial 167 finished with value: 44.8924121 and parameters: {'learning_rate': 0.0006779264700467766, 'n_steps': 512, 'gamma': 0.9400000000000001, 'ent_coef': 8.056233772567953e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9497795678242165, 'n_epochs': 18}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:40:20,738] Trial 168 finished with value: 85.613701 and parameters: {'learning_rate': 0.0010158365948052816, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.0003643332787654254, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8603448524291685, 'n_epochs': 14}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:41:37,936] Trial 169 finished with value: 103.0586812 and parameters: {'learning_rate': 0.0007684224656672547, 'n_steps': 1152, 'gamma': 0.96, 'ent_coef': 3.8191023994824e-06, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9129872988949094, 'n_epochs': 17}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:43:02,722] Trial 170 finished with value: 76.99099290000001 and parameters: {'learning_rate': 0.0005756673109845623, 'n_steps': 1152, 'gamma': 0.96, 'ent_coef': 0.0007060394051659315, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9121047714871936, 'n_epochs': 20}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:44:21,738] Trial 171 finished with value: 80.7836922 and parameters: {'learning_rate': 0.0007645551805544376, 'n_steps': 1280, 'gamma': 0.96, 'ent_coef': 6.289067227028621e-06, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9171834905677295, 'n_epochs': 17}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:45:41,769] Trial 172 finished with value: 55.4384397 and parameters: {'learning_rate': 0.0004290774980385003, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 4.805958069226473e-06, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9633437066209631, 'n_epochs': 17}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:46:57,415] Trial 173 finished with value: 86.3701045 and parameters: {'learning_rate': 0.0009194509693969509, 'n_steps': 1152, 'gamma': 0.9500000000000001, 'ent_coef': 1.1063980261818594e-06, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9004303247813904, 'n_epochs': 16}. Best is trial 149 with value: 120.9218599.\n",
      "[I 2025-02-03 09:48:20,578] Trial 174 finished with value: 127.03462019999999 and parameters: {'learning_rate': 0.0006538850472453465, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 0.020686964806400542, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9213441132019706, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:49:40,618] Trial 175 finished with value: 91.8064284 and parameters: {'learning_rate': 0.0006373347263039438, 'n_steps': 1152, 'gamma': 0.97, 'ent_coef': 0.02058962941918159, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9208395285186676, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:51:02,606] Trial 176 finished with value: 48.746033499999996 and parameters: {'learning_rate': 0.00048194185341621465, 'n_steps': 1280, 'gamma': 0.98, 'ent_coef': 0.06339262444892674, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9145918134161328, 'n_epochs': 19}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:52:25,019] Trial 177 finished with value: 66.9003582 and parameters: {'learning_rate': 0.0008052171407674028, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.03777443224765958, 'clip_range': 0.2, 'batch_size': 64, 'gae_lambda': 0.9263418326096109, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:53:31,744] Trial 178 finished with value: 73.16720799999999 and parameters: {'learning_rate': 0.0007221509918357745, 'n_steps': 1024, 'gamma': 0.97, 'ent_coef': 0.010647368844251947, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9230535092205729, 'n_epochs': 11}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:54:43,503] Trial 179 finished with value: 90.72784759999999 and parameters: {'learning_rate': 0.0010183921785164968, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 0.02340321779634247, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.9096560687789107, 'n_epochs': 12}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:56:04,728] Trial 180 finished with value: 60.728310799999996 and parameters: {'learning_rate': 0.0005341472414113888, 'n_steps': 1408, 'gamma': 0.96, 'ent_coef': 0.013044779399851813, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.9029112747870355, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:57:50,480] Trial 181 finished with value: 60.81880520000001 and parameters: {'learning_rate': 0.0006279690817258479, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 1.597473250348399e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9191538669274443, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 09:59:30,346] Trial 182 finished with value: 95.3810688 and parameters: {'learning_rate': 0.0008927134998314314, 'n_steps': 1024, 'gamma': 0.9500000000000001, 'ent_coef': 0.00015621769535352457, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8716450502171763, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:01:14,269] Trial 183 finished with value: 92.83840749999999 and parameters: {'learning_rate': 0.00475974420196218, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 3.004675846075821e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8882491496594724, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:02:57,618] Trial 184 finished with value: 71.69927040000002 and parameters: {'learning_rate': 0.0011351714190254924, 'n_steps': 2048, 'gamma': 0.9500000000000001, 'ent_coef': 3.8707894155176545e-06, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8945365722183352, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:04:48,316] Trial 185 finished with value: 111.0702022 and parameters: {'learning_rate': 0.0007134912319745983, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.00021126902182646483, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8093895270044248, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:06:41,047] Trial 186 finished with value: 89.8040142 and parameters: {'learning_rate': 0.0007391040119406198, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.0002839142792895499, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9288364160257383, 'n_epochs': 19}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:08:31,104] Trial 187 finished with value: 93.8830865 and parameters: {'learning_rate': 0.0005822681404714893, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.00020876126118697446, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8308033006519168, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:10:20,803] Trial 188 finished with value: 82.1722829 and parameters: {'learning_rate': 0.0008153734980472399, 'n_steps': 128, 'gamma': 0.97, 'ent_coef': 0.0004712136383156284, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9239576474420128, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:12:10,062] Trial 189 finished with value: 99.0025017 and parameters: {'learning_rate': 0.0004784971914390579, 'n_steps': 128, 'gamma': 0.96, 'ent_coef': 0.004977039904367689, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8157808213221056, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:14:03,501] Trial 190 finished with value: 101.6010471 and parameters: {'learning_rate': 0.0006825754346978261, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 4.9054011893144674e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8234580811453358, 'n_epochs': 19}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:15:48,845] Trial 191 finished with value: 103.13093390000002 and parameters: {'learning_rate': 0.0003883294276542177, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.00017715787661671018, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8051292996244566, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:17:35,843] Trial 192 finished with value: 52.712516400000005 and parameters: {'learning_rate': 0.0004062503259275498, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 0.00017770667343533999, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8131288797554381, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:19:25,829] Trial 193 finished with value: 95.73317220000001 and parameters: {'learning_rate': 0.00029225607443514616, 'n_steps': 256, 'gamma': 0.9400000000000001, 'ent_coef': 0.00010797732945497877, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9151001829853088, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:21:13,802] Trial 194 finished with value: 111.7679734 and parameters: {'learning_rate': 0.00036141974453227945, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.00029950332472130443, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8062111445837761, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:23:01,872] Trial 195 finished with value: 76.51312820000001 and parameters: {'learning_rate': 0.00036158445838586255, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.00019759597096634125, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8061352030532486, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:24:56,649] Trial 196 finished with value: 91.46198179999999 and parameters: {'learning_rate': 0.0003287408918200503, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.0003283705383677825, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8042595196611444, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:26:35,465] Trial 197 finished with value: 87.7878655 and parameters: {'learning_rate': 0.00036173191571136276, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 0.0005780683259743814, 'clip_range': 0.30000000000000004, 'batch_size': 32, 'gae_lambda': 0.8024044257497045, 'n_epochs': 15}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:28:21,692] Trial 198 finished with value: 84.8779069 and parameters: {'learning_rate': 0.00022598007097163593, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 8.378100005109027e-05, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8121298818548078, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:29:50,565] Trial 199 finished with value: 96.8318889 and parameters: {'learning_rate': 0.00044075979681194286, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0002821750931552537, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8084273174336504, 'n_epochs': 12}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:31:33,109] Trial 200 finished with value: 80.5519118 and parameters: {'learning_rate': 0.0005448644712156139, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.0001351948566042372, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8055967928710415, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:33:17,534] Trial 201 finished with value: 73.84318119999999 and parameters: {'learning_rate': 0.00025990556723023853, 'n_steps': 256, 'gamma': 0.9500000000000001, 'ent_coef': 0.007595376549098322, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.810581899548161, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:35:07,499] Trial 202 finished with value: 84.37830149999999 and parameters: {'learning_rate': 0.0006394951691456131, 'n_steps': 256, 'gamma': 0.96, 'ent_coef': 0.0002237592750591998, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.9358880739186273, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:36:52,174] Trial 203 finished with value: 100.11043379999998 and parameters: {'learning_rate': 0.0008273723816396133, 'n_steps': 128, 'gamma': 0.9400000000000001, 'ent_coef': 0.0001459768820980715, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8020052929940141, 'n_epochs': 13}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:38:54,692] Trial 204 finished with value: 29.002725199999997 and parameters: {'learning_rate': 1.4587486119530976e-05, 'n_steps': 256, 'gamma': 0.93, 'ent_coef': 0.0004317301127512582, 'clip_range': 0.35, 'batch_size': 32, 'gae_lambda': 0.8082099086748701, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:40:19,602] Trial 205 finished with value: 83.30427069999999 and parameters: {'learning_rate': 0.0004886389054772718, 'n_steps': 128, 'gamma': 0.9500000000000001, 'ent_coef': 6.911280510180139e-05, 'clip_range': 0.35, 'batch_size': 64, 'gae_lambda': 0.8805034992701294, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:42:19,485] Trial 206 finished with value: 114.02815100000001 and parameters: {'learning_rate': 0.0009837705528414787, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.00024489481153415195, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8167828525214661, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:44:22,143] Trial 207 finished with value: 103.384579 and parameters: {'learning_rate': 0.0014319909246791526, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.0003389803180107607, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8202883711225388, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:46:26,518] Trial 208 finished with value: 103.07281379999999 and parameters: {'learning_rate': 0.001476431920187997, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.0003215809000524394, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8890388489039706, 'n_epochs': 19}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:48:27,458] Trial 209 finished with value: 88.35364809999999 and parameters: {'learning_rate': 0.0011938896314449333, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.000507835973551248, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8249731359226556, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:50:32,312] Trial 210 finished with value: 103.1403538 and parameters: {'learning_rate': 0.002157615195187568, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.0008879609412291487, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8189026356835171, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:52:32,977] Trial 211 finished with value: 91.19121290000001 and parameters: {'learning_rate': 0.002154625345256767, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0011671221397198208, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.816001642510304, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:54:31,821] Trial 212 finished with value: 88.3064904 and parameters: {'learning_rate': 0.0017348870254286462, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.0008735329643728963, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8223261248844418, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:56:41,267] Trial 213 finished with value: 94.7233207 and parameters: {'learning_rate': 0.0015121114020997801, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.0003763563648177898, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8278613942330674, 'n_epochs': 19}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 10:58:45,461] Trial 214 finished with value: 103.43601220000001 and parameters: {'learning_rate': 0.0012918629604913357, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.001458686917944612, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8175255883719534, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:00:53,213] Trial 215 finished with value: 109.6614708 and parameters: {'learning_rate': 0.0013497260952362116, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.00023937026647285694, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8149820294643565, 'n_epochs': 18}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:02:55,968] Trial 216 finished with value: 99.9156792 and parameters: {'learning_rate': 0.0010363430472818075, 'n_steps': 384, 'gamma': 0.98, 'ent_coef': 0.0017776802400861556, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8152840232983269, 'n_epochs': 19}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:04:46,707] Trial 217 finished with value: 104.2388939 and parameters: {'learning_rate': 0.0012543627789264543, 'n_steps': 256, 'gamma': 0.97, 'ent_coef': 0.0002488455599575102, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.810652895265453, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:06:32,397] Trial 218 finished with value: 67.7243736 and parameters: {'learning_rate': 0.0009623168066109943, 'n_steps': 256, 'gamma': 0.97, 'ent_coef': 0.0002490546722161623, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8100171501683552, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:08:24,093] Trial 219 finished with value: 95.1694751 and parameters: {'learning_rate': 0.0010864827445895295, 'n_steps': 256, 'gamma': 0.97, 'ent_coef': 0.00011579386594223469, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8092806284884848, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:10:03,823] Trial 220 finished with value: 104.0142153 and parameters: {'learning_rate': 0.0008957592759733624, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00022076071289381044, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8845247692213951, 'n_epochs': 15}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:11:42,566] Trial 221 finished with value: 31.864887799999998 and parameters: {'learning_rate': 0.0009311461436933193, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00023478270817398473, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8866486959076079, 'n_epochs': 15}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:13:19,762] Trial 222 finished with value: 93.2913651 and parameters: {'learning_rate': 0.0008492699927153671, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00017424215947673492, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8834936346256991, 'n_epochs': 15}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:15:10,263] Trial 223 finished with value: 107.5236633 and parameters: {'learning_rate': 0.0012613057813009485, 'n_steps': 384, 'gamma': 0.99, 'ent_coef': 0.00025162174829466077, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8129575380290925, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:16:59,752] Trial 224 finished with value: 90.7826543 and parameters: {'learning_rate': 0.0013237434266928551, 'n_steps': 384, 'gamma': 0.99, 'ent_coef': 0.017209387320348973, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8921223691871728, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:18:40,004] Trial 225 finished with value: 100.26103400000002 and parameters: {'learning_rate': 0.0011383780529701344, 'n_steps': 896, 'gamma': 0.99, 'ent_coef': 9.901691274144597e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8122209052691983, 'n_epochs': 14}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:20:29,984] Trial 226 finished with value: 115.00119009999999 and parameters: {'learning_rate': 0.0007314284602952508, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00023561289110894258, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8127743095828445, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:22:27,271] Trial 227 finished with value: 99.1246625 and parameters: {'learning_rate': 0.0007164043904084698, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.000151777476253152, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8133393382973252, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:24:24,708] Trial 228 finished with value: 107.72309800000001 and parameters: {'learning_rate': 0.0006270640978184021, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00026519768148933925, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.807304794100014, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:26:20,809] Trial 229 finished with value: 109.98826349999999 and parameters: {'learning_rate': 0.0005925413980354653, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00012758163784344745, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.838510278383871, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:28:12,050] Trial 230 finished with value: 90.3546269 and parameters: {'learning_rate': 0.0005919530810949032, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00011463095779540086, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8450947352984398, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:30:01,553] Trial 231 finished with value: 110.3956398 and parameters: {'learning_rate': 0.0006636699665188169, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.000286859910472721, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8077343748419288, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:31:58,934] Trial 232 finished with value: 90.1345707 and parameters: {'learning_rate': 0.0006591829786321414, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00027819732951903645, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8007891447305429, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:33:55,395] Trial 233 finished with value: 105.55233960000001 and parameters: {'learning_rate': 0.0005744315176461576, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0001906779321552358, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8143645672613333, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:35:49,941] Trial 234 finished with value: 85.72718160000001 and parameters: {'learning_rate': 0.000535860826746333, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00016921741362356304, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8153057176174779, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:37:41,185] Trial 235 finished with value: 72.30790739999999 and parameters: {'learning_rate': 0.0005929029441334561, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00020494363534780615, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8078691925213415, 'n_epochs': 16}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:39:39,284] Trial 236 finished with value: 110.5060911 and parameters: {'learning_rate': 0.0006579437646714993, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0001310213595710723, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8180960617102335, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:41:31,938] Trial 237 finished with value: 87.01384080000001 and parameters: {'learning_rate': 0.0006849342696487195, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 8.602874031539018e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8191572317290302, 'n_epochs': 17}. Best is trial 174 with value: 127.03462019999999.\n",
      "[I 2025-02-03 11:43:25,279] Trial 238 finished with value: 140.7981624 and parameters: {'learning_rate': 0.0007349336867716473, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 5.364021124191972e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8384513004766956, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:45:26,531] Trial 239 finished with value: 95.80687599999999 and parameters: {'learning_rate': 0.0007687044940981853, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 6.095047131555356e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8053051320241595, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:47:28,119] Trial 240 finished with value: 97.54053569999999 and parameters: {'learning_rate': 0.00045332124236611943, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00013225456928166852, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8345651502908288, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:49:27,339] Trial 241 finished with value: 105.37424500000002 and parameters: {'learning_rate': 0.000682663382618488, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 5.1437528294513295e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8112448835200657, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:51:23,462] Trial 242 finished with value: 68.65850329999999 and parameters: {'learning_rate': 0.0007374535033608125, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 3.883243718069849e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8368195806820504, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:53:20,200] Trial 243 finished with value: 91.4291145 and parameters: {'learning_rate': 0.000643210499143367, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 3.217104210635821e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8521884948270139, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:55:14,128] Trial 244 finished with value: 72.4555215 and parameters: {'learning_rate': 0.000516117672425598, 'n_steps': 768, 'gamma': 0.99, 'ent_coef': 0.00033005322002486743, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8178869685229305, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:57:09,453] Trial 245 finished with value: 92.5179261 and parameters: {'learning_rate': 0.0008175222315436183, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 8.01806592663333e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8060230488088374, 'n_epochs': 16}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 11:59:00,442] Trial 246 finished with value: 107.8328945 and parameters: {'learning_rate': 0.0006386937786776759, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00012724024873113032, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8283561797460495, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:00:48,358] Trial 247 finished with value: 115.09429270000001 and parameters: {'learning_rate': 0.0005763289239555515, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0001344450854708483, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8404377639893528, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:02:38,765] Trial 248 finished with value: 113.74814799999999 and parameters: {'learning_rate': 0.0005933859423439183, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00011444585353288886, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8370231302954955, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:04:26,537] Trial 249 finished with value: 80.33995519999999 and parameters: {'learning_rate': 0.0005815505346133775, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00011613519439578466, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8383514386476425, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:06:13,551] Trial 250 finished with value: 102.5899189 and parameters: {'learning_rate': 0.0006377914296636281, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00013311499909679625, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8450803179376403, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:08:00,985] Trial 251 finished with value: 93.6272187 and parameters: {'learning_rate': 0.000729920535747899, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 6.90648402378197e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.827620605851444, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:09:51,178] Trial 252 finished with value: 78.19559899999999 and parameters: {'learning_rate': 0.0005458383877489309, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 9.94751808661086e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8406316189103021, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:11:38,378] Trial 253 finished with value: 90.6023869 and parameters: {'learning_rate': 0.0006477891765744425, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00026601565194334407, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8323265334794143, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:13:26,391] Trial 254 finished with value: 109.66631630000002 and parameters: {'learning_rate': 0.0005152798269021589, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00014478308732412232, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8420960510568428, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:15:13,279] Trial 255 finished with value: 84.57319559999999 and parameters: {'learning_rate': 0.0004767953172154026, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0001388319377595804, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8421211303451972, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:17:00,639] Trial 256 finished with value: 115.13959440000001 and parameters: {'learning_rate': 0.0007652860011672528, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0001664943238805339, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8482174689835242, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:18:49,854] Trial 257 finished with value: 110.2780123 and parameters: {'learning_rate': 0.0007407066772322952, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00015369862771134717, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8377443900165036, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:20:36,347] Trial 258 finished with value: 97.1777276 and parameters: {'learning_rate': 0.0008002251734601248, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 9.836019044251912e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8359881546621407, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:22:23,037] Trial 259 finished with value: 89.14952459999999 and parameters: {'learning_rate': 0.0007232353785895924, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00015700246391112964, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8415754473771297, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:24:11,094] Trial 260 finished with value: 72.1062389 and parameters: {'learning_rate': 0.0008737662817130254, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00012066400033485162, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8380022183371284, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:26:01,096] Trial 261 finished with value: 91.4594696 and parameters: {'learning_rate': 0.0005210683728452184, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0001821457378128433, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8467609459752764, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:27:49,207] Trial 262 finished with value: 104.6954336 and parameters: {'learning_rate': 0.000583964076779826, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 8.594637816035808e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8415664220536428, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:29:40,228] Trial 263 finished with value: 86.3784015 and parameters: {'learning_rate': 0.0007316821930448635, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00014961608035925236, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8312539599513509, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:31:27,778] Trial 264 finished with value: 88.5395049 and parameters: {'learning_rate': 0.0008491519881952916, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00041517319925503567, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8344425001678151, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:33:19,174] Trial 265 finished with value: 78.37732550000001 and parameters: {'learning_rate': 0.0006674734091523378, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.03278173753367399, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8480922856345576, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:35:06,776] Trial 266 finished with value: 89.14315919999999 and parameters: {'learning_rate': 0.000765942046322617, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 4.080409075975609e-07, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.829882208188863, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:36:57,822] Trial 267 finished with value: 62.16212320000001 and parameters: {'learning_rate': 0.0005072085722939999, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00020007710647895814, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8397045341617829, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:38:46,096] Trial 268 finished with value: 96.13618840000001 and parameters: {'learning_rate': 0.0009262950563828996, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00010080965356577544, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8449606362740706, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:40:33,378] Trial 269 finished with value: 112.09717149999999 and parameters: {'learning_rate': 0.0006065996380990904, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 6.893218103371425e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8510684560877371, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:42:33,342] Trial 270 finished with value: 98.1641137 and parameters: {'learning_rate': 0.0005759259495620269, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 6.526036413897553e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8474243467760851, 'n_epochs': 20}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:44:27,392] Trial 271 finished with value: 92.6243549 and parameters: {'learning_rate': 0.00044375475904761375, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 8.176180047084363e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8369817010401593, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:46:15,399] Trial 272 finished with value: 104.1649485 and parameters: {'learning_rate': 0.0007643665073895475, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0006318136045910035, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8501839516871098, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:48:05,942] Trial 273 finished with value: 68.3345511 and parameters: {'learning_rate': 0.0006915853386006281, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00021637635138563706, 'clip_range': 0.15000000000000002, 'batch_size': 32, 'gae_lambda': 0.8543151255860274, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:49:52,257] Trial 274 finished with value: 99.3352639 and parameters: {'learning_rate': 0.0008704168656261255, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00035658611674356674, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8430985380611687, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:51:41,644] Trial 275 finished with value: 88.3358651 and parameters: {'learning_rate': 0.0005562490268956973, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.00015999609510659028, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8440788325880715, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:53:33,513] Trial 276 finished with value: 96.2763782 and parameters: {'learning_rate': 0.00095378491028379, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 5.689175787882148e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9324374506672862, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:55:27,959] Trial 277 finished with value: 108.0307057 and parameters: {'learning_rate': 0.0006184022717650435, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00010433607907433861, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8526614232416223, 'n_epochs': 19}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:57:22,298] Trial 278 finished with value: 113.93357110000002 and parameters: {'learning_rate': 0.00046909768628213195, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00032888096391325557, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8573539459546963, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 12:59:14,434] Trial 279 finished with value: 72.02468569999999 and parameters: {'learning_rate': 0.0004646705020624435, 'n_steps': 128, 'gamma': 0.92, 'ent_coef': 0.0003066525846227524, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8482924203081772, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:01:05,991] Trial 280 finished with value: 102.39268039999999 and parameters: {'learning_rate': 0.00040004414643504986, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00022620569678853436, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8558609887927675, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:02:56,797] Trial 281 finished with value: 121.92023319999998 and parameters: {'learning_rate': 0.0005099869140016997, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 1.1078085728464385e-07, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8506671587853118, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:04:47,687] Trial 282 finished with value: 99.0486441 and parameters: {'learning_rate': 0.0004986441871238741, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 1.3986744749659144e-08, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8510829403000566, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:06:38,754] Trial 283 finished with value: 92.22445629999999 and parameters: {'learning_rate': 0.0005406520726672495, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 8.899908026209256e-08, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8402565412624938, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:08:32,706] Trial 284 finished with value: 99.69423300000001 and parameters: {'learning_rate': 0.000412297514992768, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 3.3308390927166785e-08, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8586001040033255, 'n_epochs': 19}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:10:24,931] Trial 285 finished with value: 87.76522449999999 and parameters: {'learning_rate': 0.0004671298024491915, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 1.764297882316485e-07, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8563999782822617, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:11:45,541] Trial 286 finished with value: 78.45519820000001 and parameters: {'learning_rate': 0.0006275536331020559, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0004860679138184203, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.8215024812317406, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:13:39,409] Trial 287 finished with value: 67.8437535 and parameters: {'learning_rate': 0.0005371729644417172, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 7.204805502418493e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8490142755055755, 'n_epochs': 19}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:15:30,216] Trial 288 finished with value: 97.58878180000002 and parameters: {'learning_rate': 0.0003545089367638567, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0003566547004770072, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.9287312470857156, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:17:17,185] Trial 289 finished with value: 126.2609742 and parameters: {'learning_rate': 0.001024312693590713, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.00014835362641985934, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.834187575594768, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:19:05,014] Trial 290 finished with value: 78.12959370000002 and parameters: {'learning_rate': 0.0010317707299427512, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 0.00012065363619303448, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8330060192614904, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:20:56,512] Trial 291 finished with value: 89.49941380000001 and parameters: {'learning_rate': 0.0008567860180213955, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 4.4680123932407304e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8364391228703155, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:22:43,169] Trial 292 finished with value: 83.4428913 and parameters: {'learning_rate': 0.0010440552450811371, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.09863605168129726, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8441775525494597, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:24:30,041] Trial 293 finished with value: 106.34625009999999 and parameters: {'learning_rate': 0.0007533498949268507, 'n_steps': 256, 'gamma': 0.98, 'ent_coef': 2.9785364374494866e-07, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8404564221423361, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:26:20,832] Trial 294 finished with value: 89.0331471 and parameters: {'learning_rate': 0.0006686908521538595, 'n_steps': 128, 'gamma': 0.98, 'ent_coef': 0.0001520508225703751, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.852541244985441, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:28:07,179] Trial 295 finished with value: 96.3802848 and parameters: {'learning_rate': 0.0008122880443046776, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 9.015169741481524e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8384571801410998, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:30:00,696] Trial 296 finished with value: 72.0930541 and parameters: {'learning_rate': 0.0009197019100003979, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.00017520242048255766, 'clip_range': 0.25, 'batch_size': 32, 'gae_lambda': 0.8460799161734454, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:31:46,530] Trial 297 finished with value: 70.99429190000001 and parameters: {'learning_rate': 0.0006938997208713233, 'n_steps': 1664, 'gamma': 0.98, 'ent_coef': 5.697085712476226e-08, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8333283875188311, 'n_epochs': 17}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:33:13,457] Trial 298 finished with value: 101.28104900000001 and parameters: {'learning_rate': 0.0005651544168520943, 'n_steps': 256, 'gamma': 0.99, 'ent_coef': 0.00013146440383653542, 'clip_range': 0.4, 'batch_size': 64, 'gae_lambda': 0.8263312800146166, 'n_epochs': 19}. Best is trial 238 with value: 140.7981624.\n",
      "[I 2025-02-03 13:35:06,406] Trial 299 finished with value: 95.79821240000001 and parameters: {'learning_rate': 0.001099984562577656, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 0.0002611968846001441, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8364248110668199, 'n_epochs': 18}. Best is trial 238 with value: 140.7981624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.0007349336867716473, 'n_steps': 128, 'gamma': 0.99, 'ent_coef': 5.364021124191972e-05, 'clip_range': 0.4, 'batch_size': 32, 'gae_lambda': 0.8384513004766956, 'n_epochs': 17}\n",
      "Best value (objective): 140.7981624\n"
     ]
    }
   ],
   "source": [
    "#Run fine tuning\n",
    "study = run_optimization()\n",
    "\n",
    "with open(\"ppo_best_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1a805-c19d-48cd-bbab-57820e66ab3f",
   "metadata": {},
   "source": [
    "## b. Training final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d4d28-cf4a-4428-b756-cec7b7b8584c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5521 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 128  |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2003       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 0          |\n",
      "|    total_timesteps      | 256        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06256106 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.656     |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.14      |\n",
      "|    n_updates            | 17         |\n",
      "|    policy_gradient_loss | -0.0653    |\n",
      "|    value_loss           | 0.0205     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1680        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 384         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024234558 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | -0.219      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0576     |\n",
      "|    n_updates            | 34          |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.0348      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500, episode_reward=55.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 500        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04012928 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.497     |\n",
      "|    explained_variance   | -1.05      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 51         |\n",
      "|    policy_gradient_loss | -0.0776    |\n",
      "|    value_loss           | 0.0134     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1033 |\n",
      "|    iterations      | 4    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 512  |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 640         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057251036 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | -0.855      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.113      |\n",
      "|    n_updates            | 68          |\n",
      "|    policy_gradient_loss | -0.0731     |\n",
      "|    value_loss           | 0.00659     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 768         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045504056 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | -0.037      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0953     |\n",
      "|    n_updates            | 85          |\n",
      "|    policy_gradient_loss | -0.0683     |\n",
      "|    value_loss           | 0.0247      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1152        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 896         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025756763 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | -0.388      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0655     |\n",
      "|    n_updates            | 102         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 0.0847      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=59.01 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 59          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042228438 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.0362      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0824     |\n",
      "|    n_updates            | 119         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 0.0981      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 952  |\n",
      "|    iterations      | 8    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 1024 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 975        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 1152       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10963792 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0325    |\n",
      "|    n_updates            | 136        |\n",
      "|    policy_gradient_loss | -0.0697    |\n",
      "|    value_loss           | 0.41       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1001        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 1280        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018930266 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | -0.0522     |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 153         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1014       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 1408       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04169722 |\n",
      "|    clip_fraction        | 0.0611     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.156     |\n",
      "|    explained_variance   | -0.0935    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0275    |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0361    |\n",
      "|    value_loss           | 0.235      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1500, episode_reward=46.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1500       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10302407 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | -0.0777    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0149     |\n",
      "|    n_updates            | 187        |\n",
      "|    policy_gradient_loss | -0.0779    |\n",
      "|    value_loss           | 0.67       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 23.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 1536     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 930         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 1664        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070374645 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0586     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.0641     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 23.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 953       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 1792      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1100605 |\n",
      "|    clip_fraction        | 0.0859    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.186    |\n",
      "|    explained_variance   | -0.172    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0868   |\n",
      "|    n_updates            | 221       |\n",
      "|    policy_gradient_loss | -0.0374   |\n",
      "|    value_loss           | 0.0809    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 976         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 1920        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038214743 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | -0.303      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0478     |\n",
      "|    n_updates            | 238         |\n",
      "|    policy_gradient_loss | -0.06       |\n",
      "|    value_loss           | 0.0153      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=61.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 61.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07406451 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.332     |\n",
      "|    explained_variance   | -0.149     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.123     |\n",
      "|    n_updates            | 255        |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    value_loss           | 0.0142     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 23.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 920      |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 934         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 2176        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072599225 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | -0.172      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.119      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.0629     |\n",
      "|    value_loss           | 0.0444      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 945        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 2304       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09860418 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.165     |\n",
      "|    explained_variance   | -0.276     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0618    |\n",
      "|    n_updates            | 289        |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    value_loss           | 0.0461     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 963        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 2432       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04794316 |\n",
      "|    clip_fraction        | 0.074      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0942    |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0224    |\n",
      "|    n_updates            | 306        |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 0.0345     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2500, episode_reward=96.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 96.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2500       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03543757 |\n",
      "|    clip_fraction        | 0.0469     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.00448    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0417    |\n",
      "|    n_updates            | 323        |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 23.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 896      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2560     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 2688       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20802583 |\n",
      "|    clip_fraction        | 0.0795     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.181     |\n",
      "|    explained_variance   | -0.0629    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0691     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.977      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 2816       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01704029 |\n",
      "|    clip_fraction        | 0.0345     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.243      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0376     |\n",
      "|    n_updates            | 357        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    value_loss           | 0.399      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 924         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 2944        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036530532 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | -0.248      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.586       |\n",
      "|    n_updates            | 374         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=83.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 83.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050459042 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 391         |\n",
      "|    policy_gradient_loss | -0.051      |\n",
      "|    value_loss           | 0.908       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 22       |\n",
      "| time/              |          |\n",
      "|    fps             | 893      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 3072     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 3200       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11344206 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.206     |\n",
      "|    explained_variance   | -0.494     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 408        |\n",
      "|    policy_gradient_loss | -0.0816    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 922         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 3328        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047494266 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0432     |\n",
      "|    n_updates            | 425         |\n",
      "|    policy_gradient_loss | -0.0635     |\n",
      "|    value_loss           | 0.0754      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 935         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 3456        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046242297 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.055      |\n",
      "|    n_updates            | 442         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3500, episode_reward=72.86 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 72.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053558495 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.123      |\n",
      "|    explained_variance   | -0.213      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0408     |\n",
      "|    n_updates            | 459         |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.033       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 22       |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 28       |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 3584     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 3712       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21735996 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.489      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0779    |\n",
      "|    n_updates            | 476        |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 0.0801     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 921        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 3840       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27551037 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.154     |\n",
      "|    explained_variance   | -0.254     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 493        |\n",
      "|    policy_gradient_loss | -0.0499    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 920        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 3968       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55890465 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.252     |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.194     |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.0813    |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=81.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 81.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09880872 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.205     |\n",
      "|    explained_variance   | 0.288      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0396     |\n",
      "|    n_updates            | 527        |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 22       |\n",
      "| time/              |          |\n",
      "|    fps             | 895      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 4224       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14194013 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.237     |\n",
      "|    explained_variance   | 0.254      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0355    |\n",
      "|    n_updates            | 544        |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    value_loss           | 0.989      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 908         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4352        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046103008 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.149      |\n",
      "|    explained_variance   | 0.0608      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0227      |\n",
      "|    n_updates            | 561         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.627       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 915         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4480        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.107889324 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | -0.0505     |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 578         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4500, episode_reward=83.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 83.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.113365166 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | -0.497      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.133      |\n",
      "|    n_updates            | 595         |\n",
      "|    policy_gradient_loss | -0.0785     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 23.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 897      |\n",
      "|    iterations      | 36       |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 4608     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4736       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14173701 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.367     |\n",
      "|    explained_variance   | -1.02      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 612        |\n",
      "|    policy_gradient_loss | -0.0853    |\n",
      "|    value_loss           | 0.0337     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4864       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06658021 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.275     |\n",
      "|    explained_variance   | -1.12      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.124     |\n",
      "|    n_updates            | 629        |\n",
      "|    policy_gradient_loss | -0.0592    |\n",
      "|    value_loss           | 0.023      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 925         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4992        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059671834 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.181      |\n",
      "|    explained_variance   | -0.306      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0684     |\n",
      "|    n_updates            | 646         |\n",
      "|    policy_gradient_loss | -0.0511     |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=46.35 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17576277 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.248     |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 663        |\n",
      "|    policy_gradient_loss | -0.0524    |\n",
      "|    value_loss           | 0.154      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 23.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 5120     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 5248       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13819441 |\n",
      "|    clip_fraction        | 0.0928     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.236     |\n",
      "|    explained_variance   | -0.147     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0618    |\n",
      "|    value_loss           | 0.277      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 925         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 5376        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078948595 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | -0.209      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0681     |\n",
      "|    n_updates            | 697         |\n",
      "|    policy_gradient_loss | -0.0612     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5500, episode_reward=22.63 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 22.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 5500      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0638226 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.219    |\n",
      "|    explained_variance   | 0.325     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0457    |\n",
      "|    n_updates            | 714       |\n",
      "|    policy_gradient_loss | -0.0497   |\n",
      "|    value_loss           | 0.362     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 23.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 43       |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 5504     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 23.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 919        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 5632       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11430736 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.373     |\n",
      "|    explained_variance   | 0.56       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 731        |\n",
      "|    policy_gradient_loss | -0.0957    |\n",
      "|    value_loss           | 0.394      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 23.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 926         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 5760        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.083339505 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0727     |\n",
      "|    n_updates            | 748         |\n",
      "|    policy_gradient_loss | -0.0699     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 22.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 934         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 5888        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030417405 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | -0.195      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0599      |\n",
      "|    n_updates            | 765         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 0.9         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=61.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 61.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062045094 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0793     |\n",
      "|    n_updates            | 782         |\n",
      "|    policy_gradient_loss | -0.0659     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 22.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 919      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 6016     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 921        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20413046 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.262     |\n",
      "|    explained_variance   | -0.195     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 799        |\n",
      "|    policy_gradient_loss | -0.0734    |\n",
      "|    value_loss           | 0.048      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 925        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 6272       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12996644 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.205     |\n",
      "|    explained_variance   | -0.758     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 816        |\n",
      "|    policy_gradient_loss | -0.0821    |\n",
      "|    value_loss           | 0.0281     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 931        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 6400       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48742166 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | -0.577     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0637    |\n",
      "|    n_updates            | 833        |\n",
      "|    policy_gradient_loss | -0.102     |\n",
      "|    value_loss           | 0.00733    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6500, episode_reward=61.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 61         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 6500       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19060138 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.167     |\n",
      "|    explained_variance   | -0.0441    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.087     |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.071     |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 22.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 918      |\n",
      "|    iterations      | 51       |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 6528     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 925        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18673491 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.166     |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0977    |\n",
      "|    n_updates            | 867        |\n",
      "|    policy_gradient_loss | -0.0464    |\n",
      "|    value_loss           | 0.0575     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 932        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6784       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09932216 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.264     |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.139     |\n",
      "|    n_updates            | 884        |\n",
      "|    policy_gradient_loss | -0.0655    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 22.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 938        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6912       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13538797 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.243     |\n",
      "|    explained_variance   | -0.076     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00301   |\n",
      "|    n_updates            | 901        |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    value_loss           | 0.5        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=53.32 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 7000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14997938 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.252     |\n",
      "|    explained_variance   | 0.0416     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0183    |\n",
      "|    n_updates            | 918        |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    value_loss           | 0.569      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 22.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 921      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 7040     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 22.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 927       |\n",
      "|    iterations           | 56        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 7168      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1107274 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.365    |\n",
      "|    explained_variance   | 0.487     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 935       |\n",
      "|    policy_gradient_loss | -0.0661   |\n",
      "|    value_loss           | 0.244     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 933        |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 7296       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13018866 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | -0.231     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 952        |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 2.05       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 939        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 7424       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08963706 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.339     |\n",
      "|    explained_variance   | 0.0129     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0542    |\n",
      "|    n_updates            | 969        |\n",
      "|    policy_gradient_loss | -0.084     |\n",
      "|    value_loss           | 0.344      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=7500, episode_reward=70.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 70.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 7500       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13496548 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | -1.22      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.151     |\n",
      "|    n_updates            | 986        |\n",
      "|    policy_gradient_loss | -0.1       |\n",
      "|    value_loss           | 0.074      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 28       |\n",
      "| time/              |          |\n",
      "|    fps             | 926      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 7552     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 932        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 7680       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28007066 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.348     |\n",
      "|    explained_variance   | -0.00265   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 1003       |\n",
      "|    policy_gradient_loss | -0.108     |\n",
      "|    value_loss           | 0.024      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 937        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 7808       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13190337 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.349     |\n",
      "|    explained_variance   | -0.487     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.144     |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0774    |\n",
      "|    value_loss           | 0.0159     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 941        |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 7936       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24268983 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.316     |\n",
      "|    explained_variance   | -0.907     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0777    |\n",
      "|    n_updates            | 1037       |\n",
      "|    policy_gradient_loss | -0.0821    |\n",
      "|    value_loss           | 0.0754     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=40.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 8000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20856214 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.271     |\n",
      "|    explained_variance   | -0.583     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0979    |\n",
      "|    n_updates            | 1054       |\n",
      "|    policy_gradient_loss | -0.083     |\n",
      "|    value_loss           | 0.116      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 28       |\n",
      "| time/              |          |\n",
      "|    fps             | 928      |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 8064     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 931        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13986897 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.157     |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0674    |\n",
      "|    n_updates            | 1071       |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    value_loss           | 0.0815     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 28       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 936      |\n",
      "|    iterations           | 65       |\n",
      "|    time_elapsed         | 8        |\n",
      "|    total_timesteps      | 8320     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.292854 |\n",
      "|    clip_fraction        | 0.192    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.23    |\n",
      "|    explained_variance   | -0.043   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.113   |\n",
      "|    n_updates            | 1088     |\n",
      "|    policy_gradient_loss | -0.0908  |\n",
      "|    value_loss           | 0.0547   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 28         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 940        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 8448       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.66125715 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.272     |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0474    |\n",
      "|    n_updates            | 1105       |\n",
      "|    policy_gradient_loss | -0.09      |\n",
      "|    value_loss           | 0.462      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=8500, episode_reward=-10.72 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | -10.7       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.118309826 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0497     |\n",
      "|    n_updates            | 1122        |\n",
      "|    policy_gradient_loss | -0.0511     |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 28       |\n",
      "| time/              |          |\n",
      "|    fps             | 928      |\n",
      "|    iterations      | 67       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 8576     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 931        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 8704       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25164205 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.282     |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00535    |\n",
      "|    n_updates            | 1139       |\n",
      "|    policy_gradient_loss | -0.0843    |\n",
      "|    value_loss           | 0.988      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 935        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 8832       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65460825 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.219     |\n",
      "|    explained_variance   | 0.0129     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 1156       |\n",
      "|    policy_gradient_loss | -0.106     |\n",
      "|    value_loss           | 0.094      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 939       |\n",
      "|    iterations           | 70        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 8960      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4404203 |\n",
      "|    clip_fraction        | 0.226     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.286    |\n",
      "|    explained_variance   | -1.25     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.144    |\n",
      "|    n_updates            | 1173      |\n",
      "|    policy_gradient_loss | -0.0755   |\n",
      "|    value_loss           | 0.128     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=2.64 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.64       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 9000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18266726 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | -0.0251    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.148     |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.0931    |\n",
      "|    value_loss           | 0.0637     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 29.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 928      |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 9088     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 928       |\n",
      "|    iterations           | 72        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 9216      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2564016 |\n",
      "|    clip_fraction        | 0.348     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.474    |\n",
      "|    explained_variance   | -0.557    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.205    |\n",
      "|    n_updates            | 1207      |\n",
      "|    policy_gradient_loss | -0.136    |\n",
      "|    value_loss           | 0.0356    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 930        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 9344       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25380126 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.39      |\n",
      "|    explained_variance   | -0.605     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.143     |\n",
      "|    n_updates            | 1224       |\n",
      "|    policy_gradient_loss | -0.105     |\n",
      "|    value_loss           | 0.019      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 930       |\n",
      "|    iterations           | 74        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 9472      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3006056 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.246    |\n",
      "|    explained_variance   | 0.587     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0886   |\n",
      "|    n_updates            | 1241      |\n",
      "|    policy_gradient_loss | -0.0732   |\n",
      "|    value_loss           | 0.0497    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=9500, episode_reward=36.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 9500       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20445578 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.138     |\n",
      "|    explained_variance   | 0.62       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.144     |\n",
      "|    n_updates            | 1258       |\n",
      "|    policy_gradient_loss | -0.0673    |\n",
      "|    value_loss           | 0.0673     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 29.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 907      |\n",
      "|    iterations      | 75       |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 9600     |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 29.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 909      |\n",
      "|    iterations           | 76       |\n",
      "|    time_elapsed         | 10       |\n",
      "|    total_timesteps      | 9728     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.381707 |\n",
      "|    clip_fraction        | 0.207    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.252   |\n",
      "|    explained_variance   | -0.527   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.11    |\n",
      "|    n_updates            | 1275     |\n",
      "|    policy_gradient_loss | -0.0723  |\n",
      "|    value_loss           | 0.142    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 9856       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42477527 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.238     |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 1292       |\n",
      "|    policy_gradient_loss | -0.0851    |\n",
      "|    value_loss           | 0.331      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 78        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 9984      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7759862 |\n",
      "|    clip_fraction        | 0.428     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.204    |\n",
      "|    explained_variance   | 0.4       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 1309      |\n",
      "|    policy_gradient_loss | -0.113    |\n",
      "|    value_loss           | 0.151     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=20.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 10000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34520912 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | -0.0968    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0116    |\n",
      "|    n_updates            | 1326       |\n",
      "|    policy_gradient_loss | -0.0857    |\n",
      "|    value_loss           | 0.643      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 29.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 10112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 29.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 908         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.084637105 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | -0.185      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0636     |\n",
      "|    n_updates            | 1343        |\n",
      "|    policy_gradient_loss | -0.066      |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 10368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5502908 |\n",
      "|    clip_fraction        | 0.208     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.235    |\n",
      "|    explained_variance   | 0.921     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.109    |\n",
      "|    n_updates            | 1360      |\n",
      "|    policy_gradient_loss | -0.0934   |\n",
      "|    value_loss           | 0.131     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 10496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10997908 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.16      |\n",
      "|    explained_variance   | -0.199     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.157     |\n",
      "|    n_updates            | 1377       |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.0286     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=10500, episode_reward=45.32 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 45.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 10500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2870404 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.179    |\n",
      "|    explained_variance   | -0.746    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0697   |\n",
      "|    n_updates            | 1394      |\n",
      "|    policy_gradient_loss | -0.0649   |\n",
      "|    value_loss           | 0.0167    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 29.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 895      |\n",
      "|    iterations      | 83       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 10624    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 896       |\n",
      "|    iterations           | 84        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 10752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0215808 |\n",
      "|    clip_fraction        | 0.356     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.134    |\n",
      "|    explained_variance   | -0.901    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.154    |\n",
      "|    n_updates            | 1411      |\n",
      "|    policy_gradient_loss | -0.098    |\n",
      "|    value_loss           | 0.0103    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 898        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 10880      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43903604 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0373    |\n",
      "|    n_updates            | 1428       |\n",
      "|    policy_gradient_loss | -0.0387    |\n",
      "|    value_loss           | 0.0203     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=48.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 11000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15005364 |\n",
      "|    clip_fraction        | 0.0731     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0908    |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0588    |\n",
      "|    n_updates            | 1445       |\n",
      "|    policy_gradient_loss | -0.0346    |\n",
      "|    value_loss           | 0.067      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 29.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 884      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 11008    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 886        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 11136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24818587 |\n",
      "|    clip_fraction        | 0.0928     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0988    |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0312    |\n",
      "|    n_updates            | 1462       |\n",
      "|    policy_gradient_loss | -0.0471    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 29.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 889       |\n",
      "|    iterations           | 88        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 11264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4729399 |\n",
      "|    clip_fraction        | 0.209     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.157    |\n",
      "|    explained_variance   | 0.162     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0397   |\n",
      "|    n_updates            | 1479      |\n",
      "|    policy_gradient_loss | -0.0617   |\n",
      "|    value_loss           | 0.688     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 29.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 892        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 11392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53091854 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0621     |\n",
      "|    n_updates            | 1496       |\n",
      "|    policy_gradient_loss | -0.0641    |\n",
      "|    value_loss           | 0.321      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=11500, episode_reward=30.71 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 30.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 11500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062804714 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | -0.278      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0766     |\n",
      "|    n_updates            | 1513        |\n",
      "|    policy_gradient_loss | -0.0547     |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 29.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 885      |\n",
      "|    iterations      | 90       |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 11520    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 888       |\n",
      "|    iterations           | 91        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1146884 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.282    |\n",
      "|    explained_variance   | 0.0948    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0554    |\n",
      "|    n_updates            | 1530      |\n",
      "|    policy_gradient_loss | -0.0658   |\n",
      "|    value_loss           | 0.66      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 890       |\n",
      "|    iterations           | 92        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6229991 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.137    |\n",
      "|    explained_variance   | 0.686     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0356    |\n",
      "|    n_updates            | 1547      |\n",
      "|    policy_gradient_loss | -0.0496   |\n",
      "|    value_loss           | 0.28      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 894        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 11904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29224256 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | -0.532     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0822    |\n",
      "|    n_updates            | 1564       |\n",
      "|    policy_gradient_loss | -0.0734    |\n",
      "|    value_loss           | 0.0414     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=64.06 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 64.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 12000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19646503 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.154     |\n",
      "|    explained_variance   | -0.409     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00749    |\n",
      "|    n_updates            | 1581       |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    value_loss           | 0.0209     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 888      |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 12032    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 891        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 12160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76686406 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.185     |\n",
      "|    explained_variance   | -0.318     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 1598       |\n",
      "|    policy_gradient_loss | -0.0955    |\n",
      "|    value_loss           | 0.0135     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 895        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37261873 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.21      |\n",
      "|    explained_variance   | -0.159     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0628    |\n",
      "|    n_updates            | 1615       |\n",
      "|    policy_gradient_loss | -0.0585    |\n",
      "|    value_loss           | 0.0506     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 97        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 12416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2398895 |\n",
      "|    clip_fraction        | 0.0956    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0935   |\n",
      "|    explained_variance   | -0.862    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0287   |\n",
      "|    n_updates            | 1632      |\n",
      "|    policy_gradient_loss | -0.0264   |\n",
      "|    value_loss           | 0.094     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=12500, episode_reward=24.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 24.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 12500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4658821 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0862   |\n",
      "|    explained_variance   | -0.239    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00927  |\n",
      "|    n_updates            | 1649      |\n",
      "|    policy_gradient_loss | -0.0389   |\n",
      "|    value_loss           | 0.121     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 892      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 12544    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 895        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 12672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25273025 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.206     |\n",
      "|    explained_variance   | -0.319     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 1666       |\n",
      "|    policy_gradient_loss | -0.0747    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 31.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 896         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101439595 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.108      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0416     |\n",
      "|    n_updates            | 1683        |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 0.327       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 898        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 12928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20622812 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.165     |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00967   |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | -0.0668    |\n",
      "|    value_loss           | 0.341      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-1.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -1.36      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 13000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10706168 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.17      |\n",
      "|    explained_variance   | -0.175     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.66       |\n",
      "|    n_updates            | 1717       |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 1.53       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32       |\n",
      "| time/              |          |\n",
      "|    fps             | 891      |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 13056    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 894       |\n",
      "|    iterations           | 103       |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 13184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6563231 |\n",
      "|    clip_fraction        | 0.256     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.143    |\n",
      "|    explained_variance   | 0.666     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 1734      |\n",
      "|    policy_gradient_loss | -0.109    |\n",
      "|    value_loss           | 0.182     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 897        |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22647747 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0995    |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0765    |\n",
      "|    n_updates            | 1751       |\n",
      "|    policy_gradient_loss | -0.0582    |\n",
      "|    value_loss           | 0.0608     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 13440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10775613 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0578    |\n",
      "|    explained_variance   | -0.458     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0529    |\n",
      "|    n_updates            | 1768       |\n",
      "|    policy_gradient_loss | -0.0445    |\n",
      "|    value_loss           | 0.0392     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=13500, episode_reward=3.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 3.24       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 13500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13181856 |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0639    |\n",
      "|    explained_variance   | -1.38      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0821    |\n",
      "|    n_updates            | 1785       |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.0244     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32       |\n",
      "| time/              |          |\n",
      "|    fps             | 895      |\n",
      "|    iterations      | 106      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 13568    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 898        |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 13696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45127326 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 1802       |\n",
      "|    policy_gradient_loss | -0.0674    |\n",
      "|    value_loss           | 0.0289     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 13824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32426503 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0991    |\n",
      "|    explained_variance   | 0.114      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.074     |\n",
      "|    n_updates            | 1819       |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 0.153      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 13952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25594634 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.087     |\n",
      "|    explained_variance   | -0.251     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0877    |\n",
      "|    n_updates            | 1836       |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.162      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=10.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 10.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 14000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50128764 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.17      |\n",
      "|    explained_variance   | 0.657      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0883    |\n",
      "|    n_updates            | 1853       |\n",
      "|    policy_gradient_loss | -0.0649    |\n",
      "|    value_loss           | 0.0906     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32       |\n",
      "| time/              |          |\n",
      "|    fps             | 895      |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 14080    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 897       |\n",
      "|    iterations           | 111       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 14208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9983593 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.177    |\n",
      "|    explained_variance   | -0.0785   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0469   |\n",
      "|    n_updates            | 1870      |\n",
      "|    policy_gradient_loss | -0.0961   |\n",
      "|    value_loss           | 0.409     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17377456 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0613    |\n",
      "|    n_updates            | 1887       |\n",
      "|    policy_gradient_loss | -0.065     |\n",
      "|    value_loss           | 0.655      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 113       |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 14464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4035771 |\n",
      "|    clip_fraction        | 0.175     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.13     |\n",
      "|    explained_variance   | 0.438     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0879   |\n",
      "|    n_updates            | 1904      |\n",
      "|    policy_gradient_loss | -0.056    |\n",
      "|    value_loss           | 0.218     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=14500, episode_reward=75.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 75.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 14500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2195576 |\n",
      "|    clip_fraction        | 0.324     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.153    |\n",
      "|    explained_variance   | 0.246     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0896   |\n",
      "|    n_updates            | 1921      |\n",
      "|    policy_gradient_loss | -0.108    |\n",
      "|    value_loss           | 0.421     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 898      |\n",
      "|    iterations      | 114      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 14592    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13128024 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0194    |\n",
      "|    n_updates            | 1938       |\n",
      "|    policy_gradient_loss | -0.0567    |\n",
      "|    value_loss           | 0.347      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37024555 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | -0.214     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 1955       |\n",
      "|    policy_gradient_loss | -0.093     |\n",
      "|    value_loss           | 0.0624     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 14976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47822744 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | -0.935     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0419    |\n",
      "|    n_updates            | 1972       |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.0421     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=32.38 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 32.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 15000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4095186 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.165    |\n",
      "|    explained_variance   | -1.22     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.135    |\n",
      "|    n_updates            | 1989      |\n",
      "|    policy_gradient_loss | -0.0825   |\n",
      "|    value_loss           | 0.0241    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 15104    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 15232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08583989 |\n",
      "|    clip_fraction        | 0.0777     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.0205     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 2006       |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    value_loss           | 0.0362     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29139328 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0527    |\n",
      "|    n_updates            | 2023       |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 121       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 15488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1123746 |\n",
      "|    clip_fraction        | 0.0501    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0466   |\n",
      "|    explained_variance   | 0.504     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0744   |\n",
      "|    n_updates            | 2040      |\n",
      "|    policy_gradient_loss | -0.0279   |\n",
      "|    value_loss           | 0.105     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=15500, episode_reward=-7.34 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -7.34     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 15500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4603429 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | -0.0602   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0988   |\n",
      "|    n_updates            | 2057      |\n",
      "|    policy_gradient_loss | -0.0742   |\n",
      "|    value_loss           | 0.191     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 122      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 15616    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 15744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36326587 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0498    |\n",
      "|    n_updates            | 2074       |\n",
      "|    policy_gradient_loss | -0.0731    |\n",
      "|    value_loss           | 0.292      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 15872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91094655 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0517    |\n",
      "|    explained_variance   | -0.177     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0814    |\n",
      "|    n_updates            | 2091       |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    value_loss           | 0.131      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=22.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 22.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 16000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6295023 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | -0.0667   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0483    |\n",
      "|    n_updates            | 2108      |\n",
      "|    policy_gradient_loss | -0.0472   |\n",
      "|    value_loss           | 1.31      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 16000    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 126       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 16128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1155045 |\n",
      "|    clip_fraction        | 0.0657    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0603   |\n",
      "|    explained_variance   | 0.937     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0338   |\n",
      "|    n_updates            | 2125      |\n",
      "|    policy_gradient_loss | -0.0301   |\n",
      "|    value_loss           | 0.0956    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 906       |\n",
      "|    iterations           | 127       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 16256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3669657 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | -0.717    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0899   |\n",
      "|    n_updates            | 2142      |\n",
      "|    policy_gradient_loss | -0.0418   |\n",
      "|    value_loss           | 0.0444    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 33.6     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 908      |\n",
      "|    iterations           | 128      |\n",
      "|    time_elapsed         | 18       |\n",
      "|    total_timesteps      | 16384    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.27959  |\n",
      "|    clip_fraction        | 0.21     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.119   |\n",
      "|    explained_variance   | -0.0437  |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0638  |\n",
      "|    n_updates            | 2159     |\n",
      "|    policy_gradient_loss | -0.0452  |\n",
      "|    value_loss           | 0.0457   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=16500, episode_reward=36.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 16500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12201305 |\n",
      "|    clip_fraction        | 0.0823     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0964    |\n",
      "|    explained_variance   | -0.795     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.094     |\n",
      "|    n_updates            | 2176       |\n",
      "|    policy_gradient_loss | -0.0565    |\n",
      "|    value_loss           | 0.0172     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 129      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 16512    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 16640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33880773 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.137     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0978    |\n",
      "|    n_updates            | 2193       |\n",
      "|    policy_gradient_loss | -0.0699    |\n",
      "|    value_loss           | 0.0982     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 131       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 16768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3027871 |\n",
      "|    clip_fraction        | 0.0942    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.094    |\n",
      "|    explained_variance   | 0.248     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0625   |\n",
      "|    n_updates            | 2210      |\n",
      "|    policy_gradient_loss | -0.0372   |\n",
      "|    value_loss           | 0.102     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 16896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26669165 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0682    |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0782    |\n",
      "|    n_updates            | 2227       |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 0.067      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=-3.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -3.53     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 17000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7973447 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | -0.247    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 2244      |\n",
      "|    policy_gradient_loss | -0.0798   |\n",
      "|    value_loss           | 0.0769    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 133      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 17024    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 17152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13323879 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0507    |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0235     |\n",
      "|    n_updates            | 2261       |\n",
      "|    policy_gradient_loss | -0.0375    |\n",
      "|    value_loss           | 0.971      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 135       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 17280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3909765 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.122    |\n",
      "|    explained_variance   | 0.545     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.118    |\n",
      "|    n_updates            | 2278      |\n",
      "|    policy_gradient_loss | -0.0687   |\n",
      "|    value_loss           | 0.168     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19997288 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | -0.286     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.116      |\n",
      "|    n_updates            | 2295       |\n",
      "|    policy_gradient_loss | -0.0565    |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=17500, episode_reward=50.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 50.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 17500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14242601 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0938    |\n",
      "|    explained_variance   | 0.697      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0972    |\n",
      "|    n_updates            | 2312       |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.291      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 17536    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 17664      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20173635 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0901    |\n",
      "|    explained_variance   | -0.907     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 2329       |\n",
      "|    policy_gradient_loss | -0.0434    |\n",
      "|    value_loss           | 0.0578     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 17792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50896573 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | 0.132      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 2346       |\n",
      "|    policy_gradient_loss | -0.0518    |\n",
      "|    value_loss           | 0.0555     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 17920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30960107 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.148     |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0888    |\n",
      "|    n_updates            | 2363       |\n",
      "|    policy_gradient_loss | -0.0663    |\n",
      "|    value_loss           | 0.0136     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=44.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 44.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 18000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1617412 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    explained_variance   | 0.0143    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0663   |\n",
      "|    n_updates            | 2380      |\n",
      "|    policy_gradient_loss | -0.059    |\n",
      "|    value_loss           | 0.0248    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 141      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 18048    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 142       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 18176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9002864 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0964   |\n",
      "|    explained_variance   | -0.152    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.124    |\n",
      "|    n_updates            | 2397      |\n",
      "|    policy_gradient_loss | -0.0743   |\n",
      "|    value_loss           | 0.0651    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 34.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 905         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 18304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.100979075 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.112      |\n",
      "|    explained_variance   | -0.0953     |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.061      |\n",
      "|    n_updates            | 2414        |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.0736      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31737787 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0887    |\n",
      "|    explained_variance   | 0.647      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0238    |\n",
      "|    n_updates            | 2431       |\n",
      "|    policy_gradient_loss | -0.0534    |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=18500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 18500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3666646 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0499   |\n",
      "|    explained_variance   | 0.405     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0623   |\n",
      "|    n_updates            | 2448      |\n",
      "|    policy_gradient_loss | -0.0681   |\n",
      "|    value_loss           | 0.152     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 145      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 18560    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 18688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19249398 |\n",
      "|    clip_fraction        | 0.0915     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0696    |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0332    |\n",
      "|    n_updates            | 2465       |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 147       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 18816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6125691 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0836   |\n",
      "|    explained_variance   | 0.396     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0346   |\n",
      "|    n_updates            | 2482      |\n",
      "|    policy_gradient_loss | -0.0405   |\n",
      "|    value_loss           | 0.241     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 34       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 148      |\n",
      "|    time_elapsed         | 21       |\n",
      "|    total_timesteps      | 18944    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.34346  |\n",
      "|    clip_fraction        | 0.108    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.107   |\n",
      "|    explained_variance   | 0.0457   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0268   |\n",
      "|    n_updates            | 2499     |\n",
      "|    policy_gradient_loss | -0.0409  |\n",
      "|    value_loss           | 1.17     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=0.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0.499     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 19000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4557533 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | 0.732     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0359   |\n",
      "|    n_updates            | 2516      |\n",
      "|    policy_gradient_loss | -0.0586   |\n",
      "|    value_loss           | 0.387     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34       |\n",
      "| time/              |          |\n",
      "|    fps             | 894      |\n",
      "|    iterations      | 149      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 19072    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 896        |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 19200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35963622 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 2533       |\n",
      "|    policy_gradient_loss | -0.0464    |\n",
      "|    value_loss           | 0.145      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 897       |\n",
      "|    iterations           | 151       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 19328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4818213 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.0862    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.078    |\n",
      "|    n_updates            | 2550      |\n",
      "|    policy_gradient_loss | -0.0385   |\n",
      "|    value_loss           | 0.0349    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 152       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 19456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3618725 |\n",
      "|    clip_fraction        | 0.106     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0723   |\n",
      "|    explained_variance   | -0.448    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0186   |\n",
      "|    n_updates            | 2567      |\n",
      "|    policy_gradient_loss | -0.0448   |\n",
      "|    value_loss           | 0.034     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=19500, episode_reward=85.73 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 85.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 19500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17673871 |\n",
      "|    clip_fraction        | 0.0717     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0735    |\n",
      "|    explained_variance   | -0.269     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0524    |\n",
      "|    n_updates            | 2584       |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.0249     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34       |\n",
      "| time/              |          |\n",
      "|    fps             | 894      |\n",
      "|    iterations      | 153      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 19584    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 897       |\n",
      "|    iterations           | 154       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 19712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6040478 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.587     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0639   |\n",
      "|    n_updates            | 2601      |\n",
      "|    policy_gradient_loss | -0.0535   |\n",
      "|    value_loss           | 0.0484    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 155       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 19840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7677345 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0943   |\n",
      "|    explained_variance   | 0.845     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0609   |\n",
      "|    n_updates            | 2618      |\n",
      "|    policy_gradient_loss | -0.0535   |\n",
      "|    value_loss           | 0.0598    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 156       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 19968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7942257 |\n",
      "|    clip_fraction        | 0.202     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.491     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.136    |\n",
      "|    n_updates            | 2635      |\n",
      "|    policy_gradient_loss | -0.0849   |\n",
      "|    value_loss           | 0.174     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=58.56 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 58.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 20000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24015076 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0377    |\n",
      "|    n_updates            | 2652       |\n",
      "|    policy_gradient_loss | -0.0576    |\n",
      "|    value_loss           | 0.316      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34       |\n",
      "| time/              |          |\n",
      "|    fps             | 897      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 20096    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 898        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 20224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30020535 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0994    |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0276    |\n",
      "|    n_updates            | 2669       |\n",
      "|    policy_gradient_loss | -0.0589    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 159       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 20352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6003981 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.134    |\n",
      "|    explained_variance   | -0.0829   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 1.16      |\n",
      "|    n_updates            | 2686      |\n",
      "|    policy_gradient_loss | -0.0306   |\n",
      "|    value_loss           | 2.36      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48587316 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | -0.416     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0655     |\n",
      "|    n_updates            | 2703       |\n",
      "|    policy_gradient_loss | -0.0716    |\n",
      "|    value_loss           | 0.403      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20500, episode_reward=22.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 22.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 20500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77285683 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.165     |\n",
      "|    explained_variance   | -0.934     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0908    |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.0646    |\n",
      "|    value_loss           | 0.0537     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 898      |\n",
      "|    iterations      | 161      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 20608    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 162       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 20736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6036887 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0963   |\n",
      "|    explained_variance   | -0.436    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0938   |\n",
      "|    n_updates            | 2737      |\n",
      "|    policy_gradient_loss | -0.079    |\n",
      "|    value_loss           | 0.0297    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 20864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14227082 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0761    |\n",
      "|    explained_variance   | -1.04      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0377    |\n",
      "|    n_updates            | 2754       |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 0.0158     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 164       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 20992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3095922 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0928   |\n",
      "|    explained_variance   | 0.0857    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0424   |\n",
      "|    n_updates            | 2771      |\n",
      "|    policy_gradient_loss | -0.0522   |\n",
      "|    value_loss           | 0.0412    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=23.41 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 23.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 21000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3829945 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0824   |\n",
      "|    explained_variance   | -0.0765   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0551   |\n",
      "|    n_updates            | 2788      |\n",
      "|    policy_gradient_loss | -0.0433   |\n",
      "|    value_loss           | 0.0587    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 165      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 21120    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 21248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19960459 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0523    |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0603    |\n",
      "|    n_updates            | 2805       |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.0864     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 167       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 21376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3007773 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.091    |\n",
      "|    explained_variance   | 0.224     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.081    |\n",
      "|    n_updates            | 2822      |\n",
      "|    policy_gradient_loss | -0.0457   |\n",
      "|    value_loss           | 0.229     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=21500, episode_reward=0.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0.429     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 21500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6263054 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0811   |\n",
      "|    explained_variance   | 0.14      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0822   |\n",
      "|    n_updates            | 2839      |\n",
      "|    policy_gradient_loss | -0.098    |\n",
      "|    value_loss           | 0.499     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 896      |\n",
      "|    iterations      | 168      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 21504    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 898       |\n",
      "|    iterations           | 169       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 21632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6843356 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | 0.101     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0423    |\n",
      "|    n_updates            | 2856      |\n",
      "|    policy_gradient_loss | -0.0829   |\n",
      "|    value_loss           | 0.327     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 33.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 900         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 21760       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.116626084 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.145      |\n",
      "|    explained_variance   | -0.152      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.43        |\n",
      "|    n_updates            | 2873        |\n",
      "|    policy_gradient_loss | -0.0563     |\n",
      "|    value_loss           | 0.989       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 171        |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 21888      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41479588 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0707    |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0862    |\n",
      "|    n_updates            | 2890       |\n",
      "|    policy_gradient_loss | -0.0476    |\n",
      "|    value_loss           | 0.154      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=48.65 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 48.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 22000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 4.4552684 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0718   |\n",
      "|    explained_variance   | 0.0782    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0962   |\n",
      "|    n_updates            | 2907      |\n",
      "|    policy_gradient_loss | -0.0786   |\n",
      "|    value_loss           | 0.0915    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 172      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 22016    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 22144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22034512 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 2924       |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.0616     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 22272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24427378 |\n",
      "|    clip_fraction        | 0.0547     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.041     |\n",
      "|    explained_variance   | -0.439     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0487    |\n",
      "|    n_updates            | 2941       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    value_loss           | 0.019      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 175       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 22400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8038579 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0734   |\n",
      "|    explained_variance   | 0.25      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0613   |\n",
      "|    n_updates            | 2958      |\n",
      "|    policy_gradient_loss | -0.0486   |\n",
      "|    value_loss           | 0.0268    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=22500, episode_reward=14.97 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 22500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25706515 |\n",
      "|    clip_fraction        | 0.0827     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0782    |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.061     |\n",
      "|    n_updates            | 2975       |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 0.0408     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 22656      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21177973 |\n",
      "|    clip_fraction        | 0.0676     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0877    |\n",
      "|    explained_variance   | -0.0524    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0386    |\n",
      "|    n_updates            | 2992       |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 22784      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43715978 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 3009       |\n",
      "|    policy_gradient_loss | -0.0547    |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 22912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59216774 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.5        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.054     |\n",
      "|    n_updates            | 3026       |\n",
      "|    policy_gradient_loss | -0.0868    |\n",
      "|    value_loss           | 0.432      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=12.63 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 12.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 23000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32125694 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0109     |\n",
      "|    n_updates            | 3043       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 0.42       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 23040    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 181       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 23168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5488331 |\n",
      "|    clip_fraction        | 0.218     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.149    |\n",
      "|    explained_variance   | 0.762     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0527   |\n",
      "|    n_updates            | 3060      |\n",
      "|    policy_gradient_loss | -0.0799   |\n",
      "|    value_loss           | 0.153     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 182       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 23296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6074916 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0799   |\n",
      "|    explained_variance   | 0.369     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.148     |\n",
      "|    n_updates            | 3077      |\n",
      "|    policy_gradient_loss | -0.0406   |\n",
      "|    value_loss           | 0.751     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 23424      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63175803 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0798    |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 3094       |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.63       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=23500, episode_reward=6.34 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.34       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 23500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13052833 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0772    |\n",
      "|    explained_variance   | -0.0515    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0911    |\n",
      "|    n_updates            | 3111       |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 184      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 23552    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 23680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68228537 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0929    |\n",
      "|    n_updates            | 3128       |\n",
      "|    policy_gradient_loss | -0.0723    |\n",
      "|    value_loss           | 0.0318     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 23808      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76927716 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.15      |\n",
      "|    explained_variance   | 0.35       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 3145       |\n",
      "|    policy_gradient_loss | -0.0683    |\n",
      "|    value_loss           | 0.037      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 187        |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 23936      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34564173 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.276      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0787    |\n",
      "|    n_updates            | 3162       |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    value_loss           | 0.0597     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=52.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 52.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 24000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45531508 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0728    |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0169    |\n",
      "|    n_updates            | 3179       |\n",
      "|    policy_gradient_loss | -0.0492    |\n",
      "|    value_loss           | 0.0479     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 188      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 24064    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 189       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 24192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5509721 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | 0.679     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0954   |\n",
      "|    n_updates            | 3196      |\n",
      "|    policy_gradient_loss | -0.0763   |\n",
      "|    value_loss           | 0.0739    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 190       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 24320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3804171 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.117    |\n",
      "|    explained_variance   | 0.217     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.329     |\n",
      "|    n_updates            | 3213      |\n",
      "|    policy_gradient_loss | -0.059    |\n",
      "|    value_loss           | 0.96      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 191        |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 24448      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19462064 |\n",
      "|    clip_fraction        | 0.0689     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.064     |\n",
      "|    explained_variance   | 0.699      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0334    |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=24500, episode_reward=8.64 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 8.64      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 24500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8428908 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0874   |\n",
      "|    explained_variance   | 0.453     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00213  |\n",
      "|    n_updates            | 3247      |\n",
      "|    policy_gradient_loss | -0.0543   |\n",
      "|    value_loss           | 0.209     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 192      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 24576    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 24704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30455703 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0982    |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0705     |\n",
      "|    n_updates            | 3264       |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.71       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 24832      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18177888 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0504    |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.06       |\n",
      "|    n_updates            | 3281       |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.407      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 195        |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 24960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44243026 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | -0.242     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.144     |\n",
      "|    n_updates            | 3298       |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.0394     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=20.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59006286 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.09      |\n",
      "|    explained_variance   | 0.0862     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0961    |\n",
      "|    n_updates            | 3315       |\n",
      "|    policy_gradient_loss | -0.0623    |\n",
      "|    value_loss           | 0.0235     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 25088    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 31.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 908      |\n",
      "|    iterations           | 197      |\n",
      "|    time_elapsed         | 27       |\n",
      "|    total_timesteps      | 25216    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 4.720296 |\n",
      "|    clip_fraction        | 0.302    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0849  |\n",
      "|    explained_variance   | -0.533   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.171   |\n",
      "|    n_updates            | 3332     |\n",
      "|    policy_gradient_loss | -0.104   |\n",
      "|    value_loss           | 0.0121   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 25344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16802736 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0932    |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000466  |\n",
      "|    n_updates            | 3349       |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.0743     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 25472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52666974 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.506      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 3366       |\n",
      "|    policy_gradient_loss | -0.0607    |\n",
      "|    value_loss           | 0.0736     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=25500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34533912 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0688    |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0262    |\n",
      "|    n_updates            | 3383       |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.115      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 25600    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 201        |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 25728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.81961274 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.064     |\n",
      "|    explained_variance   | 0.0796     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0528    |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 202       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 25856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7178322 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0685   |\n",
      "|    explained_variance   | 0.487     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.126    |\n",
      "|    n_updates            | 3417      |\n",
      "|    policy_gradient_loss | -0.0734   |\n",
      "|    value_loss           | 0.254     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 31.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 203      |\n",
      "|    time_elapsed         | 28       |\n",
      "|    total_timesteps      | 25984    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.448909 |\n",
      "|    clip_fraction        | 0.158    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.135   |\n",
      "|    explained_variance   | 0.599    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.095   |\n",
      "|    n_updates            | 3434     |\n",
      "|    policy_gradient_loss | -0.0551  |\n",
      "|    value_loss           | 0.129    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 0        |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 26000    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.067475 |\n",
      "|    clip_fraction        | 0.185    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.109   |\n",
      "|    explained_variance   | 0.483    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.217    |\n",
      "|    n_updates            | 3451     |\n",
      "|    policy_gradient_loss | -0.0611  |\n",
      "|    value_loss           | 0.685    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 204      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 26112    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 205       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 26240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7051203 |\n",
      "|    clip_fraction        | 0.0841    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0105   |\n",
      "|    explained_variance   | 0.608     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0281    |\n",
      "|    n_updates            | 3468      |\n",
      "|    policy_gradient_loss | -0.0121   |\n",
      "|    value_loss           | 0.105     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 206        |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 26368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10026534 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0438    |\n",
      "|    explained_variance   | -0.596     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0368    |\n",
      "|    n_updates            | 3485       |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 26496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64040744 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0812    |\n",
      "|    explained_variance   | -0.229     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.307      |\n",
      "|    n_updates            | 3502       |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.0826     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=26500, episode_reward=6.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.27       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 26500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17400727 |\n",
      "|    clip_fraction        | 0.0694     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0543    |\n",
      "|    explained_variance   | 0.0575     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0323    |\n",
      "|    n_updates            | 3519       |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 0.0466     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 208      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 26624    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 26752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07477399 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0717    |\n",
      "|    explained_variance   | 0.0682     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0838    |\n",
      "|    n_updates            | 3536       |\n",
      "|    policy_gradient_loss | -0.0284    |\n",
      "|    value_loss           | 0.0583     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 210       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 26880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3032341 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | -0.0969   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0497   |\n",
      "|    n_updates            | 3553      |\n",
      "|    policy_gradient_loss | -0.0335   |\n",
      "|    value_loss           | 0.115     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=6.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.54       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 27000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22804488 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0957    |\n",
      "|    explained_variance   | -0.295     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0621    |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    value_loss           | 0.075      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 211      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 27008    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 212        |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 27136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48462427 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.15      |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0618    |\n",
      "|    n_updates            | 3587       |\n",
      "|    policy_gradient_loss | -0.0643    |\n",
      "|    value_loss           | 0.0909     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 213       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 27264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4156599 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.124    |\n",
      "|    explained_variance   | 0.261     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0536   |\n",
      "|    n_updates            | 3604      |\n",
      "|    policy_gradient_loss | -0.0756   |\n",
      "|    value_loss           | 0.212     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 214       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 27392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6648528 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.242     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00245  |\n",
      "|    n_updates            | 3621      |\n",
      "|    policy_gradient_loss | -0.0571   |\n",
      "|    value_loss           | 0.389     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=27500, episode_reward=19.62 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 27500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23172994 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.165     |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0188    |\n",
      "|    n_updates            | 3638       |\n",
      "|    policy_gradient_loss | -0.0685    |\n",
      "|    value_loss           | 0.457      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 27520    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18055907 |\n",
      "|    clip_fraction        | 0.0905     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0867    |\n",
      "|    explained_variance   | 0.245      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.426      |\n",
      "|    n_updates            | 3655       |\n",
      "|    policy_gradient_loss | -0.0503    |\n",
      "|    value_loss           | 0.9        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 31.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 911      |\n",
      "|    iterations           | 217      |\n",
      "|    time_elapsed         | 30       |\n",
      "|    total_timesteps      | 27776    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 4.412685 |\n",
      "|    clip_fraction        | 0.284    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0848  |\n",
      "|    explained_variance   | 0.298    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0846  |\n",
      "|    n_updates            | 3672     |\n",
      "|    policy_gradient_loss | -0.0664  |\n",
      "|    value_loss           | 0.202    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 218       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 27904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2969811 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.133    |\n",
      "|    explained_variance   | 0.553     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0606   |\n",
      "|    n_updates            | 3689      |\n",
      "|    policy_gradient_loss | -0.0562   |\n",
      "|    value_loss           | 0.0859    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=21.84 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 21.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 28000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2505604 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0756   |\n",
      "|    explained_variance   | 0.56      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0794   |\n",
      "|    n_updates            | 3706      |\n",
      "|    policy_gradient_loss | -0.0369   |\n",
      "|    value_loss           | 0.0392    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 219      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 28032    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 220       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 28160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.4616978 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0823   |\n",
      "|    explained_variance   | -0.302    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.154    |\n",
      "|    n_updates            | 3723      |\n",
      "|    policy_gradient_loss | -0.0605   |\n",
      "|    value_loss           | 0.039     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 221       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 28288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3668989 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.116    |\n",
      "|    explained_variance   | -0.411    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0532   |\n",
      "|    n_updates            | 3740      |\n",
      "|    policy_gradient_loss | -0.042    |\n",
      "|    value_loss           | 0.0565    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 222       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 28416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3622141 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0896   |\n",
      "|    explained_variance   | -0.4      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0945   |\n",
      "|    n_updates            | 3757      |\n",
      "|    policy_gradient_loss | -0.0535   |\n",
      "|    value_loss           | 0.0428    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=28500, episode_reward=3.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 3.13      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 28500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7261315 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.482     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0947   |\n",
      "|    n_updates            | 3774      |\n",
      "|    policy_gradient_loss | -0.073    |\n",
      "|    value_loss           | 0.13      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 223      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 28544    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 31.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 224       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9603323 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | 0.19      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.059     |\n",
      "|    n_updates            | 3791      |\n",
      "|    policy_gradient_loss | -0.0625   |\n",
      "|    value_loss           | 0.466     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 28800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44314587 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0706    |\n",
      "|    n_updates            | 3808       |\n",
      "|    policy_gradient_loss | -0.0556    |\n",
      "|    value_loss           | 0.273      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 31.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 226        |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 28928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48028362 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0998    |\n",
      "|    explained_variance   | 0.595      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0686    |\n",
      "|    n_updates            | 3825       |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.358      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=31.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 31        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 29000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3355645 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0946   |\n",
      "|    explained_variance   | -0.0274   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.21      |\n",
      "|    n_updates            | 3842      |\n",
      "|    policy_gradient_loss | -0.0529   |\n",
      "|    value_loss           | 1.11      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 227      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 29056    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 228       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 29184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9064484 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0737   |\n",
      "|    explained_variance   | -0.211    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0475   |\n",
      "|    n_updates            | 3859      |\n",
      "|    policy_gradient_loss | -0.0497   |\n",
      "|    value_loss           | 0.12      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 229       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 29312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0390325 |\n",
      "|    clip_fraction        | 0.227     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0947   |\n",
      "|    explained_variance   | -0.256    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.124    |\n",
      "|    n_updates            | 3876      |\n",
      "|    policy_gradient_loss | -0.0816   |\n",
      "|    value_loss           | 0.118     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 230       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 29440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9381206 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0723   |\n",
      "|    explained_variance   | 0.456     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0754   |\n",
      "|    n_updates            | 3893      |\n",
      "|    policy_gradient_loss | -0.0545   |\n",
      "|    value_loss           | 0.0425    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=29500, episode_reward=58.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 58.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 29500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1270545 |\n",
      "|    clip_fraction        | 0.212     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.105     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 3910      |\n",
      "|    policy_gradient_loss | -0.0722   |\n",
      "|    value_loss           | 0.0184    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 231      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 29568    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 232        |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 29696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21572623 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | -0.199     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0415    |\n",
      "|    n_updates            | 3927       |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.0335     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 233        |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 29824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31257117 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | -0.288     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0795    |\n",
      "|    n_updates            | 3944       |\n",
      "|    policy_gradient_loss | -0.0609    |\n",
      "|    value_loss           | 0.054      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 234        |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 29952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78736246 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0815    |\n",
      "|    explained_variance   | 0.759      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.058     |\n",
      "|    n_updates            | 3961       |\n",
      "|    policy_gradient_loss | -0.0692    |\n",
      "|    value_loss           | 0.0857     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=41.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 30000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3766439 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0875   |\n",
      "|    explained_variance   | 0.285     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00944  |\n",
      "|    n_updates            | 3978      |\n",
      "|    policy_gradient_loss | -0.0318   |\n",
      "|    value_loss           | 0.323     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 898      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 30080    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 898        |\n",
      "|    iterations           | 236        |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 30208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20048162 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.206      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0261     |\n",
      "|    n_updates            | 3995       |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.592      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 237        |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 30336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49911246 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.147     |\n",
      "|    n_updates            | 4012       |\n",
      "|    policy_gradient_loss | -0.0767    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 30464      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79048944 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0502    |\n",
      "|    n_updates            | 4029       |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    value_loss           | 0.374      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30500, episode_reward=37.06 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44123277 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.107      |\n",
      "|    n_updates            | 4046       |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    value_loss           | 0.841      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 896      |\n",
      "|    iterations      | 239      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 30592    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 897        |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.82862777 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0938    |\n",
      "|    explained_variance   | -1.14      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0886    |\n",
      "|    n_updates            | 4063       |\n",
      "|    policy_gradient_loss | -0.0664    |\n",
      "|    value_loss           | 0.0795     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 30848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14606492 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.138     |\n",
      "|    explained_variance   | -0.452     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0836    |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.0376    |\n",
      "|    value_loss           | 0.0487     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 242       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 30976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6004752 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    explained_variance   | -0.0922   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.109    |\n",
      "|    n_updates            | 4097      |\n",
      "|    policy_gradient_loss | -0.0683   |\n",
      "|    value_loss           | 0.0126    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=54.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 31000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5552578 |\n",
      "|    clip_fraction        | 0.179     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0985   |\n",
      "|    explained_variance   | 0.342     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0865   |\n",
      "|    n_updates            | 4114      |\n",
      "|    policy_gradient_loss | -0.0705   |\n",
      "|    value_loss           | 0.017     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 898      |\n",
      "|    iterations      | 243      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 31104    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 244       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 31232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0282421 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.105    |\n",
      "|    explained_variance   | -0.79     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.109    |\n",
      "|    n_updates            | 4131      |\n",
      "|    policy_gradient_loss | -0.0469   |\n",
      "|    value_loss           | 0.0315    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 245        |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 31360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30366915 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0893    |\n",
      "|    explained_variance   | -0.756     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.052     |\n",
      "|    n_updates            | 4148       |\n",
      "|    policy_gradient_loss | -0.0608    |\n",
      "|    value_loss           | 0.0532     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 246        |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 31488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10402127 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0516    |\n",
      "|    n_updates            | 4165       |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    value_loss           | 0.049      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=31500, episode_reward=26.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 31500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3005068 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.135    |\n",
      "|    explained_variance   | 0.101     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0161    |\n",
      "|    n_updates            | 4182      |\n",
      "|    policy_gradient_loss | -0.0622   |\n",
      "|    value_loss           | 0.944     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 247      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 31616    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 248        |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 31744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22546476 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | -0.641     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 4199       |\n",
      "|    policy_gradient_loss | -0.0736    |\n",
      "|    value_loss           | 0.232      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 31872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32082856 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.217     |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 4216       |\n",
      "|    policy_gradient_loss | -0.0805    |\n",
      "|    value_loss           | 0.172      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=47.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 47.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 32000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2975194 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.124    |\n",
      "|    explained_variance   | -0.0524   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.107     |\n",
      "|    n_updates            | 4233      |\n",
      "|    policy_gradient_loss | -0.0559   |\n",
      "|    value_loss           | 1.66      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 250      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 32000    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 251        |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 32128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29752913 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0966    |\n",
      "|    explained_variance   | -0.228     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.000222   |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 32.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 252      |\n",
      "|    time_elapsed         | 35       |\n",
      "|    total_timesteps      | 32256    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.559109 |\n",
      "|    clip_fraction        | 0.227    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.159   |\n",
      "|    explained_variance   | 0.0679   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.116   |\n",
      "|    n_updates            | 4267     |\n",
      "|    policy_gradient_loss | -0.0768  |\n",
      "|    value_loss           | 0.064    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 253       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 32384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4937434 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.119    |\n",
      "|    explained_variance   | 0.537     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 4284      |\n",
      "|    policy_gradient_loss | -0.0642   |\n",
      "|    value_loss           | 0.024     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=32500, episode_reward=82.03 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 82         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 32500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47939515 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0981    |\n",
      "|    explained_variance   | 0.0458     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0841    |\n",
      "|    n_updates            | 4301       |\n",
      "|    policy_gradient_loss | -0.0624    |\n",
      "|    value_loss           | 0.0313     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 254      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 32512    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 255       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 32640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5592334 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0638   |\n",
      "|    explained_variance   | -0.457    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0713   |\n",
      "|    n_updates            | 4318      |\n",
      "|    policy_gradient_loss | -0.0715   |\n",
      "|    value_loss           | 0.0453    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 256       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7776845 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0671   |\n",
      "|    explained_variance   | 0.177     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0496   |\n",
      "|    n_updates            | 4335      |\n",
      "|    policy_gradient_loss | -0.0556   |\n",
      "|    value_loss           | 0.0704    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 257        |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 32896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08243671 |\n",
      "|    clip_fraction        | 0.0528     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0566    |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0434    |\n",
      "|    n_updates            | 4352       |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=53.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 53.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 33000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6552763 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.186     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0439   |\n",
      "|    n_updates            | 4369      |\n",
      "|    policy_gradient_loss | -0.0844   |\n",
      "|    value_loss           | 0.295     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 258      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 33024    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 259        |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 33152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16923445 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0519    |\n",
      "|    n_updates            | 4386       |\n",
      "|    policy_gradient_loss | -0.0566    |\n",
      "|    value_loss           | 0.143      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 260       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 33280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2954375 |\n",
      "|    clip_fraction        | 0.0951    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.473     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0673   |\n",
      "|    n_updates            | 4403      |\n",
      "|    policy_gradient_loss | -0.0436   |\n",
      "|    value_loss           | 0.185     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 33408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34454095 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | -0.0618    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00528    |\n",
      "|    n_updates            | 4420       |\n",
      "|    policy_gradient_loss | -0.0594    |\n",
      "|    value_loss           | 1.35       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=33500, episode_reward=35.98 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 33500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45157206 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0884    |\n",
      "|    explained_variance   | -0.0695    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00446   |\n",
      "|    n_updates            | 4437       |\n",
      "|    policy_gradient_loss | -0.0698    |\n",
      "|    value_loss           | 0.389      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 262      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 33536    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 263        |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 33664      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.85167813 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | -0.291     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 4454       |\n",
      "|    policy_gradient_loss | -0.0827    |\n",
      "|    value_loss           | 0.0806     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 264        |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 33792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48365372 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0756    |\n",
      "|    explained_variance   | -0.354     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.122     |\n",
      "|    n_updates            | 4471       |\n",
      "|    policy_gradient_loss | -0.0606    |\n",
      "|    value_loss           | 0.023      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 265        |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 33920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37058574 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0973    |\n",
      "|    explained_variance   | -0.777     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0965    |\n",
      "|    n_updates            | 4488       |\n",
      "|    policy_gradient_loss | -0.0707    |\n",
      "|    value_loss           | 0.0215     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=35.94 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 34000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43220612 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | -0.0609    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0742    |\n",
      "|    n_updates            | 4505       |\n",
      "|    policy_gradient_loss | -0.0681    |\n",
      "|    value_loss           | 0.0369     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 266      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 34048    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 32.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 267       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 34176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2796013 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.139    |\n",
      "|    explained_variance   | -0.152    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 4522      |\n",
      "|    policy_gradient_loss | -0.0524   |\n",
      "|    value_loss           | 0.0688    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 34304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16565558 |\n",
      "|    clip_fraction        | 0.0873     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0483    |\n",
      "|    explained_variance   | 0.821      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0184    |\n",
      "|    n_updates            | 4539       |\n",
      "|    policy_gradient_loss | -0.0402    |\n",
      "|    value_loss           | 0.0787     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 269        |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 34432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16602764 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.0292     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.045     |\n",
      "|    n_updates            | 4556       |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=34500, episode_reward=3.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 3.48      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 34500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3432422 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0928   |\n",
      "|    explained_variance   | 0.442     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0147   |\n",
      "|    n_updates            | 4573      |\n",
      "|    policy_gradient_loss | -0.0354   |\n",
      "|    value_loss           | 0.223     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 32.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 270      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 34560    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 34688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50976187 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.166     |\n",
      "|    explained_variance   | 0.579      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0363    |\n",
      "|    n_updates            | 4590       |\n",
      "|    policy_gradient_loss | -0.0576    |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 272        |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16619538 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0365    |\n",
      "|    n_updates            | 4607       |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 0.68       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 34944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40009952 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0818    |\n",
      "|    n_updates            | 4624       |\n",
      "|    policy_gradient_loss | -0.0799    |\n",
      "|    value_loss           | 0.355      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=11.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 11.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 35000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2030321 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | 0.148     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0854   |\n",
      "|    n_updates            | 4641      |\n",
      "|    policy_gradient_loss | -0.0493   |\n",
      "|    value_loss           | 0.158     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 274      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 35072    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 906       |\n",
      "|    iterations           | 275       |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 35200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4364644 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.092    |\n",
      "|    explained_variance   | -0.509    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.032    |\n",
      "|    n_updates            | 4658      |\n",
      "|    policy_gradient_loss | -0.0309   |\n",
      "|    value_loss           | 0.0716    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 35328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31932765 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.16      |\n",
      "|    explained_variance   | -0.45      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0827    |\n",
      "|    n_updates            | 4675       |\n",
      "|    policy_gradient_loss | -0.0541    |\n",
      "|    value_loss           | 0.0328     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 277       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 35456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1648304 |\n",
      "|    clip_fraction        | 0.23      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.157    |\n",
      "|    explained_variance   | -0.293    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.075    |\n",
      "|    n_updates            | 4692      |\n",
      "|    policy_gradient_loss | -0.0629   |\n",
      "|    value_loss           | 0.033     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=35500, episode_reward=60.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 60.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 35500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36464748 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | -0.311     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 4709       |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 0.0549     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 278      |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 35584    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 279        |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 35712      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35027146 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0505    |\n",
      "|    explained_variance   | 0.224      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0323    |\n",
      "|    n_updates            | 4726       |\n",
      "|    policy_gradient_loss | -0.0369    |\n",
      "|    value_loss           | 0.0543     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 35840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47525334 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.832      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 4743       |\n",
      "|    policy_gradient_loss | -0.0525    |\n",
      "|    value_loss           | 0.0566     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 281        |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 35968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62990195 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0887    |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0945    |\n",
      "|    n_updates            | 4760       |\n",
      "|    policy_gradient_loss | -0.0678    |\n",
      "|    value_loss           | 0.159      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=21.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 21.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 36000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6810074 |\n",
      "|    clip_fraction        | 0.224     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.195     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.111    |\n",
      "|    n_updates            | 4777      |\n",
      "|    policy_gradient_loss | -0.0743   |\n",
      "|    value_loss           | 0.0725    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 282      |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 36096    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 283        |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 36224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22936475 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.15      |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0884    |\n",
      "|    n_updates            | 4794       |\n",
      "|    policy_gradient_loss | -0.071     |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 284        |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 36352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34989214 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | -0.332     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0475    |\n",
      "|    n_updates            | 4811       |\n",
      "|    policy_gradient_loss | -0.0629    |\n",
      "|    value_loss           | 0.238      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 33.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 905      |\n",
      "|    iterations           | 285      |\n",
      "|    time_elapsed         | 40       |\n",
      "|    total_timesteps      | 36480    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.693815 |\n",
      "|    clip_fraction        | 0.121    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0849  |\n",
      "|    explained_variance   | -0.0952  |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0775  |\n",
      "|    n_updates            | 4828     |\n",
      "|    policy_gradient_loss | -0.0551  |\n",
      "|    value_loss           | 0.0843   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=36500, episode_reward=10.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 10        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 36500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2642216 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0747   |\n",
      "|    explained_variance   | -0.163    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0666   |\n",
      "|    n_updates            | 4845      |\n",
      "|    policy_gradient_loss | -0.0489   |\n",
      "|    value_loss           | 0.074     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 286      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 36608    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 287        |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 36736      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38899237 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0373    |\n",
      "|    explained_variance   | -0.664     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0362    |\n",
      "|    n_updates            | 4862       |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 0.0235     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 288       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5476072 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.187    |\n",
      "|    explained_variance   | 0.115     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0629   |\n",
      "|    n_updates            | 4879      |\n",
      "|    policy_gradient_loss | -0.0726   |\n",
      "|    value_loss           | 0.0184    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 289       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 36992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4716752 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | -0.315    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0675   |\n",
      "|    n_updates            | 4896      |\n",
      "|    policy_gradient_loss | -0.069    |\n",
      "|    value_loss           | 0.0892    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=46.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 47         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 37000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32584184 |\n",
      "|    clip_fraction        | 0.0607     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0633    |\n",
      "|    explained_variance   | -0.22      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0878    |\n",
      "|    n_updates            | 4913       |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    value_loss           | 0.0703     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 290      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 37120    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 291        |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 37248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40210074 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0863    |\n",
      "|    n_updates            | 4930       |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 0.0771     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 292        |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 37376      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.80627394 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0781    |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0676    |\n",
      "|    n_updates            | 4947       |\n",
      "|    policy_gradient_loss | -0.0455    |\n",
      "|    value_loss           | 0.0781     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=37500, episode_reward=25.34 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 25.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 37500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056746356 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0347     |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 4964        |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 37504    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 294       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 37632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1964111 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0991   |\n",
      "|    explained_variance   | 0.737     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0988   |\n",
      "|    n_updates            | 4981      |\n",
      "|    policy_gradient_loss | -0.0378   |\n",
      "|    value_loss           | 0.0974    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 295        |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 37760      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41774037 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0694    |\n",
      "|    n_updates            | 4998       |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    value_loss           | 0.573      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 296        |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 37888      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31692895 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0198     |\n",
      "|    n_updates            | 5015       |\n",
      "|    policy_gradient_loss | -0.0696    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=33.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 38000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15203297 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | -1.55      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0423    |\n",
      "|    n_updates            | 5032       |\n",
      "|    policy_gradient_loss | -0.0553    |\n",
      "|    value_loss           | 0.0645     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 297      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 38016    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 298       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 38144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5788086 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.137    |\n",
      "|    explained_variance   | -0.448    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 5049      |\n",
      "|    policy_gradient_loss | -0.0462   |\n",
      "|    value_loss           | 0.0234    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 299        |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 38272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20178077 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.165     |\n",
      "|    explained_variance   | -0.335     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 5066       |\n",
      "|    policy_gradient_loss | -0.0613    |\n",
      "|    value_loss           | 0.0315     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 300       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 38400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5917061 |\n",
      "|    clip_fraction        | 0.238     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.213    |\n",
      "|    explained_variance   | 0.441     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.127    |\n",
      "|    n_updates            | 5083      |\n",
      "|    policy_gradient_loss | -0.0832   |\n",
      "|    value_loss           | 0.0514    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=38500, episode_reward=4.71 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.71       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 38500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32253268 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.176     |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0702    |\n",
      "|    n_updates            | 5100       |\n",
      "|    policy_gradient_loss | -0.0539    |\n",
      "|    value_loss           | 0.0651     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 301      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 38528    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 302        |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 38656      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19246604 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0601    |\n",
      "|    explained_variance   | 0.728      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0456    |\n",
      "|    n_updates            | 5117       |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    value_loss           | 0.0691     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 303        |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 38784      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47150913 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.083     |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 5134       |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.0738     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 304       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8124263 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0931   |\n",
      "|    explained_variance   | 0.095     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0719   |\n",
      "|    n_updates            | 5151      |\n",
      "|    policy_gradient_loss | -0.0835   |\n",
      "|    value_loss           | 0.182     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=30.57 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 39000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39365393 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.693      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 5168       |\n",
      "|    policy_gradient_loss | -0.0776    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 305      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 39040    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 306        |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 39168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20552517 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.158     |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.337      |\n",
      "|    n_updates            | 5185       |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    value_loss           | 0.931      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 307        |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 39296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46604556 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | 0.157      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.191      |\n",
      "|    n_updates            | 5202       |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    value_loss           | 1.3        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 308       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 39424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5442057 |\n",
      "|    clip_fraction        | 0.258     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.145    |\n",
      "|    explained_variance   | -0.00436  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0992   |\n",
      "|    n_updates            | 5219      |\n",
      "|    policy_gradient_loss | -0.0878   |\n",
      "|    value_loss           | 0.286     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=39500, episode_reward=39.89 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 39.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 39500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0531746 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.533     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.081    |\n",
      "|    n_updates            | 5236      |\n",
      "|    policy_gradient_loss | -0.0565   |\n",
      "|    value_loss           | 0.114     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 309      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 39552    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 34.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 310      |\n",
      "|    time_elapsed         | 44       |\n",
      "|    total_timesteps      | 39680    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.532717 |\n",
      "|    clip_fraction        | 0.293    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.106   |\n",
      "|    explained_variance   | 0.0669   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0774  |\n",
      "|    n_updates            | 5253     |\n",
      "|    policy_gradient_loss | -0.0709  |\n",
      "|    value_loss           | 0.0668   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 311       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 39808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8509654 |\n",
      "|    clip_fraction        | 0.249     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.166    |\n",
      "|    explained_variance   | -0.617    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 5270      |\n",
      "|    policy_gradient_loss | -0.0345   |\n",
      "|    value_loss           | 0.0549    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 312        |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 39936      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26039362 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0889    |\n",
      "|    n_updates            | 5287       |\n",
      "|    policy_gradient_loss | -0.0553    |\n",
      "|    value_loss           | 0.0476     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0.576     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 40000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2844525 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0668   |\n",
      "|    explained_variance   | -0.576    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0464   |\n",
      "|    n_updates            | 5304      |\n",
      "|    policy_gradient_loss | -0.0405   |\n",
      "|    value_loss           | 0.0789    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 313      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 40064    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 314       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 40192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4037273 |\n",
      "|    clip_fraction        | 0.0951    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0418   |\n",
      "|    explained_variance   | 0.517     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0174   |\n",
      "|    n_updates            | 5321      |\n",
      "|    policy_gradient_loss | -0.0521   |\n",
      "|    value_loss           | 0.0468    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 315       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 40320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6506217 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0913   |\n",
      "|    explained_variance   | 0.339     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0836   |\n",
      "|    n_updates            | 5338      |\n",
      "|    policy_gradient_loss | -0.0849   |\n",
      "|    value_loss           | 0.247     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 316       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 40448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0305928 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0647   |\n",
      "|    explained_variance   | 0.482     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0463   |\n",
      "|    n_updates            | 5355      |\n",
      "|    policy_gradient_loss | -0.0592   |\n",
      "|    value_loss           | 0.132     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=40500, episode_reward=-10.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -10.4    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 40500    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.582892 |\n",
      "|    clip_fraction        | 0.121    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0917  |\n",
      "|    explained_variance   | 0.666    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0388  |\n",
      "|    n_updates            | 5372     |\n",
      "|    policy_gradient_loss | -0.0317  |\n",
      "|    value_loss           | 0.166    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 317      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 40576    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 318        |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 40704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26171693 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.042      |\n",
      "|    n_updates            | 5389       |\n",
      "|    policy_gradient_loss | -0.0585    |\n",
      "|    value_loss           | 0.27       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 319       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 40832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0640037 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0744   |\n",
      "|    explained_variance   | 0.716     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0626   |\n",
      "|    n_updates            | 5406      |\n",
      "|    policy_gradient_loss | -0.0726   |\n",
      "|    value_loss           | 0.0782    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 320       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3199601 |\n",
      "|    clip_fraction        | 0.102     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0607   |\n",
      "|    explained_variance   | -0.123    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00774   |\n",
      "|    n_updates            | 5423      |\n",
      "|    policy_gradient_loss | -0.033    |\n",
      "|    value_loss           | 0.073     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=-20.72 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -20.7     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 41000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6543689 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.172    |\n",
      "|    explained_variance   | -0.191    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.15     |\n",
      "|    n_updates            | 5440      |\n",
      "|    policy_gradient_loss | -0.0714   |\n",
      "|    value_loss           | 0.0316    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 321      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 41088    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 322        |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 41216      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36545575 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.0195     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.144     |\n",
      "|    n_updates            | 5457       |\n",
      "|    policy_gradient_loss | -0.081     |\n",
      "|    value_loss           | 0.0192     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 323        |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 41344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.89038265 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.155     |\n",
      "|    n_updates            | 5474       |\n",
      "|    policy_gradient_loss | -0.0893    |\n",
      "|    value_loss           | 0.0311     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 324        |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 41472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30505133 |\n",
      "|    clip_fraction        | 0.0896     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0698    |\n",
      "|    explained_variance   | -0.163     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.067     |\n",
      "|    n_updates            | 5491       |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.0535     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=41500, episode_reward=-1.01 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -1.01     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 41500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2405136 |\n",
      "|    clip_fraction        | 0.105     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | 0.322     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00411  |\n",
      "|    n_updates            | 5508      |\n",
      "|    policy_gradient_loss | -0.0397   |\n",
      "|    value_loss           | 0.0774    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 325      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 41600    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 326        |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 41728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63716406 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.1       |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0405    |\n",
      "|    n_updates            | 5525       |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 327       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 41856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6355058 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.138    |\n",
      "|    explained_variance   | 0.273     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.136    |\n",
      "|    n_updates            | 5542      |\n",
      "|    policy_gradient_loss | -0.0621   |\n",
      "|    value_loss           | 0.15      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 328        |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 41984      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34714377 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0816    |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.114     |\n",
      "|    n_updates            | 5559       |\n",
      "|    policy_gradient_loss | -0.0499    |\n",
      "|    value_loss           | 0.0611     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=18.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 18.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 42000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7821976 |\n",
      "|    clip_fraction        | 0.225     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.156    |\n",
      "|    explained_variance   | 0.101     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0895    |\n",
      "|    n_updates            | 5576      |\n",
      "|    policy_gradient_loss | -0.0698   |\n",
      "|    value_loss           | 1.11      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 329      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 42112    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 42240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23557183 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0654     |\n",
      "|    n_updates            | 5593       |\n",
      "|    policy_gradient_loss | -0.0542    |\n",
      "|    value_loss           | 0.518      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 42368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59745085 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0838    |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.091     |\n",
      "|    n_updates            | 5610       |\n",
      "|    policy_gradient_loss | -0.0573    |\n",
      "|    value_loss           | 0.0591     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 332        |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 42496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53786206 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.156     |\n",
      "|    n_updates            | 5627       |\n",
      "|    policy_gradient_loss | -0.0873    |\n",
      "|    value_loss           | 0.0254     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=42500, episode_reward=12.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 12.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 42500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41543627 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.118     |\n",
      "|    explained_variance   | -0.232     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 5644       |\n",
      "|    policy_gradient_loss | -0.0706    |\n",
      "|    value_loss           | 0.0205     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 333      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 42624    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 905       |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 42752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3567273 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.264     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0904   |\n",
      "|    n_updates            | 5661      |\n",
      "|    policy_gradient_loss | -0.0608   |\n",
      "|    value_loss           | 0.103     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 42880      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36565214 |\n",
      "|    clip_fraction        | 0.0763     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0849    |\n",
      "|    explained_variance   | 0.302      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.031     |\n",
      "|    n_updates            | 5678       |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.0637     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=5.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 5.61       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 43000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57412493 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0826    |\n",
      "|    explained_variance   | 0.601      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0771    |\n",
      "|    n_updates            | 5695       |\n",
      "|    policy_gradient_loss | -0.0608    |\n",
      "|    value_loss           | 0.0682     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 336      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 43136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63292456 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0948    |\n",
      "|    explained_variance   | 0.493      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0715    |\n",
      "|    n_updates            | 5712       |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 43264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55821306 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0837    |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 5729       |\n",
      "|    policy_gradient_loss | -0.0603    |\n",
      "|    value_loss           | 0.132      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 43392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6213467 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.116    |\n",
      "|    explained_variance   | 0.85      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0833   |\n",
      "|    n_updates            | 5746      |\n",
      "|    policy_gradient_loss | -0.0467   |\n",
      "|    value_loss           | 0.0791    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=43500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 43500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5008231 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0738   |\n",
      "|    explained_variance   | 0.757     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0553   |\n",
      "|    n_updates            | 5763      |\n",
      "|    policy_gradient_loss | -0.0747   |\n",
      "|    value_loss           | 0.176     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 340      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 43520    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 906       |\n",
      "|    iterations           | 341       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 43648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.3196986 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0379   |\n",
      "|    explained_variance   | 0.462     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 5780      |\n",
      "|    policy_gradient_loss | -0.0522   |\n",
      "|    value_loss           | 0.103     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 342       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 43776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4041922 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0555   |\n",
      "|    explained_variance   | -0.729    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0449   |\n",
      "|    n_updates            | 5797      |\n",
      "|    policy_gradient_loss | -0.0785   |\n",
      "|    value_loss           | 0.0309    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 343        |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 43904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14840695 |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.043     |\n",
      "|    explained_variance   | -0.0751    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0151    |\n",
      "|    n_updates            | 5814       |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.0998     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=16.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 16.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 44000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6429288 |\n",
      "|    clip_fraction        | 0.215     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0523   |\n",
      "|    explained_variance   | -1.5      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0752   |\n",
      "|    n_updates            | 5831      |\n",
      "|    policy_gradient_loss | -0.0569   |\n",
      "|    value_loss           | 0.0537    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 344      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 44032    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 34.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 907      |\n",
      "|    iterations           | 345      |\n",
      "|    time_elapsed         | 48       |\n",
      "|    total_timesteps      | 44160    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.143292 |\n",
      "|    clip_fraction        | 0.208    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0965  |\n",
      "|    explained_variance   | -0.265   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.085   |\n",
      "|    n_updates            | 5848     |\n",
      "|    policy_gradient_loss | -0.0669  |\n",
      "|    value_loss           | 0.0331   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 346        |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 44288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20873114 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.069     |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0503     |\n",
      "|    n_updates            | 5865       |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 347       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 44416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2527825 |\n",
      "|    clip_fraction        | 0.0869    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0507   |\n",
      "|    explained_variance   | 0.267     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0176   |\n",
      "|    n_updates            | 5882      |\n",
      "|    policy_gradient_loss | -0.0313   |\n",
      "|    value_loss           | 0.0287    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=44500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 44500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0227431 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0645   |\n",
      "|    explained_variance   | 0.526     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0732   |\n",
      "|    n_updates            | 5899      |\n",
      "|    policy_gradient_loss | -0.0609   |\n",
      "|    value_loss           | 0.115     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 348      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 44544    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 349        |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 44672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12612917 |\n",
      "|    clip_fraction        | 0.0579     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0304    |\n",
      "|    explained_variance   | 0.017      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 5916       |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    value_loss           | 0.0807     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 350       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 44800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4361962 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.834     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 5933      |\n",
      "|    policy_gradient_loss | -0.0523   |\n",
      "|    value_loss           | 0.0696    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 351        |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 44928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98055047 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0595    |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 5950       |\n",
      "|    policy_gradient_loss | -0.0569    |\n",
      "|    value_loss           | 0.0589     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 45000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18371244 |\n",
      "|    clip_fraction        | 0.046      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0332    |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0454    |\n",
      "|    n_updates            | 5967       |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 0.0151     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 45056    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 353       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 45184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0031042 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0676   |\n",
      "|    explained_variance   | 0.586     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.12     |\n",
      "|    n_updates            | 5984      |\n",
      "|    policy_gradient_loss | -0.0881   |\n",
      "|    value_loss           | 0.0113    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 45312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53221786 |\n",
      "|    clip_fraction        | 0.0818     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.03      |\n",
      "|    explained_variance   | -0.262     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0156    |\n",
      "|    n_updates            | 6001       |\n",
      "|    policy_gradient_loss | -0.0239    |\n",
      "|    value_loss           | 0.0434     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 355        |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 45440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54464924 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0624    |\n",
      "|    explained_variance   | -0.0985    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0529    |\n",
      "|    n_updates            | 6018       |\n",
      "|    policy_gradient_loss | -0.0458    |\n",
      "|    value_loss           | 0.0165     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=45500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 45500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24340849 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.118     |\n",
      "|    explained_variance   | -0.177     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0703    |\n",
      "|    n_updates            | 6035       |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.0189     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 356      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 45568    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 357       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 45696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5559783 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0817   |\n",
      "|    explained_variance   | 0.275     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0587   |\n",
      "|    n_updates            | 6052      |\n",
      "|    policy_gradient_loss | -0.0685   |\n",
      "|    value_loss           | 0.0582    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 358       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 45824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5274534 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0751   |\n",
      "|    explained_variance   | 0.349     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 6069      |\n",
      "|    policy_gradient_loss | -0.064    |\n",
      "|    value_loss           | 0.0293    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 359       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 45952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0727031 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0798   |\n",
      "|    explained_variance   | 0.679     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0715   |\n",
      "|    n_updates            | 6086      |\n",
      "|    policy_gradient_loss | -0.0568   |\n",
      "|    value_loss           | 0.0575    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 46000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76424533 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0445    |\n",
      "|    explained_variance   | -0.223     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0494    |\n",
      "|    n_updates            | 6103       |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.149      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 360      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 46080    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 361        |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 46208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36721098 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0642    |\n",
      "|    explained_variance   | 0.0412     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0656    |\n",
      "|    n_updates            | 6120       |\n",
      "|    policy_gradient_loss | -0.0522    |\n",
      "|    value_loss           | 0.067      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 362       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 46336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5367707 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0776   |\n",
      "|    explained_variance   | 0.823     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0749   |\n",
      "|    n_updates            | 6137      |\n",
      "|    policy_gradient_loss | -0.0621   |\n",
      "|    value_loss           | 0.0955    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 35.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 911         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 46464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078356765 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0412     |\n",
      "|    explained_variance   | 0.057       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.26        |\n",
      "|    n_updates            | 6154        |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.626       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=46500, episode_reward=38.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 38.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 46500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0588813 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0658   |\n",
      "|    explained_variance   | 0.886     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 6171      |\n",
      "|    policy_gradient_loss | -0.0488   |\n",
      "|    value_loss           | 0.0643    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 364      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 46592    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 365        |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 46720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30726206 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0743    |\n",
      "|    explained_variance   | -1.2       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.065     |\n",
      "|    n_updates            | 6188       |\n",
      "|    policy_gradient_loss | -0.0473    |\n",
      "|    value_loss           | 0.05       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 366       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 46848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2172054 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0708   |\n",
      "|    explained_variance   | 0.0704    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.073    |\n",
      "|    n_updates            | 6205      |\n",
      "|    policy_gradient_loss | -0.0477   |\n",
      "|    value_loss           | 0.015     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 46976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18903902 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.071     |\n",
      "|    explained_variance   | -1.01      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0592    |\n",
      "|    n_updates            | 6222       |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.0175     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=25.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 47000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27045923 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | 0.0459     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0621    |\n",
      "|    n_updates            | 6239       |\n",
      "|    policy_gradient_loss | -0.0696    |\n",
      "|    value_loss           | 0.0683     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 368      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 47104    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 369       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 47232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9413253 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0726   |\n",
      "|    explained_variance   | -0.013    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.105    |\n",
      "|    n_updates            | 6256      |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 0.0379    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 370        |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 47360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.93374753 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0744    |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0965    |\n",
      "|    n_updates            | 6273       |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    value_loss           | 0.06       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 371       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 47488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8704189 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.066    |\n",
      "|    explained_variance   | 0.114     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.109    |\n",
      "|    n_updates            | 6290      |\n",
      "|    policy_gradient_loss | -0.0559   |\n",
      "|    value_loss           | 0.0937    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=47500, episode_reward=14.82 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 14.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 47500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4184293 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0725   |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.135    |\n",
      "|    n_updates            | 6307      |\n",
      "|    policy_gradient_loss | -0.0869   |\n",
      "|    value_loss           | 0.181     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 907      |\n",
      "|    iterations      | 372      |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 47616    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 373        |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 47744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40974423 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.115     |\n",
      "|    n_updates            | 6324       |\n",
      "|    policy_gradient_loss | -0.0489    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 374       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 47872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8023149 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0684   |\n",
      "|    explained_variance   | 0.799     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0825   |\n",
      "|    n_updates            | 6341      |\n",
      "|    policy_gradient_loss | -0.0648   |\n",
      "|    value_loss           | 0.0828    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-3.22 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -3.22    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 48000    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.195923 |\n",
      "|    clip_fraction        | 0.233    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.117   |\n",
      "|    explained_variance   | 0.0234   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.495    |\n",
      "|    n_updates            | 6358     |\n",
      "|    policy_gradient_loss | -0.0643  |\n",
      "|    value_loss           | 1.67     |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 375      |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 48000    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 376       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 48128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5356937 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0659   |\n",
      "|    explained_variance   | -0.215    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0691   |\n",
      "|    n_updates            | 6375      |\n",
      "|    policy_gradient_loss | -0.039    |\n",
      "|    value_loss           | 0.022     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 377        |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 48256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50133073 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0363    |\n",
      "|    explained_variance   | 0.0101     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0818    |\n",
      "|    n_updates            | 6392       |\n",
      "|    policy_gradient_loss | -0.05      |\n",
      "|    value_loss           | 0.0516     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 378       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 48384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.1932435 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.073    |\n",
      "|    explained_variance   | -0.536    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0951   |\n",
      "|    n_updates            | 6409      |\n",
      "|    policy_gradient_loss | 0.0918    |\n",
      "|    value_loss           | 0.0298    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=48500, episode_reward=68.38 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 68.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 48500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.89409554 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.157     |\n",
      "|    explained_variance   | 0.0944     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 6426       |\n",
      "|    policy_gradient_loss | -0.0708    |\n",
      "|    value_loss           | 0.0248     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 907      |\n",
      "|    iterations      | 379      |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 48512    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 380       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 48640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5554463 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.566     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 6443      |\n",
      "|    policy_gradient_loss | -0.0642   |\n",
      "|    value_loss           | 0.0324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 381       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 48768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3114708 |\n",
      "|    clip_fraction        | 0.107     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0616   |\n",
      "|    explained_variance   | -1.01     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 6460      |\n",
      "|    policy_gradient_loss | -0.0523   |\n",
      "|    value_loss           | 0.0464    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 382       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 48896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3547726 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0665   |\n",
      "|    explained_variance   | 0.66      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0654   |\n",
      "|    n_updates            | 6477      |\n",
      "|    policy_gradient_loss | -0.0669   |\n",
      "|    value_loss           | 0.0553    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=38.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 38.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 49000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5845469 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.013     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0548   |\n",
      "|    n_updates            | 6494      |\n",
      "|    policy_gradient_loss | -0.0723   |\n",
      "|    value_loss           | 0.673     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 383      |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 49024    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 384       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6133108 |\n",
      "|    clip_fraction        | 0.299     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0913   |\n",
      "|    explained_variance   | 0.516     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0822   |\n",
      "|    n_updates            | 6511      |\n",
      "|    policy_gradient_loss | -0.0793   |\n",
      "|    value_loss           | 0.103     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 385       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 49280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5955248 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0791   |\n",
      "|    explained_variance   | 0.71      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0307   |\n",
      "|    n_updates            | 6528      |\n",
      "|    policy_gradient_loss | -0.0328   |\n",
      "|    value_loss           | 0.194     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 386        |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 49408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55451995 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.152     |\n",
      "|    explained_variance   | 0.0496     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.553      |\n",
      "|    n_updates            | 6545       |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 1.61       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=49500, episode_reward=88.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 88         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 49500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98559797 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.438     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0286     |\n",
      "|    n_updates            | 6562       |\n",
      "|    policy_gradient_loss | -0.0673    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 387      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 49536    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 49664      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73074114 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | -0.227     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0908    |\n",
      "|    n_updates            | 6579       |\n",
      "|    policy_gradient_loss | -0.0757    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 49792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47101778 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0738    |\n",
      "|    n_updates            | 6596       |\n",
      "|    policy_gradient_loss | -0.0723    |\n",
      "|    value_loss           | 0.0383     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 390       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 49920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5604838 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.164    |\n",
      "|    explained_variance   | -0.466    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0448   |\n",
      "|    n_updates            | 6613      |\n",
      "|    policy_gradient_loss | -0.0591   |\n",
      "|    value_loss           | 0.0317    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=75.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 75.3     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 50000    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.432543 |\n",
      "|    clip_fraction        | 0.244    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.13    |\n",
      "|    explained_variance   | 0.299    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0648  |\n",
      "|    n_updates            | 6630     |\n",
      "|    policy_gradient_loss | -0.0705  |\n",
      "|    value_loss           | 0.0553   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 391      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 50048    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 392       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 50176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8544396 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0739   |\n",
      "|    explained_variance   | -0.297    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.111    |\n",
      "|    n_updates            | 6647      |\n",
      "|    policy_gradient_loss | -0.0694   |\n",
      "|    value_loss           | 0.0902    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 393       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 50304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7937341 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0917   |\n",
      "|    explained_variance   | 0.0169    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.126    |\n",
      "|    n_updates            | 6664      |\n",
      "|    policy_gradient_loss | -0.0561   |\n",
      "|    value_loss           | 0.138     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 394       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 50432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4717414 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0849   |\n",
      "|    explained_variance   | 0.0978    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0543   |\n",
      "|    n_updates            | 6681      |\n",
      "|    policy_gradient_loss | -0.0609   |\n",
      "|    value_loss           | 0.258     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=50500, episode_reward=50.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 50.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 50500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06800887 |\n",
      "|    clip_fraction        | 0.0372     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0201    |\n",
      "|    explained_variance   | 0.652      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00991    |\n",
      "|    n_updates            | 6698       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 395      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 50560    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 34.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 396        |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 50688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19474354 |\n",
      "|    clip_fraction        | 0.0634     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0373    |\n",
      "|    explained_variance   | -0.0701    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0387     |\n",
      "|    n_updates            | 6715       |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 0.4        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 397       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 50816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6032218 |\n",
      "|    clip_fraction        | 0.0786    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0512   |\n",
      "|    explained_variance   | 0.183     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.185     |\n",
      "|    n_updates            | 6732      |\n",
      "|    policy_gradient_loss | -0.0226   |\n",
      "|    value_loss           | 1.68      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 398       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 50944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4129908 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.692     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00277  |\n",
      "|    n_updates            | 6749      |\n",
      "|    policy_gradient_loss | -0.046    |\n",
      "|    value_loss           | 0.275     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=31.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 31.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 51000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6518817 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0891   |\n",
      "|    explained_variance   | -0.944    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0633   |\n",
      "|    n_updates            | 6766      |\n",
      "|    policy_gradient_loss | -0.0672   |\n",
      "|    value_loss           | 0.0773    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 399      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 51072    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 400        |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64570534 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | -0.0868    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0641    |\n",
      "|    n_updates            | 6783       |\n",
      "|    policy_gradient_loss | -0.063     |\n",
      "|    value_loss           | 0.0215     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 401        |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 51328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32804182 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | -0.081     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0796    |\n",
      "|    n_updates            | 6800       |\n",
      "|    policy_gradient_loss | -0.0451    |\n",
      "|    value_loss           | 0.0321     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 402        |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 51456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33607286 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.155     |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 6817       |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 0.0399     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=51500, episode_reward=5.18 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 5.18       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 51500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60115427 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0826    |\n",
      "|    explained_variance   | 0.0872     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0523    |\n",
      "|    n_updates            | 6834       |\n",
      "|    policy_gradient_loss | -0.0566    |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 403      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 51584    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 404       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 51712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9814211 |\n",
      "|    clip_fraction        | 0.174     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0611   |\n",
      "|    explained_variance   | 0.715     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.127    |\n",
      "|    n_updates            | 6851      |\n",
      "|    policy_gradient_loss | -0.0673   |\n",
      "|    value_loss           | 0.0773    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 405       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 51840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7714306 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.123    |\n",
      "|    explained_variance   | 0.371     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0429   |\n",
      "|    n_updates            | 6868      |\n",
      "|    policy_gradient_loss | -0.0733   |\n",
      "|    value_loss           | 0.719     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 406       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 51968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9477726 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0816   |\n",
      "|    explained_variance   | 0.236     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0912   |\n",
      "|    n_updates            | 6885      |\n",
      "|    policy_gradient_loss | -0.0699   |\n",
      "|    value_loss           | 0.224     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=39.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 39.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 52000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64223135 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0789    |\n",
      "|    n_updates            | 6902       |\n",
      "|    policy_gradient_loss | -0.0618    |\n",
      "|    value_loss           | 0.289      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 407      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 52096    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 408        |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 52224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54880023 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0963    |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.119      |\n",
      "|    n_updates            | 6919       |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 1.95       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 52352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23443493 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0816     |\n",
      "|    n_updates            | 6936       |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 1.16       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 410       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 52480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7752721 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0851   |\n",
      "|    explained_variance   | -1.27     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0559   |\n",
      "|    n_updates            | 6953      |\n",
      "|    policy_gradient_loss | -0.0494   |\n",
      "|    value_loss           | 0.0637    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=52500, episode_reward=28.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 28        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 52500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3043946 |\n",
      "|    clip_fraction        | 0.12      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0925   |\n",
      "|    explained_variance   | -0.11     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0549   |\n",
      "|    n_updates            | 6970      |\n",
      "|    policy_gradient_loss | -0.0497   |\n",
      "|    value_loss           | 0.0426    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 411      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 52608    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 35       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 412      |\n",
      "|    time_elapsed         | 57       |\n",
      "|    total_timesteps      | 52736    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.421017 |\n",
      "|    clip_fraction        | 0.225    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.154   |\n",
      "|    explained_variance   | -0.562   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0838  |\n",
      "|    n_updates            | 6987     |\n",
      "|    policy_gradient_loss | -0.0812  |\n",
      "|    value_loss           | 0.0449   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 413       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 52864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3744231 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.0721    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.144    |\n",
      "|    n_updates            | 7004      |\n",
      "|    policy_gradient_loss | -0.0812   |\n",
      "|    value_loss           | 0.0774    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 414        |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 52992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38574147 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.186     |\n",
      "|    explained_variance   | -0.812     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 7021       |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    value_loss           | 0.0601     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=23.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 23.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 53000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8659742 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0627   |\n",
      "|    explained_variance   | 0.344     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.125    |\n",
      "|    n_updates            | 7038      |\n",
      "|    policy_gradient_loss | -0.0469   |\n",
      "|    value_loss           | 0.0953    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 415      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 53120    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 416        |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45769003 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0435    |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0164    |\n",
      "|    n_updates            | 7055       |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.116      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 417        |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 53376      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22848186 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0846    |\n",
      "|    explained_variance   | 0.269      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0967     |\n",
      "|    n_updates            | 7072       |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 0.655      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=53500, episode_reward=25.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 25.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 53500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9680566 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.136    |\n",
      "|    explained_variance   | 0.448     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.145     |\n",
      "|    n_updates            | 7089      |\n",
      "|    policy_gradient_loss | -0.0383   |\n",
      "|    value_loss           | 0.123     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 418      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 53504    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 419        |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 53632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58180493 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | 0.676      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 7106       |\n",
      "|    policy_gradient_loss | -0.0647    |\n",
      "|    value_loss           | 0.264      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 420       |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 53760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2502306 |\n",
      "|    clip_fraction        | 0.296     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.18     |\n",
      "|    explained_variance   | -0.072    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0711    |\n",
      "|    n_updates            | 7123      |\n",
      "|    policy_gradient_loss | -0.0702   |\n",
      "|    value_loss           | 0.796     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 421        |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 53888      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42753887 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.682      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0753    |\n",
      "|    n_updates            | 7140       |\n",
      "|    policy_gradient_loss | -0.0749    |\n",
      "|    value_loss           | 0.0616     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=16.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 16.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 54000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1568723 |\n",
      "|    clip_fraction        | 0.267     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.167    |\n",
      "|    explained_variance   | -0.665    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0884   |\n",
      "|    n_updates            | 7157      |\n",
      "|    policy_gradient_loss | -0.0739   |\n",
      "|    value_loss           | 0.0384    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 422      |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 54016    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 423       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 54144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6573156 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0802   |\n",
      "|    explained_variance   | 0.127     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 7174      |\n",
      "|    policy_gradient_loss | -0.0931   |\n",
      "|    value_loss           | 0.0381    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 424       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 54272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7402539 |\n",
      "|    clip_fraction        | 0.24      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | -1.26     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.133    |\n",
      "|    n_updates            | 7191      |\n",
      "|    policy_gradient_loss | -0.0745   |\n",
      "|    value_loss           | 0.0231    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 425        |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 54400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71989626 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.156      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0767    |\n",
      "|    n_updates            | 7208       |\n",
      "|    policy_gradient_loss | -0.0809    |\n",
      "|    value_loss           | 0.0712     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=54500, episode_reward=26.19 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 54500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4209428 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0817   |\n",
      "|    explained_variance   | 0.195     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0747   |\n",
      "|    n_updates            | 7225      |\n",
      "|    policy_gradient_loss | -0.0598   |\n",
      "|    value_loss           | 0.119     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 426      |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 54528    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 427       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 54656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8919929 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0765   |\n",
      "|    explained_variance   | 0.632     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0877   |\n",
      "|    n_updates            | 7242      |\n",
      "|    policy_gradient_loss | -0.0723   |\n",
      "|    value_loss           | 0.109     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 428       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 54784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2661102 |\n",
      "|    clip_fraction        | 0.085     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0573   |\n",
      "|    explained_variance   | -0.242    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.113     |\n",
      "|    n_updates            | 7259      |\n",
      "|    policy_gradient_loss | -0.0458   |\n",
      "|    value_loss           | 2.4       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 429        |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 54912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20313975 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0919    |\n",
      "|    explained_variance   | 0.808      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0855    |\n",
      "|    n_updates            | 7276       |\n",
      "|    policy_gradient_loss | -0.0566    |\n",
      "|    value_loss           | 0.0793     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=35.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 55000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.82855785 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0939    |\n",
      "|    explained_variance   | 0.596      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.05      |\n",
      "|    n_updates            | 7293       |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 430      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 55040    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 431        |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 55168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37946743 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0335     |\n",
      "|    n_updates            | 7310       |\n",
      "|    policy_gradient_loss | -0.0486    |\n",
      "|    value_loss           | 0.979      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 432        |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29042995 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.195     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0384    |\n",
      "|    n_updates            | 7327       |\n",
      "|    policy_gradient_loss | -0.0768    |\n",
      "|    value_loss           | 0.277      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 433        |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 55424      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68960893 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0509    |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0821    |\n",
      "|    n_updates            | 7344       |\n",
      "|    policy_gradient_loss | -0.0609    |\n",
      "|    value_loss           | 0.0286     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=55500, episode_reward=57.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 57.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 55500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7559055 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0698   |\n",
      "|    explained_variance   | -0.271    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0468   |\n",
      "|    n_updates            | 7361      |\n",
      "|    policy_gradient_loss | -0.0544   |\n",
      "|    value_loss           | 0.0198    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 434      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 55552    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 435        |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 55680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11686248 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0615    |\n",
      "|    explained_variance   | -0.411     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0393    |\n",
      "|    n_updates            | 7378       |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    value_loss           | 0.019      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 436        |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 55808      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06625177 |\n",
      "|    clip_fraction        | 0.0717     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | -0.00195   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 7395       |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.0781     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 437       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 55936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1410234 |\n",
      "|    clip_fraction        | 0.0933    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.078    |\n",
      "|    explained_variance   | 0.292     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0554   |\n",
      "|    n_updates            | 7412      |\n",
      "|    policy_gradient_loss | -0.0357   |\n",
      "|    value_loss           | 0.0451    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=53.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 53.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 56000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2017927 |\n",
      "|    clip_fraction        | 0.0813    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0597   |\n",
      "|    explained_variance   | 0.927     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 7429      |\n",
      "|    policy_gradient_loss | -0.0318   |\n",
      "|    value_loss           | 0.0774    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 35.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 438      |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 56064    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 35.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 439        |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 56192      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41501498 |\n",
      "|    clip_fraction        | 0.0928     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0647    |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00776   |\n",
      "|    n_updates            | 7446       |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 0.843      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 440       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 56320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2806347 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0946   |\n",
      "|    explained_variance   | 0.672     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.019     |\n",
      "|    n_updates            | 7463      |\n",
      "|    policy_gradient_loss | -0.0451   |\n",
      "|    value_loss           | 0.223     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 35.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 441       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 56448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1806045 |\n",
      "|    clip_fraction        | 0.218     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0823   |\n",
      "|    explained_variance   | 0.647     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 7480      |\n",
      "|    policy_gradient_loss | -0.0802   |\n",
      "|    value_loss           | 0.144     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=56500, episode_reward=27.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 27.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 56500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5162942 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.099    |\n",
      "|    explained_variance   | 0.453     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.189     |\n",
      "|    n_updates            | 7497      |\n",
      "|    policy_gradient_loss | -0.064    |\n",
      "|    value_loss           | 1.07      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 442      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 56576    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 443        |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 56704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22275229 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0377     |\n",
      "|    n_updates            | 7514       |\n",
      "|    policy_gradient_loss | -0.0565    |\n",
      "|    value_loss           | 0.341      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 444        |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 56832      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.89226216 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0964    |\n",
      "|    explained_variance   | -0.216     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0669    |\n",
      "|    n_updates            | 7531       |\n",
      "|    policy_gradient_loss | -0.0549    |\n",
      "|    value_loss           | 0.0352     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 445        |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 56960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48235118 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0874    |\n",
      "|    explained_variance   | -0.233     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0663    |\n",
      "|    n_updates            | 7548       |\n",
      "|    policy_gradient_loss | -0.0416    |\n",
      "|    value_loss           | 0.0288     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=57000, episode_reward=17.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 17.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 57000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.61606365 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0982    |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0786    |\n",
      "|    n_updates            | 7565       |\n",
      "|    policy_gradient_loss | -0.0708    |\n",
      "|    value_loss           | 0.0233     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 446      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 57088    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 447       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 57216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3620697 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.17     |\n",
      "|    explained_variance   | 0.0321    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.127    |\n",
      "|    n_updates            | 7582      |\n",
      "|    policy_gradient_loss | -0.0564   |\n",
      "|    value_loss           | 0.0646    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 448       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7337711 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.134    |\n",
      "|    explained_variance   | 0.103     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0898   |\n",
      "|    n_updates            | 7599      |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 0.0546    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 449       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 57472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7859186 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0706   |\n",
      "|    explained_variance   | 0.0425    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 7616      |\n",
      "|    policy_gradient_loss | -0.0513   |\n",
      "|    value_loss           | 0.0514    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=57500, episode_reward=36.87 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 57500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29309505 |\n",
      "|    clip_fraction        | 0.0602     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0275    |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00977   |\n",
      "|    n_updates            | 7633       |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    value_loss           | 0.0927     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 450      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 57600    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 36       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 451      |\n",
      "|    time_elapsed         | 63       |\n",
      "|    total_timesteps      | 57728    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.270836 |\n",
      "|    clip_fraction        | 0.091    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0555  |\n",
      "|    explained_variance   | 0.472    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.042   |\n",
      "|    n_updates            | 7650     |\n",
      "|    policy_gradient_loss | -0.0411  |\n",
      "|    value_loss           | 0.214    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 36       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 452      |\n",
      "|    time_elapsed         | 63       |\n",
      "|    total_timesteps      | 57856    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.695192 |\n",
      "|    clip_fraction        | 0.146    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0808  |\n",
      "|    explained_variance   | 0.562    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0951  |\n",
      "|    n_updates            | 7667     |\n",
      "|    policy_gradient_loss | -0.0522  |\n",
      "|    value_loss           | 0.135    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 453       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 57984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4250652 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0794   |\n",
      "|    explained_variance   | 0.674     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0723   |\n",
      "|    n_updates            | 7684      |\n",
      "|    policy_gradient_loss | -0.0728   |\n",
      "|    value_loss           | 0.172     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=67.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 67.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 58000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3776826 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.142    |\n",
      "|    explained_variance   | -0.148    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.283     |\n",
      "|    n_updates            | 7701      |\n",
      "|    policy_gradient_loss | -0.0543   |\n",
      "|    value_loss           | 1.53      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36       |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 454      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 58112    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 455        |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 58240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47191024 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0572    |\n",
      "|    explained_variance   | 0.915      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0701    |\n",
      "|    n_updates            | 7718       |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    value_loss           | 0.0373     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 456       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 58368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5813058 |\n",
      "|    clip_fraction        | 0.0694    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0374   |\n",
      "|    explained_variance   | -0.03     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00532   |\n",
      "|    n_updates            | 7735      |\n",
      "|    policy_gradient_loss | -0.0286   |\n",
      "|    value_loss           | 0.0286    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 457        |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 58496      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39407605 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0576    |\n",
      "|    explained_variance   | -1.07      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0615    |\n",
      "|    n_updates            | 7752       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=58500, episode_reward=51.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 58500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3951475 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.149    |\n",
      "|    explained_variance   | 0.219     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.122    |\n",
      "|    n_updates            | 7769      |\n",
      "|    policy_gradient_loss | -0.074    |\n",
      "|    value_loss           | 0.0144    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 458      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 58624    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 459       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 58752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3042982 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0938   |\n",
      "|    explained_variance   | 0.135     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0714   |\n",
      "|    n_updates            | 7786      |\n",
      "|    policy_gradient_loss | -0.0526   |\n",
      "|    value_loss           | 0.076     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 460       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 58880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2836539 |\n",
      "|    clip_fraction        | 0.057     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0305   |\n",
      "|    explained_variance   | -0.187    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0694   |\n",
      "|    n_updates            | 7803      |\n",
      "|    policy_gradient_loss | -0.0268   |\n",
      "|    value_loss           | 0.0568    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=59000, episode_reward=53.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 59000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77475715 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0633    |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 7820       |\n",
      "|    policy_gradient_loss | -0.0877    |\n",
      "|    value_loss           | 0.0895     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 461      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 59008    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 462        |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 59136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58429265 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 7837       |\n",
      "|    policy_gradient_loss | -0.0719    |\n",
      "|    value_loss           | 0.514      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 463       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 59264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3124681 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.063    |\n",
      "|    explained_variance   | 0.357     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0769   |\n",
      "|    n_updates            | 7854      |\n",
      "|    policy_gradient_loss | -0.0532   |\n",
      "|    value_loss           | 0.244     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 464        |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.92359054 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0867    |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0192    |\n",
      "|    n_updates            | 7871       |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    value_loss           | 0.249      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=59500, episode_reward=69.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 69.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 59500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3329142 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0908   |\n",
      "|    explained_variance   | 0.235     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.907     |\n",
      "|    n_updates            | 7888      |\n",
      "|    policy_gradient_loss | -0.0309   |\n",
      "|    value_loss           | 1.8       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 465      |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 59520    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 59648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35439444 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0722     |\n",
      "|    n_updates            | 7905       |\n",
      "|    policy_gradient_loss | -0.0709    |\n",
      "|    value_loss           | 0.291      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 467       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 59776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1117833 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0749   |\n",
      "|    explained_variance   | -0.49     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0277   |\n",
      "|    n_updates            | 7922      |\n",
      "|    policy_gradient_loss | -0.0666   |\n",
      "|    value_loss           | 0.0566    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 468       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 59904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8953841 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0765   |\n",
      "|    explained_variance   | -0.21     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0471   |\n",
      "|    n_updates            | 7939      |\n",
      "|    policy_gradient_loss | -0.0627   |\n",
      "|    value_loss           | 0.0302    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=40.20 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 40.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 60000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3865918 |\n",
      "|    clip_fraction        | 0.0965    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0629   |\n",
      "|    explained_variance   | -0.662    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0173   |\n",
      "|    n_updates            | 7956      |\n",
      "|    policy_gradient_loss | -0.0281   |\n",
      "|    value_loss           | 0.0247    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 469      |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 60032    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 470       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 60160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0550827 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0613   |\n",
      "|    explained_variance   | 0.206     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0907   |\n",
      "|    n_updates            | 7973      |\n",
      "|    policy_gradient_loss | -0.0558   |\n",
      "|    value_loss           | 0.0238    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 471        |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 60288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50526637 |\n",
      "|    clip_fraction        | 0.063      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0213    |\n",
      "|    explained_variance   | -2.09      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0202    |\n",
      "|    n_updates            | 7990       |\n",
      "|    policy_gradient_loss | -0.0348    |\n",
      "|    value_loss           | 0.0528     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 472        |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 60416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35046908 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0833    |\n",
      "|    explained_variance   | 0.758      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.032     |\n",
      "|    n_updates            | 8007       |\n",
      "|    policy_gradient_loss | -0.0454    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60500, episode_reward=107.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 108       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 60500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3917557 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0874   |\n",
      "|    explained_variance   | 0.554     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0555   |\n",
      "|    n_updates            | 8024      |\n",
      "|    policy_gradient_loss | -0.0591   |\n",
      "|    value_loss           | 0.438     |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 473      |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 60544    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 474        |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 60672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17797093 |\n",
      "|    clip_fraction        | 0.0616     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0441    |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0289     |\n",
      "|    n_updates            | 8041       |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    value_loss           | 0.637      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 475       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 60800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6197231 |\n",
      "|    clip_fraction        | 0.0726    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.055    |\n",
      "|    explained_variance   | 0.648     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0772   |\n",
      "|    n_updates            | 8058      |\n",
      "|    policy_gradient_loss | -0.0366   |\n",
      "|    value_loss           | 0.14      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 476        |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 60928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24436155 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0358    |\n",
      "|    explained_variance   | -0.285     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.576      |\n",
      "|    n_updates            | 8075       |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 4.86       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=61000, episode_reward=84.83 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 84.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 61000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4533734 |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0542   |\n",
      "|    explained_variance   | 0.685     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0575    |\n",
      "|    n_updates            | 8092      |\n",
      "|    policy_gradient_loss | -0.0619   |\n",
      "|    value_loss           | 0.865     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 477      |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 61056    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 478       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 61184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2475317 |\n",
      "|    clip_fraction        | 0.0662    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0299   |\n",
      "|    explained_variance   | -0.667    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0164   |\n",
      "|    n_updates            | 8109      |\n",
      "|    policy_gradient_loss | -0.0265   |\n",
      "|    value_loss           | 0.0299    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 479       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 61312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0454528 |\n",
      "|    clip_fraction        | 0.0869    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0386   |\n",
      "|    explained_variance   | -0.75     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0489   |\n",
      "|    n_updates            | 8126      |\n",
      "|    policy_gradient_loss | -0.0144   |\n",
      "|    value_loss           | 0.0303    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 480        |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33525473 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0539    |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.024     |\n",
      "|    n_updates            | 8143       |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    value_loss           | 0.0141     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=61500, episode_reward=45.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 45.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 61500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.83062077 |\n",
      "|    clip_fraction        | 0.0699     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0207    |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0799    |\n",
      "|    n_updates            | 8160       |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    value_loss           | 0.0394     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 481      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 61568    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 482       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 61696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2788877 |\n",
      "|    clip_fraction        | 0.0423    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0212   |\n",
      "|    explained_variance   | -0.585    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0786   |\n",
      "|    n_updates            | 8177      |\n",
      "|    policy_gradient_loss | -0.0265   |\n",
      "|    value_loss           | 0.0634    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 483       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 61824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3388105 |\n",
      "|    clip_fraction        | 0.057     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0295   |\n",
      "|    explained_variance   | 0.509     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0266   |\n",
      "|    n_updates            | 8194      |\n",
      "|    policy_gradient_loss | -0.0157   |\n",
      "|    value_loss           | 0.0934    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 36.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 916      |\n",
      "|    iterations           | 484      |\n",
      "|    time_elapsed         | 67       |\n",
      "|    total_timesteps      | 61952    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.538352 |\n",
      "|    clip_fraction        | 0.156    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0576  |\n",
      "|    explained_variance   | 0.356    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0931  |\n",
      "|    n_updates            | 8211     |\n",
      "|    policy_gradient_loss | -0.0427  |\n",
      "|    value_loss           | 0.129    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=65.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 65.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 62000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31084633 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0639    |\n",
      "|    explained_variance   | 0.153      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.117      |\n",
      "|    n_updates            | 8228       |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 1.19       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 485      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 62080    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 486       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 62208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3273073 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0386   |\n",
      "|    explained_variance   | 0.518     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0678   |\n",
      "|    n_updates            | 8245      |\n",
      "|    policy_gradient_loss | -0.0511   |\n",
      "|    value_loss           | 0.253     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 487        |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 62336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14708388 |\n",
      "|    clip_fraction        | 0.0915     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.068     |\n",
      "|    explained_variance   | 0.642      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.063      |\n",
      "|    n_updates            | 8262       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 0.365      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 488       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 62464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3679755 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | 0.226     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.245     |\n",
      "|    n_updates            | 8279      |\n",
      "|    policy_gradient_loss | -0.0483   |\n",
      "|    value_loss           | 1.48      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=62500, episode_reward=28.38 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 28.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 62500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9961388 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0932   |\n",
      "|    explained_variance   | 0.607     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0326   |\n",
      "|    n_updates            | 8296      |\n",
      "|    policy_gradient_loss | -0.055    |\n",
      "|    value_loss           | 0.117     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 489      |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 62592    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 490        |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 62720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23263371 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0798    |\n",
      "|    explained_variance   | 0.593      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00939   |\n",
      "|    n_updates            | 8313       |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 36.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 491      |\n",
      "|    time_elapsed         | 68       |\n",
      "|    total_timesteps      | 62848    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.438034 |\n",
      "|    clip_fraction        | 0.156    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0912  |\n",
      "|    explained_variance   | -0.135   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0816  |\n",
      "|    n_updates            | 8330     |\n",
      "|    policy_gradient_loss | -0.0447  |\n",
      "|    value_loss           | 0.0356   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 492       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 62976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2569792 |\n",
      "|    clip_fraction        | 0.277     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.127    |\n",
      "|    explained_variance   | 0.17      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.133    |\n",
      "|    n_updates            | 8347      |\n",
      "|    policy_gradient_loss | -0.0827   |\n",
      "|    value_loss           | 0.0283    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=63000, episode_reward=32.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 32.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 63000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8675669 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.093    |\n",
      "|    explained_variance   | 0.000451  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0649   |\n",
      "|    n_updates            | 8364      |\n",
      "|    policy_gradient_loss | -0.0566   |\n",
      "|    value_loss           | 0.0891    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 493      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 63104    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 494       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 63232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4485348 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0465   |\n",
      "|    explained_variance   | -0.00719  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0266   |\n",
      "|    n_updates            | 8381      |\n",
      "|    policy_gradient_loss | -0.0446   |\n",
      "|    value_loss           | 0.126     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 495       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 63360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6305727 |\n",
      "|    clip_fraction        | 0.091     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0406   |\n",
      "|    explained_variance   | 0.594     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0894   |\n",
      "|    n_updates            | 8398      |\n",
      "|    policy_gradient_loss | -0.0415   |\n",
      "|    value_loss           | 0.139     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 496        |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77155185 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.093     |\n",
      "|    explained_variance   | 0.406      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0263    |\n",
      "|    n_updates            | 8415       |\n",
      "|    policy_gradient_loss | -0.0606    |\n",
      "|    value_loss           | 0.601      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=63500, episode_reward=100.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 100       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 63500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3423999 |\n",
      "|    clip_fraction        | 0.0749    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0352   |\n",
      "|    explained_variance   | 0.457     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0575   |\n",
      "|    n_updates            | 8432      |\n",
      "|    policy_gradient_loss | -0.0257   |\n",
      "|    value_loss           | 0.347     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 497      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 63616    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 498       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 63744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0217011 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0603   |\n",
      "|    explained_variance   | 0.762     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.098    |\n",
      "|    n_updates            | 8449      |\n",
      "|    policy_gradient_loss | -0.0529   |\n",
      "|    value_loss           | 0.195     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 499        |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 63872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29245487 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0968    |\n",
      "|    explained_variance   | -0.0632    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.233      |\n",
      "|    n_updates            | 8466       |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    value_loss           | 3.07       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=12.65 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 12.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 64000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8087295 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0627   |\n",
      "|    explained_variance   | -0.458    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.086    |\n",
      "|    n_updates            | 8483      |\n",
      "|    policy_gradient_loss | -0.0959   |\n",
      "|    value_loss           | 0.196     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 64000    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 501        |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 64128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15636519 |\n",
      "|    clip_fraction        | 0.062      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0365    |\n",
      "|    explained_variance   | -0.512     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00945    |\n",
      "|    n_updates            | 8500       |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    value_loss           | 0.0588     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 502        |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 64256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24816427 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0412    |\n",
      "|    explained_variance   | 0.0944     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0474    |\n",
      "|    n_updates            | 8517       |\n",
      "|    policy_gradient_loss | -0.0546    |\n",
      "|    value_loss           | 0.032      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 503        |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 64384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18536931 |\n",
      "|    clip_fraction        | 0.04       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0131    |\n",
      "|    explained_variance   | 0.0999     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0503    |\n",
      "|    n_updates            | 8534       |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    value_loss           | 0.0264     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=64500, episode_reward=76.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 76.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 64500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3961147 |\n",
      "|    clip_fraction        | 0.186     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0586   |\n",
      "|    explained_variance   | -0.117    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0855   |\n",
      "|    n_updates            | 8551      |\n",
      "|    policy_gradient_loss | -0.0714   |\n",
      "|    value_loss           | 0.0541    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 504      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 64512    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 505        |\n",
      "|    time_elapsed         | 70         |\n",
      "|    total_timesteps      | 64640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33991164 |\n",
      "|    clip_fraction        | 0.0754     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0374    |\n",
      "|    explained_variance   | 0.224      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0397    |\n",
      "|    n_updates            | 8568       |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 506       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 64768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6294958 |\n",
      "|    clip_fraction        | 0.0703    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0316   |\n",
      "|    explained_variance   | 0.664     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0175   |\n",
      "|    n_updates            | 8585      |\n",
      "|    policy_gradient_loss | -0.0399   |\n",
      "|    value_loss           | 0.1       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 507        |\n",
      "|    time_elapsed         | 71         |\n",
      "|    total_timesteps      | 64896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21706155 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0454    |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.582      |\n",
      "|    n_updates            | 8602       |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 1.45       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=109.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 109       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 65000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3951894 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.066    |\n",
      "|    explained_variance   | 0.698     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00629   |\n",
      "|    n_updates            | 8619      |\n",
      "|    policy_gradient_loss | -0.0471   |\n",
      "|    value_loss           | 0.263     |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 508      |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 65024    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 509        |\n",
      "|    time_elapsed         | 71         |\n",
      "|    total_timesteps      | 65152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42741364 |\n",
      "|    clip_fraction        | 0.0846     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0586    |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.041     |\n",
      "|    n_updates            | 8636       |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.282      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 36.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 911         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 65280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060008395 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0171     |\n",
      "|    explained_variance   | 0.00766     |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0605      |\n",
      "|    n_updates            | 8653        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 511        |\n",
      "|    time_elapsed         | 71         |\n",
      "|    total_timesteps      | 65408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12958479 |\n",
      "|    clip_fraction        | 0.0717     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0583    |\n",
      "|    explained_variance   | 0.00455    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 4.26       |\n",
      "|    n_updates            | 8670       |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 6.73       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=65500, episode_reward=68.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 68.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 65500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7929036 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | -0.524    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.121    |\n",
      "|    n_updates            | 8687      |\n",
      "|    policy_gradient_loss | -0.0672   |\n",
      "|    value_loss           | 0.0718    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 512      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 513        |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 65664      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31663027 |\n",
      "|    clip_fraction        | 0.0409     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0291    |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0247    |\n",
      "|    n_updates            | 8704       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 514       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 65792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3473781 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0773   |\n",
      "|    explained_variance   | -0.832    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0823   |\n",
      "|    n_updates            | 8721      |\n",
      "|    policy_gradient_loss | -0.059    |\n",
      "|    value_loss           | 0.0244    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 515       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 65920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2578001 |\n",
      "|    clip_fraction        | 0.194     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | -0.351    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.119    |\n",
      "|    n_updates            | 8738      |\n",
      "|    policy_gradient_loss | -0.0633   |\n",
      "|    value_loss           | 0.0706    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=60.38 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 60.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 66000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74626994 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0495    |\n",
      "|    explained_variance   | -0.388     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 8755       |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.0958     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 516      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 66048    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 517       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 66176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9878621 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0537   |\n",
      "|    explained_variance   | 0.53      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 8772      |\n",
      "|    policy_gradient_loss | -0.0537   |\n",
      "|    value_loss           | 0.0721    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 518       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 66304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6136328 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0492   |\n",
      "|    explained_variance   | 0.385     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0644   |\n",
      "|    n_updates            | 8789      |\n",
      "|    policy_gradient_loss | -0.0577   |\n",
      "|    value_loss           | 0.0889    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 519       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 66432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4081193 |\n",
      "|    clip_fraction        | 0.0965    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0492   |\n",
      "|    explained_variance   | 0.379     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0097   |\n",
      "|    n_updates            | 8806      |\n",
      "|    policy_gradient_loss | -0.0306   |\n",
      "|    value_loss           | 0.335     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=66500, episode_reward=16.07 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 16.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 66500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1351973 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.802     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.103    |\n",
      "|    n_updates            | 8823      |\n",
      "|    policy_gradient_loss | -0.0721   |\n",
      "|    value_loss           | 0.137     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 520      |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 66560    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 521        |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 66688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19827008 |\n",
      "|    clip_fraction        | 0.0731     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0398    |\n",
      "|    explained_variance   | 0.647      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0296    |\n",
      "|    n_updates            | 8840       |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    value_loss           | 0.263      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 522        |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 66816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28533712 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0875    |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.177      |\n",
      "|    n_updates            | 8857       |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 1.15       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 523       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 66944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5310547 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0809   |\n",
      "|    explained_variance   | 0.867     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0451   |\n",
      "|    n_updates            | 8874      |\n",
      "|    policy_gradient_loss | -0.0362   |\n",
      "|    value_loss           | 0.0378    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=67000, episode_reward=15.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 67000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91589034 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0471    |\n",
      "|    explained_variance   | -0.0682    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0754    |\n",
      "|    n_updates            | 8891       |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    value_loss           | 0.0371     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 524      |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 67072    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 525        |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 67200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53718907 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0929    |\n",
      "|    explained_variance   | -0.393     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0646    |\n",
      "|    n_updates            | 8908       |\n",
      "|    policy_gradient_loss | -0.0682    |\n",
      "|    value_loss           | 0.0228     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 526       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 67328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3422229 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.27      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0934   |\n",
      "|    n_updates            | 8925      |\n",
      "|    policy_gradient_loss | -0.0444   |\n",
      "|    value_loss           | 0.0161    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 527        |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 67456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.83545446 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0846    |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0843    |\n",
      "|    n_updates            | 8942       |\n",
      "|    policy_gradient_loss | -0.0543    |\n",
      "|    value_loss           | 0.0402     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=67500, episode_reward=26.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 67500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74517614 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.033     |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0596    |\n",
      "|    n_updates            | 8959       |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    value_loss           | 0.0734     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 528      |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 67584    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 529       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 67712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0535091 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0505   |\n",
      "|    explained_variance   | 0.476     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0635   |\n",
      "|    n_updates            | 8976      |\n",
      "|    policy_gradient_loss | -0.0465   |\n",
      "|    value_loss           | 0.0657    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 530       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 67840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2673862 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0952   |\n",
      "|    explained_variance   | 0.218     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0544    |\n",
      "|    n_updates            | 8993      |\n",
      "|    policy_gradient_loss | -0.0596   |\n",
      "|    value_loss           | 0.45      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 531       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 67968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6087669 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0832   |\n",
      "|    explained_variance   | 0.21      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 9010      |\n",
      "|    policy_gradient_loss | -0.0622   |\n",
      "|    value_loss           | 0.273     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=25.31 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 25.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 68000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5047609 |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0783   |\n",
      "|    explained_variance   | 0.682     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0274   |\n",
      "|    n_updates            | 9027      |\n",
      "|    policy_gradient_loss | -0.037    |\n",
      "|    value_loss           | 0.156     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 532      |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 68096    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 533        |\n",
      "|    time_elapsed         | 74         |\n",
      "|    total_timesteps      | 68224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49664673 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.28       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 9044       |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 1.37       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 534       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 68352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6600664 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0529   |\n",
      "|    explained_variance   | 0.739     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00621   |\n",
      "|    n_updates            | 9061      |\n",
      "|    policy_gradient_loss | -0.0541   |\n",
      "|    value_loss           | 0.21      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 535        |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 68480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37377012 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0558    |\n",
      "|    explained_variance   | -1.34      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.000125   |\n",
      "|    n_updates            | 9078       |\n",
      "|    policy_gradient_loss | -0.0398    |\n",
      "|    value_loss           | 0.0526     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=68500, episode_reward=39.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 39.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 68500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5396287 |\n",
      "|    clip_fraction        | 0.12      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0639   |\n",
      "|    explained_variance   | -0.731    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.035    |\n",
      "|    n_updates            | 9095      |\n",
      "|    policy_gradient_loss | -0.0537   |\n",
      "|    value_loss           | 0.0228    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 536      |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 68608    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 537        |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 68736      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26804715 |\n",
      "|    clip_fraction        | 0.0657     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0503    |\n",
      "|    explained_variance   | -0.727     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0382    |\n",
      "|    n_updates            | 9112       |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.0189     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 538        |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 68864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26539022 |\n",
      "|    clip_fraction        | 0.0726     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0471    |\n",
      "|    explained_variance   | -0.168     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0201    |\n",
      "|    n_updates            | 9129       |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.0513     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 539       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 68992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5173228 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0623   |\n",
      "|    explained_variance   | -0.371    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.063    |\n",
      "|    n_updates            | 9146      |\n",
      "|    policy_gradient_loss | -0.043    |\n",
      "|    value_loss           | 0.0592    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=69000, episode_reward=10.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 10.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 69000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32411265 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0628    |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0599    |\n",
      "|    n_updates            | 9163       |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 0.0591     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 540      |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 69120    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 541       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 69248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2817008 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0756   |\n",
      "|    explained_variance   | 0.584     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0986   |\n",
      "|    n_updates            | 9180      |\n",
      "|    policy_gradient_loss | -0.0498   |\n",
      "|    value_loss           | 0.104     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 542        |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 69376      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52378935 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0684    |\n",
      "|    explained_variance   | 0.463      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0701    |\n",
      "|    n_updates            | 9197       |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.346      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=69500, episode_reward=-0.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -0.962    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 69500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.5591555 |\n",
      "|    clip_fraction        | 0.205     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0492   |\n",
      "|    explained_variance   | 0.779     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0989   |\n",
      "|    n_updates            | 9214      |\n",
      "|    policy_gradient_loss | -0.0527   |\n",
      "|    value_loss           | 0.0893    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 543      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 69504    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 544        |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54061824 |\n",
      "|    clip_fraction        | 0.0735     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.019     |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00157   |\n",
      "|    n_updates            | 9231       |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 545        |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 69760      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29090032 |\n",
      "|    clip_fraction        | 0.0744     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0219    |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0169     |\n",
      "|    n_updates            | 9248       |\n",
      "|    policy_gradient_loss | -0.0372    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 546       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 69888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5431504 |\n",
      "|    clip_fraction        | 0.0818    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0256   |\n",
      "|    explained_variance   | 0.256     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0605   |\n",
      "|    n_updates            | 9265      |\n",
      "|    policy_gradient_loss | -0.0442   |\n",
      "|    value_loss           | 0.0374    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=15.20 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 70000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22729245 |\n",
      "|    clip_fraction        | 0.0643     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0348    |\n",
      "|    explained_variance   | -0.166     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00414    |\n",
      "|    n_updates            | 9282       |\n",
      "|    policy_gradient_loss | -0.0345    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 547      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 70016    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 548        |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 70144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28718394 |\n",
      "|    clip_fraction        | 0.063      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0487    |\n",
      "|    explained_variance   | -0.38      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0403    |\n",
      "|    n_updates            | 9299       |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    value_loss           | 0.0274     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 549        |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 70272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30671677 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0762    |\n",
      "|    explained_variance   | -0.145     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0365    |\n",
      "|    n_updates            | 9316       |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    value_loss           | 0.0595     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 550       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 70400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9232945 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | -0.0511   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0649   |\n",
      "|    n_updates            | 9333      |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.0984    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=70500, episode_reward=19.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 70500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56427306 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0555    |\n",
      "|    explained_variance   | 0.771      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 9350       |\n",
      "|    policy_gradient_loss | -0.0637    |\n",
      "|    value_loss           | 0.0434     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 551      |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 70528    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 552       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 70656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3354683 |\n",
      "|    clip_fraction        | 0.0611    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0399   |\n",
      "|    explained_variance   | 0.48      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0251   |\n",
      "|    n_updates            | 9367      |\n",
      "|    policy_gradient_loss | -0.0285   |\n",
      "|    value_loss           | 0.106     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 553       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 70784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1152537 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0513   |\n",
      "|    explained_variance   | 0.53      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0728   |\n",
      "|    n_updates            | 9384      |\n",
      "|    policy_gradient_loss | -0.0528   |\n",
      "|    value_loss           | 0.13      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 554        |\n",
      "|    time_elapsed         | 77         |\n",
      "|    total_timesteps      | 70912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45433766 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.662      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0579    |\n",
      "|    n_updates            | 9401       |\n",
      "|    policy_gradient_loss | -0.0564    |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=71000, episode_reward=18.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 18.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 71000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8949426 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0833   |\n",
      "|    explained_variance   | 0.574     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0607   |\n",
      "|    n_updates            | 9418      |\n",
      "|    policy_gradient_loss | -0.0524   |\n",
      "|    value_loss           | 0.245     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 555      |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 71040    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 556        |\n",
      "|    time_elapsed         | 77         |\n",
      "|    total_timesteps      | 71168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29957736 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0513    |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.7        |\n",
      "|    n_updates            | 9435       |\n",
      "|    policy_gradient_loss | -0.0485    |\n",
      "|    value_loss           | 1.69       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 557       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 71296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.6855474 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0475   |\n",
      "|    explained_variance   | 0.842     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0359   |\n",
      "|    n_updates            | 9452      |\n",
      "|    policy_gradient_loss | -0.045    |\n",
      "|    value_loss           | 0.0696    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 558       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 71424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4763475 |\n",
      "|    clip_fraction        | 0.0919    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0506   |\n",
      "|    explained_variance   | 0.323     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0321    |\n",
      "|    n_updates            | 9469      |\n",
      "|    policy_gradient_loss | -0.0425   |\n",
      "|    value_loss           | 0.0829    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=71500, episode_reward=-8.06 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -8.06     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 71500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7472205 |\n",
      "|    clip_fraction        | 0.0859    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0277   |\n",
      "|    explained_variance   | 0.144     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0872   |\n",
      "|    n_updates            | 9486      |\n",
      "|    policy_gradient_loss | -0.0534   |\n",
      "|    value_loss           | 0.0304    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 559      |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 71552    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 560        |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56555164 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0688    |\n",
      "|    explained_variance   | -0.705     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0735    |\n",
      "|    n_updates            | 9503       |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.0221     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 561       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 71808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3699355 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0464   |\n",
      "|    explained_variance   | 0.0601    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0388   |\n",
      "|    n_updates            | 9520      |\n",
      "|    policy_gradient_loss | -0.035    |\n",
      "|    value_loss           | 0.0769    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 562        |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 71936      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45377505 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0477    |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0328    |\n",
      "|    n_updates            | 9537       |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=12.18 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 12.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 72000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4519196 |\n",
      "|    clip_fraction        | 0.0593    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.036    |\n",
      "|    explained_variance   | 0.258     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0519   |\n",
      "|    n_updates            | 9554      |\n",
      "|    policy_gradient_loss | -0.0222   |\n",
      "|    value_loss           | 0.102     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 563      |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 72064    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 564       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 72192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0986828 |\n",
      "|    clip_fraction        | 0.179     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0645   |\n",
      "|    explained_variance   | 0.714     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.131    |\n",
      "|    n_updates            | 9571      |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.0782    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 565       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 72320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7404351 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0311   |\n",
      "|    explained_variance   | 0.00717   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0553   |\n",
      "|    n_updates            | 9588      |\n",
      "|    policy_gradient_loss | -0.0604   |\n",
      "|    value_loss           | 0.124     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 72448      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36261058 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0515    |\n",
      "|    explained_variance   | 0.0606     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0258    |\n",
      "|    n_updates            | 9605       |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    value_loss           | 0.245      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=72500, episode_reward=28.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 28.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 72500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04080388 |\n",
      "|    clip_fraction        | 0.057      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0574    |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0656     |\n",
      "|    n_updates            | 9622       |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    value_loss           | 0.464      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 567      |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 72576    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 568       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 72704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2025398 |\n",
      "|    clip_fraction        | 0.0694    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0504   |\n",
      "|    explained_variance   | 0.956     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0251   |\n",
      "|    n_updates            | 9639      |\n",
      "|    policy_gradient_loss | -0.0193   |\n",
      "|    value_loss           | 0.209     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 569        |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 72832      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16261172 |\n",
      "|    clip_fraction        | 0.0772     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0576    |\n",
      "|    explained_variance   | -0.0468    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00964   |\n",
      "|    n_updates            | 9656       |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 0.0403     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 570       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 72960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0195215 |\n",
      "|    clip_fraction        | 0.205     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0699   |\n",
      "|    explained_variance   | 0.413     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 9673      |\n",
      "|    policy_gradient_loss | -0.0789   |\n",
      "|    value_loss           | 0.0191    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=73000, episode_reward=38.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 38.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 73000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40187377 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | -0.915     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0684    |\n",
      "|    n_updates            | 9690       |\n",
      "|    policy_gradient_loss | -0.071     |\n",
      "|    value_loss           | 0.00868    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 571      |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 73088    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 572       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 73216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2862488 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0565   |\n",
      "|    explained_variance   | 0.429     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0433   |\n",
      "|    n_updates            | 9707      |\n",
      "|    policy_gradient_loss | -0.0465   |\n",
      "|    value_loss           | 0.0427    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 573       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 73344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4960628 |\n",
      "|    clip_fraction        | 0.0823    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0302   |\n",
      "|    explained_variance   | -0.197    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0187   |\n",
      "|    n_updates            | 9724      |\n",
      "|    policy_gradient_loss | -0.025    |\n",
      "|    value_loss           | 0.0608    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 574        |\n",
      "|    time_elapsed         | 80         |\n",
      "|    total_timesteps      | 73472      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11940888 |\n",
      "|    clip_fraction        | 0.0487     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0172    |\n",
      "|    explained_variance   | 0.752      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0846    |\n",
      "|    n_updates            | 9741       |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    value_loss           | 0.0507     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=73500, episode_reward=38.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 38.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 73500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37279266 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0643    |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0222    |\n",
      "|    n_updates            | 9758       |\n",
      "|    policy_gradient_loss | -0.0537    |\n",
      "|    value_loss           | 0.658      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 575      |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 73600    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 576       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4821363 |\n",
      "|    clip_fraction        | 0.0781    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.045    |\n",
      "|    explained_variance   | -0.391    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0246   |\n",
      "|    n_updates            | 9775      |\n",
      "|    policy_gradient_loss | -0.0464   |\n",
      "|    value_loss           | 0.376     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 577        |\n",
      "|    time_elapsed         | 80         |\n",
      "|    total_timesteps      | 73856      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39219797 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0367    |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0556    |\n",
      "|    n_updates            | 9792       |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 578       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 73984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6474922 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.086    |\n",
      "|    explained_variance   | 0.54      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.46      |\n",
      "|    n_updates            | 9809      |\n",
      "|    policy_gradient_loss | -0.0728   |\n",
      "|    value_loss           | 1.31      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=51.60 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 74000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3153382 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.874     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.239     |\n",
      "|    n_updates            | 9826      |\n",
      "|    policy_gradient_loss | -0.0476   |\n",
      "|    value_loss           | 1.07      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 579      |\n",
      "|    time_elapsed    | 81       |\n",
      "|    total_timesteps | 74112    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 912      |\n",
      "|    iterations           | 580      |\n",
      "|    time_elapsed         | 81       |\n",
      "|    total_timesteps      | 74240    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.69118  |\n",
      "|    clip_fraction        | 0.148    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0543  |\n",
      "|    explained_variance   | -0.413   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0744  |\n",
      "|    n_updates            | 9843     |\n",
      "|    policy_gradient_loss | -0.0662  |\n",
      "|    value_loss           | 0.0323   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 581        |\n",
      "|    time_elapsed         | 81         |\n",
      "|    total_timesteps      | 74368      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69912237 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0769    |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.077     |\n",
      "|    n_updates            | 9860       |\n",
      "|    policy_gradient_loss | -0.067     |\n",
      "|    value_loss           | 0.053      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 582       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 74496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6582811 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | 0.318     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0631   |\n",
      "|    n_updates            | 9877      |\n",
      "|    policy_gradient_loss | -0.0569   |\n",
      "|    value_loss           | 0.0161    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=74500, episode_reward=27.86 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 27.9     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 74500    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.446657 |\n",
      "|    clip_fraction        | 0.149    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0666  |\n",
      "|    explained_variance   | 0.63     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0938  |\n",
      "|    n_updates            | 9894     |\n",
      "|    policy_gradient_loss | -0.0427  |\n",
      "|    value_loss           | 0.042    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 583      |\n",
      "|    time_elapsed    | 81       |\n",
      "|    total_timesteps | 74624    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 584       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 74752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9680591 |\n",
      "|    clip_fraction        | 0.0708    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0501   |\n",
      "|    explained_variance   | 0.278     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0945   |\n",
      "|    n_updates            | 9911      |\n",
      "|    policy_gradient_loss | -0.0322   |\n",
      "|    value_loss           | 0.0835    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 585       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 74880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0599055 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0434   |\n",
      "|    explained_variance   | 0.806     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0785   |\n",
      "|    n_updates            | 9928      |\n",
      "|    policy_gradient_loss | -0.0472   |\n",
      "|    value_loss           | 0.0622    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0.667     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 75000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5410912 |\n",
      "|    clip_fraction        | 0.068     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0159   |\n",
      "|    explained_variance   | 0.412     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00507  |\n",
      "|    n_updates            | 9945      |\n",
      "|    policy_gradient_loss | -0.0341   |\n",
      "|    value_loss           | 0.0839    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 586      |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 75008    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 587        |\n",
      "|    time_elapsed         | 82         |\n",
      "|    total_timesteps      | 75136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43433106 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0291    |\n",
      "|    explained_variance   | 0.69       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0107    |\n",
      "|    n_updates            | 9962       |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.248      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 588       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 75264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1342998 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0585   |\n",
      "|    explained_variance   | 0.0797    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.063    |\n",
      "|    n_updates            | 9979      |\n",
      "|    policy_gradient_loss | -0.0519   |\n",
      "|    value_loss           | 0.0755    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 589        |\n",
      "|    time_elapsed         | 82         |\n",
      "|    total_timesteps      | 75392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47684342 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0952    |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0947    |\n",
      "|    n_updates            | 9996       |\n",
      "|    policy_gradient_loss | -0.0574    |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=75500, episode_reward=41.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 75500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2543261 |\n",
      "|    clip_fraction        | 0.0634    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0458   |\n",
      "|    explained_variance   | 0.296     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.525     |\n",
      "|    n_updates            | 10013     |\n",
      "|    policy_gradient_loss | -0.0407   |\n",
      "|    value_loss           | 1.54      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 590      |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 75520    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 591        |\n",
      "|    time_elapsed         | 82         |\n",
      "|    total_timesteps      | 75648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22588533 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0813    |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.109     |\n",
      "|    n_updates            | 10030      |\n",
      "|    policy_gradient_loss | -0.046     |\n",
      "|    value_loss           | 0.0511     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 592       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4718678 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0721   |\n",
      "|    explained_variance   | 0.000979  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0866   |\n",
      "|    n_updates            | 10047     |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 0.0577    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 593        |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 75904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78493357 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0544    |\n",
      "|    explained_variance   | 0.0199     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0876    |\n",
      "|    n_updates            | 10064      |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    value_loss           | 0.0168     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=6.46 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.46       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 76000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42553562 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0896    |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0938    |\n",
      "|    n_updates            | 10081      |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    value_loss           | 0.0372     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 594      |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 76032    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 595        |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 76160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20028421 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0825    |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0282    |\n",
      "|    n_updates            | 10098      |\n",
      "|    policy_gradient_loss | -0.0431    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 596       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 76288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1823149 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.046    |\n",
      "|    explained_variance   | 0.35      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0789   |\n",
      "|    n_updates            | 10115     |\n",
      "|    policy_gradient_loss | -0.0479   |\n",
      "|    value_loss           | 0.141     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 597        |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 76416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20218813 |\n",
      "|    clip_fraction        | 0.0772     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0405    |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.042      |\n",
      "|    n_updates            | 10132      |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=76500, episode_reward=26.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 76500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5289474 |\n",
      "|    clip_fraction        | 0.183     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.0948    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.331     |\n",
      "|    n_updates            | 10149     |\n",
      "|    policy_gradient_loss | -0.0649   |\n",
      "|    value_loss           | 1.31      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 598      |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 76544    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 599        |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 76672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29425174 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0587    |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0931    |\n",
      "|    n_updates            | 10166      |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 600        |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 76800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45623752 |\n",
      "|    clip_fraction        | 0.0754     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.033     |\n",
      "|    explained_variance   | -0.443     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0643     |\n",
      "|    n_updates            | 10183      |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 0.669      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 601        |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 76928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17419586 |\n",
      "|    clip_fraction        | 0.0473     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0398    |\n",
      "|    explained_variance   | 0.0582     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.122      |\n",
      "|    n_updates            | 10200      |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 3.06       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=77000, episode_reward=22.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 22.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 77000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18121815 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0238    |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00518   |\n",
      "|    n_updates            | 10217      |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.0547     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 602      |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 77056    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 603       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 77184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0787727 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0502   |\n",
      "|    explained_variance   | -0.148    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0944   |\n",
      "|    n_updates            | 10234     |\n",
      "|    policy_gradient_loss | -0.0552   |\n",
      "|    value_loss           | 0.0526    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 604       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 77312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.8149319 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0425   |\n",
      "|    explained_variance   | -0.286    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0694   |\n",
      "|    n_updates            | 10251     |\n",
      "|    policy_gradient_loss | -0.0504   |\n",
      "|    value_loss           | 0.0332    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 605       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 77440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6577494 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0413   |\n",
      "|    explained_variance   | -0.0205   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0431   |\n",
      "|    n_updates            | 10268     |\n",
      "|    policy_gradient_loss | -0.0505   |\n",
      "|    value_loss           | 0.0444    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=77500, episode_reward=5.84 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 5.84       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 77500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23019204 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.064     |\n",
      "|    explained_variance   | 0.269      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0586    |\n",
      "|    n_updates            | 10285      |\n",
      "|    policy_gradient_loss | -0.0377    |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 606      |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 77568    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 607       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 77696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6599978 |\n",
      "|    clip_fraction        | 0.0855    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0368   |\n",
      "|    explained_variance   | -0.401    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00171  |\n",
      "|    n_updates            | 10302     |\n",
      "|    policy_gradient_loss | -0.0348   |\n",
      "|    value_loss           | 0.0774    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 38       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 608      |\n",
      "|    time_elapsed         | 85       |\n",
      "|    total_timesteps      | 77824    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.118247 |\n",
      "|    clip_fraction        | 0.108    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0279  |\n",
      "|    explained_variance   | 0.763    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0588  |\n",
      "|    n_updates            | 10319    |\n",
      "|    policy_gradient_loss | -0.0424  |\n",
      "|    value_loss           | 0.0762   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 609        |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 77952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44629896 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0514    |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0117     |\n",
      "|    n_updates            | 10336      |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 0.23       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=19.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 78000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20634311 |\n",
      "|    clip_fraction        | 0.0988     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0252     |\n",
      "|    n_updates            | 10353      |\n",
      "|    policy_gradient_loss | -0.0492    |\n",
      "|    value_loss           | 0.608      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 610      |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 78080    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 611        |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 78208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63136035 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.525      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0115     |\n",
      "|    n_updates            | 10370      |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 612        |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 78336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11152941 |\n",
      "|    clip_fraction        | 0.0878     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0601    |\n",
      "|    explained_variance   | 0.0071     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.343      |\n",
      "|    n_updates            | 10387      |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    value_loss           | 3.56       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 613        |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 78464      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63634217 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0908    |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 10404      |\n",
      "|    policy_gradient_loss | -0.0581    |\n",
      "|    value_loss           | 0.651      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=78500, episode_reward=-2.47 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -2.47     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 78500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1630211 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0866   |\n",
      "|    explained_variance   | -0.227    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0711   |\n",
      "|    n_updates            | 10421     |\n",
      "|    policy_gradient_loss | -0.0921   |\n",
      "|    value_loss           | 0.0397    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 614      |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 78592    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 615       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 78720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6000216 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0624   |\n",
      "|    explained_variance   | -0.287    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0597   |\n",
      "|    n_updates            | 10438     |\n",
      "|    policy_gradient_loss | -0.0583   |\n",
      "|    value_loss           | 0.0356    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 616       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 78848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1544439 |\n",
      "|    clip_fraction        | 0.203     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | -0.477    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0974   |\n",
      "|    n_updates            | 10455     |\n",
      "|    policy_gradient_loss | -0.0698   |\n",
      "|    value_loss           | 0.0212    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 617        |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 78976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67328554 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0793    |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0104    |\n",
      "|    n_updates            | 10472      |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    value_loss           | 0.0629     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=79000, episode_reward=47.51 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 47.5     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 79000    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.192052 |\n",
      "|    clip_fraction        | 0.191    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.107   |\n",
      "|    explained_variance   | -1.1     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.107   |\n",
      "|    n_updates            | 10489    |\n",
      "|    policy_gradient_loss | -0.0507  |\n",
      "|    value_loss           | 0.0924   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 618      |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 79104    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 619       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 79232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2992827 |\n",
      "|    clip_fraction        | 0.104     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0527   |\n",
      "|    explained_variance   | 0.638     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0879   |\n",
      "|    n_updates            | 10506     |\n",
      "|    policy_gradient_loss | -0.0388   |\n",
      "|    value_loss           | 0.0495    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 620        |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 79360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42561507 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0943    |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.082     |\n",
      "|    n_updates            | 10523      |\n",
      "|    policy_gradient_loss | -0.0599    |\n",
      "|    value_loss           | 0.134      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 621        |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 79488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.87214607 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0162    |\n",
      "|    n_updates            | 10540      |\n",
      "|    policy_gradient_loss | -0.068     |\n",
      "|    value_loss           | 0.52       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=79500, episode_reward=17.73 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 17.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 79500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51385194 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0917    |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0516    |\n",
      "|    n_updates            | 10557      |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 0.233      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 622      |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 79616    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 623       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 79744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0521746 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0924   |\n",
      "|    explained_variance   | 0.578     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0813   |\n",
      "|    n_updates            | 10574     |\n",
      "|    policy_gradient_loss | -0.0464   |\n",
      "|    value_loss           | 0.451     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 38.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 915         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028119527 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0336     |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 10591       |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=4.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 4.54      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 80000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0495715 |\n",
      "|    clip_fraction        | 0.191     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0625   |\n",
      "|    explained_variance   | 0.831     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0553   |\n",
      "|    n_updates            | 10608     |\n",
      "|    policy_gradient_loss | -0.0516   |\n",
      "|    value_loss           | 0.0419    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 625      |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 626       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 80128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6003461 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0596   |\n",
      "|    explained_variance   | 0.153     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.143    |\n",
      "|    n_updates            | 10625     |\n",
      "|    policy_gradient_loss | -0.0694   |\n",
      "|    value_loss           | 0.0294    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 627       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 80256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6598772 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.061    |\n",
      "|    explained_variance   | -0.402    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.155    |\n",
      "|    n_updates            | 10642     |\n",
      "|    policy_gradient_loss | 0.0516    |\n",
      "|    value_loss           | 0.0309    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 628        |\n",
      "|    time_elapsed         | 87         |\n",
      "|    total_timesteps      | 80384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28808945 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0891    |\n",
      "|    explained_variance   | -0.00903   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0738    |\n",
      "|    n_updates            | 10659      |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.0253     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80500, episode_reward=21.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 21.6     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 80500    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.722395 |\n",
      "|    clip_fraction        | 0.203    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.057   |\n",
      "|    explained_variance   | 0.109    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0443  |\n",
      "|    n_updates            | 10676    |\n",
      "|    policy_gradient_loss | -0.0593  |\n",
      "|    value_loss           | 0.0905   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 629      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 80512    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 630       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 80640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2939582 |\n",
      "|    clip_fraction        | 0.0813    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0517   |\n",
      "|    explained_variance   | 0.485     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0145   |\n",
      "|    n_updates            | 10693     |\n",
      "|    policy_gradient_loss | -0.0205   |\n",
      "|    value_loss           | 0.0772    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 631        |\n",
      "|    time_elapsed         | 88         |\n",
      "|    total_timesteps      | 80768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75477463 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.1       |\n",
      "|    explained_variance   | 0.449      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0459    |\n",
      "|    n_updates            | 10710      |\n",
      "|    policy_gradient_loss | -0.0632    |\n",
      "|    value_loss           | 0.263      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 632        |\n",
      "|    time_elapsed         | 88         |\n",
      "|    total_timesteps      | 80896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33528462 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0501    |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0393    |\n",
      "|    n_updates            | 10727      |\n",
      "|    policy_gradient_loss | -0.0621    |\n",
      "|    value_loss           | 0.371      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=81000, episode_reward=26.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 81000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0075865 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0573   |\n",
      "|    explained_variance   | 0.655     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00175  |\n",
      "|    n_updates            | 10744     |\n",
      "|    policy_gradient_loss | -0.0522   |\n",
      "|    value_loss           | 0.155     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 633      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 81024    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 634       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 81152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5781026 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0845   |\n",
      "|    explained_variance   | -0.0896   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.098     |\n",
      "|    n_updates            | 10761     |\n",
      "|    policy_gradient_loss | -0.0567   |\n",
      "|    value_loss           | 0.599     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 635       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 81280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3245055 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0688   |\n",
      "|    explained_variance   | 0.262     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0767    |\n",
      "|    n_updates            | 10778     |\n",
      "|    policy_gradient_loss | -0.05     |\n",
      "|    value_loss           | 0.562     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 636        |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 81408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59240186 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0787    |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.169      |\n",
      "|    n_updates            | 10795      |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 0.244      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=81500, episode_reward=26.73 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 81500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7021129 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0658   |\n",
      "|    explained_variance   | 0.431     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0946   |\n",
      "|    n_updates            | 10812     |\n",
      "|    policy_gradient_loss | -0.0589   |\n",
      "|    value_loss           | 0.0349    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 637      |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 81536    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 638       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 81664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2928002 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.417     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0908   |\n",
      "|    n_updates            | 10829     |\n",
      "|    policy_gradient_loss | -0.0526   |\n",
      "|    value_loss           | 0.0274    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 639       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 81792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5648099 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0511   |\n",
      "|    explained_variance   | 0.105     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0473   |\n",
      "|    n_updates            | 10846     |\n",
      "|    policy_gradient_loss | -0.0358   |\n",
      "|    value_loss           | 0.0175    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 640        |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58503014 |\n",
      "|    clip_fraction        | 0.0983     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0429    |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0814    |\n",
      "|    n_updates            | 10863      |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    value_loss           | 0.0193     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=35.18 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 82000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59049565 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.051     |\n",
      "|    explained_variance   | 0.491      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0307    |\n",
      "|    n_updates            | 10880      |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 641      |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 82048    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 642       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 82176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8094196 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.082    |\n",
      "|    explained_variance   | 0.904     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0843   |\n",
      "|    n_updates            | 10897     |\n",
      "|    policy_gradient_loss | -0.0472   |\n",
      "|    value_loss           | 0.0801    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 643        |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 82304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42839128 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.07      |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0871    |\n",
      "|    n_updates            | 10914      |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 644        |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 82432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.93209845 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.058     |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0362    |\n",
      "|    n_updates            | 10931      |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 0.25       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=82500, episode_reward=43.26 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 43.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 82500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6940731 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.048    |\n",
      "|    explained_variance   | 0.513     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.111    |\n",
      "|    n_updates            | 10948     |\n",
      "|    policy_gradient_loss | -0.0588   |\n",
      "|    value_loss           | 0.112     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 645      |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 82560    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 646        |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 82688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53437424 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0308    |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00248   |\n",
      "|    n_updates            | 10965      |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    value_loss           | 0.35       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 647        |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 82816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42572552 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0286    |\n",
      "|    explained_variance   | 0.773      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0325    |\n",
      "|    n_updates            | 10982      |\n",
      "|    policy_gradient_loss | -0.0613    |\n",
      "|    value_loss           | 0.294      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 648       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 82944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5061313 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0515   |\n",
      "|    explained_variance   | -1.14     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0158   |\n",
      "|    n_updates            | 10999     |\n",
      "|    policy_gradient_loss | -0.0436   |\n",
      "|    value_loss           | 0.0543    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=83000, episode_reward=13.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 13.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 83000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45951527 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0396    |\n",
      "|    explained_variance   | -1.44      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0492    |\n",
      "|    n_updates            | 11016      |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.054      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 649      |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 83072    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 650       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 83200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1698315 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.06     |\n",
      "|    explained_variance   | -0.692    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 11033     |\n",
      "|    policy_gradient_loss | -0.061    |\n",
      "|    value_loss           | 0.0205    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 651        |\n",
      "|    time_elapsed         | 91         |\n",
      "|    total_timesteps      | 83328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26815316 |\n",
      "|    clip_fraction        | 0.0905     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0466    |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.057     |\n",
      "|    n_updates            | 11050      |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 0.0275     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 652       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 83456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3720809 |\n",
      "|    clip_fraction        | 0.112     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.063    |\n",
      "|    explained_variance   | 0.395     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0218   |\n",
      "|    n_updates            | 11067     |\n",
      "|    policy_gradient_loss | -0.028    |\n",
      "|    value_loss           | 0.0672    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=83500, episode_reward=13.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 13.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 83500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29507184 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0638    |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0464    |\n",
      "|    n_updates            | 11084      |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 0.0465     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 653      |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 83584    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 654       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 83712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1455367 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0733   |\n",
      "|    explained_variance   | 0.742     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0595   |\n",
      "|    n_updates            | 11101     |\n",
      "|    policy_gradient_loss | -0.0784   |\n",
      "|    value_loss           | 0.167     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 655       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 83840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4164029 |\n",
      "|    clip_fraction        | 0.0983    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0537   |\n",
      "|    explained_variance   | 0.511     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00691   |\n",
      "|    n_updates            | 11118     |\n",
      "|    policy_gradient_loss | -0.0316   |\n",
      "|    value_loss           | 0.222     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 656       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 83968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4334065 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0689   |\n",
      "|    explained_variance   | 0.639     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0834   |\n",
      "|    n_updates            | 11135     |\n",
      "|    policy_gradient_loss | -0.0455   |\n",
      "|    value_loss           | 0.137     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=23.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 23.7     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 84000    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.512292 |\n",
      "|    clip_fraction        | 0.0813   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0518  |\n",
      "|    explained_variance   | 0.409    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0893  |\n",
      "|    n_updates            | 11152    |\n",
      "|    policy_gradient_loss | -0.0362  |\n",
      "|    value_loss           | 0.167    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 657      |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 84096    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 658        |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 84224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35316232 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0659    |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.142      |\n",
      "|    n_updates            | 11169      |\n",
      "|    policy_gradient_loss | -0.047     |\n",
      "|    value_loss           | 0.392      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 659        |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 84352      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47876033 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0574    |\n",
      "|    explained_variance   | 0.529      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00115   |\n",
      "|    n_updates            | 11186      |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 660       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 84480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9381734 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.064    |\n",
      "|    explained_variance   | 0.6       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.038    |\n",
      "|    n_updates            | 11203     |\n",
      "|    policy_gradient_loss | -0.0425   |\n",
      "|    value_loss           | 0.051     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=84500, episode_reward=26.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 84500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3294975 |\n",
      "|    clip_fraction        | 0.096     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0423   |\n",
      "|    explained_variance   | 0.17      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.017    |\n",
      "|    n_updates            | 11220     |\n",
      "|    policy_gradient_loss | -0.031    |\n",
      "|    value_loss           | 0.0338    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 661      |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 84608    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 662        |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 84736      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33697608 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0396    |\n",
      "|    explained_variance   | 0.0819     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 11237      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.0257     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 663        |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 84864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.92288184 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0879    |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0941    |\n",
      "|    n_updates            | 11254      |\n",
      "|    policy_gradient_loss | -0.0617    |\n",
      "|    value_loss           | 0.0772     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 664        |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 84992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43790632 |\n",
      "|    clip_fraction        | 0.0892     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0404    |\n",
      "|    explained_variance   | 0.692      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0364    |\n",
      "|    n_updates            | 11271      |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.0556     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=20.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 85000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40697017 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0778    |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0684    |\n",
      "|    n_updates            | 11288      |\n",
      "|    policy_gradient_loss | 0.00816    |\n",
      "|    value_loss           | 0.115      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 665      |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 85120    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 666        |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 85248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24954298 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0812    |\n",
      "|    explained_variance   | -0.00742   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.176      |\n",
      "|    n_updates            | 11305      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 1.25       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 667       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 85376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4673851 |\n",
      "|    clip_fraction        | 0.106     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0627   |\n",
      "|    explained_variance   | 0.372     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0567   |\n",
      "|    n_updates            | 11322     |\n",
      "|    policy_gradient_loss | -0.0458   |\n",
      "|    value_loss           | 0.408     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=85500, episode_reward=56.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 56.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 85500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4687343 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.085    |\n",
      "|    explained_variance   | 0.468     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00398  |\n",
      "|    n_updates            | 11339     |\n",
      "|    policy_gradient_loss | -0.0391   |\n",
      "|    value_loss           | 0.434     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 668      |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 85504    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 669        |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 85632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48939636 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.327      |\n",
      "|    n_updates            | 11356      |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 1.11       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 85760      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21667385 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0709    |\n",
      "|    explained_variance   | 0.895      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0814     |\n",
      "|    n_updates            | 11373      |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.372      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 671        |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 85888      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44170338 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0593    |\n",
      "|    explained_variance   | -0.101     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0402    |\n",
      "|    n_updates            | 11390      |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.0312     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=86000, episode_reward=51.63 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 86000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5167359 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0959   |\n",
      "|    explained_variance   | 0.321     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0734   |\n",
      "|    n_updates            | 11407     |\n",
      "|    policy_gradient_loss | -0.0455   |\n",
      "|    value_loss           | 0.0435    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 672      |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 86016    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 673        |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 86144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35166556 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0289    |\n",
      "|    explained_variance   | -0.604     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0946    |\n",
      "|    n_updates            | 11424      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.00812    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 674        |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 86272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24638921 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0615    |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00514    |\n",
      "|    n_updates            | 11441      |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    value_loss           | 0.068      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 675        |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 86400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27457154 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0718    |\n",
      "|    explained_variance   | 0.0687     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 11458      |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=86500, episode_reward=37.62 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 86500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68541586 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0695    |\n",
      "|    explained_variance   | 0.716      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 11475      |\n",
      "|    policy_gradient_loss | -0.0596    |\n",
      "|    value_loss           | 0.135      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 676      |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 86528    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 677       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 86656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2360727 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0362   |\n",
      "|    explained_variance   | 0.0501    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0353   |\n",
      "|    n_updates            | 11492     |\n",
      "|    policy_gradient_loss | -0.0558   |\n",
      "|    value_loss           | 0.197     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 678       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 86784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7158053 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0824   |\n",
      "|    explained_variance   | 0.226     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0118    |\n",
      "|    n_updates            | 11509     |\n",
      "|    policy_gradient_loss | -0.0713   |\n",
      "|    value_loss           | 0.699     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 679        |\n",
      "|    time_elapsed         | 95         |\n",
      "|    total_timesteps      | 86912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44226643 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0375    |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0533    |\n",
      "|    n_updates            | 11526      |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=14.18 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 14.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 87000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5220251 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0873   |\n",
      "|    explained_variance   | 0.642     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0779   |\n",
      "|    n_updates            | 11543     |\n",
      "|    policy_gradient_loss | -0.0633   |\n",
      "|    value_loss           | 0.151     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 680      |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 87040    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 681       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 87168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0266107 |\n",
      "|    clip_fraction        | 0.175     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0678   |\n",
      "|    explained_variance   | 0.719     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0345   |\n",
      "|    n_updates            | 11560     |\n",
      "|    policy_gradient_loss | -0.067    |\n",
      "|    value_loss           | 0.46      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 682       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 87296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5815302 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0927   |\n",
      "|    explained_variance   | -0.768    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.042    |\n",
      "|    n_updates            | 11577     |\n",
      "|    policy_gradient_loss | -0.0477   |\n",
      "|    value_loss           | 0.0491    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 683       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 87424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7955388 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0754   |\n",
      "|    explained_variance   | 0.0003    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0994   |\n",
      "|    n_updates            | 11594     |\n",
      "|    policy_gradient_loss | -0.0671   |\n",
      "|    value_loss           | 0.0373    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=87500, episode_reward=21.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 21.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 87500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6766657 |\n",
      "|    clip_fraction        | 0.224     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.143    |\n",
      "|    explained_variance   | 0.33      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0569   |\n",
      "|    n_updates            | 11611     |\n",
      "|    policy_gradient_loss | -0.0735   |\n",
      "|    value_loss           | 0.0423    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 684      |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 87552    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 685       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 87680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6898743 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0744   |\n",
      "|    explained_variance   | 0.226     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0614   |\n",
      "|    n_updates            | 11628     |\n",
      "|    policy_gradient_loss | -0.0543   |\n",
      "|    value_loss           | 0.0439    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 686       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 87808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5765052 |\n",
      "|    clip_fraction        | 0.183     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.096    |\n",
      "|    explained_variance   | 0.426     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.143    |\n",
      "|    n_updates            | 11645     |\n",
      "|    policy_gradient_loss | -0.073    |\n",
      "|    value_loss           | 0.0648    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 687        |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 87936      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35372195 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0767    |\n",
      "|    explained_variance   | 0.493      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0428    |\n",
      "|    n_updates            | 11662      |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=11.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 11.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 88000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1112331 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0702   |\n",
      "|    explained_variance   | 0.582     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.13     |\n",
      "|    n_updates            | 11679     |\n",
      "|    policy_gradient_loss | -0.0648   |\n",
      "|    value_loss           | 0.0907    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 688      |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 88064    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 689        |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 88192      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.92873657 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.074     |\n",
      "|    n_updates            | 11696      |\n",
      "|    policy_gradient_loss | -0.0826    |\n",
      "|    value_loss           | 0.337      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 690        |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 88320      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35785985 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0781    |\n",
      "|    explained_variance   | 0.55       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0586    |\n",
      "|    n_updates            | 11713      |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 691        |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 88448      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49513018 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0349    |\n",
      "|    n_updates            | 11730      |\n",
      "|    policy_gradient_loss | -0.0463    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=88500, episode_reward=2.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 2.77      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 88500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2406324 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0433   |\n",
      "|    explained_variance   | 0.336     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.12      |\n",
      "|    n_updates            | 11747     |\n",
      "|    policy_gradient_loss | -0.0663   |\n",
      "|    value_loss           | 0.482     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 692      |\n",
      "|    time_elapsed    | 97       |\n",
      "|    total_timesteps | 88576    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 693        |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 88704      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26413986 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0588    |\n",
      "|    explained_variance   | -0.187     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0373    |\n",
      "|    n_updates            | 11764      |\n",
      "|    policy_gradient_loss | -0.0465    |\n",
      "|    value_loss           | 0.0382     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 694        |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 88832      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46425793 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0757    |\n",
      "|    explained_variance   | -0.193     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0748    |\n",
      "|    n_updates            | 11781      |\n",
      "|    policy_gradient_loss | -0.0516    |\n",
      "|    value_loss           | 0.0386     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 695       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 88960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6131073 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0684   |\n",
      "|    explained_variance   | -0.722    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0212   |\n",
      "|    n_updates            | 11798     |\n",
      "|    policy_gradient_loss | -0.0397   |\n",
      "|    value_loss           | 0.0167    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=6.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.5        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 89000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24204451 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.019      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0873    |\n",
      "|    n_updates            | 11815      |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    value_loss           | 0.0288     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 696      |\n",
      "|    time_elapsed    | 97       |\n",
      "|    total_timesteps | 89088    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 697        |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 89216      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43376935 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.123     |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0601    |\n",
      "|    n_updates            | 11832      |\n",
      "|    policy_gradient_loss | -0.0594    |\n",
      "|    value_loss           | 0.0407     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 698       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 89344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7074586 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0503   |\n",
      "|    explained_variance   | 0.368     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0831   |\n",
      "|    n_updates            | 11849     |\n",
      "|    policy_gradient_loss | -0.0532   |\n",
      "|    value_loss           | 0.0764    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 38.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 914      |\n",
      "|    iterations           | 699      |\n",
      "|    time_elapsed         | 97       |\n",
      "|    total_timesteps      | 89472    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 9.79758  |\n",
      "|    clip_fraction        | 0.136    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0686  |\n",
      "|    explained_variance   | 0.409    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0664  |\n",
      "|    n_updates            | 11866    |\n",
      "|    policy_gradient_loss | -0.0498  |\n",
      "|    value_loss           | 0.0727   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=89500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 89500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43424243 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0523    |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0809    |\n",
      "|    n_updates            | 11883      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 700      |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 89600    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 701       |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 89728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8096535 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.166     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0884   |\n",
      "|    n_updates            | 11900     |\n",
      "|    policy_gradient_loss | -0.0653   |\n",
      "|    value_loss           | 0.226     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 702       |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 89856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4137755 |\n",
      "|    clip_fraction        | 0.0947    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0525   |\n",
      "|    explained_variance   | 0.293     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0616   |\n",
      "|    n_updates            | 11917     |\n",
      "|    policy_gradient_loss | -0.053    |\n",
      "|    value_loss           | 0.166     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 38.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 89984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.107298374 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.00858    |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 11934       |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 90000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3139682 |\n",
      "|    clip_fraction        | 0.0974    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.073    |\n",
      "|    explained_variance   | 0.456     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.063    |\n",
      "|    n_updates            | 11951     |\n",
      "|    policy_gradient_loss | -0.0387   |\n",
      "|    value_loss           | 0.115     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 704      |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 705        |\n",
      "|    time_elapsed         | 98         |\n",
      "|    total_timesteps      | 90240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35570228 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0812    |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0219    |\n",
      "|    n_updates            | 11968      |\n",
      "|    policy_gradient_loss | -0.0581    |\n",
      "|    value_loss           | 0.0664     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 706       |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 90368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6103366 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0727   |\n",
      "|    explained_variance   | -0.111    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0598   |\n",
      "|    n_updates            | 11985     |\n",
      "|    policy_gradient_loss | -0.0509   |\n",
      "|    value_loss           | 0.0294    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 707       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 90496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4127962 |\n",
      "|    clip_fraction        | 0.186     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.141    |\n",
      "|    explained_variance   | -0.193    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0881   |\n",
      "|    n_updates            | 12002     |\n",
      "|    policy_gradient_loss | -0.0675   |\n",
      "|    value_loss           | 0.033     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=90500, episode_reward=2.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 2.13      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 90500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6651336 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.154    |\n",
      "|    explained_variance   | -0.0443   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0779   |\n",
      "|    n_updates            | 12019     |\n",
      "|    policy_gradient_loss | -0.048    |\n",
      "|    value_loss           | 0.0529    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 708      |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 90624    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 709       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 90752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0055511 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0851   |\n",
      "|    explained_variance   | 0.353     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0827   |\n",
      "|    n_updates            | 12036     |\n",
      "|    policy_gradient_loss | -0.069    |\n",
      "|    value_loss           | 0.0537    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 710       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 90880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2553676 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0629   |\n",
      "|    explained_variance   | 0.0499    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0344   |\n",
      "|    n_updates            | 12053     |\n",
      "|    policy_gradient_loss | -0.0372   |\n",
      "|    value_loss           | 0.0636    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=7.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 7.5        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 91000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.94820863 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0817    |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0357    |\n",
      "|    n_updates            | 12070      |\n",
      "|    policy_gradient_loss | -0.0628    |\n",
      "|    value_loss           | 0.344      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 711      |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 91008    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 712        |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 91136      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36920673 |\n",
      "|    clip_fraction        | 0.097      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0501    |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.058     |\n",
      "|    n_updates            | 12087      |\n",
      "|    policy_gradient_loss | -0.0429    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 713        |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 91264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79427314 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0495    |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0685    |\n",
      "|    n_updates            | 12104      |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    value_loss           | 0.097      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 714       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 91392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8232903 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.76      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0928   |\n",
      "|    n_updates            | 12121     |\n",
      "|    policy_gradient_loss | -0.0589   |\n",
      "|    value_loss           | 0.212     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=91500, episode_reward=-11.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -11.2     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 91500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5250499 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0743   |\n",
      "|    explained_variance   | 0.179     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0697    |\n",
      "|    n_updates            | 12138     |\n",
      "|    policy_gradient_loss | -0.0441   |\n",
      "|    value_loss           | 0.752     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 715      |\n",
      "|    time_elapsed    | 100      |\n",
      "|    total_timesteps | 91520    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 716        |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 91648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71758884 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0564    |\n",
      "|    explained_variance   | -0.195     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0618    |\n",
      "|    n_updates            | 12155      |\n",
      "|    policy_gradient_loss | -0.0515    |\n",
      "|    value_loss           | 0.0221     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 717        |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 91776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11615309 |\n",
      "|    clip_fraction        | 0.0395     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0416    |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0171    |\n",
      "|    n_updates            | 12172      |\n",
      "|    policy_gradient_loss | -0.00988   |\n",
      "|    value_loss           | 0.0206     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 718       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 91904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4352733 |\n",
      "|    clip_fraction        | 0.0708    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0558   |\n",
      "|    explained_variance   | 0.418     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 12189     |\n",
      "|    policy_gradient_loss | -0.025    |\n",
      "|    value_loss           | 0.0318    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=1.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 1.67      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 92000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6141595 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0516   |\n",
      "|    explained_variance   | 0.0906    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0735   |\n",
      "|    n_updates            | 12206     |\n",
      "|    policy_gradient_loss | -0.0666   |\n",
      "|    value_loss           | 0.0473    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 719      |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 92032    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 720        |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53327495 |\n",
      "|    clip_fraction        | 0.0561     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0396    |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0448    |\n",
      "|    n_updates            | 12223      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.0479     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 721       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 92288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4366302 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0707   |\n",
      "|    explained_variance   | 0.519     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0648   |\n",
      "|    n_updates            | 12240     |\n",
      "|    policy_gradient_loss | -0.0441   |\n",
      "|    value_loss           | 0.0486    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 722        |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 92416      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37164193 |\n",
      "|    clip_fraction        | 0.0731     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0398    |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00214   |\n",
      "|    n_updates            | 12257      |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=92500, episode_reward=2.60 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.6        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 92500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.81886756 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0442    |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0545     |\n",
      "|    n_updates            | 12274      |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    value_loss           | 0.477      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 723      |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 92544    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 724       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 92672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5262088 |\n",
      "|    clip_fraction        | 0.0754    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0346   |\n",
      "|    explained_variance   | 0.59      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.071    |\n",
      "|    n_updates            | 12291     |\n",
      "|    policy_gradient_loss | -0.0308   |\n",
      "|    value_loss           | 0.159     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 725        |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 92800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54272985 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0551    |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.046     |\n",
      "|    n_updates            | 12308      |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    value_loss           | 0.149      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 726        |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 92928      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20684496 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0871    |\n",
      "|    explained_variance   | -0.0758    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0908     |\n",
      "|    n_updates            | 12325      |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    value_loss           | 0.821      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=7.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 7.81      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 93000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7733359 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0887   |\n",
      "|    explained_variance   | -0.331    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0797   |\n",
      "|    n_updates            | 12342     |\n",
      "|    policy_gradient_loss | -0.0721   |\n",
      "|    value_loss           | 0.0365    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 727      |\n",
      "|    time_elapsed    | 102      |\n",
      "|    total_timesteps | 93056    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 728        |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 93184      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21085458 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0868    |\n",
      "|    explained_variance   | -0.312     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0438    |\n",
      "|    n_updates            | 12359      |\n",
      "|    policy_gradient_loss | -0.0519    |\n",
      "|    value_loss           | 0.0599     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 729       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 93312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3910731 |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.095    |\n",
      "|    explained_variance   | -0.769    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.158    |\n",
      "|    n_updates            | 12376     |\n",
      "|    policy_gradient_loss | -0.0725   |\n",
      "|    value_loss           | 0.0183    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 730        |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 93440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14957651 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0769    |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0489    |\n",
      "|    n_updates            | 12393      |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.0292     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=93500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 93500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2946212 |\n",
      "|    clip_fraction        | 0.063     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0399   |\n",
      "|    explained_variance   | 0.218     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.000775 |\n",
      "|    n_updates            | 12410     |\n",
      "|    policy_gradient_loss | -0.0401   |\n",
      "|    value_loss           | 0.0554    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 731      |\n",
      "|    time_elapsed    | 102      |\n",
      "|    total_timesteps | 93568    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 732       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 93696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5541388 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0565   |\n",
      "|    explained_variance   | 0.117     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0609   |\n",
      "|    n_updates            | 12427     |\n",
      "|    policy_gradient_loss | -0.0437   |\n",
      "|    value_loss           | 0.05      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 733        |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 93824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40481603 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0424    |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0436    |\n",
      "|    n_updates            | 12444      |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.0571     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 734        |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 93952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31109685 |\n",
      "|    clip_fraction        | 0.0717     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0218    |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0225     |\n",
      "|    n_updates            | 12461      |\n",
      "|    policy_gradient_loss | -0.0236    |\n",
      "|    value_loss           | 0.356      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 94000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4964487 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0853   |\n",
      "|    explained_variance   | 0.545     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0471   |\n",
      "|    n_updates            | 12478     |\n",
      "|    policy_gradient_loss | -0.0739   |\n",
      "|    value_loss           | 0.443     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 735      |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 94080    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 736        |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.72131026 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0532    |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0666    |\n",
      "|    n_updates            | 12495      |\n",
      "|    policy_gradient_loss | -0.0514    |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 737        |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 94336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60071516 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0517    |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0312    |\n",
      "|    n_updates            | 12512      |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 738       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 94464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1855577 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0863   |\n",
      "|    explained_variance   | 0.266     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0443   |\n",
      "|    n_updates            | 12529     |\n",
      "|    policy_gradient_loss | -0.0585   |\n",
      "|    value_loss           | 0.121     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=94500, episode_reward=4.17 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.17       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 94500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50421125 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0638    |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0135    |\n",
      "|    n_updates            | 12546      |\n",
      "|    policy_gradient_loss | -0.0505    |\n",
      "|    value_loss           | 0.0396     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 739      |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 94592    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 740        |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 94720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.80486715 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0746    |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0992    |\n",
      "|    n_updates            | 12563      |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    value_loss           | 0.02       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 741       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 94848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.1604776 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | -0.678    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.142    |\n",
      "|    n_updates            | 12580     |\n",
      "|    policy_gradient_loss | -0.08     |\n",
      "|    value_loss           | 0.0125    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 742        |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 94976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78077674 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.084     |\n",
      "|    explained_variance   | -0.428     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0142     |\n",
      "|    n_updates            | 12597      |\n",
      "|    policy_gradient_loss | -0.0571    |\n",
      "|    value_loss           | 0.053      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=52.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 52.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 95000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7067225 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0403   |\n",
      "|    explained_variance   | 0.197     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0611   |\n",
      "|    n_updates            | 12614     |\n",
      "|    policy_gradient_loss | -0.0608   |\n",
      "|    value_loss           | 0.0457    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 743      |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 95104    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.2     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 910      |\n",
      "|    iterations           | 744      |\n",
      "|    time_elapsed         | 104      |\n",
      "|    total_timesteps      | 95232    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.215838 |\n",
      "|    clip_fraction        | 0.108    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0407  |\n",
      "|    explained_variance   | 0.527    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.071   |\n",
      "|    n_updates            | 12631    |\n",
      "|    policy_gradient_loss | -0.028   |\n",
      "|    value_loss           | 0.058    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 745        |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 95360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63723373 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0566    |\n",
      "|    explained_variance   | -0.24      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.993      |\n",
      "|    n_updates            | 12648      |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 1.68       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 746       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 95488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1072079 |\n",
      "|    clip_fraction        | 0.0813    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0346   |\n",
      "|    explained_variance   | 0.471     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0741    |\n",
      "|    n_updates            | 12665     |\n",
      "|    policy_gradient_loss | -0.0352   |\n",
      "|    value_loss           | 0.409     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=95500, episode_reward=42.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 42.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 95500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79609424 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0512    |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.021     |\n",
      "|    n_updates            | 12682      |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.155      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 747      |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 95616    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 748        |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 95744      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36304823 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0435    |\n",
      "|    explained_variance   | 0.134      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.522      |\n",
      "|    n_updates            | 12699      |\n",
      "|    policy_gradient_loss | -0.0516    |\n",
      "|    value_loss           | 2.42       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 749       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 95872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4084878 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.075    |\n",
      "|    explained_variance   | 0.142     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00489  |\n",
      "|    n_updates            | 12716     |\n",
      "|    policy_gradient_loss | -0.073    |\n",
      "|    value_loss           | 0.88      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-3.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -3.74      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 96000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.86747205 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0638    |\n",
      "|    explained_variance   | -0.358     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0864    |\n",
      "|    n_updates            | 12733      |\n",
      "|    policy_gradient_loss | -0.0549    |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 750      |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 96000    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 751       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 96128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2351885 |\n",
      "|    clip_fraction        | 0.0478    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0323   |\n",
      "|    explained_variance   | -0.377    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.012    |\n",
      "|    n_updates            | 12750     |\n",
      "|    policy_gradient_loss | -0.0139   |\n",
      "|    value_loss           | 0.0305    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 752        |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26419115 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0782    |\n",
      "|    explained_variance   | -1.3       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0317    |\n",
      "|    n_updates            | 12767      |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.0142     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 753        |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 96384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31380382 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0793    |\n",
      "|    explained_variance   | -0.149     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0668    |\n",
      "|    n_updates            | 12784      |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    value_loss           | 0.0348     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=96500, episode_reward=6.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.59       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 96500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.61869884 |\n",
      "|    clip_fraction        | 0.0602     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0298    |\n",
      "|    explained_variance   | 0.128      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0704    |\n",
      "|    n_updates            | 12801      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.0599     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 754      |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 96512    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 96640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08621912 |\n",
      "|    clip_fraction        | 0.0285     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.011     |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00598    |\n",
      "|    n_updates            | 12818      |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.0782     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 910      |\n",
      "|    iterations           | 756      |\n",
      "|    time_elapsed         | 106      |\n",
      "|    total_timesteps      | 96768    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.467376 |\n",
      "|    clip_fraction        | 0.11     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0542  |\n",
      "|    explained_variance   | 0.397    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0368  |\n",
      "|    n_updates            | 12835    |\n",
      "|    policy_gradient_loss | -0.0364  |\n",
      "|    value_loss           | 0.178    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 757        |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 96896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40638533 |\n",
      "|    clip_fraction        | 0.0983     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0815    |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0971     |\n",
      "|    n_updates            | 12852      |\n",
      "|    policy_gradient_loss | -0.0494    |\n",
      "|    value_loss           | 1.25       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=32.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 97000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63709354 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0902    |\n",
      "|    explained_variance   | 0.0699     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0279    |\n",
      "|    n_updates            | 12869      |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    value_loss           | 0.332      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 758      |\n",
      "|    time_elapsed    | 106      |\n",
      "|    total_timesteps | 97024    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 759        |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 97152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17698193 |\n",
      "|    clip_fraction        | 0.0354     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0167    |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0203     |\n",
      "|    n_updates            | 12886      |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    value_loss           | 0.263      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 760        |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 97280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08031535 |\n",
      "|    clip_fraction        | 0.0639     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0813    |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 12903      |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    value_loss           | 0.609      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 761        |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 97408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21354795 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0455    |\n",
      "|    explained_variance   | -0.569     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0103     |\n",
      "|    n_updates            | 12920      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.0317     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=97500, episode_reward=42.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 97500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27646822 |\n",
      "|    clip_fraction        | 0.0409     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0183    |\n",
      "|    explained_variance   | -0.775     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0378    |\n",
      "|    n_updates            | 12937      |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    value_loss           | 0.0159     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 97536    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 763       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 97664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5323772 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0597   |\n",
      "|    explained_variance   | -0.584    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 12954     |\n",
      "|    policy_gradient_loss | -0.0704   |\n",
      "|    value_loss           | 0.0141    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 764        |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 97792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32303834 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0607    |\n",
      "|    explained_variance   | -1.57      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0462    |\n",
      "|    n_updates            | 12971      |\n",
      "|    policy_gradient_loss | -0.0413    |\n",
      "|    value_loss           | 0.0163     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 765       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 97920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5810672 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0783   |\n",
      "|    explained_variance   | 0.58      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0733   |\n",
      "|    n_updates            | 12988     |\n",
      "|    policy_gradient_loss | -0.0562   |\n",
      "|    value_loss           | 0.0666    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=9.44 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 9.44       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 98000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28585356 |\n",
      "|    clip_fraction        | 0.0777     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0375    |\n",
      "|    explained_variance   | -0.00362   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0149    |\n",
      "|    n_updates            | 13005      |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 0.0704     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 766      |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 98048    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 767        |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 98176      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49192417 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0815    |\n",
      "|    explained_variance   | 0.222      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0618    |\n",
      "|    n_updates            | 13022      |\n",
      "|    policy_gradient_loss | -0.0516    |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 768       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0331192 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0295   |\n",
      "|    explained_variance   | 0.753     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0113   |\n",
      "|    n_updates            | 13039     |\n",
      "|    policy_gradient_loss | -0.0284   |\n",
      "|    value_loss           | 0.326     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 769        |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 98432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58155286 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0887    |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0291    |\n",
      "|    n_updates            | 13056      |\n",
      "|    policy_gradient_loss | -0.0668    |\n",
      "|    value_loss           | 0.462      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=98500, episode_reward=20.63 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 98500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42813668 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0629    |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 13073      |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 770      |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 98560    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 771       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 98688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1199106 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0817   |\n",
      "|    explained_variance   | 0.564     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0371   |\n",
      "|    n_updates            | 13090     |\n",
      "|    policy_gradient_loss | -0.0555   |\n",
      "|    value_loss           | 0.329     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 772       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 98816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3234869 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0656   |\n",
      "|    explained_variance   | 0.481     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.027    |\n",
      "|    n_updates            | 13107     |\n",
      "|    policy_gradient_loss | -0.0502   |\n",
      "|    value_loss           | 0.115     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 773        |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 98944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21073039 |\n",
      "|    clip_fraction        | 0.0643     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.063     |\n",
      "|    explained_variance   | -0.0458    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0299    |\n",
      "|    n_updates            | 13124      |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 0.0462     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=99000, episode_reward=41.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 99000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5210652 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0779   |\n",
      "|    explained_variance   | 0.256     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0908   |\n",
      "|    n_updates            | 13141     |\n",
      "|    policy_gradient_loss | -0.057    |\n",
      "|    value_loss           | 0.0176    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 774      |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 99072    |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 912      |\n",
      "|    iterations           | 775      |\n",
      "|    time_elapsed         | 108      |\n",
      "|    total_timesteps      | 99200    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.09624  |\n",
      "|    clip_fraction        | 0.216    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.116   |\n",
      "|    explained_variance   | -0.184   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0978  |\n",
      "|    n_updates            | 13158    |\n",
      "|    policy_gradient_loss | -0.0727  |\n",
      "|    value_loss           | 0.016    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 776        |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 99328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36723694 |\n",
      "|    clip_fraction        | 0.0892     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0509    |\n",
      "|    explained_variance   | -0.892     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 13175      |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 0.0624     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 777        |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 99456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47656935 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0471    |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0715    |\n",
      "|    n_updates            | 13192      |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    value_loss           | 0.0624     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=99500, episode_reward=20.63 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 20.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 99500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4238064 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0557   |\n",
      "|    explained_variance   | 0.319     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0976   |\n",
      "|    n_updates            | 13209     |\n",
      "|    policy_gradient_loss | -0.0465   |\n",
      "|    value_loss           | 0.115     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 778      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 99584    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 779        |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 99712      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12792079 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.04      |\n",
      "|    explained_variance   | 0.477      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0011    |\n",
      "|    n_updates            | 13226      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.53       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 780        |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 99840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25515708 |\n",
      "|    clip_fraction        | 0.0542     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0364    |\n",
      "|    explained_variance   | 0.79       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00536   |\n",
      "|    n_updates            | 13243      |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 781       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 99968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6115815 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0896   |\n",
      "|    explained_variance   | 0.515     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 13260     |\n",
      "|    policy_gradient_loss | -0.0434   |\n",
      "|    value_loss           | 0.186     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=33.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 100000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15213005 |\n",
      "|    clip_fraction        | 0.0496     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0249    |\n",
      "|    explained_variance   | 0.233      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00803   |\n",
      "|    n_updates            | 13277      |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 782      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 100096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 783       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 100224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5067416 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0797   |\n",
      "|    explained_variance   | 0.571     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0166   |\n",
      "|    n_updates            | 13294     |\n",
      "|    policy_gradient_loss | -0.0344   |\n",
      "|    value_loss           | 0.117     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 784       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4424801 |\n",
      "|    clip_fraction        | 0.224     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0803   |\n",
      "|    explained_variance   | -0.318    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 13311     |\n",
      "|    policy_gradient_loss | -0.085    |\n",
      "|    value_loss           | 0.0342    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 785        |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 100480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65240395 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0884    |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0211    |\n",
      "|    n_updates            | 13328      |\n",
      "|    policy_gradient_loss | -0.0662    |\n",
      "|    value_loss           | 0.0385     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100500, episode_reward=23.66 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 23.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 100500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48930174 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0501    |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0348    |\n",
      "|    n_updates            | 13345      |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 786      |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 100608   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 787       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 100736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9567225 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0858   |\n",
      "|    explained_variance   | 0.0263    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0964   |\n",
      "|    n_updates            | 13362     |\n",
      "|    policy_gradient_loss | -0.0595   |\n",
      "|    value_loss           | 0.0318    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 788        |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 100864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.90733886 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0599    |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0546    |\n",
      "|    n_updates            | 13379      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.0454     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 789        |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 100992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06807821 |\n",
      "|    clip_fraction        | 0.0556     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0356    |\n",
      "|    explained_variance   | 0.0167     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.051     |\n",
      "|    n_updates            | 13396      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.0455     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=101000, episode_reward=-7.84 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -7.84     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 101000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2788002 |\n",
      "|    clip_fraction        | 0.0556    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0522   |\n",
      "|    explained_variance   | 0.371     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0885    |\n",
      "|    n_updates            | 13413     |\n",
      "|    policy_gradient_loss | -0.015    |\n",
      "|    value_loss           | 0.534     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 790      |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 101120   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 912      |\n",
      "|    iterations           | 791      |\n",
      "|    time_elapsed         | 110      |\n",
      "|    total_timesteps      | 101248   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.280666 |\n",
      "|    clip_fraction        | 0.0694   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0232  |\n",
      "|    explained_variance   | 0.431    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0278   |\n",
      "|    n_updates            | 13430    |\n",
      "|    policy_gradient_loss | -0.0346  |\n",
      "|    value_loss           | 0.407    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 37          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022193454 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0101     |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.00118    |\n",
      "|    n_updates            | 13447       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=101500, episode_reward=13.16 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 13.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 101500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32137224 |\n",
      "|    clip_fraction        | 0.097      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0375    |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0288    |\n",
      "|    n_updates            | 13464      |\n",
      "|    policy_gradient_loss | -0.0515    |\n",
      "|    value_loss           | 0.0977     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 793      |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 101504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 794        |\n",
      "|    time_elapsed         | 111        |\n",
      "|    total_timesteps      | 101632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24120437 |\n",
      "|    clip_fraction        | 0.045      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0152    |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0132     |\n",
      "|    n_updates            | 13481      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 795       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 101760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8595538 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0543   |\n",
      "|    explained_variance   | -0.275    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0609   |\n",
      "|    n_updates            | 13498     |\n",
      "|    policy_gradient_loss | -0.0545   |\n",
      "|    value_loss           | 0.0226    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 796        |\n",
      "|    time_elapsed         | 111        |\n",
      "|    total_timesteps      | 101888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28003287 |\n",
      "|    clip_fraction        | 0.0501     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0194    |\n",
      "|    explained_variance   | -0.779     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0441    |\n",
      "|    n_updates            | 13515      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.0696     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=23.16 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 23.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 102000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51724476 |\n",
      "|    clip_fraction        | 0.0896     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0194    |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0421    |\n",
      "|    n_updates            | 13532      |\n",
      "|    policy_gradient_loss | -0.0402    |\n",
      "|    value_loss           | 0.0282     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 797      |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 102016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 798        |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 102144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13193204 |\n",
      "|    clip_fraction        | 0.0317     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0103    |\n",
      "|    explained_variance   | 0.00545    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0103    |\n",
      "|    n_updates            | 13549      |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    value_loss           | 0.0138     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 799        |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 102272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22824505 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0227    |\n",
      "|    explained_variance   | 0.143      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0356    |\n",
      "|    n_updates            | 13566      |\n",
      "|    policy_gradient_loss | -0.0348    |\n",
      "|    value_loss           | 0.0455     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 800        |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48426703 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0564    |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0566    |\n",
      "|    n_updates            | 13583      |\n",
      "|    policy_gradient_loss | -0.0377    |\n",
      "|    value_loss           | 0.0468     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=102500, episode_reward=30.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 102500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49909607 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.05      |\n",
      "|    explained_variance   | -0.0319    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0295    |\n",
      "|    n_updates            | 13600      |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    value_loss           | 0.0559     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 801      |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 102528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 802       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 102656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7374164 |\n",
      "|    clip_fraction        | 0.085     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.033    |\n",
      "|    explained_variance   | 0.766     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0909   |\n",
      "|    n_updates            | 13617     |\n",
      "|    policy_gradient_loss | -0.0416   |\n",
      "|    value_loss           | 0.211     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 803        |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 102784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15979515 |\n",
      "|    clip_fraction        | 0.0506     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0207    |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0309    |\n",
      "|    n_updates            | 13634      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.135      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 804        |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 102912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36351663 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0536    |\n",
      "|    explained_variance   | 0.377      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0463    |\n",
      "|    n_updates            | 13651      |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 0.131      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=103000, episode_reward=-7.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -7.49     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 103000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3502413 |\n",
      "|    clip_fraction        | 0.0492    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0237   |\n",
      "|    explained_variance   | 0.596     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00148   |\n",
      "|    n_updates            | 13668     |\n",
      "|    policy_gradient_loss | -0.0171   |\n",
      "|    value_loss           | 0.142     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 805      |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 103040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 806       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 103168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0563006 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.041    |\n",
      "|    explained_variance   | 0.863     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0188    |\n",
      "|    n_updates            | 13685     |\n",
      "|    policy_gradient_loss | -0.0212   |\n",
      "|    value_loss           | 0.0694    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 807        |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 103296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68692076 |\n",
      "|    clip_fraction        | 0.0951     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0307    |\n",
      "|    explained_variance   | 0.0358     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0184    |\n",
      "|    n_updates            | 13702      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.0451     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 808       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 103424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.4156275 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0478   |\n",
      "|    explained_variance   | 0.185     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0766   |\n",
      "|    n_updates            | 13719     |\n",
      "|    policy_gradient_loss | -0.0663   |\n",
      "|    value_loss           | 0.0196    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=103500, episode_reward=14.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 14.9     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 103500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.688483 |\n",
      "|    clip_fraction        | 0.145    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0822  |\n",
      "|    explained_variance   | 0.281    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.105   |\n",
      "|    n_updates            | 13736    |\n",
      "|    policy_gradient_loss | -0.0493  |\n",
      "|    value_loss           | 0.008    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 809      |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 103552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 810        |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 103680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74224967 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0542    |\n",
      "|    explained_variance   | -0.119     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0701    |\n",
      "|    n_updates            | 13753      |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.0769     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 811        |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 103808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32389474 |\n",
      "|    clip_fraction        | 0.0561     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0229    |\n",
      "|    explained_variance   | 0.642      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00868   |\n",
      "|    n_updates            | 13770      |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.0479     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 812        |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 103936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40459874 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0574    |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0488    |\n",
      "|    n_updates            | 13787      |\n",
      "|    policy_gradient_loss | -0.0471    |\n",
      "|    value_loss           | 0.07       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=-0.41 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -0.408    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 104000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4614483 |\n",
      "|    clip_fraction        | 0.0699    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.043    |\n",
      "|    explained_variance   | -0.416    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.235     |\n",
      "|    n_updates            | 13804     |\n",
      "|    policy_gradient_loss | -0.0259   |\n",
      "|    value_loss           | 1.25      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 813      |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 104064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 814        |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 104192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25478777 |\n",
      "|    clip_fraction        | 0.0542     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0357    |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.015      |\n",
      "|    n_updates            | 13821      |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    value_loss           | 0.276      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 815       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 104320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2631441 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0554   |\n",
      "|    explained_variance   | -0.0206   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.119    |\n",
      "|    n_updates            | 13838     |\n",
      "|    policy_gradient_loss | -0.0589   |\n",
      "|    value_loss           | 0.203     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 816        |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 104448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18591306 |\n",
      "|    clip_fraction        | 0.0506     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0249    |\n",
      "|    explained_variance   | 0.482      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0616     |\n",
      "|    n_updates            | 13855      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.436      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=104500, episode_reward=-16.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -16.8      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 104500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10016227 |\n",
      "|    clip_fraction        | 0.0377     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.021     |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00484   |\n",
      "|    n_updates            | 13872      |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.0363     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 817      |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 104576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 818       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 104704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2339112 |\n",
      "|    clip_fraction        | 0.0515    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0204   |\n",
      "|    explained_variance   | -0.363    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00208  |\n",
      "|    n_updates            | 13889     |\n",
      "|    policy_gradient_loss | -0.0281   |\n",
      "|    value_loss           | 0.0379    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 819        |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 104832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68605036 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0518    |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0853    |\n",
      "|    n_updates            | 13906      |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.056      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 820       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 104960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9386607 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0473   |\n",
      "|    explained_variance   | 0.0115    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0532   |\n",
      "|    n_updates            | 13923     |\n",
      "|    policy_gradient_loss | -0.0606   |\n",
      "|    value_loss           | 0.0156    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=36.69 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 105000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6738262 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0763   |\n",
      "|    explained_variance   | 0.03      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 13940     |\n",
      "|    policy_gradient_loss | -0.0568   |\n",
      "|    value_loss           | 0.0523    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 821      |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 105088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 822       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 105216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6136956 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0548   |\n",
      "|    explained_variance   | -0.3      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0591   |\n",
      "|    n_updates            | 13957     |\n",
      "|    policy_gradient_loss | -0.0543   |\n",
      "|    value_loss           | 0.0911    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 823       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 105344    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7625208 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0505   |\n",
      "|    explained_variance   | -0.333    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 13974     |\n",
      "|    policy_gradient_loss | -0.0585   |\n",
      "|    value_loss           | 0.0579    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 824       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 105472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6192623 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0806   |\n",
      "|    explained_variance   | 0.0648    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0333   |\n",
      "|    n_updates            | 13991     |\n",
      "|    policy_gradient_loss | -0.0476   |\n",
      "|    value_loss           | 0.527     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=105500, episode_reward=33.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 105500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20681047 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0316    |\n",
      "|    explained_variance   | 0.111      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0969     |\n",
      "|    n_updates            | 14008      |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    value_loss           | 0.479      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 825      |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 105600   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 36.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 912      |\n",
      "|    iterations           | 826      |\n",
      "|    time_elapsed         | 115      |\n",
      "|    total_timesteps      | 105728   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.492346 |\n",
      "|    clip_fraction        | 0.112    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0659  |\n",
      "|    explained_variance   | 0.626    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0355  |\n",
      "|    n_updates            | 14025    |\n",
      "|    policy_gradient_loss | -0.0424  |\n",
      "|    value_loss           | 0.19     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 827       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 105856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5049257 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.082    |\n",
      "|    explained_variance   | -0.0182   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.301     |\n",
      "|    n_updates            | 14042     |\n",
      "|    policy_gradient_loss | -0.0534   |\n",
      "|    value_loss           | 1.27      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 828        |\n",
      "|    time_elapsed         | 115        |\n",
      "|    total_timesteps      | 105984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91358656 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0484    |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0284    |\n",
      "|    n_updates            | 14059      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.427      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=95.72 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 95.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 106000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.3797886 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0284   |\n",
      "|    explained_variance   | -0.211    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0151    |\n",
      "|    n_updates            | 14076     |\n",
      "|    policy_gradient_loss | -0.0325   |\n",
      "|    value_loss           | 0.167     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 829      |\n",
      "|    time_elapsed    | 116      |\n",
      "|    total_timesteps | 106112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 830       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 106240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8063084 |\n",
      "|    clip_fraction        | 0.0574    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0141   |\n",
      "|    explained_variance   | 0.33      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00395  |\n",
      "|    n_updates            | 14093     |\n",
      "|    policy_gradient_loss | -0.0216   |\n",
      "|    value_loss           | 0.0723    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 831       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 106368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8668981 |\n",
      "|    clip_fraction        | 0.0331    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.00624  |\n",
      "|    explained_variance   | 0.033     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0322   |\n",
      "|    n_updates            | 14110     |\n",
      "|    policy_gradient_loss | -0.0132   |\n",
      "|    value_loss           | 0.018     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 832        |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91637444 |\n",
      "|    clip_fraction        | 0.0607     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0168    |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0687    |\n",
      "|    n_updates            | 14127      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.0375     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=106500, episode_reward=32.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 32.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 106500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6538583 |\n",
      "|    clip_fraction        | 0.0786    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0323   |\n",
      "|    explained_variance   | -0.112    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.033    |\n",
      "|    n_updates            | 14144     |\n",
      "|    policy_gradient_loss | -0.0373   |\n",
      "|    value_loss           | 0.0393    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 833      |\n",
      "|    time_elapsed    | 116      |\n",
      "|    total_timesteps | 106624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 834        |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 106752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.82574236 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0682    |\n",
      "|    explained_variance   | 0.327      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.114     |\n",
      "|    n_updates            | 14161      |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0815     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 835        |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 106880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68549424 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0482    |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 14178      |\n",
      "|    policy_gradient_loss | -0.0442    |\n",
      "|    value_loss           | 0.0917     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=107000, episode_reward=22.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 22.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 107000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3307904 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0606   |\n",
      "|    explained_variance   | 0.277     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0353   |\n",
      "|    n_updates            | 14195     |\n",
      "|    policy_gradient_loss | -0.05     |\n",
      "|    value_loss           | 0.319     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 836      |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 107008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 837        |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 107136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19123459 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0374    |\n",
      "|    explained_variance   | 0.578      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0227    |\n",
      "|    n_updates            | 14212      |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    value_loss           | 0.636      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 838       |\n",
      "|    time_elapsed         | 117       |\n",
      "|    total_timesteps      | 107264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7439329 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0881   |\n",
      "|    explained_variance   | 0.335     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0781   |\n",
      "|    n_updates            | 14229     |\n",
      "|    policy_gradient_loss | -0.068    |\n",
      "|    value_loss           | 0.283     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 839       |\n",
      "|    time_elapsed         | 117       |\n",
      "|    total_timesteps      | 107392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5522363 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.151    |\n",
      "|    explained_variance   | 0.301     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.369     |\n",
      "|    n_updates            | 14246     |\n",
      "|    policy_gradient_loss | -0.0695   |\n",
      "|    value_loss           | 1.99      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=107500, episode_reward=21.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 21.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 107500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31239176 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0519    |\n",
      "|    explained_variance   | -0.957     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0577     |\n",
      "|    n_updates            | 14263      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.683      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 840      |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 107520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 841        |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 107648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46403655 |\n",
      "|    clip_fraction        | 0.0722     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0333    |\n",
      "|    explained_variance   | 0.357      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00933    |\n",
      "|    n_updates            | 14280      |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    value_loss           | 0.0489     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 842        |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 107776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08070499 |\n",
      "|    clip_fraction        | 0.0432     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0126    |\n",
      "|    explained_variance   | 0.0946     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0125    |\n",
      "|    n_updates            | 14297      |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    value_loss           | 0.0286     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 843        |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 107904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37860316 |\n",
      "|    clip_fraction        | 0.0593     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00851   |\n",
      "|    explained_variance   | -0.751     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0472    |\n",
      "|    n_updates            | 14314      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.011      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=52.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 52.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 108000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22620463 |\n",
      "|    clip_fraction        | 0.0147     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00431   |\n",
      "|    explained_variance   | 0.0347     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00132   |\n",
      "|    n_updates            | 14331      |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 0.0302     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 844      |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 108032   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 914      |\n",
      "|    iterations           | 845      |\n",
      "|    time_elapsed         | 118      |\n",
      "|    total_timesteps      | 108160   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.614244 |\n",
      "|    clip_fraction        | 0.0611   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0211  |\n",
      "|    explained_variance   | 0.584    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0152  |\n",
      "|    n_updates            | 14348    |\n",
      "|    policy_gradient_loss | -0.0142  |\n",
      "|    value_loss           | 0.0617   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 846       |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 108288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3722463 |\n",
      "|    clip_fraction        | 0.0671    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0246   |\n",
      "|    explained_variance   | 0.122     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0168   |\n",
      "|    n_updates            | 14365     |\n",
      "|    policy_gradient_loss | -0.0277   |\n",
      "|    value_loss           | 0.0769    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 847        |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 108416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16551234 |\n",
      "|    clip_fraction        | 0.0335     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0178    |\n",
      "|    explained_variance   | -0.308     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0349     |\n",
      "|    n_updates            | 14382      |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    value_loss           | 0.597      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=108500, episode_reward=64.97 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 65         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 108500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22852865 |\n",
      "|    clip_fraction        | 0.0326     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0217    |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.000691   |\n",
      "|    n_updates            | 14399      |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    value_loss           | 0.408      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 848      |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 108544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 849        |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 108672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18226537 |\n",
      "|    clip_fraction        | 0.0317     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0161    |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.04      |\n",
      "|    n_updates            | 14416      |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 850       |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 108800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8086118 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0773   |\n",
      "|    explained_variance   | 0.279     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.508     |\n",
      "|    n_updates            | 14433     |\n",
      "|    policy_gradient_loss | -0.0566   |\n",
      "|    value_loss           | 1.32      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 851        |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 108928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38618207 |\n",
      "|    clip_fraction        | 0.0542     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0259    |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0161     |\n",
      "|    n_updates            | 14450      |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=109000, episode_reward=48.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 48.2     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 109000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.08768  |\n",
      "|    clip_fraction        | 0.0271   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.00829 |\n",
      "|    explained_variance   | 0.0716   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.00805  |\n",
      "|    n_updates            | 14467    |\n",
      "|    policy_gradient_loss | -0.0139  |\n",
      "|    value_loss           | 0.0293   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 852      |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 109056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 853        |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 109184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17442648 |\n",
      "|    clip_fraction        | 0.0303     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00576   |\n",
      "|    explained_variance   | -2.17      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00186    |\n",
      "|    n_updates            | 14484      |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.0154     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 37.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 914         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 109312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024063574 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.00697    |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.00166    |\n",
      "|    n_updates            | 14501       |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 0.0054      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | 37.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 914          |\n",
      "|    iterations           | 855          |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 109440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027184836 |\n",
      "|    clip_fraction        | 0.00735      |\n",
      "|    clip_range           | 0.4          |\n",
      "|    entropy_loss         | -0.000383    |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.000735     |\n",
      "|    loss                 | 0.00236      |\n",
      "|    n_updates            | 14518        |\n",
      "|    policy_gradient_loss | -0.00743     |\n",
      "|    value_loss           | 0.0108       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=109500, episode_reward=83.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 83        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 109500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1328942 |\n",
      "|    clip_fraction        | 0.0202    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.00311  |\n",
      "|    explained_variance   | -0.418    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00721   |\n",
      "|    n_updates            | 14535     |\n",
      "|    policy_gradient_loss | -0.00885  |\n",
      "|    value_loss           | 0.106     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 856      |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 109568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 857        |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 109696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67976236 |\n",
      "|    clip_fraction        | 0.046      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0157    |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0921    |\n",
      "|    n_updates            | 14552      |\n",
      "|    policy_gradient_loss | -0.0238    |\n",
      "|    value_loss           | 0.0391     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 858       |\n",
      "|    time_elapsed         | 120       |\n",
      "|    total_timesteps      | 109824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4449476 |\n",
      "|    clip_fraction        | 0.0551    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0184   |\n",
      "|    explained_variance   | 0.33      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00175   |\n",
      "|    n_updates            | 14569     |\n",
      "|    policy_gradient_loss | -0.0311   |\n",
      "|    value_loss           | 0.187     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 915      |\n",
      "|    iterations           | 859      |\n",
      "|    time_elapsed         | 120      |\n",
      "|    total_timesteps      | 109952   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.766314 |\n",
      "|    clip_fraction        | 0.104    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0457  |\n",
      "|    explained_variance   | 0.371    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0548   |\n",
      "|    n_updates            | 14586    |\n",
      "|    policy_gradient_loss | -0.0358  |\n",
      "|    value_loss           | 0.519    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=50.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 50.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 110000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37457982 |\n",
      "|    clip_fraction        | 0.0404     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0128    |\n",
      "|    explained_variance   | 0.132      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0107    |\n",
      "|    n_updates            | 14603      |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 860      |\n",
      "|    time_elapsed    | 120      |\n",
      "|    total_timesteps | 110080   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 861       |\n",
      "|    time_elapsed         | 120       |\n",
      "|    total_timesteps      | 110208    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5870001 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0913   |\n",
      "|    explained_variance   | 0.0753    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.254     |\n",
      "|    n_updates            | 14620     |\n",
      "|    policy_gradient_loss | -0.0415   |\n",
      "|    value_loss           | 1.28      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 862        |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 110336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62632245 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.1       |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.173      |\n",
      "|    n_updates            | 14637      |\n",
      "|    policy_gradient_loss | -0.057     |\n",
      "|    value_loss           | 0.643      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 863        |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 110464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68187153 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0247    |\n",
      "|    explained_variance   | -0.158     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0121    |\n",
      "|    n_updates            | 14654      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.083      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=110500, episode_reward=61.92 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 61.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 110500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.61516494 |\n",
      "|    clip_fraction        | 0.0473     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0139    |\n",
      "|    explained_variance   | -1.14      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00672   |\n",
      "|    n_updates            | 14671      |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    value_loss           | 0.031      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 864      |\n",
      "|    time_elapsed    | 120      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 914      |\n",
      "|    iterations           | 865      |\n",
      "|    time_elapsed         | 121      |\n",
      "|    total_timesteps      | 110720   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.969358 |\n",
      "|    clip_fraction        | 0.102    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0141  |\n",
      "|    explained_variance   | 0.122    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.095   |\n",
      "|    n_updates            | 14688    |\n",
      "|    policy_gradient_loss | -0.0381  |\n",
      "|    value_loss           | 0.00351  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 915      |\n",
      "|    iterations           | 866      |\n",
      "|    time_elapsed         | 121      |\n",
      "|    total_timesteps      | 110848   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.294933 |\n",
      "|    clip_fraction        | 0.11     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0183  |\n",
      "|    explained_variance   | -0.562   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0445  |\n",
      "|    n_updates            | 14705    |\n",
      "|    policy_gradient_loss | -0.0434  |\n",
      "|    value_loss           | 0.0128   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 37.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 915         |\n",
      "|    iterations           | 867         |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 110976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013107108 |\n",
      "|    clip_fraction        | 0.00551     |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.00516    |\n",
      "|    explained_variance   | -1.62       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.00592     |\n",
      "|    n_updates            | 14722       |\n",
      "|    policy_gradient_loss | -0.000557   |\n",
      "|    value_loss           | 0.0429      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=111000, episode_reward=29.42 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 111000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20575097 |\n",
      "|    clip_fraction        | 0.0377     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0166    |\n",
      "|    explained_variance   | 0.111      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000236  |\n",
      "|    n_updates            | 14739      |\n",
      "|    policy_gradient_loss | -0.00912   |\n",
      "|    value_loss           | 0.0424     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 868      |\n",
      "|    time_elapsed    | 121      |\n",
      "|    total_timesteps | 111104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 869        |\n",
      "|    time_elapsed         | 121        |\n",
      "|    total_timesteps      | 111232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24677783 |\n",
      "|    clip_fraction        | 0.0267     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00658   |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00958    |\n",
      "|    n_updates            | 14756      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.14       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 870       |\n",
      "|    time_elapsed         | 121       |\n",
      "|    total_timesteps      | 111360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6121623 |\n",
      "|    clip_fraction        | 0.0882    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0362   |\n",
      "|    explained_variance   | 0.603     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00877  |\n",
      "|    n_updates            | 14773     |\n",
      "|    policy_gradient_loss | -0.0282   |\n",
      "|    value_loss           | 0.191     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 871       |\n",
      "|    time_elapsed         | 121       |\n",
      "|    total_timesteps      | 111488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4003173 |\n",
      "|    clip_fraction        | 0.0579    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0154   |\n",
      "|    explained_variance   | 0.285     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00412  |\n",
      "|    n_updates            | 14790     |\n",
      "|    policy_gradient_loss | -0.0264   |\n",
      "|    value_loss           | 0.183     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=111500, episode_reward=42.57 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 42.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 111500      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036528114 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0158     |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.00052    |\n",
      "|    n_updates            | 14807       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.0845      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 872      |\n",
      "|    time_elapsed    | 121      |\n",
      "|    total_timesteps | 111616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 873        |\n",
      "|    time_elapsed         | 122        |\n",
      "|    total_timesteps      | 111744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13116573 |\n",
      "|    clip_fraction        | 0.0666     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0333    |\n",
      "|    explained_variance   | 0.186      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 14824      |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.42       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 874        |\n",
      "|    time_elapsed         | 122        |\n",
      "|    total_timesteps      | 111872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75487685 |\n",
      "|    clip_fraction        | 0.0726     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.017     |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00944   |\n",
      "|    n_updates            | 14841      |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=52.87 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 52.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 112000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2550483 |\n",
      "|    clip_fraction        | 0.0432    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0123   |\n",
      "|    explained_variance   | -0.31     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.015     |\n",
      "|    n_updates            | 14858     |\n",
      "|    policy_gradient_loss | -0.0247   |\n",
      "|    value_loss           | 0.0883    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 875      |\n",
      "|    time_elapsed    | 122      |\n",
      "|    total_timesteps | 112000   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 876       |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 112128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5259405 |\n",
      "|    clip_fraction        | 0.0184    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.00761  |\n",
      "|    explained_variance   | -0.302    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00187   |\n",
      "|    n_updates            | 14875     |\n",
      "|    policy_gradient_loss | -0.01     |\n",
      "|    value_loss           | 0.0234    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 877       |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 112256    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9555533 |\n",
      "|    clip_fraction        | 0.0951    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.032    |\n",
      "|    explained_variance   | 0.166     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0756   |\n",
      "|    n_updates            | 14892     |\n",
      "|    policy_gradient_loss | -0.0382   |\n",
      "|    value_loss           | 0.00966   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 878       |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 112384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 4.0889125 |\n",
      "|    clip_fraction        | 0.234     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0403   |\n",
      "|    explained_variance   | 0.438     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0545   |\n",
      "|    n_updates            | 14909     |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.0711    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=112500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 112500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70128393 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0112    |\n",
      "|    explained_variance   | 0.0242     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0545    |\n",
      "|    n_updates            | 14926      |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    value_loss           | 0.0486     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 879      |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 112512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 880        |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.97895736 |\n",
      "|    clip_fraction        | 0.0597     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0173    |\n",
      "|    explained_variance   | -0.209     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.022     |\n",
      "|    n_updates            | 14943      |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    value_loss           | 0.0772     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 881        |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 112768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38652965 |\n",
      "|    clip_fraction        | 0.046      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0118    |\n",
      "|    explained_variance   | -0.251     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00902    |\n",
      "|    n_updates            | 14960      |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    value_loss           | 0.292      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 882      |\n",
      "|    time_elapsed         | 123      |\n",
      "|    total_timesteps      | 112896   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.617237 |\n",
      "|    clip_fraction        | 0.0579   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0223  |\n",
      "|    explained_variance   | 0.383    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0465   |\n",
      "|    n_updates            | 14977    |\n",
      "|    policy_gradient_loss | -0.0253  |\n",
      "|    value_loss           | 0.469    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=113000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 113000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5638286 |\n",
      "|    clip_fraction        | 0.0432    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.00966  |\n",
      "|    explained_variance   | 0.462     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0195   |\n",
      "|    n_updates            | 14994     |\n",
      "|    policy_gradient_loss | -0.0265   |\n",
      "|    value_loss           | 0.0867    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 883      |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 113024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 884        |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 113152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09549531 |\n",
      "|    clip_fraction        | 0.0138     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00116   |\n",
      "|    explained_variance   | 0.664      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00471    |\n",
      "|    n_updates            | 15011      |\n",
      "|    policy_gradient_loss | -0.00858   |\n",
      "|    value_loss           | 0.0393     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 885        |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 113280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15118022 |\n",
      "|    clip_fraction        | 0.0193     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0106    |\n",
      "|    explained_variance   | 0.691      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00855    |\n",
      "|    n_updates            | 15028      |\n",
      "|    policy_gradient_loss | -0.0031    |\n",
      "|    value_loss           | 0.134      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 886        |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 113408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47590816 |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0155    |\n",
      "|    explained_variance   | -0.172     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0363    |\n",
      "|    n_updates            | 15045      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 0.0186     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=113500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 113500      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038366277 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0218     |\n",
      "|    explained_variance   | -0.0656     |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0896      |\n",
      "|    n_updates            | 15062       |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 887      |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 113536   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 888       |\n",
      "|    time_elapsed         | 124       |\n",
      "|    total_timesteps      | 113664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5007716 |\n",
      "|    clip_fraction        | 0.0722    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0364   |\n",
      "|    explained_variance   | 0.422     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0306   |\n",
      "|    n_updates            | 15079     |\n",
      "|    policy_gradient_loss | -0.0184   |\n",
      "|    value_loss           | 0.0205    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 889        |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 113792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46431136 |\n",
      "|    clip_fraction        | 0.0915     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0341    |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00108   |\n",
      "|    n_updates            | 15096      |\n",
      "|    policy_gradient_loss | 0.0263     |\n",
      "|    value_loss           | 0.0155     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 890       |\n",
      "|    time_elapsed         | 124       |\n",
      "|    total_timesteps      | 113920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.3876011 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0516   |\n",
      "|    explained_variance   | 0.177     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.074    |\n",
      "|    n_updates            | 15113     |\n",
      "|    policy_gradient_loss | -0.0632   |\n",
      "|    value_loss           | 0.0363    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=7.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 7.12      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 114000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8128453 |\n",
      "|    clip_fraction        | 0.0988    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0134   |\n",
      "|    explained_variance   | -0.207    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0438   |\n",
      "|    n_updates            | 15130     |\n",
      "|    policy_gradient_loss | -0.0353   |\n",
      "|    value_loss           | 0.0528    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 891      |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 114048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 892        |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 114176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18384272 |\n",
      "|    clip_fraction        | 0.0207     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00506   |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00537    |\n",
      "|    n_updates            | 15147      |\n",
      "|    policy_gradient_loss | -0.00958   |\n",
      "|    value_loss           | 0.0735     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 893        |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 114304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57769746 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0733    |\n",
      "|    explained_variance   | -0.0155    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00238    |\n",
      "|    n_updates            | 15164      |\n",
      "|    policy_gradient_loss | -0.0713    |\n",
      "|    value_loss           | 0.433      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 894       |\n",
      "|    time_elapsed         | 125       |\n",
      "|    total_timesteps      | 114432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3152814 |\n",
      "|    clip_fraction        | 0.0662    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0246   |\n",
      "|    explained_variance   | 0.612     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0368   |\n",
      "|    n_updates            | 15181     |\n",
      "|    policy_gradient_loss | -0.0267   |\n",
      "|    value_loss           | 0.0517    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=114500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 114500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12252273 |\n",
      "|    clip_fraction        | 0.0211     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00236   |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00273    |\n",
      "|    n_updates            | 15198      |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.0709     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 895      |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 114560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 896       |\n",
      "|    time_elapsed         | 125       |\n",
      "|    total_timesteps      | 114688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.3825521 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0133   |\n",
      "|    explained_variance   | 0.357     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.051    |\n",
      "|    n_updates            | 15215     |\n",
      "|    policy_gradient_loss | -0.0421   |\n",
      "|    value_loss           | 0.0514    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 897       |\n",
      "|    time_elapsed         | 125       |\n",
      "|    total_timesteps      | 114816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.2478328 |\n",
      "|    clip_fraction        | 0.245     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.04     |\n",
      "|    explained_variance   | -0.0748   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0929   |\n",
      "|    n_updates            | 15232     |\n",
      "|    policy_gradient_loss | -0.0541   |\n",
      "|    value_loss           | 0.0249    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 898        |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 114944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30544597 |\n",
      "|    clip_fraction        | 0.0731     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0407    |\n",
      "|    explained_variance   | 0.185      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000254  |\n",
      "|    n_updates            | 15249      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.0955     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-12.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -12.1    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 115000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.369334 |\n",
      "|    clip_fraction        | 0.0634   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0291  |\n",
      "|    explained_variance   | 0.64     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.00164  |\n",
      "|    n_updates            | 15266    |\n",
      "|    policy_gradient_loss | -0.0178  |\n",
      "|    value_loss           | 0.0133   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 899      |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 115072   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 36.9     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 900      |\n",
      "|    time_elapsed         | 126      |\n",
      "|    total_timesteps      | 115200   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.052031 |\n",
      "|    clip_fraction        | 0.127    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0574  |\n",
      "|    explained_variance   | 0.388    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0546  |\n",
      "|    n_updates            | 15283    |\n",
      "|    policy_gradient_loss | -0.0469  |\n",
      "|    value_loss           | 0.0267   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 901       |\n",
      "|    time_elapsed         | 126       |\n",
      "|    total_timesteps      | 115328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3310988 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0595   |\n",
      "|    explained_variance   | -0.1      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0312   |\n",
      "|    n_updates            | 15300     |\n",
      "|    policy_gradient_loss | -0.0403   |\n",
      "|    value_loss           | 0.0283    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 902       |\n",
      "|    time_elapsed         | 126       |\n",
      "|    total_timesteps      | 115456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9445423 |\n",
      "|    clip_fraction        | 0.0414    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.00713  |\n",
      "|    explained_variance   | 0.0861    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0103   |\n",
      "|    n_updates            | 15317     |\n",
      "|    policy_gradient_loss | -0.0174   |\n",
      "|    value_loss           | 0.0229    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=115500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 115500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18857113 |\n",
      "|    clip_fraction        | 0.0262     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00541   |\n",
      "|    explained_variance   | 0.00374    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00161    |\n",
      "|    n_updates            | 15334      |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 903      |\n",
      "|    time_elapsed    | 126      |\n",
      "|    total_timesteps | 115584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 904        |\n",
      "|    time_elapsed         | 126        |\n",
      "|    total_timesteps      | 115712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18961215 |\n",
      "|    clip_fraction        | 0.0418     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0348    |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00926   |\n",
      "|    n_updates            | 15351      |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 905        |\n",
      "|    time_elapsed         | 126        |\n",
      "|    total_timesteps      | 115840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60794747 |\n",
      "|    clip_fraction        | 0.0671     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0143    |\n",
      "|    explained_variance   | 0.661      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0326    |\n",
      "|    n_updates            | 15368      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.0906     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 906       |\n",
      "|    time_elapsed         | 126       |\n",
      "|    total_timesteps      | 115968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2758267 |\n",
      "|    clip_fraction        | 0.0216    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.00527  |\n",
      "|    explained_variance   | 0.759     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0016    |\n",
      "|    n_updates            | 15385     |\n",
      "|    policy_gradient_loss | -0.0135   |\n",
      "|    value_loss           | 0.0308    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=-2.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -2.43     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 116000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8675889 |\n",
      "|    clip_fraction        | 0.051     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0117   |\n",
      "|    explained_variance   | 0.0596    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0446    |\n",
      "|    n_updates            | 15402     |\n",
      "|    policy_gradient_loss | -0.0156   |\n",
      "|    value_loss           | 0.0669    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 907      |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 116096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 908        |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 116224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.87020993 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.036     |\n",
      "|    explained_variance   | -0.188     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0335     |\n",
      "|    n_updates            | 15419      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 909        |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 116352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21225253 |\n",
      "|    clip_fraction        | 0.045      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0108    |\n",
      "|    explained_variance   | -0.139     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0592     |\n",
      "|    n_updates            | 15436      |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 0.229      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 910        |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 116480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46544936 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.059     |\n",
      "|    explained_variance   | 0.0126     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00885    |\n",
      "|    n_updates            | 15453      |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.026      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=116500, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 116500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37264243 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0351    |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0402    |\n",
      "|    n_updates            | 15470      |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    value_loss           | 0.0133     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 911      |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 116608   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 912       |\n",
      "|    time_elapsed         | 127       |\n",
      "|    total_timesteps      | 116736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6150936 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0531   |\n",
      "|    explained_variance   | 0.204     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.022    |\n",
      "|    n_updates            | 15487     |\n",
      "|    policy_gradient_loss | -0.0136   |\n",
      "|    value_loss           | 0.101     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 913        |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 116864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53232867 |\n",
      "|    clip_fraction        | 0.0473     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0239    |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.07      |\n",
      "|    n_updates            | 15504      |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    value_loss           | 0.0422     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 914       |\n",
      "|    time_elapsed         | 127       |\n",
      "|    total_timesteps      | 116992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7323797 |\n",
      "|    clip_fraction        | 0.0928    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0367   |\n",
      "|    explained_variance   | 0.0698    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0904   |\n",
      "|    n_updates            | 15521     |\n",
      "|    policy_gradient_loss | -0.041    |\n",
      "|    value_loss           | 0.0525    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=117000, episode_reward=-5.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -5.59    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 117000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.29056  |\n",
      "|    clip_fraction        | 0.103    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0381  |\n",
      "|    explained_variance   | 0.269    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.028   |\n",
      "|    n_updates            | 15538    |\n",
      "|    policy_gradient_loss | -0.0497  |\n",
      "|    value_loss           | 0.194    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 915      |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 117120   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 916       |\n",
      "|    time_elapsed         | 128       |\n",
      "|    total_timesteps      | 117248    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7598256 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0693   |\n",
      "|    explained_variance   | 0.676     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0799   |\n",
      "|    n_updates            | 15555     |\n",
      "|    policy_gradient_loss | -0.0602   |\n",
      "|    value_loss           | 0.157     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 917       |\n",
      "|    time_elapsed         | 128       |\n",
      "|    total_timesteps      | 117376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7316446 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0584   |\n",
      "|    explained_variance   | 0.163     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0515   |\n",
      "|    n_updates            | 15572     |\n",
      "|    policy_gradient_loss | -0.0483   |\n",
      "|    value_loss           | 0.0885    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=117500, episode_reward=47.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 117500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68633735 |\n",
      "|    clip_fraction        | 0.045      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00768   |\n",
      "|    explained_variance   | -0.457     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0219    |\n",
      "|    n_updates            | 15589      |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    value_loss           | 0.0216     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 918      |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 117504   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 919       |\n",
      "|    time_elapsed         | 128       |\n",
      "|    total_timesteps      | 117632    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5290828 |\n",
      "|    clip_fraction        | 0.074     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0376   |\n",
      "|    explained_variance   | 0.467     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0437    |\n",
      "|    n_updates            | 15606     |\n",
      "|    policy_gradient_loss | -0.0253   |\n",
      "|    value_loss           | 0.394     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 920        |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 117760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16919994 |\n",
      "|    clip_fraction        | 0.0648     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0305    |\n",
      "|    explained_variance   | 0.276      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0401    |\n",
      "|    n_updates            | 15623      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 921        |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 117888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49130425 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0399    |\n",
      "|    explained_variance   | -0.393     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 15640      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.0531     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=40.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 40.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 118000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0875151 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0557   |\n",
      "|    explained_variance   | 0.183     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0721   |\n",
      "|    n_updates            | 15657     |\n",
      "|    policy_gradient_loss | -0.0565   |\n",
      "|    value_loss           | 0.0165    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 922      |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 118016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 923       |\n",
      "|    time_elapsed         | 129       |\n",
      "|    total_timesteps      | 118144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2969602 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0455   |\n",
      "|    explained_variance   | 0.0386    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0844   |\n",
      "|    n_updates            | 15674     |\n",
      "|    policy_gradient_loss | -0.0653   |\n",
      "|    value_loss           | 0.0489    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 924       |\n",
      "|    time_elapsed         | 129       |\n",
      "|    total_timesteps      | 118272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3300355 |\n",
      "|    clip_fraction        | 0.109     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0634   |\n",
      "|    explained_variance   | 0.522     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0622   |\n",
      "|    n_updates            | 15691     |\n",
      "|    policy_gradient_loss | -0.0237   |\n",
      "|    value_loss           | 0.075     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 925        |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 118400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41053748 |\n",
      "|    clip_fraction        | 0.0574     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0381    |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0496    |\n",
      "|    n_updates            | 15708      |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    value_loss           | 0.0978     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=118500, episode_reward=26.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 118500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22328536 |\n",
      "|    clip_fraction        | 0.0501     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.021     |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00118   |\n",
      "|    n_updates            | 15725      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 926      |\n",
      "|    time_elapsed    | 129      |\n",
      "|    total_timesteps | 118528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 927        |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 118656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36281708 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0827    |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 15742      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.596      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 928        |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39175206 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0827    |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0353    |\n",
      "|    n_updates            | 15759      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.0648     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 929        |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 118912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74388456 |\n",
      "|    clip_fraction        | 0.0763     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0222    |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.033     |\n",
      "|    n_updates            | 15776      |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    value_loss           | 0.0954     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=119000, episode_reward=30.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 119000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55184627 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0696    |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.049      |\n",
      "|    n_updates            | 15793      |\n",
      "|    policy_gradient_loss | -0.0496    |\n",
      "|    value_loss           | 0.423      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 930      |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 119040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 931       |\n",
      "|    time_elapsed         | 130       |\n",
      "|    total_timesteps      | 119168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2543435 |\n",
      "|    clip_fraction        | 0.0611    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0198   |\n",
      "|    explained_variance   | 0.198     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0132   |\n",
      "|    n_updates            | 15810     |\n",
      "|    policy_gradient_loss | -0.0223   |\n",
      "|    value_loss           | 0.047     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 932       |\n",
      "|    time_elapsed         | 130       |\n",
      "|    total_timesteps      | 119296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8446256 |\n",
      "|    clip_fraction        | 0.113     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0379   |\n",
      "|    explained_variance   | 0.414     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0618   |\n",
      "|    n_updates            | 15827     |\n",
      "|    policy_gradient_loss | -0.0388   |\n",
      "|    value_loss           | 0.0783    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 933        |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 119424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44594377 |\n",
      "|    clip_fraction        | 0.0818     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0265    |\n",
      "|    explained_variance   | 0.482      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0517    |\n",
      "|    n_updates            | 15844      |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.0342     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=119500, episode_reward=27.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 27.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 119500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8087578 |\n",
      "|    clip_fraction        | 0.0947    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0249   |\n",
      "|    explained_variance   | 0.276     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0413   |\n",
      "|    n_updates            | 15861     |\n",
      "|    policy_gradient_loss | -0.0503   |\n",
      "|    value_loss           | 0.055     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 934      |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 119552   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 935       |\n",
      "|    time_elapsed         | 130       |\n",
      "|    total_timesteps      | 119680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1203624 |\n",
      "|    clip_fraction        | 0.241     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0748   |\n",
      "|    explained_variance   | 0.461     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0478   |\n",
      "|    n_updates            | 15878     |\n",
      "|    policy_gradient_loss | -0.0492   |\n",
      "|    value_loss           | 0.065     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 936        |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 119808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25485295 |\n",
      "|    clip_fraction        | 0.0611     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0339    |\n",
      "|    explained_variance   | 0.197      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0773    |\n",
      "|    n_updates            | 15895      |\n",
      "|    policy_gradient_loss | -0.0239    |\n",
      "|    value_loss           | 0.0802     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 937        |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 119936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23843268 |\n",
      "|    clip_fraction        | 0.0358     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.024     |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0234    |\n",
      "|    n_updates            | 15912      |\n",
      "|    policy_gradient_loss | -0.00964   |\n",
      "|    value_loss           | 0.0751     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=15.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71619403 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.048     |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0504    |\n",
      "|    n_updates            | 15929      |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 120064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 939        |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 120192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10810562 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.139     |\n",
      "|    explained_variance   | 0.616      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0489    |\n",
      "|    n_updates            | 15946      |\n",
      "|    policy_gradient_loss | -0.0655    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 940        |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 120320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41960785 |\n",
      "|    clip_fraction        | 0.0634     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0417    |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00639   |\n",
      "|    n_updates            | 15963      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 941       |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 120448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5854092 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0515   |\n",
      "|    explained_variance   | 0.504     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0531   |\n",
      "|    n_updates            | 15980     |\n",
      "|    policy_gradient_loss | -0.0549   |\n",
      "|    value_loss           | 0.253     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=120500, episode_reward=37.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 120500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39804578 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0672    |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.021      |\n",
      "|    n_updates            | 15997      |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 0.227      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 942      |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 120576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 943       |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 120704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5954779 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0477   |\n",
      "|    explained_variance   | 0.551     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00195   |\n",
      "|    n_updates            | 16014     |\n",
      "|    policy_gradient_loss | -0.0394   |\n",
      "|    value_loss           | 0.135     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 944        |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43269205 |\n",
      "|    clip_fraction        | 0.0864     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0343    |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0121    |\n",
      "|    n_updates            | 16031      |\n",
      "|    policy_gradient_loss | -0.00757   |\n",
      "|    value_loss           | 0.0601     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 945        |\n",
      "|    time_elapsed         | 132        |\n",
      "|    total_timesteps      | 120960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30671984 |\n",
      "|    clip_fraction        | 0.0326     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0165    |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0226     |\n",
      "|    n_updates            | 16048      |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.0579     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=121000, episode_reward=11.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 11.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 121000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2095354 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0573   |\n",
      "|    explained_variance   | 0.379     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0377   |\n",
      "|    n_updates            | 16065     |\n",
      "|    policy_gradient_loss | -0.0715   |\n",
      "|    value_loss           | 0.0758    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 946      |\n",
      "|    time_elapsed    | 132      |\n",
      "|    total_timesteps | 121088   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 947        |\n",
      "|    time_elapsed         | 132        |\n",
      "|    total_timesteps      | 121216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39737985 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.056     |\n",
      "|    explained_variance   | 0.692      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00952   |\n",
      "|    n_updates            | 16082      |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    value_loss           | 0.0676     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 948        |\n",
      "|    time_elapsed         | 132        |\n",
      "|    total_timesteps      | 121344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32392323 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0619    |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0375    |\n",
      "|    n_updates            | 16099      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.0934     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 949        |\n",
      "|    time_elapsed         | 132        |\n",
      "|    total_timesteps      | 121472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54433966 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0889    |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.158      |\n",
      "|    n_updates            | 16116      |\n",
      "|    policy_gradient_loss | -0.068     |\n",
      "|    value_loss           | 1.08       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=121500, episode_reward=3.73 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 3.73       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 121500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46442965 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0979    |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00986    |\n",
      "|    n_updates            | 16133      |\n",
      "|    policy_gradient_loss | -0.0482    |\n",
      "|    value_loss           | 0.453      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 36.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 950      |\n",
      "|    time_elapsed    | 132      |\n",
      "|    total_timesteps | 121600   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 36.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 951       |\n",
      "|    time_elapsed         | 133       |\n",
      "|    total_timesteps      | 121728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8372043 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.123    |\n",
      "|    explained_variance   | 0.452     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0396   |\n",
      "|    n_updates            | 16150     |\n",
      "|    policy_gradient_loss | -0.0579   |\n",
      "|    value_loss           | 0.201     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 952       |\n",
      "|    time_elapsed         | 133       |\n",
      "|    total_timesteps      | 121856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1807713 |\n",
      "|    clip_fraction        | 0.102     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0733   |\n",
      "|    explained_variance   | 0.0735    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.409     |\n",
      "|    n_updates            | 16167     |\n",
      "|    policy_gradient_loss | -0.0405   |\n",
      "|    value_loss           | 2.03      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 953        |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 121984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42034397 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0531    |\n",
      "|    explained_variance   | 0.742      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 16184      |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    value_loss           | 0.384      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=122000, episode_reward=49.07 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 49.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 122000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33531424 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0691    |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0253    |\n",
      "|    n_updates            | 16201      |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    value_loss           | 0.0757     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 954      |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 122112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 955       |\n",
      "|    time_elapsed         | 133       |\n",
      "|    total_timesteps      | 122240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8160034 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0504   |\n",
      "|    explained_variance   | 0.569     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0618   |\n",
      "|    n_updates            | 16218     |\n",
      "|    policy_gradient_loss | -0.0552   |\n",
      "|    value_loss           | 0.0264    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 956       |\n",
      "|    time_elapsed         | 133       |\n",
      "|    total_timesteps      | 122368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3756037 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0521   |\n",
      "|    explained_variance   | -0.177    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0662   |\n",
      "|    n_updates            | 16235     |\n",
      "|    policy_gradient_loss | -0.053    |\n",
      "|    value_loss           | 0.0278    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 957        |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 122496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33273456 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0438    |\n",
      "|    explained_variance   | 0.5        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0746    |\n",
      "|    n_updates            | 16252      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.0172     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=122500, episode_reward=13.47 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 13.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 122500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1717117 |\n",
      "|    clip_fraction        | 0.23      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0973   |\n",
      "|    explained_variance   | -0.383    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0739   |\n",
      "|    n_updates            | 16269     |\n",
      "|    policy_gradient_loss | -0.0681   |\n",
      "|    value_loss           | 0.116     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 958      |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 122624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 959        |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 122752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12932159 |\n",
      "|    clip_fraction        | 0.0565     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.043     |\n",
      "|    explained_variance   | 0.588      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0427    |\n",
      "|    n_updates            | 16286      |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 0.0466     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 914      |\n",
      "|    iterations           | 960      |\n",
      "|    time_elapsed         | 134      |\n",
      "|    total_timesteps      | 122880   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.74092  |\n",
      "|    clip_fraction        | 0.23     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0635  |\n",
      "|    explained_variance   | 0.666    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.143   |\n",
      "|    n_updates            | 16303    |\n",
      "|    policy_gradient_loss | -0.0717  |\n",
      "|    value_loss           | 0.139    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=123000, episode_reward=-7.88 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -7.88      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 123000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36644575 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0908    |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 16320      |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    value_loss           | 0.505      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 961      |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 123008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 962        |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 123136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52059996 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 16337      |\n",
      "|    policy_gradient_loss | -0.0745    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 963        |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 123264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23121399 |\n",
      "|    clip_fraction        | 0.0676     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0694    |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.77       |\n",
      "|    n_updates            | 16354      |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 1.32       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 915      |\n",
      "|    iterations           | 964      |\n",
      "|    time_elapsed         | 134      |\n",
      "|    total_timesteps      | 123392   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.313995 |\n",
      "|    clip_fraction        | 0.148    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0512  |\n",
      "|    explained_variance   | 0.318    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.054   |\n",
      "|    n_updates            | 16371    |\n",
      "|    policy_gradient_loss | -0.0541  |\n",
      "|    value_loss           | 0.264    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=123500, episode_reward=34.88 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 123500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8392723 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.092    |\n",
      "|    explained_variance   | 0.0302    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0478   |\n",
      "|    n_updates            | 16388     |\n",
      "|    policy_gradient_loss | -0.0609   |\n",
      "|    value_loss           | 0.0591    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 965      |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 123520   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 914      |\n",
      "|    iterations           | 966      |\n",
      "|    time_elapsed         | 135      |\n",
      "|    total_timesteps      | 123648   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.528455 |\n",
      "|    clip_fraction        | 0.105    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0624  |\n",
      "|    explained_variance   | 0.188    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0481  |\n",
      "|    n_updates            | 16405    |\n",
      "|    policy_gradient_loss | -0.0449  |\n",
      "|    value_loss           | 0.0604   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 967        |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 123776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73965657 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.076     |\n",
      "|    explained_variance   | -0.115     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.094     |\n",
      "|    n_updates            | 16422      |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    value_loss           | 0.0148     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 968       |\n",
      "|    time_elapsed         | 135       |\n",
      "|    total_timesteps      | 123904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5621124 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0778   |\n",
      "|    explained_variance   | -0.399    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0981   |\n",
      "|    n_updates            | 16439     |\n",
      "|    policy_gradient_loss | -0.0347   |\n",
      "|    value_loss           | 0.0139    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=73.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 73.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 124000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40699294 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | 0.08       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.087     |\n",
      "|    n_updates            | 16456      |\n",
      "|    policy_gradient_loss | -0.0772    |\n",
      "|    value_loss           | 0.0647     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 969      |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 124032   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 970       |\n",
      "|    time_elapsed         | 135       |\n",
      "|    total_timesteps      | 124160    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8797935 |\n",
      "|    clip_fraction        | 0.0795    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0369   |\n",
      "|    explained_variance   | 0.276     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0264   |\n",
      "|    n_updates            | 16473     |\n",
      "|    policy_gradient_loss | -0.0479   |\n",
      "|    value_loss           | 0.0469    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 971        |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 124288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30210325 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0825    |\n",
      "|    explained_variance   | 0.509      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0588    |\n",
      "|    n_updates            | 16490      |\n",
      "|    policy_gradient_loss | -0.0562    |\n",
      "|    value_loss           | 0.083      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 915      |\n",
      "|    iterations           | 972      |\n",
      "|    time_elapsed         | 135      |\n",
      "|    total_timesteps      | 124416   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.644351 |\n",
      "|    clip_fraction        | 0.148    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0985  |\n",
      "|    explained_variance   | 0.588    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0472  |\n",
      "|    n_updates            | 16507    |\n",
      "|    policy_gradient_loss | -0.0741  |\n",
      "|    value_loss           | 0.352    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=124500, episode_reward=48.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 48         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 124500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39225546 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.117     |\n",
      "|    n_updates            | 16524      |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.145      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 973      |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 124544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 974        |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 124672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34062722 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0693    |\n",
      "|    n_updates            | 16541      |\n",
      "|    policy_gradient_loss | -0.0485    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 975        |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 124800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32899082 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0568    |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.098      |\n",
      "|    n_updates            | 16558      |\n",
      "|    policy_gradient_loss | -0.0358    |\n",
      "|    value_loss           | 0.812      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 976        |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35719064 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0667    |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 16575      |\n",
      "|    policy_gradient_loss | -0.0402    |\n",
      "|    value_loss           | 0.265      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=65.37 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 65.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 125000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5534164 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0552   |\n",
      "|    explained_variance   | 0.432     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0269   |\n",
      "|    n_updates            | 16592     |\n",
      "|    policy_gradient_loss | -0.0494   |\n",
      "|    value_loss           | 0.0483    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 977      |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 125056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 978       |\n",
      "|    time_elapsed         | 136       |\n",
      "|    total_timesteps      | 125184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1312811 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0629   |\n",
      "|    explained_variance   | 0.296     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.117    |\n",
      "|    n_updates            | 16609     |\n",
      "|    policy_gradient_loss | -0.0711   |\n",
      "|    value_loss           | 0.0253    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 979        |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 125312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37699434 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.065     |\n",
      "|    explained_variance   | -0.661     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0247    |\n",
      "|    n_updates            | 16626      |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 0.0157     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 916      |\n",
      "|    iterations           | 980      |\n",
      "|    time_elapsed         | 136      |\n",
      "|    total_timesteps      | 125440   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.73844  |\n",
      "|    clip_fraction        | 0.219    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0881  |\n",
      "|    explained_variance   | -1.32    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0967  |\n",
      "|    n_updates            | 16643    |\n",
      "|    policy_gradient_loss | -0.0697  |\n",
      "|    value_loss           | 0.0289   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=125500, episode_reward=82.71 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 82.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 125500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36820155 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.074     |\n",
      "|    explained_variance   | 0.779      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0629    |\n",
      "|    n_updates            | 16660      |\n",
      "|    policy_gradient_loss | -0.0354    |\n",
      "|    value_loss           | 0.0518     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 981      |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 125568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 982        |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 125696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59091884 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0825    |\n",
      "|    n_updates            | 16677      |\n",
      "|    policy_gradient_loss | -0.05      |\n",
      "|    value_loss           | 0.0833     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 983       |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 125824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3012656 |\n",
      "|    clip_fraction        | 0.12      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0923   |\n",
      "|    explained_variance   | 0.33      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0201    |\n",
      "|    n_updates            | 16694     |\n",
      "|    policy_gradient_loss | -0.034    |\n",
      "|    value_loss           | 0.537     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 984       |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 125952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7670481 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.097    |\n",
      "|    explained_variance   | 0.861     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0507   |\n",
      "|    n_updates            | 16711     |\n",
      "|    policy_gradient_loss | -0.0519   |\n",
      "|    value_loss           | 0.143     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=81.39 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 81.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 126000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35755187 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0538    |\n",
      "|    n_updates            | 16728      |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 985      |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 126080   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 986       |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 126208    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4502266 |\n",
      "|    clip_fraction        | 0.0763    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0423   |\n",
      "|    explained_variance   | 0.429     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.164     |\n",
      "|    n_updates            | 16745     |\n",
      "|    policy_gradient_loss | -0.0399   |\n",
      "|    value_loss           | 0.515     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 916      |\n",
      "|    iterations           | 987      |\n",
      "|    time_elapsed         | 137      |\n",
      "|    total_timesteps      | 126336   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.615934 |\n",
      "|    clip_fraction        | 0.13     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0629  |\n",
      "|    explained_variance   | 0.539    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.00501 |\n",
      "|    n_updates            | 16762    |\n",
      "|    policy_gradient_loss | -0.055   |\n",
      "|    value_loss           | 0.259    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 988        |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 126464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27878708 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0671    |\n",
      "|    explained_variance   | 0.414      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.042     |\n",
      "|    n_updates            | 16779      |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=126500, episode_reward=55.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 126500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63939124 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0766    |\n",
      "|    explained_variance   | 0.27       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0647    |\n",
      "|    n_updates            | 16796      |\n",
      "|    policy_gradient_loss | -0.0586    |\n",
      "|    value_loss           | 0.023      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 989      |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 126592   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 990       |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 126720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.9873977 |\n",
      "|    clip_fraction        | 0.226     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0492   |\n",
      "|    explained_variance   | -0.511    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0707   |\n",
      "|    n_updates            | 16813     |\n",
      "|    policy_gradient_loss | -0.0524   |\n",
      "|    value_loss           | 0.0102    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 991        |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 126848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56322515 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0722    |\n",
      "|    explained_variance   | -0.0858    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0384    |\n",
      "|    n_updates            | 16830      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.034      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 992       |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 126976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 4.6759453 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0732   |\n",
      "|    explained_variance   | 0.773     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.072    |\n",
      "|    n_updates            | 16847     |\n",
      "|    policy_gradient_loss | -0.0543   |\n",
      "|    value_loss           | 0.0412    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=127000, episode_reward=40.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 127000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18286045 |\n",
      "|    clip_fraction        | 0.062      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.03      |\n",
      "|    explained_variance   | 0.632      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0344    |\n",
      "|    n_updates            | 16864      |\n",
      "|    policy_gradient_loss | -0.0255    |\n",
      "|    value_loss           | 0.0507     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 993      |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 127104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 994        |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 127232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42392805 |\n",
      "|    clip_fraction        | 0.0804     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0403    |\n",
      "|    explained_variance   | 0.608      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0656    |\n",
      "|    n_updates            | 16881      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 995       |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 127360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4949736 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0645   |\n",
      "|    explained_variance   | 0.728     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0307   |\n",
      "|    n_updates            | 16898     |\n",
      "|    policy_gradient_loss | -0.0465   |\n",
      "|    value_loss           | 0.21      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 996        |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 127488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48016047 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0849    |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 16915      |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    value_loss           | 0.0902     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=127500, episode_reward=16.72 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 16.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 127500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3752454 |\n",
      "|    clip_fraction        | 0.0901    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.083    |\n",
      "|    explained_variance   | 0.0586    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0281    |\n",
      "|    n_updates            | 16932     |\n",
      "|    policy_gradient_loss | -0.0324   |\n",
      "|    value_loss           | 1.32      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 997      |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 127616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 998        |\n",
      "|    time_elapsed         | 139        |\n",
      "|    total_timesteps      | 127744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23571822 |\n",
      "|    clip_fraction        | 0.0588     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0405    |\n",
      "|    explained_variance   | 0.598      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.147      |\n",
      "|    n_updates            | 16949      |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    value_loss           | 0.326      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 999       |\n",
      "|    time_elapsed         | 139       |\n",
      "|    total_timesteps      | 127872    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0249515 |\n",
      "|    clip_fraction        | 0.0915    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0254   |\n",
      "|    explained_variance   | -0.242    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0121    |\n",
      "|    n_updates            | 16966     |\n",
      "|    policy_gradient_loss | -0.043    |\n",
      "|    value_loss           | 0.042     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=38.56 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 128000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3008065 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0496   |\n",
      "|    explained_variance   | -0.0315   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0393   |\n",
      "|    n_updates            | 16983     |\n",
      "|    policy_gradient_loss | -0.0716   |\n",
      "|    value_loss           | 0.0698    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 128000   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1001      |\n",
      "|    time_elapsed         | 139       |\n",
      "|    total_timesteps      | 128128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5889299 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0298   |\n",
      "|    explained_variance   | -0.955    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 17000     |\n",
      "|    policy_gradient_loss | -0.0791   |\n",
      "|    value_loss           | 0.0168    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1002       |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 128256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77959704 |\n",
      "|    clip_fraction        | 0.0524     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.00837   |\n",
      "|    explained_variance   | 0.0871     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0115    |\n",
      "|    n_updates            | 17017      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.0569     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1003       |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 128384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67918116 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0781    |\n",
      "|    explained_variance   | -0.277     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.055     |\n",
      "|    n_updates            | 17034      |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.0932     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=128500, episode_reward=33.32 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 128500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36123055 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0824    |\n",
      "|    explained_variance   | -0.708     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0531    |\n",
      "|    n_updates            | 17051      |\n",
      "|    policy_gradient_loss | -0.0476    |\n",
      "|    value_loss           | 0.0506     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1004     |\n",
      "|    time_elapsed    | 140      |\n",
      "|    total_timesteps | 128512   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1005      |\n",
      "|    time_elapsed         | 140       |\n",
      "|    total_timesteps      | 128640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3651362 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0861   |\n",
      "|    explained_variance   | -0.397    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0707   |\n",
      "|    n_updates            | 17068     |\n",
      "|    policy_gradient_loss | -0.0482   |\n",
      "|    value_loss           | 0.184     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1006      |\n",
      "|    time_elapsed         | 140       |\n",
      "|    total_timesteps      | 128768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1848947 |\n",
      "|    clip_fraction        | 0.0754    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0688   |\n",
      "|    explained_variance   | 0.54      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0256    |\n",
      "|    n_updates            | 17085     |\n",
      "|    policy_gradient_loss | -0.0335   |\n",
      "|    value_loss           | 0.608     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1007      |\n",
      "|    time_elapsed         | 140       |\n",
      "|    total_timesteps      | 128896    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0767907 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.295     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0374   |\n",
      "|    n_updates            | 17102     |\n",
      "|    policy_gradient_loss | -0.065    |\n",
      "|    value_loss           | 0.212     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=129000, episode_reward=19.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 19.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 129000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1923043 |\n",
      "|    clip_fraction        | 0.0818    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0649   |\n",
      "|    explained_variance   | 0.547     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00257  |\n",
      "|    n_updates            | 17119     |\n",
      "|    policy_gradient_loss | -0.0198   |\n",
      "|    value_loss           | 0.315     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1008     |\n",
      "|    time_elapsed    | 140      |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1009      |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 129152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8617026 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0477   |\n",
      "|    explained_variance   | 0.483     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.444     |\n",
      "|    n_updates            | 17136     |\n",
      "|    policy_gradient_loss | -0.0363   |\n",
      "|    value_loss           | 0.872     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1010      |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 129280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9696562 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0536   |\n",
      "|    explained_variance   | 0.497     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0237    |\n",
      "|    n_updates            | 17153     |\n",
      "|    policy_gradient_loss | -0.0461   |\n",
      "|    value_loss           | 0.34      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1011      |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 129408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0442814 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0463   |\n",
      "|    explained_variance   | -0.609    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00387   |\n",
      "|    n_updates            | 17170     |\n",
      "|    policy_gradient_loss | -0.0342   |\n",
      "|    value_loss           | 0.0628    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=129500, episode_reward=8.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 8.14       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 129500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74508333 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.041     |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0538    |\n",
      "|    n_updates            | 17187      |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    value_loss           | 0.0187     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1012     |\n",
      "|    time_elapsed    | 141      |\n",
      "|    total_timesteps | 129536   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1013      |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 129664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7131366 |\n",
      "|    clip_fraction        | 0.194     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | -0.102    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0674   |\n",
      "|    n_updates            | 17204     |\n",
      "|    policy_gradient_loss | -0.0586   |\n",
      "|    value_loss           | 0.0244    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1014       |\n",
      "|    time_elapsed         | 141        |\n",
      "|    total_timesteps      | 129792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30414322 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0934    |\n",
      "|    explained_variance   | -1.4       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0579    |\n",
      "|    n_updates            | 17221      |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 0.0701     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1015       |\n",
      "|    time_elapsed         | 141        |\n",
      "|    total_timesteps      | 129920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29969463 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0881    |\n",
      "|    explained_variance   | 0.809      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0698    |\n",
      "|    n_updates            | 17238      |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    value_loss           | 0.056      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-11.90 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -11.9      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 130000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28062597 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0966    |\n",
      "|    explained_variance   | 0.657      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0375    |\n",
      "|    n_updates            | 17255      |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    value_loss           | 0.0965     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1016     |\n",
      "|    time_elapsed    | 142      |\n",
      "|    total_timesteps | 130048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1017       |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 130176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20967203 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00334    |\n",
      "|    n_updates            | 17272      |\n",
      "|    policy_gradient_loss | -0.0524    |\n",
      "|    value_loss           | 0.502      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1018      |\n",
      "|    time_elapsed         | 142       |\n",
      "|    total_timesteps      | 130304    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3123957 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.13     |\n",
      "|    explained_variance   | 0.611     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0544   |\n",
      "|    n_updates            | 17289     |\n",
      "|    policy_gradient_loss | -0.0535   |\n",
      "|    value_loss           | 0.248     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1019      |\n",
      "|    time_elapsed         | 142       |\n",
      "|    total_timesteps      | 130432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7322944 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.528     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0526   |\n",
      "|    n_updates            | 17306     |\n",
      "|    policy_gradient_loss | -0.0767   |\n",
      "|    value_loss           | 0.264     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=130500, episode_reward=21.72 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 21.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 130500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3223908 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0563   |\n",
      "|    explained_variance   | 0.532     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.118     |\n",
      "|    n_updates            | 17323     |\n",
      "|    policy_gradient_loss | -0.0335   |\n",
      "|    value_loss           | 0.809     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1020     |\n",
      "|    time_elapsed    | 142      |\n",
      "|    total_timesteps | 130560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1021      |\n",
      "|    time_elapsed         | 142       |\n",
      "|    total_timesteps      | 130688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1466286 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0728   |\n",
      "|    explained_variance   | 0.821     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0147   |\n",
      "|    n_updates            | 17340     |\n",
      "|    policy_gradient_loss | -0.0576   |\n",
      "|    value_loss           | 0.593     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1022       |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 130816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69828904 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0771    |\n",
      "|    explained_variance   | -0.604     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0394    |\n",
      "|    n_updates            | 17357      |\n",
      "|    policy_gradient_loss | -0.0581    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1023      |\n",
      "|    time_elapsed         | 142       |\n",
      "|    total_timesteps      | 130944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5488945 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0356   |\n",
      "|    explained_variance   | -2.27     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0655   |\n",
      "|    n_updates            | 17374     |\n",
      "|    policy_gradient_loss | -0.0724   |\n",
      "|    value_loss           | 0.0323    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=131000, episode_reward=55.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 55.4     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 131000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.754823 |\n",
      "|    clip_fraction        | 0.189    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0906  |\n",
      "|    explained_variance   | 0.117    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0862  |\n",
      "|    n_updates            | 17391    |\n",
      "|    policy_gradient_loss | -0.0569  |\n",
      "|    value_loss           | 0.0155   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1024     |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1025       |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 131200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41312677 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0652    |\n",
      "|    explained_variance   | 0.06       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0356    |\n",
      "|    n_updates            | 17408      |\n",
      "|    policy_gradient_loss | -0.0472    |\n",
      "|    value_loss           | 0.0614     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1026       |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 131328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28863326 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.706      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0732    |\n",
      "|    n_updates            | 17425      |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1027      |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 131456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2653946 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0614   |\n",
      "|    explained_variance   | 0.779     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0756   |\n",
      "|    n_updates            | 17442     |\n",
      "|    policy_gradient_loss | -0.0479   |\n",
      "|    value_loss           | 0.0639    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=131500, episode_reward=94.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 94.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 131500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8969981 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0863   |\n",
      "|    explained_variance   | -0.255    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0844   |\n",
      "|    n_updates            | 17459     |\n",
      "|    policy_gradient_loss | -0.0533   |\n",
      "|    value_loss           | 0.697     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1028     |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 131584   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1029      |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 131712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3782304 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.133    |\n",
      "|    explained_variance   | 0.446     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0417   |\n",
      "|    n_updates            | 17476     |\n",
      "|    policy_gradient_loss | -0.0408   |\n",
      "|    value_loss           | 0.44      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1030       |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 131840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.99492025 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.078     |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.083     |\n",
      "|    n_updates            | 17493      |\n",
      "|    policy_gradient_loss | -0.0649    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1031      |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 131968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5658493 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0716   |\n",
      "|    explained_variance   | 0.455     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00444   |\n",
      "|    n_updates            | 17510     |\n",
      "|    policy_gradient_loss | -0.0541   |\n",
      "|    value_loss           | 0.799     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=95.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 95.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 132000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0925672 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0568   |\n",
      "|    explained_variance   | 0.152     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.175     |\n",
      "|    n_updates            | 17527     |\n",
      "|    policy_gradient_loss | -0.0702   |\n",
      "|    value_loss           | 1.2       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1032     |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 132096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1033      |\n",
      "|    time_elapsed         | 144       |\n",
      "|    total_timesteps      | 132224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5031888 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0766   |\n",
      "|    explained_variance   | -0.578    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0845   |\n",
      "|    n_updates            | 17544     |\n",
      "|    policy_gradient_loss | -0.076    |\n",
      "|    value_loss           | 0.0901    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 37.9     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 916      |\n",
      "|    iterations           | 1034     |\n",
      "|    time_elapsed         | 144      |\n",
      "|    total_timesteps      | 132352   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.059392 |\n",
      "|    clip_fraction        | 0.162    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0715  |\n",
      "|    explained_variance   | 0.0587   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.025   |\n",
      "|    n_updates            | 17561    |\n",
      "|    policy_gradient_loss | -0.0707  |\n",
      "|    value_loss           | 0.147    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1035      |\n",
      "|    time_elapsed         | 144       |\n",
      "|    total_timesteps      | 132480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0642539 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0623   |\n",
      "|    explained_variance   | -0.0582   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 17578     |\n",
      "|    policy_gradient_loss | -0.0741   |\n",
      "|    value_loss           | 0.036     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=132500, episode_reward=82.66 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 82.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 132500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6116737 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0651   |\n",
      "|    explained_variance   | -0.245    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00354  |\n",
      "|    n_updates            | 17595     |\n",
      "|    policy_gradient_loss | -0.0376   |\n",
      "|    value_loss           | 0.022     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1036     |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 132608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1037       |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 132736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.89969915 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0991    |\n",
      "|    explained_variance   | -0.449     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0876    |\n",
      "|    n_updates            | 17612      |\n",
      "|    policy_gradient_loss | -0.0622    |\n",
      "|    value_loss           | 0.0608     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1038      |\n",
      "|    time_elapsed         | 144       |\n",
      "|    total_timesteps      | 132864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8507314 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0706   |\n",
      "|    explained_variance   | -0.0698   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0989   |\n",
      "|    n_updates            | 17629     |\n",
      "|    policy_gradient_loss | -0.0611   |\n",
      "|    value_loss           | 0.0497    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 37.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 917         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 132992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058917042 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0705     |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 17646       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.0876      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=133000, episode_reward=80.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 80.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 133000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64545393 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.619      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 17663      |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 0.795      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 37.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1040     |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 133120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1041       |\n",
      "|    time_elapsed         | 145        |\n",
      "|    total_timesteps      | 133248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30912846 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0827    |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0956    |\n",
      "|    n_updates            | 17680      |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 37.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1042      |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 133376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3147164 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.08     |\n",
      "|    explained_variance   | 0.725     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0554   |\n",
      "|    n_updates            | 17697     |\n",
      "|    policy_gradient_loss | -0.0581   |\n",
      "|    value_loss           | 0.149     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=133500, episode_reward=59.38 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 59.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 133500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8552456 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0826   |\n",
      "|    explained_variance   | 0.667     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0231   |\n",
      "|    n_updates            | 17714     |\n",
      "|    policy_gradient_loss | -0.0661   |\n",
      "|    value_loss           | 0.728     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1043     |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 133504   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1044      |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 133632    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5180092 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0654   |\n",
      "|    explained_variance   | -0.128    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0332   |\n",
      "|    n_updates            | 17731     |\n",
      "|    policy_gradient_loss | -0.0446   |\n",
      "|    value_loss           | 0.19      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1045      |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 133760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2884456 |\n",
      "|    clip_fraction        | 0.0515    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0219   |\n",
      "|    explained_variance   | 0.186     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0075    |\n",
      "|    n_updates            | 17748     |\n",
      "|    policy_gradient_loss | -0.021    |\n",
      "|    value_loss           | 0.0845    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1046      |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 133888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.5642846 |\n",
      "|    clip_fraction        | 0.191     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.056    |\n",
      "|    explained_variance   | 0.28      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0418   |\n",
      "|    n_updates            | 17765     |\n",
      "|    policy_gradient_loss | -0.0469   |\n",
      "|    value_loss           | 0.00856   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=134000, episode_reward=8.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 8.8       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 134000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6962813 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.061    |\n",
      "|    explained_variance   | -0.16     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0174   |\n",
      "|    n_updates            | 17782     |\n",
      "|    policy_gradient_loss | -0.032    |\n",
      "|    value_loss           | 0.0231    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1047     |\n",
      "|    time_elapsed    | 146      |\n",
      "|    total_timesteps | 134016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1048      |\n",
      "|    time_elapsed         | 146       |\n",
      "|    total_timesteps      | 134144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2147463 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.116    |\n",
      "|    explained_variance   | 0.15      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0368   |\n",
      "|    n_updates            | 17799     |\n",
      "|    policy_gradient_loss | -0.0414   |\n",
      "|    value_loss           | 0.0799    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1049       |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 134272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51913315 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0922    |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.123     |\n",
      "|    n_updates            | 17816      |\n",
      "|    policy_gradient_loss | -0.0694    |\n",
      "|    value_loss           | 0.0522     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1050       |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 134400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56982195 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0574    |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0742    |\n",
      "|    n_updates            | 17833      |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    value_loss           | 0.0688     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=134500, episode_reward=3.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 3.54      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 134500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7041649 |\n",
      "|    clip_fraction        | 0.0882    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0648   |\n",
      "|    explained_variance   | 0.432     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0484    |\n",
      "|    n_updates            | 17850     |\n",
      "|    policy_gradient_loss | -0.0222   |\n",
      "|    value_loss           | 0.84      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38       |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1051     |\n",
      "|    time_elapsed    | 146      |\n",
      "|    total_timesteps | 134528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1052      |\n",
      "|    time_elapsed         | 146       |\n",
      "|    total_timesteps      | 134656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1094515 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.1      |\n",
      "|    explained_variance   | 0.778     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0514   |\n",
      "|    n_updates            | 17867     |\n",
      "|    policy_gradient_loss | -0.0549   |\n",
      "|    value_loss           | 0.126     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 38       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 916      |\n",
      "|    iterations           | 1053     |\n",
      "|    time_elapsed         | 147      |\n",
      "|    total_timesteps      | 134784   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.534749 |\n",
      "|    clip_fraction        | 0.149    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.105   |\n",
      "|    explained_variance   | 0.554    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0858  |\n",
      "|    n_updates            | 17884    |\n",
      "|    policy_gradient_loss | -0.0626  |\n",
      "|    value_loss           | 0.112    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1054       |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 134912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09886195 |\n",
      "|    clip_fraction        | 0.0221     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0224    |\n",
      "|    explained_variance   | 0.629      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0408     |\n",
      "|    n_updates            | 17901      |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    value_loss           | 0.42       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=36.52 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 135000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37815952 |\n",
      "|    clip_fraction        | 0.0643     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0557    |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0446     |\n",
      "|    n_updates            | 17918      |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    value_loss           | 0.407      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1055     |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 135040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1056      |\n",
      "|    time_elapsed         | 147       |\n",
      "|    total_timesteps      | 135168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7154865 |\n",
      "|    clip_fraction        | 0.085     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0342   |\n",
      "|    explained_variance   | 0.361     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0541   |\n",
      "|    n_updates            | 17935     |\n",
      "|    policy_gradient_loss | -0.0349   |\n",
      "|    value_loss           | 0.0519    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1057      |\n",
      "|    time_elapsed         | 147       |\n",
      "|    total_timesteps      | 135296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5303423 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0337   |\n",
      "|    explained_variance   | 0.44      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.121    |\n",
      "|    n_updates            | 17952     |\n",
      "|    policy_gradient_loss | -0.0782   |\n",
      "|    value_loss           | 0.0236    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 38.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 917      |\n",
      "|    iterations           | 1058     |\n",
      "|    time_elapsed         | 147      |\n",
      "|    total_timesteps      | 135424   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.04223  |\n",
      "|    clip_fraction        | 0.142    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0515  |\n",
      "|    explained_variance   | -0.184   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0723  |\n",
      "|    n_updates            | 17969    |\n",
      "|    policy_gradient_loss | -0.0455  |\n",
      "|    value_loss           | 0.0224   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=135500, episode_reward=30.52 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 30.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 135500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9290678 |\n",
      "|    clip_fraction        | 0.0988    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0561   |\n",
      "|    explained_variance   | 0.103     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0342   |\n",
      "|    n_updates            | 17986     |\n",
      "|    policy_gradient_loss | -0.0308   |\n",
      "|    value_loss           | 0.0155    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1059     |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 135552   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1060      |\n",
      "|    time_elapsed         | 147       |\n",
      "|    total_timesteps      | 135680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2317284 |\n",
      "|    clip_fraction        | 0.0873    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0477   |\n",
      "|    explained_variance   | 0.764     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0496   |\n",
      "|    n_updates            | 18003     |\n",
      "|    policy_gradient_loss | -0.0349   |\n",
      "|    value_loss           | 0.0573    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1061       |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 135808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33538657 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0479    |\n",
      "|    explained_variance   | 0.878      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0368    |\n",
      "|    n_updates            | 18020      |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 0.0225     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1062      |\n",
      "|    time_elapsed         | 148       |\n",
      "|    total_timesteps      | 135936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6088503 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0473   |\n",
      "|    explained_variance   | 0.459     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0216   |\n",
      "|    n_updates            | 18037     |\n",
      "|    policy_gradient_loss | -0.0418   |\n",
      "|    value_loss           | 0.434     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=49.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 49.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 136000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14432304 |\n",
      "|    clip_fraction        | 0.0377     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0318    |\n",
      "|    explained_variance   | -0.0312    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00992    |\n",
      "|    n_updates            | 18054      |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.28       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1063     |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 136064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1064       |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 136192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51610154 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0436    |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0467    |\n",
      "|    n_updates            | 18071      |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.0862     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1065       |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 136320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21846898 |\n",
      "|    clip_fraction        | 0.0524     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0383    |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0919     |\n",
      "|    n_updates            | 18088      |\n",
      "|    policy_gradient_loss | -0.00992   |\n",
      "|    value_loss           | 0.871      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1066      |\n",
      "|    time_elapsed         | 148       |\n",
      "|    total_timesteps      | 136448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6662129 |\n",
      "|    clip_fraction        | 0.105     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0582   |\n",
      "|    explained_variance   | 0.787     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00284  |\n",
      "|    n_updates            | 18105     |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 0.609     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=136500, episode_reward=51.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 136500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9070535 |\n",
      "|    clip_fraction        | 0.164     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0592   |\n",
      "|    explained_variance   | -0.715    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0512   |\n",
      "|    n_updates            | 18122     |\n",
      "|    policy_gradient_loss | -0.0484   |\n",
      "|    value_loss           | 0.0312    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1067     |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 136576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1068       |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 136704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15535256 |\n",
      "|    clip_fraction        | 0.0441     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0199    |\n",
      "|    explained_variance   | 0.245      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0162    |\n",
      "|    n_updates            | 18139      |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    value_loss           | 0.0223     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1069      |\n",
      "|    time_elapsed         | 149       |\n",
      "|    total_timesteps      | 136832    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6662164 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.037    |\n",
      "|    explained_variance   | -1.93     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0425   |\n",
      "|    n_updates            | 18156     |\n",
      "|    policy_gradient_loss | -0.0386   |\n",
      "|    value_loss           | 0.00874   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1070       |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 136960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35748613 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0889    |\n",
      "|    explained_variance   | 0.052      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0434    |\n",
      "|    n_updates            | 18173      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.0212     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=137000, episode_reward=69.34 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 69.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 137000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33231938 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 18190      |\n",
      "|    policy_gradient_loss | -0.0577    |\n",
      "|    value_loss           | 0.0386     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1071     |\n",
      "|    time_elapsed    | 149      |\n",
      "|    total_timesteps | 137088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1072      |\n",
      "|    time_elapsed         | 149       |\n",
      "|    total_timesteps      | 137216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5983025 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0661   |\n",
      "|    explained_variance   | 0.128     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0983   |\n",
      "|    n_updates            | 18207     |\n",
      "|    policy_gradient_loss | -0.0404   |\n",
      "|    value_loss           | 0.0316    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1073      |\n",
      "|    time_elapsed         | 149       |\n",
      "|    total_timesteps      | 137344    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8299451 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0895   |\n",
      "|    explained_variance   | 0.496     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.088    |\n",
      "|    n_updates            | 18224     |\n",
      "|    policy_gradient_loss | -0.0614   |\n",
      "|    value_loss           | 0.0709    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1074       |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 137472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04200087 |\n",
      "|    clip_fraction        | 0.0528     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0826    |\n",
      "|    explained_variance   | -0.398     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.873      |\n",
      "|    n_updates            | 18241      |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 1.4        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=137500, episode_reward=77.35 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 77.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 137500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47752005 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0809    |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0611    |\n",
      "|    n_updates            | 18258      |\n",
      "|    policy_gradient_loss | -0.0443    |\n",
      "|    value_loss           | 0.239      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1075     |\n",
      "|    time_elapsed    | 150      |\n",
      "|    total_timesteps | 137600   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1076      |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 137728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5649539 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0873   |\n",
      "|    explained_variance   | 0.776     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 18275     |\n",
      "|    policy_gradient_loss | -0.0531   |\n",
      "|    value_loss           | 0.138     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1077       |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 137856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19746995 |\n",
      "|    clip_fraction        | 0.062      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0509    |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.723      |\n",
      "|    n_updates            | 18292      |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    value_loss           | 3.5        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 917        |\n",
      "|    iterations           | 1078       |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 137984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46573058 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0532    |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0031     |\n",
      "|    n_updates            | 18309      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=38.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 38         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 138000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46755588 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0342    |\n",
      "|    explained_variance   | -0.201     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0249     |\n",
      "|    n_updates            | 18326      |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 0.0684     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1079     |\n",
      "|    time_elapsed    | 150      |\n",
      "|    total_timesteps | 138112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1080      |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 138240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5636128 |\n",
      "|    clip_fraction        | 0.189     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0671   |\n",
      "|    explained_variance   | 0.194     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0693   |\n",
      "|    n_updates            | 18343     |\n",
      "|    policy_gradient_loss | -0.0758   |\n",
      "|    value_loss           | 0.0161    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1081       |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 138368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39091027 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0908    |\n",
      "|    explained_variance   | -0.728     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0661    |\n",
      "|    n_updates            | 18360      |\n",
      "|    policy_gradient_loss | -0.0701    |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 917       |\n",
      "|    iterations           | 1082      |\n",
      "|    time_elapsed         | 151       |\n",
      "|    total_timesteps      | 138496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7983086 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0952   |\n",
      "|    explained_variance   | -0.214    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0802   |\n",
      "|    n_updates            | 18377     |\n",
      "|    policy_gradient_loss | -0.0578   |\n",
      "|    value_loss           | 0.0655    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=138500, episode_reward=53.66 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 138500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60706395 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0527    |\n",
      "|    explained_variance   | 0.803      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0698    |\n",
      "|    n_updates            | 18394      |\n",
      "|    policy_gradient_loss | -0.0384    |\n",
      "|    value_loss           | 0.0512     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 916      |\n",
      "|    iterations      | 1083     |\n",
      "|    time_elapsed    | 151      |\n",
      "|    total_timesteps | 138624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1084       |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 138752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40896755 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.731      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0634    |\n",
      "|    n_updates            | 18411      |\n",
      "|    policy_gradient_loss | -0.0578    |\n",
      "|    value_loss           | 0.0618     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1085      |\n",
      "|    time_elapsed         | 151       |\n",
      "|    total_timesteps      | 138880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7156148 |\n",
      "|    clip_fraction        | 0.174     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    explained_variance   | 0.473     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.211     |\n",
      "|    n_updates            | 18428     |\n",
      "|    policy_gradient_loss | -0.0634   |\n",
      "|    value_loss           | 0.841     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=139000, episode_reward=57.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 57.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 139000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25760764 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0848    |\n",
      "|    explained_variance   | 0.677      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0295     |\n",
      "|    n_updates            | 18445      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.446      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1086     |\n",
      "|    time_elapsed    | 151      |\n",
      "|    total_timesteps | 139008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1087       |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 139136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31544167 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.123     |\n",
      "|    explained_variance   | 0.511      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 18462      |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 916        |\n",
      "|    iterations           | 1088       |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46833223 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0728    |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.757      |\n",
      "|    n_updates            | 18479      |\n",
      "|    policy_gradient_loss | -0.0486    |\n",
      "|    value_loss           | 2.15       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 916       |\n",
      "|    iterations           | 1089      |\n",
      "|    time_elapsed         | 152       |\n",
      "|    total_timesteps      | 139392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2312155 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0785   |\n",
      "|    explained_variance   | 0.0331    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.212     |\n",
      "|    n_updates            | 18496     |\n",
      "|    policy_gradient_loss | -0.0671   |\n",
      "|    value_loss           | 1.07      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=139500, episode_reward=37.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 139500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.92317855 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0653    |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0571    |\n",
      "|    n_updates            | 18513      |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    value_loss           | 0.0658     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 1090     |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 139520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1091       |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 139648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.81055486 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0747    |\n",
      "|    explained_variance   | 0.0878     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0568    |\n",
      "|    n_updates            | 18530      |\n",
      "|    policy_gradient_loss | -0.0543    |\n",
      "|    value_loss           | 0.0238     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1092      |\n",
      "|    time_elapsed         | 152       |\n",
      "|    total_timesteps      | 139776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5231627 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0365   |\n",
      "|    explained_variance   | -0.443    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0538   |\n",
      "|    n_updates            | 18547     |\n",
      "|    policy_gradient_loss | -0.0611   |\n",
      "|    value_loss           | 0.0157    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1093      |\n",
      "|    time_elapsed         | 152       |\n",
      "|    total_timesteps      | 139904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3516966 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | -0.31     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0379   |\n",
      "|    n_updates            | 18564     |\n",
      "|    policy_gradient_loss | -0.0566   |\n",
      "|    value_loss           | 0.0211    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=72.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 72.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 140000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7319133 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.156    |\n",
      "|    explained_variance   | 0.761     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0814   |\n",
      "|    n_updates            | 18581     |\n",
      "|    policy_gradient_loss | -0.0428   |\n",
      "|    value_loss           | 0.0463    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1094     |\n",
      "|    time_elapsed    | 153      |\n",
      "|    total_timesteps | 140032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1095       |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 140160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55020684 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0772    |\n",
      "|    explained_variance   | 0.851      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0905    |\n",
      "|    n_updates            | 18598      |\n",
      "|    policy_gradient_loss | -0.0492    |\n",
      "|    value_loss           | 0.0485     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 38.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1096      |\n",
      "|    time_elapsed         | 153       |\n",
      "|    total_timesteps      | 140288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3770592 |\n",
      "|    clip_fraction        | 0.231     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.73      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.14     |\n",
      "|    n_updates            | 18615     |\n",
      "|    policy_gradient_loss | -0.0712   |\n",
      "|    value_loss           | 0.374     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 38.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1097       |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 140416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40441674 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.55       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0639     |\n",
      "|    n_updates            | 18632      |\n",
      "|    policy_gradient_loss | -0.068     |\n",
      "|    value_loss           | 0.445      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=140500, episode_reward=46.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 46.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 140500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18688315 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0994    |\n",
      "|    explained_variance   | 0.721      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0834    |\n",
      "|    n_updates            | 18649      |\n",
      "|    policy_gradient_loss | -0.0508    |\n",
      "|    value_loss           | 0.132      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 38.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1098     |\n",
      "|    time_elapsed    | 153      |\n",
      "|    total_timesteps | 140544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1099       |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 140672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22826083 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0969    |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.158      |\n",
      "|    n_updates            | 18666      |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 1.45       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 39       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1100     |\n",
      "|    time_elapsed         | 154      |\n",
      "|    total_timesteps      | 140800   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.023342 |\n",
      "|    clip_fraction        | 0.168    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.083   |\n",
      "|    explained_variance   | 0.489    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0824   |\n",
      "|    n_updates            | 18683    |\n",
      "|    policy_gradient_loss | -0.044   |\n",
      "|    value_loss           | 0.942    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1101       |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 140928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48081985 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0841    |\n",
      "|    explained_variance   | -0.538     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0515    |\n",
      "|    n_updates            | 18700      |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 0.0786     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=141000, episode_reward=25.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 141000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42131937 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0848    |\n",
      "|    explained_variance   | -0.48      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0342    |\n",
      "|    n_updates            | 18717      |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    value_loss           | 0.0409     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1102     |\n",
      "|    time_elapsed    | 154      |\n",
      "|    total_timesteps | 141056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1103       |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 141184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73758847 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0716    |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.088     |\n",
      "|    n_updates            | 18734      |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.0171     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1104      |\n",
      "|    time_elapsed         | 154       |\n",
      "|    total_timesteps      | 141312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9750919 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0924   |\n",
      "|    explained_variance   | 0.405     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0287   |\n",
      "|    n_updates            | 18751     |\n",
      "|    policy_gradient_loss | -0.0551   |\n",
      "|    value_loss           | 0.0307    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1105      |\n",
      "|    time_elapsed         | 154       |\n",
      "|    total_timesteps      | 141440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9912937 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.13     |\n",
      "|    explained_variance   | 0.522     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0246   |\n",
      "|    n_updates            | 18768     |\n",
      "|    policy_gradient_loss | -0.0459   |\n",
      "|    value_loss           | 0.045     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=141500, episode_reward=17.89 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 17.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 141500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26450044 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.092     |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 18785      |\n",
      "|    policy_gradient_loss | -0.0442    |\n",
      "|    value_loss           | 0.0467     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1106     |\n",
      "|    time_elapsed    | 155      |\n",
      "|    total_timesteps | 141568   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1107      |\n",
      "|    time_elapsed         | 155       |\n",
      "|    total_timesteps      | 141696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3816172 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | -0.142    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0775   |\n",
      "|    n_updates            | 18802     |\n",
      "|    policy_gradient_loss | -0.0594   |\n",
      "|    value_loss           | 0.162     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1108       |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 141824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24094239 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 18819      |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.618      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1109      |\n",
      "|    time_elapsed         | 155       |\n",
      "|    total_timesteps      | 141952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4948126 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | 0.713     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0358   |\n",
      "|    n_updates            | 18836     |\n",
      "|    policy_gradient_loss | -0.0465   |\n",
      "|    value_loss           | 0.0981    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=142000, episode_reward=0.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 0.279     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 142000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4288168 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.059    |\n",
      "|    explained_variance   | 0.7       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0165    |\n",
      "|    n_updates            | 18853     |\n",
      "|    policy_gradient_loss | -0.051    |\n",
      "|    value_loss           | 0.226     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1110     |\n",
      "|    time_elapsed    | 155      |\n",
      "|    total_timesteps | 142080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1111       |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 142208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24296322 |\n",
      "|    clip_fraction        | 0.0519     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0302    |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0306    |\n",
      "|    n_updates            | 18870      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.237      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 39       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1112     |\n",
      "|    time_elapsed         | 155      |\n",
      "|    total_timesteps      | 142336   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.594589 |\n",
      "|    clip_fraction        | 0.0795   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0432  |\n",
      "|    explained_variance   | 0.957    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0774  |\n",
      "|    n_updates            | 18887    |\n",
      "|    policy_gradient_loss | -0.0442  |\n",
      "|    value_loss           | 0.0726   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1113      |\n",
      "|    time_elapsed         | 155       |\n",
      "|    total_timesteps      | 142464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5372487 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | -0.477    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0758   |\n",
      "|    n_updates            | 18904     |\n",
      "|    policy_gradient_loss | -0.0418   |\n",
      "|    value_loss           | 0.0503    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=142500, episode_reward=-8.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -8.09     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 142500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9028958 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.1      |\n",
      "|    explained_variance   | -0.654    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0906   |\n",
      "|    n_updates            | 18921     |\n",
      "|    policy_gradient_loss | -0.0685   |\n",
      "|    value_loss           | 0.0363    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1114     |\n",
      "|    time_elapsed    | 156      |\n",
      "|    total_timesteps | 142592   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1115      |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 142720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6387188 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0448   |\n",
      "|    explained_variance   | -0.323    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0389   |\n",
      "|    n_updates            | 18938     |\n",
      "|    policy_gradient_loss | -0.0513   |\n",
      "|    value_loss           | 0.02      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1116      |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 142848    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8002366 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0798   |\n",
      "|    explained_variance   | 0.487     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0837   |\n",
      "|    n_updates            | 18955     |\n",
      "|    policy_gradient_loss | -0.0557   |\n",
      "|    value_loss           | 0.0241    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1117       |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 142976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.90526235 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0493    |\n",
      "|    explained_variance   | 0.768      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.118     |\n",
      "|    n_updates            | 18972      |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    value_loss           | 0.0476     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=143000, episode_reward=30.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 143000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17117196 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0684    |\n",
      "|    explained_variance   | 0.71       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0486    |\n",
      "|    n_updates            | 18989      |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 0.0938     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1118     |\n",
      "|    time_elapsed    | 156      |\n",
      "|    total_timesteps | 143104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1119       |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 143232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19099358 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.548      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0148    |\n",
      "|    n_updates            | 19006      |\n",
      "|    policy_gradient_loss | -0.0429    |\n",
      "|    value_loss           | 0.512      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1120       |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17505719 |\n",
      "|    clip_fraction        | 0.0781     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0823    |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.024     |\n",
      "|    n_updates            | 19023      |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1121      |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 143488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6977563 |\n",
      "|    clip_fraction        | 0.194     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.358     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 19040     |\n",
      "|    policy_gradient_loss | -0.0673   |\n",
      "|    value_loss           | 0.12      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=143500, episode_reward=21.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 21.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 143500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6050488 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.113    |\n",
      "|    explained_variance   | 0.657     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0359   |\n",
      "|    n_updates            | 19057     |\n",
      "|    policy_gradient_loss | -0.0513   |\n",
      "|    value_loss           | 0.435     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1122     |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 143616   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1123      |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 143744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6880408 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0645   |\n",
      "|    explained_variance   | 0.653     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0298   |\n",
      "|    n_updates            | 19074     |\n",
      "|    policy_gradient_loss | -0.0539   |\n",
      "|    value_loss           | 0.277     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1124       |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 143872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22598684 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.085     |\n",
      "|    explained_variance   | -0.0191    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0302    |\n",
      "|    n_updates            | 19091      |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 0.0414     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=33.97 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 34       |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 144000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.158249 |\n",
      "|    clip_fraction        | 0.186    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.06    |\n",
      "|    explained_variance   | -0.0617  |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0538  |\n",
      "|    n_updates            | 19108    |\n",
      "|    policy_gradient_loss | -0.0809  |\n",
      "|    value_loss           | 0.0343   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1125     |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 144000   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1126      |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 144128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0326562 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0836   |\n",
      "|    explained_variance   | 0.193     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0617   |\n",
      "|    n_updates            | 19125     |\n",
      "|    policy_gradient_loss | -0.0667   |\n",
      "|    value_loss           | 0.0111    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1127       |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 144256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46290454 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0918    |\n",
      "|    explained_variance   | 0.0898     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0877    |\n",
      "|    n_updates            | 19142      |\n",
      "|    policy_gradient_loss | -0.0545    |\n",
      "|    value_loss           | 0.0518     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1128      |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 144384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2684314 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.105    |\n",
      "|    explained_variance   | 0.841     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0878   |\n",
      "|    n_updates            | 19159     |\n",
      "|    policy_gradient_loss | -0.0613   |\n",
      "|    value_loss           | 0.0632    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=144500, episode_reward=9.65 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 9.65       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 144500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62764144 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0769    |\n",
      "|    explained_variance   | 0.668      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0793    |\n",
      "|    n_updates            | 19176      |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    value_loss           | 0.0896     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1129     |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 144512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1130       |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 144640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19240105 |\n",
      "|    clip_fraction        | 0.0657     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0664    |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 19193      |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1131       |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 144768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54174674 |\n",
      "|    clip_fraction        | 0.0427     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0241    |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0331    |\n",
      "|    n_updates            | 19210      |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1132       |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 144896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69230604 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0634    |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0839    |\n",
      "|    n_updates            | 19227      |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    value_loss           | 0.0742     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=41.23 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 41.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 145000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17331323 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0867    |\n",
      "|    explained_variance   | 0.195      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.959      |\n",
      "|    n_updates            | 19244      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 1.98       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1133     |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 145024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1134      |\n",
      "|    time_elapsed         | 158       |\n",
      "|    total_timesteps      | 145152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7307321 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.795     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.013     |\n",
      "|    n_updates            | 19261     |\n",
      "|    policy_gradient_loss | -0.0561   |\n",
      "|    value_loss           | 0.339     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1135      |\n",
      "|    time_elapsed         | 158       |\n",
      "|    total_timesteps      | 145280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6203173 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0745   |\n",
      "|    explained_variance   | -0.319    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0391   |\n",
      "|    n_updates            | 19278     |\n",
      "|    policy_gradient_loss | -0.0456   |\n",
      "|    value_loss           | 0.0362    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1136       |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.72176147 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.065     |\n",
      "|    explained_variance   | -0.514     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00343   |\n",
      "|    n_updates            | 19295      |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    value_loss           | 0.0657     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=145500, episode_reward=4.90 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 4.9       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 145500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8337905 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.037    |\n",
      "|    explained_variance   | -0.248    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.122    |\n",
      "|    n_updates            | 19312     |\n",
      "|    policy_gradient_loss | -0.0493   |\n",
      "|    value_loss           | 0.0215    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1137     |\n",
      "|    time_elapsed    | 159      |\n",
      "|    total_timesteps | 145536   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1138      |\n",
      "|    time_elapsed         | 159       |\n",
      "|    total_timesteps      | 145664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4994986 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.086    |\n",
      "|    explained_variance   | 0.28      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0852   |\n",
      "|    n_updates            | 19329     |\n",
      "|    policy_gradient_loss | -0.0504   |\n",
      "|    value_loss           | 0.0209    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1139      |\n",
      "|    time_elapsed         | 159       |\n",
      "|    total_timesteps      | 145792    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7327379 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.117    |\n",
      "|    explained_variance   | 0.575     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 19346     |\n",
      "|    policy_gradient_loss | -0.0231   |\n",
      "|    value_loss           | 0.0342    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1140       |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 145920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.94060016 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0406    |\n",
      "|    explained_variance   | 0.563      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0316    |\n",
      "|    n_updates            | 19363      |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 0.0575     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=-15.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -15.2      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 146000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49885994 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0718    |\n",
      "|    explained_variance   | -0.172     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.124     |\n",
      "|    n_updates            | 19380      |\n",
      "|    policy_gradient_loss | -0.0569    |\n",
      "|    value_loss           | 0.0881     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1141     |\n",
      "|    time_elapsed    | 159      |\n",
      "|    total_timesteps | 146048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1142       |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 146176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.66752195 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | -0.561     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0727    |\n",
      "|    n_updates            | 19397      |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 0.287      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1143       |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 146304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38613564 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.464      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.062     |\n",
      "|    n_updates            | 19414      |\n",
      "|    policy_gradient_loss | -0.0558    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1144       |\n",
      "|    time_elapsed         | 160        |\n",
      "|    total_timesteps      | 146432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42388788 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0971    |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0314    |\n",
      "|    n_updates            | 19431      |\n",
      "|    policy_gradient_loss | -0.0529    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=146500, episode_reward=12.94 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 12.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 146500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33376652 |\n",
      "|    clip_fraction        | 0.0818     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0663    |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.083      |\n",
      "|    n_updates            | 19448      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.794      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1145     |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 146560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1146       |\n",
      "|    time_elapsed         | 160        |\n",
      "|    total_timesteps      | 146688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28004086 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0631    |\n",
      "|    explained_variance   | 0.913      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0556    |\n",
      "|    n_updates            | 19465      |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    value_loss           | 0.0769     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1147      |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 146816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7472324 |\n",
      "|    clip_fraction        | 0.175     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0845   |\n",
      "|    explained_variance   | -0.221    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0814   |\n",
      "|    n_updates            | 19482     |\n",
      "|    policy_gradient_loss | -0.0638   |\n",
      "|    value_loss           | 0.12      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1148      |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 146944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7571234 |\n",
      "|    clip_fraction        | 0.183     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.062    |\n",
      "|    explained_variance   | -0.149    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0596   |\n",
      "|    n_updates            | 19499     |\n",
      "|    policy_gradient_loss | -0.0645   |\n",
      "|    value_loss           | 0.0231    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=147000, episode_reward=-17.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -17.2      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 147000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77433145 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0868    |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0239    |\n",
      "|    n_updates            | 19516      |\n",
      "|    policy_gradient_loss | -0.0466    |\n",
      "|    value_loss           | 0.0191     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1149     |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 147072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1150       |\n",
      "|    time_elapsed         | 161        |\n",
      "|    total_timesteps      | 147200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42129633 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.129     |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0453    |\n",
      "|    n_updates            | 19533      |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.06       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1151      |\n",
      "|    time_elapsed         | 161       |\n",
      "|    total_timesteps      | 147328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4493626 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.073    |\n",
      "|    explained_variance   | 0.642     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0604   |\n",
      "|    n_updates            | 19550     |\n",
      "|    policy_gradient_loss | -0.0545   |\n",
      "|    value_loss           | 0.133     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1152      |\n",
      "|    time_elapsed         | 161       |\n",
      "|    total_timesteps      | 147456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1235965 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0999   |\n",
      "|    explained_variance   | 0.668     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 19567     |\n",
      "|    policy_gradient_loss | -0.0635   |\n",
      "|    value_loss           | 0.0799    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=147500, episode_reward=-4.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -4.15      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 147500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14844586 |\n",
      "|    clip_fraction        | 0.0464     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0415    |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0119    |\n",
      "|    n_updates            | 19584      |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 0.573      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 39.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1153     |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 147584   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 39.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1154      |\n",
      "|    time_elapsed         | 161       |\n",
      "|    total_timesteps      | 147712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8220275 |\n",
      "|    clip_fraction        | 0.0974    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0433   |\n",
      "|    explained_variance   | 0.469     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0971   |\n",
      "|    n_updates            | 19601     |\n",
      "|    policy_gradient_loss | -0.0502   |\n",
      "|    value_loss           | 0.168     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 39.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1155       |\n",
      "|    time_elapsed         | 161        |\n",
      "|    total_timesteps      | 147840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20128235 |\n",
      "|    clip_fraction        | 0.085      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0724    |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 1.73e-05   |\n",
      "|    n_updates            | 19618      |\n",
      "|    policy_gradient_loss | -0.0387    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 40          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 147968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124648824 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0395     |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 19635       |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=19.42 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 148000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33032373 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0835    |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0468    |\n",
      "|    n_updates            | 19652      |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1157     |\n",
      "|    time_elapsed    | 162      |\n",
      "|    total_timesteps | 148096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1158      |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 148224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2087642 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0831   |\n",
      "|    explained_variance   | -1.15     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0914   |\n",
      "|    n_updates            | 19669     |\n",
      "|    policy_gradient_loss | -0.065    |\n",
      "|    value_loss           | 0.0827    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1159      |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 148352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7193186 |\n",
      "|    clip_fraction        | 0.179     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0495   |\n",
      "|    explained_variance   | -0.0146   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0932   |\n",
      "|    n_updates            | 19686     |\n",
      "|    policy_gradient_loss | -0.0202   |\n",
      "|    value_loss           | 0.0123    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1160      |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 148480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1292837 |\n",
      "|    clip_fraction        | 0.175     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0705   |\n",
      "|    explained_variance   | -0.149    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 19703     |\n",
      "|    policy_gradient_loss | -0.0605   |\n",
      "|    value_loss           | 0.0206    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=148500, episode_reward=-12.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -12.5     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 148500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3583393 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0997   |\n",
      "|    explained_variance   | 0.0552    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0379   |\n",
      "|    n_updates            | 19720     |\n",
      "|    policy_gradient_loss | -0.0446   |\n",
      "|    value_loss           | 0.0257    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1161     |\n",
      "|    time_elapsed    | 162      |\n",
      "|    total_timesteps | 148608   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1162      |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 148736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6436149 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0827   |\n",
      "|    explained_variance   | 0.827     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 19737     |\n",
      "|    policy_gradient_loss | -0.0759   |\n",
      "|    value_loss           | 0.0621    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1163      |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 148864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9720843 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0682   |\n",
      "|    explained_variance   | 0.868     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.146    |\n",
      "|    n_updates            | 19754     |\n",
      "|    policy_gradient_loss | -0.0657   |\n",
      "|    value_loss           | 0.0561    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1164      |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 148992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9743338 |\n",
      "|    clip_fraction        | 0.223     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0509   |\n",
      "|    explained_variance   | 0.646     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.074    |\n",
      "|    n_updates            | 19771     |\n",
      "|    policy_gradient_loss | -0.0641   |\n",
      "|    value_loss           | 0.194     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=149000, episode_reward=5.47 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 5.47       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 149000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12293533 |\n",
      "|    clip_fraction        | 0.0345     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0284    |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0151    |\n",
      "|    n_updates            | 19788      |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    value_loss           | 0.146      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40       |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1165     |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 149120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1166       |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 149248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21427418 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.725      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 19805      |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 0.0992     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1167       |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 149376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47098023 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0747    |\n",
      "|    explained_variance   | 0.711      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0429     |\n",
      "|    n_updates            | 19822      |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.614      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=149500, episode_reward=25.31 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 149500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25697902 |\n",
      "|    clip_fraction        | 0.0804     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0609    |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0145     |\n",
      "|    n_updates            | 19839      |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1168     |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 149504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1169       |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 149632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55078864 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0271    |\n",
      "|    explained_variance   | -0.796     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -9.68e-05  |\n",
      "|    n_updates            | 19856      |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    value_loss           | 0.0585     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1170       |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 149760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33666897 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0344    |\n",
      "|    explained_variance   | 0.216      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.036     |\n",
      "|    n_updates            | 19873      |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 0.0264     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1171      |\n",
      "|    time_elapsed         | 164       |\n",
      "|    total_timesteps      | 149888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6413027 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0524   |\n",
      "|    explained_variance   | -0.154    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.045    |\n",
      "|    n_updates            | 19890     |\n",
      "|    policy_gradient_loss | -0.0311   |\n",
      "|    value_loss           | 0.0173    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-1.69 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -1.69      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 150000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.78968114 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0872    |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0919    |\n",
      "|    n_updates            | 19907      |\n",
      "|    policy_gradient_loss | -0.0608    |\n",
      "|    value_loss           | 0.0259     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1172     |\n",
      "|    time_elapsed    | 164      |\n",
      "|    total_timesteps | 150016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1173      |\n",
      "|    time_elapsed         | 164       |\n",
      "|    total_timesteps      | 150144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4705432 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.446     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.066    |\n",
      "|    n_updates            | 19924     |\n",
      "|    policy_gradient_loss | -0.0566   |\n",
      "|    value_loss           | 0.0506    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1174       |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 150272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35017508 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0728    |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0583    |\n",
      "|    n_updates            | 19941      |\n",
      "|    policy_gradient_loss | -0.0399    |\n",
      "|    value_loss           | 0.0506     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1175      |\n",
      "|    time_elapsed         | 164       |\n",
      "|    total_timesteps      | 150400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0972376 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0932   |\n",
      "|    explained_variance   | 0.546     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 19958     |\n",
      "|    policy_gradient_loss | -0.0582   |\n",
      "|    value_loss           | 0.0798    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=150500, episode_reward=33.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 33.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 150500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7790877 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0833   |\n",
      "|    explained_variance   | 0.543     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0745   |\n",
      "|    n_updates            | 19975     |\n",
      "|    policy_gradient_loss | -0.0664   |\n",
      "|    value_loss           | 0.237     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1176     |\n",
      "|    time_elapsed    | 164      |\n",
      "|    total_timesteps | 150528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1177      |\n",
      "|    time_elapsed         | 164       |\n",
      "|    total_timesteps      | 150656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1760967 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.648     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0665   |\n",
      "|    n_updates            | 19992     |\n",
      "|    policy_gradient_loss | -0.0594   |\n",
      "|    value_loss           | 0.0858    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 40.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1178     |\n",
      "|    time_elapsed         | 164      |\n",
      "|    total_timesteps      | 150784   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.170232 |\n",
      "|    clip_fraction        | 0.211    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0877  |\n",
      "|    explained_variance   | 0.675    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0502  |\n",
      "|    n_updates            | 20009    |\n",
      "|    policy_gradient_loss | -0.0646  |\n",
      "|    value_loss           | 0.249    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1179      |\n",
      "|    time_elapsed         | 165       |\n",
      "|    total_timesteps      | 150912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0622714 |\n",
      "|    clip_fraction        | 0.234     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.408     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0408    |\n",
      "|    n_updates            | 20026     |\n",
      "|    policy_gradient_loss | -0.0486   |\n",
      "|    value_loss           | 1.05      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=151000, episode_reward=24.07 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 24.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 151000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8775754 |\n",
      "|    clip_fraction        | 0.112     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0771   |\n",
      "|    explained_variance   | 0.911     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0887   |\n",
      "|    n_updates            | 20043     |\n",
      "|    policy_gradient_loss | -0.0365   |\n",
      "|    value_loss           | 0.0424    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1180     |\n",
      "|    time_elapsed    | 165      |\n",
      "|    total_timesteps | 151040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1181       |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 151168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32929644 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0849    |\n",
      "|    explained_variance   | -0.24      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0573    |\n",
      "|    n_updates            | 20060      |\n",
      "|    policy_gradient_loss | -0.0446    |\n",
      "|    value_loss           | 0.0434     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1182      |\n",
      "|    time_elapsed         | 165       |\n",
      "|    total_timesteps      | 151296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5415009 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0832   |\n",
      "|    explained_variance   | 0.0915    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0711   |\n",
      "|    n_updates            | 20077     |\n",
      "|    policy_gradient_loss | -0.0307   |\n",
      "|    value_loss           | 0.00949   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1183       |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 151424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69847596 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0598    |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0465    |\n",
      "|    n_updates            | 20094      |\n",
      "|    policy_gradient_loss | -0.0661    |\n",
      "|    value_loss           | 0.0117     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=151500, episode_reward=22.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 22.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 151500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6253232 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0928   |\n",
      "|    explained_variance   | 0.498     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0489   |\n",
      "|    n_updates            | 20111     |\n",
      "|    policy_gradient_loss | -0.0673   |\n",
      "|    value_loss           | 0.0289    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1184     |\n",
      "|    time_elapsed    | 165      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1185       |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 151680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76915777 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0465    |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.07      |\n",
      "|    n_updates            | 20128      |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.0441     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1186       |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 151808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29837966 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 20145      |\n",
      "|    policy_gradient_loss | -0.061     |\n",
      "|    value_loss           | 0.084      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1187      |\n",
      "|    time_elapsed         | 166       |\n",
      "|    total_timesteps      | 151936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6599734 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0767   |\n",
      "|    explained_variance   | 0.677     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0153    |\n",
      "|    n_updates            | 20162     |\n",
      "|    policy_gradient_loss | -0.025    |\n",
      "|    value_loss           | 0.356     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=25.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 152000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23328105 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.105     |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0764    |\n",
      "|    n_updates            | 20179      |\n",
      "|    policy_gradient_loss | -0.0594    |\n",
      "|    value_loss           | 0.254      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1188     |\n",
      "|    time_elapsed    | 166      |\n",
      "|    total_timesteps | 152064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1189       |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 152192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65226173 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0902    |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0461    |\n",
      "|    n_updates            | 20196      |\n",
      "|    policy_gradient_loss | -0.0542    |\n",
      "|    value_loss           | 0.256      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1190       |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 152320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56387764 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.79       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000241  |\n",
      "|    n_updates            | 20213      |\n",
      "|    policy_gradient_loss | -0.0525    |\n",
      "|    value_loss           | 0.571      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1191       |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 152448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26103815 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0621    |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0125    |\n",
      "|    n_updates            | 20230      |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.231      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=152500, episode_reward=28.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 28.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 152500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0293998 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0694   |\n",
      "|    explained_variance   | -0.0244   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0691   |\n",
      "|    n_updates            | 20247     |\n",
      "|    policy_gradient_loss | -0.0558   |\n",
      "|    value_loss           | 0.0351    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1192     |\n",
      "|    time_elapsed    | 166      |\n",
      "|    total_timesteps | 152576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1193       |\n",
      "|    time_elapsed         | 167        |\n",
      "|    total_timesteps      | 152704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43269363 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.088     |\n",
      "|    explained_variance   | 0.253      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.06      |\n",
      "|    n_updates            | 20264      |\n",
      "|    policy_gradient_loss | -0.0535    |\n",
      "|    value_loss           | 0.0137     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1194      |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 152832    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0304544 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.091    |\n",
      "|    explained_variance   | -0.0302   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.132    |\n",
      "|    n_updates            | 20281     |\n",
      "|    policy_gradient_loss | -0.0814   |\n",
      "|    value_loss           | 0.0114    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1195      |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 152960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1147301 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0996   |\n",
      "|    explained_variance   | 0.229     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 20298     |\n",
      "|    policy_gradient_loss | -0.0697   |\n",
      "|    value_loss           | 0.0464    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=153000, episode_reward=35.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 153000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41087604 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0982    |\n",
      "|    explained_variance   | 0.821      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.161      |\n",
      "|    n_updates            | 20315      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.0712     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1196     |\n",
      "|    time_elapsed    | 167      |\n",
      "|    total_timesteps | 153088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1197      |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 153216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5766679 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0708   |\n",
      "|    explained_variance   | 0.857     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0754   |\n",
      "|    n_updates            | 20332     |\n",
      "|    policy_gradient_loss | -0.0582   |\n",
      "|    value_loss           | 0.0349    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1198      |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 153344    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9959291 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0736   |\n",
      "|    explained_variance   | 0.784     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0261    |\n",
      "|    n_updates            | 20349     |\n",
      "|    policy_gradient_loss | -0.0496   |\n",
      "|    value_loss           | 0.435     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1199      |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 153472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2847091 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | 0.678     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0676   |\n",
      "|    n_updates            | 20366     |\n",
      "|    policy_gradient_loss | -0.053    |\n",
      "|    value_loss           | 0.221     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=153500, episode_reward=17.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 17.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 153500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6053782 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.094    |\n",
      "|    explained_variance   | 0.581     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0691   |\n",
      "|    n_updates            | 20383     |\n",
      "|    policy_gradient_loss | -0.0571   |\n",
      "|    value_loss           | 0.128     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1200     |\n",
      "|    time_elapsed    | 167      |\n",
      "|    total_timesteps | 153600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1201       |\n",
      "|    time_elapsed         | 168        |\n",
      "|    total_timesteps      | 153728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40754545 |\n",
      "|    clip_fraction        | 0.0483     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0442    |\n",
      "|    explained_variance   | 0.725      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00151    |\n",
      "|    n_updates            | 20400      |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    value_loss           | 0.471      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1202      |\n",
      "|    time_elapsed         | 168       |\n",
      "|    total_timesteps      | 153856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2982036 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.085    |\n",
      "|    explained_variance   | -0.263    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.023    |\n",
      "|    n_updates            | 20417     |\n",
      "|    policy_gradient_loss | -0.063    |\n",
      "|    value_loss           | 0.443     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1203      |\n",
      "|    time_elapsed         | 168       |\n",
      "|    total_timesteps      | 153984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2519846 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.087    |\n",
      "|    explained_variance   | -0.0803   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0694   |\n",
      "|    n_updates            | 20434     |\n",
      "|    policy_gradient_loss | -0.055    |\n",
      "|    value_loss           | 0.0179    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=14.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 14.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 154000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.82941175 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0713    |\n",
      "|    explained_variance   | -0.298     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0281    |\n",
      "|    n_updates            | 20451      |\n",
      "|    policy_gradient_loss | -0.0661    |\n",
      "|    value_loss           | 0.0732     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1204     |\n",
      "|    time_elapsed    | 168      |\n",
      "|    total_timesteps | 154112   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1205       |\n",
      "|    time_elapsed         | 168        |\n",
      "|    total_timesteps      | 154240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23265332 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0651    |\n",
      "|    explained_variance   | 0.0984     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0182    |\n",
      "|    n_updates            | 20468      |\n",
      "|    policy_gradient_loss | -0.0505    |\n",
      "|    value_loss           | 0.0109     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1206      |\n",
      "|    time_elapsed         | 168       |\n",
      "|    total_timesteps      | 154368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9036108 |\n",
      "|    clip_fraction        | 0.203     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.092    |\n",
      "|    explained_variance   | -0.178    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0516   |\n",
      "|    n_updates            | 20485     |\n",
      "|    policy_gradient_loss | -0.0625   |\n",
      "|    value_loss           | 0.0229    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 40.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 915      |\n",
      "|    iterations           | 1207     |\n",
      "|    time_elapsed         | 168      |\n",
      "|    total_timesteps      | 154496   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.430573 |\n",
      "|    clip_fraction        | 0.158    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.107   |\n",
      "|    explained_variance   | 0.785    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0439  |\n",
      "|    n_updates            | 20502    |\n",
      "|    policy_gradient_loss | -0.0371  |\n",
      "|    value_loss           | 0.0528   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=154500, episode_reward=-5.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -5.08      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 154500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14717303 |\n",
      "|    clip_fraction        | 0.0639     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0428    |\n",
      "|    explained_variance   | 0.661      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0459    |\n",
      "|    n_updates            | 20519      |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    value_loss           | 0.0456     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1208     |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 154624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1209       |\n",
      "|    time_elapsed         | 169        |\n",
      "|    total_timesteps      | 154752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33159253 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0694    |\n",
      "|    n_updates            | 20536      |\n",
      "|    policy_gradient_loss | -0.0521    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1210       |\n",
      "|    time_elapsed         | 169        |\n",
      "|    total_timesteps      | 154880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.84865785 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.118     |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.011      |\n",
      "|    n_updates            | 20553      |\n",
      "|    policy_gradient_loss | -0.0776    |\n",
      "|    value_loss           | 0.412      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-19.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -19.1     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 155000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6656143 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | 0.712     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0701   |\n",
      "|    n_updates            | 20570     |\n",
      "|    policy_gradient_loss | -0.0636   |\n",
      "|    value_loss           | 0.181     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1211     |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 155008   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1212      |\n",
      "|    time_elapsed         | 169       |\n",
      "|    total_timesteps      | 155136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5533111 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.686     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0793   |\n",
      "|    n_updates            | 20587     |\n",
      "|    policy_gradient_loss | -0.0756   |\n",
      "|    value_loss           | 0.245     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1213      |\n",
      "|    time_elapsed         | 169       |\n",
      "|    total_timesteps      | 155264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6244606 |\n",
      "|    clip_fraction        | 0.205     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.371     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.062     |\n",
      "|    n_updates            | 20604     |\n",
      "|    policy_gradient_loss | -0.0606   |\n",
      "|    value_loss           | 0.727     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1214      |\n",
      "|    time_elapsed         | 169       |\n",
      "|    total_timesteps      | 155392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3366992 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0827   |\n",
      "|    explained_variance   | 0.949     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.117    |\n",
      "|    n_updates            | 20621     |\n",
      "|    policy_gradient_loss | -0.0755   |\n",
      "|    value_loss           | 0.0401    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=155500, episode_reward=18.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 19        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 155500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6070142 |\n",
      "|    clip_fraction        | 0.209     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | -0.656    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.083    |\n",
      "|    n_updates            | 20638     |\n",
      "|    policy_gradient_loss | -0.0607   |\n",
      "|    value_loss           | 0.0604    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1215     |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 155520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1216       |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.82480943 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | -0.167     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 20655      |\n",
      "|    policy_gradient_loss | -0.0885    |\n",
      "|    value_loss           | 0.0212     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1217      |\n",
      "|    time_elapsed         | 170       |\n",
      "|    total_timesteps      | 155776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7061184 |\n",
      "|    clip_fraction        | 0.22      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.117    |\n",
      "|    explained_variance   | -0.688    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.117    |\n",
      "|    n_updates            | 20672     |\n",
      "|    policy_gradient_loss | -0.081    |\n",
      "|    value_loss           | 0.0176    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 40.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1218      |\n",
      "|    time_elapsed         | 170       |\n",
      "|    total_timesteps      | 155904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3702667 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | -0.0724   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.121    |\n",
      "|    n_updates            | 20689     |\n",
      "|    policy_gradient_loss | -0.0828   |\n",
      "|    value_loss           | 0.0452    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=156000, episode_reward=47.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 47.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 156000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6385834 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0656   |\n",
      "|    explained_variance   | 0.737     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.077    |\n",
      "|    n_updates            | 20706     |\n",
      "|    policy_gradient_loss | -0.0514   |\n",
      "|    value_loss           | 0.0479    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1219     |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 156032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1220       |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 156160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24683006 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0829    |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0746    |\n",
      "|    n_updates            | 20723      |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1221       |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 156288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28567463 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.685      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00672   |\n",
      "|    n_updates            | 20740      |\n",
      "|    policy_gradient_loss | -0.0537    |\n",
      "|    value_loss           | 0.569      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 40.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1222       |\n",
      "|    time_elapsed         | 171        |\n",
      "|    total_timesteps      | 156416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27418327 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.149     |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 20757      |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=156500, episode_reward=43.84 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 43.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 156500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5943962 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | 0.854     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.097    |\n",
      "|    n_updates            | 20774     |\n",
      "|    policy_gradient_loss | -0.0752   |\n",
      "|    value_loss           | 0.121     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 40.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1223     |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 156544   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1224      |\n",
      "|    time_elapsed         | 171       |\n",
      "|    total_timesteps      | 156672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6162789 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.078    |\n",
      "|    explained_variance   | 0.591     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.129     |\n",
      "|    n_updates            | 20791     |\n",
      "|    policy_gradient_loss | -0.0487   |\n",
      "|    value_loss           | 0.869     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1225       |\n",
      "|    time_elapsed         | 171        |\n",
      "|    total_timesteps      | 156800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.83773625 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0918    |\n",
      "|    explained_variance   | 0.1        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00665   |\n",
      "|    n_updates            | 20808      |\n",
      "|    policy_gradient_loss | -0.0564    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1226       |\n",
      "|    time_elapsed         | 171        |\n",
      "|    total_timesteps      | 156928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71387494 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0858    |\n",
      "|    explained_variance   | 0.0948     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0142    |\n",
      "|    n_updates            | 20825      |\n",
      "|    policy_gradient_loss | -0.0687    |\n",
      "|    value_loss           | 0.0275     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=157000, episode_reward=46.60 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 157000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5723796 |\n",
      "|    clip_fraction        | 0.285     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.104     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0914   |\n",
      "|    n_updates            | 20842     |\n",
      "|    policy_gradient_loss | -0.077    |\n",
      "|    value_loss           | 0.0166    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1227     |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 157056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1228      |\n",
      "|    time_elapsed         | 171       |\n",
      "|    total_timesteps      | 157184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8545808 |\n",
      "|    clip_fraction        | 0.208     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0898   |\n",
      "|    explained_variance   | -0.0814   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0367   |\n",
      "|    n_updates            | 20859     |\n",
      "|    policy_gradient_loss | -0.0635   |\n",
      "|    value_loss           | 0.0157    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1229       |\n",
      "|    time_elapsed         | 172        |\n",
      "|    total_timesteps      | 157312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62455714 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.154     |\n",
      "|    explained_variance   | 0.403      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0751    |\n",
      "|    n_updates            | 20876      |\n",
      "|    policy_gradient_loss | -0.0827    |\n",
      "|    value_loss           | 0.048      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1230       |\n",
      "|    time_elapsed         | 172        |\n",
      "|    total_timesteps      | 157440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36380997 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0807    |\n",
      "|    explained_variance   | 0.844      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 20893      |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    value_loss           | 0.0423     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=157500, episode_reward=17.99 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 18         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 157500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14555734 |\n",
      "|    clip_fraction        | 0.0708     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0823    |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.047     |\n",
      "|    n_updates            | 20910      |\n",
      "|    policy_gradient_loss | -0.0418    |\n",
      "|    value_loss           | 0.0606     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1231     |\n",
      "|    time_elapsed    | 172      |\n",
      "|    total_timesteps | 157568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1232       |\n",
      "|    time_elapsed         | 172        |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28066307 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.629      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.165      |\n",
      "|    n_updates            | 20927      |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.628      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1233      |\n",
      "|    time_elapsed         | 172       |\n",
      "|    total_timesteps      | 157824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.2877133 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | 0.548     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0274    |\n",
      "|    n_updates            | 20944     |\n",
      "|    policy_gradient_loss | -0.0556   |\n",
      "|    value_loss           | 0.546     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1234      |\n",
      "|    time_elapsed         | 172       |\n",
      "|    total_timesteps      | 157952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3709673 |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.735     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.091    |\n",
      "|    n_updates            | 20961     |\n",
      "|    policy_gradient_loss | -0.0757   |\n",
      "|    value_loss           | 0.143     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=10.35 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 10.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 158000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8171507 |\n",
      "|    clip_fraction        | 0.212     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.137    |\n",
      "|    explained_variance   | 0.854     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.1      |\n",
      "|    n_updates            | 20978     |\n",
      "|    policy_gradient_loss | -0.0758   |\n",
      "|    value_loss           | 0.228     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1235     |\n",
      "|    time_elapsed    | 172      |\n",
      "|    total_timesteps | 158080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1236       |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 158208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39267918 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.09      |\n",
      "|    explained_variance   | 0.538      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0529    |\n",
      "|    n_updates            | 20995      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.382      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1237       |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 158336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32914668 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0675    |\n",
      "|    explained_variance   | -0.613     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 21012      |\n",
      "|    policy_gradient_loss | -0.0576    |\n",
      "|    value_loss           | 0.0362     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1238       |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 158464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47435987 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0784    |\n",
      "|    explained_variance   | -0.548     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 21029      |\n",
      "|    policy_gradient_loss | -0.0645    |\n",
      "|    value_loss           | 0.0154     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=158500, episode_reward=59.60 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 59.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 158500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7808741 |\n",
      "|    clip_fraction        | 0.175     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0408   |\n",
      "|    explained_variance   | 0.0854    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0708   |\n",
      "|    n_updates            | 21046     |\n",
      "|    policy_gradient_loss | -0.0615   |\n",
      "|    value_loss           | 0.0165    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1239     |\n",
      "|    time_elapsed    | 173      |\n",
      "|    total_timesteps | 158592   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1240      |\n",
      "|    time_elapsed         | 173       |\n",
      "|    total_timesteps      | 158720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6836834 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0605   |\n",
      "|    explained_variance   | 0.381     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0166   |\n",
      "|    n_updates            | 21063     |\n",
      "|    policy_gradient_loss | -0.0531   |\n",
      "|    value_loss           | 0.0126    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1241      |\n",
      "|    time_elapsed         | 173       |\n",
      "|    total_timesteps      | 158848    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1774304 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0765   |\n",
      "|    explained_variance   | 0.824     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0237    |\n",
      "|    n_updates            | 21080     |\n",
      "|    policy_gradient_loss | -0.0294   |\n",
      "|    value_loss           | 0.0285    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1242       |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 158976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69414985 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0921    |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.123     |\n",
      "|    n_updates            | 21097      |\n",
      "|    policy_gradient_loss | -0.0603    |\n",
      "|    value_loss           | 0.0367     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=159000, episode_reward=31.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 31         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 159000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70353144 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.56       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0808    |\n",
      "|    n_updates            | 21114      |\n",
      "|    policy_gradient_loss | -0.0545    |\n",
      "|    value_loss           | 0.0765     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1243     |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 159104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1244       |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 159232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37396944 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0834    |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0114    |\n",
      "|    n_updates            | 21131      |\n",
      "|    policy_gradient_loss | -0.0354    |\n",
      "|    value_loss           | 0.493      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1245      |\n",
      "|    time_elapsed         | 174       |\n",
      "|    total_timesteps      | 159360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6197002 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0789   |\n",
      "|    explained_variance   | 0.861     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0844   |\n",
      "|    n_updates            | 21148     |\n",
      "|    policy_gradient_loss | -0.0371   |\n",
      "|    value_loss           | 0.086     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1246       |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 159488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38606194 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0916    |\n",
      "|    n_updates            | 21165      |\n",
      "|    policy_gradient_loss | -0.0384    |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=159500, episode_reward=37.41 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 159500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6193813 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | -0.192    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.68      |\n",
      "|    n_updates            | 21182     |\n",
      "|    policy_gradient_loss | -0.0572   |\n",
      "|    value_loss           | 1.83      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1247     |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 159616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1248       |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48009712 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0633    |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 21199      |\n",
      "|    policy_gradient_loss | -0.0612    |\n",
      "|    value_loss           | 0.0165     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 41.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1249     |\n",
      "|    time_elapsed         | 174      |\n",
      "|    total_timesteps      | 159872   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.920782 |\n",
      "|    clip_fraction        | 0.199    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.119   |\n",
      "|    explained_variance   | 0.349    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.129   |\n",
      "|    n_updates            | 21216    |\n",
      "|    policy_gradient_loss | -0.0643  |\n",
      "|    value_loss           | 0.00842  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=7.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 7.68      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 160000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3746765 |\n",
      "|    clip_fraction        | 0.238     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0845   |\n",
      "|    explained_variance   | 0.344     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 21233     |\n",
      "|    policy_gradient_loss | -0.0766   |\n",
      "|    value_loss           | 0.0103    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1250     |\n",
      "|    time_elapsed    | 175      |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 41.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1251     |\n",
      "|    time_elapsed         | 175      |\n",
      "|    total_timesteps      | 160128   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.504571 |\n",
      "|    clip_fraction        | 0.243    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0816  |\n",
      "|    explained_variance   | 0.357    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0937  |\n",
      "|    n_updates            | 21250    |\n",
      "|    policy_gradient_loss | -0.0747  |\n",
      "|    value_loss           | 0.00903  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 41.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1252     |\n",
      "|    time_elapsed         | 175      |\n",
      "|    total_timesteps      | 160256   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.822863 |\n",
      "|    clip_fraction        | 0.129    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.105   |\n",
      "|    explained_variance   | -0.482   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0741  |\n",
      "|    n_updates            | 21267    |\n",
      "|    policy_gradient_loss | -0.048   |\n",
      "|    value_loss           | 0.0461   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1253      |\n",
      "|    time_elapsed         | 175       |\n",
      "|    total_timesteps      | 160384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1391629 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0705   |\n",
      "|    explained_variance   | 0.646     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0869   |\n",
      "|    n_updates            | 21284     |\n",
      "|    policy_gradient_loss | -0.0511   |\n",
      "|    value_loss           | 0.0298    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=160500, episode_reward=4.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.27       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 160500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42388195 |\n",
      "|    clip_fraction        | 0.0501     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.045     |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0269    |\n",
      "|    n_updates            | 21301      |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    value_loss           | 0.057      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1254     |\n",
      "|    time_elapsed    | 175      |\n",
      "|    total_timesteps | 160512   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1255      |\n",
      "|    time_elapsed         | 175       |\n",
      "|    total_timesteps      | 160640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8430583 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0799   |\n",
      "|    explained_variance   | 0.451     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0901   |\n",
      "|    n_updates            | 21318     |\n",
      "|    policy_gradient_loss | -0.0845   |\n",
      "|    value_loss           | 0.316     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1256      |\n",
      "|    time_elapsed         | 175       |\n",
      "|    total_timesteps      | 160768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2828586 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0737   |\n",
      "|    explained_variance   | 0.786     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0789   |\n",
      "|    n_updates            | 21335     |\n",
      "|    policy_gradient_loss | -0.0522   |\n",
      "|    value_loss           | 0.155     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1257       |\n",
      "|    time_elapsed         | 175        |\n",
      "|    total_timesteps      | 160896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23677166 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0912    |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.1       |\n",
      "|    n_updates            | 21352      |\n",
      "|    policy_gradient_loss | -0.0619    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=161000, episode_reward=59.07 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 59.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 161000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7342827 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0717   |\n",
      "|    explained_variance   | 0.0892    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0617    |\n",
      "|    n_updates            | 21369     |\n",
      "|    policy_gradient_loss | -0.0552   |\n",
      "|    value_loss           | 0.35      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1258     |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 161024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1259       |\n",
      "|    time_elapsed         | 176        |\n",
      "|    total_timesteps      | 161152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28634644 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.302      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0876     |\n",
      "|    n_updates            | 21386      |\n",
      "|    policy_gradient_loss | -0.0376    |\n",
      "|    value_loss           | 0.364      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1260      |\n",
      "|    time_elapsed         | 176       |\n",
      "|    total_timesteps      | 161280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4664773 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0935   |\n",
      "|    explained_variance   | 0.27      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0524   |\n",
      "|    n_updates            | 21403     |\n",
      "|    policy_gradient_loss | -0.0545   |\n",
      "|    value_loss           | 0.0328    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1261      |\n",
      "|    time_elapsed         | 176       |\n",
      "|    total_timesteps      | 161408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5710525 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.141    |\n",
      "|    explained_variance   | -0.398    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.115    |\n",
      "|    n_updates            | 21420     |\n",
      "|    policy_gradient_loss | -0.067    |\n",
      "|    value_loss           | 0.0182    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=161500, episode_reward=25.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 25.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 161500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0155003 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0781   |\n",
      "|    explained_variance   | -0.182    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0336   |\n",
      "|    n_updates            | 21437     |\n",
      "|    policy_gradient_loss | -0.0574   |\n",
      "|    value_loss           | 0.0124    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1262     |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 161536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1263       |\n",
      "|    time_elapsed         | 176        |\n",
      "|    total_timesteps      | 161664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76957047 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | -0.175     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0313    |\n",
      "|    n_updates            | 21454      |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0315     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1264      |\n",
      "|    time_elapsed         | 176       |\n",
      "|    total_timesteps      | 161792    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2638619 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0588   |\n",
      "|    explained_variance   | 0.645     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0256   |\n",
      "|    n_updates            | 21471     |\n",
      "|    policy_gradient_loss | -0.0577   |\n",
      "|    value_loss           | 0.0628    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1265       |\n",
      "|    time_elapsed         | 177        |\n",
      "|    total_timesteps      | 161920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29841447 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.531      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0428    |\n",
      "|    n_updates            | 21488      |\n",
      "|    policy_gradient_loss | -0.0519    |\n",
      "|    value_loss           | 0.0776     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=65.66 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 65.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 162000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33153796 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0753    |\n",
      "|    explained_variance   | 0.475      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 21505      |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    value_loss           | 0.464      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1266     |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 162048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1267       |\n",
      "|    time_elapsed         | 177        |\n",
      "|    total_timesteps      | 162176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40578583 |\n",
      "|    clip_fraction        | 0.0873     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0579    |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0461    |\n",
      "|    n_updates            | 21522      |\n",
      "|    policy_gradient_loss | -0.0425    |\n",
      "|    value_loss           | 0.303      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1268       |\n",
      "|    time_elapsed         | 177        |\n",
      "|    total_timesteps      | 162304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32021427 |\n",
      "|    clip_fraction        | 0.0873     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0558    |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.056     |\n",
      "|    n_updates            | 21539      |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    value_loss           | 0.0979     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1269       |\n",
      "|    time_elapsed         | 177        |\n",
      "|    total_timesteps      | 162432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43501928 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0881    |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0258     |\n",
      "|    n_updates            | 21556      |\n",
      "|    policy_gradient_loss | -0.0726    |\n",
      "|    value_loss           | 0.313      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=162500, episode_reward=64.31 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 64.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 162500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54598993 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.403      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 21573      |\n",
      "|    policy_gradient_loss | -0.0613    |\n",
      "|    value_loss           | 0.562      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1270     |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 162560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1271      |\n",
      "|    time_elapsed         | 177       |\n",
      "|    total_timesteps      | 162688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1915828 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0988   |\n",
      "|    explained_variance   | 0.0723    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 21590     |\n",
      "|    policy_gradient_loss | -0.0915   |\n",
      "|    value_loss           | 0.0293    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1272      |\n",
      "|    time_elapsed         | 177       |\n",
      "|    total_timesteps      | 162816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5534675 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0899   |\n",
      "|    explained_variance   | 0.0699    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0782   |\n",
      "|    n_updates            | 21607     |\n",
      "|    policy_gradient_loss | -0.0396   |\n",
      "|    value_loss           | 0.0292    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1273       |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 162944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25087163 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0714    |\n",
      "|    explained_variance   | -0.578     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0585    |\n",
      "|    n_updates            | 21624      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.00959    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=163000, episode_reward=-7.92 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -7.92     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 163000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2446241 |\n",
      "|    clip_fraction        | 0.227     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0925   |\n",
      "|    explained_variance   | 0.312     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0562   |\n",
      "|    n_updates            | 21641     |\n",
      "|    policy_gradient_loss | -0.0778   |\n",
      "|    value_loss           | 0.0411    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1274     |\n",
      "|    time_elapsed    | 178      |\n",
      "|    total_timesteps | 163072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1275       |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 163200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32281178 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0857    |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0549    |\n",
      "|    n_updates            | 21658      |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    value_loss           | 0.0547     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1276       |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 163328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46875852 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0654    |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0961    |\n",
      "|    n_updates            | 21675      |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 0.0591     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1277       |\n",
      "|    time_elapsed         | 178        |\n",
      "|    total_timesteps      | 163456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19613764 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0807    |\n",
      "|    explained_variance   | 0.274      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0502    |\n",
      "|    n_updates            | 21692      |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=163500, episode_reward=18.04 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 18         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 163500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25990456 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0763    |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.021     |\n",
      "|    n_updates            | 21709      |\n",
      "|    policy_gradient_loss | -0.0466    |\n",
      "|    value_loss           | 0.719      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1278     |\n",
      "|    time_elapsed    | 178      |\n",
      "|    total_timesteps | 163584   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1279      |\n",
      "|    time_elapsed         | 178       |\n",
      "|    total_timesteps      | 163712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6517248 |\n",
      "|    clip_fraction        | 0.0915    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0316   |\n",
      "|    explained_variance   | 0.716     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0472   |\n",
      "|    n_updates            | 21726     |\n",
      "|    policy_gradient_loss | -0.0399   |\n",
      "|    value_loss           | 0.0598    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1280      |\n",
      "|    time_elapsed         | 179       |\n",
      "|    total_timesteps      | 163840    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3314968 |\n",
      "|    clip_fraction        | 0.109     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0773   |\n",
      "|    explained_variance   | 0.643     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00416   |\n",
      "|    n_updates            | 21743     |\n",
      "|    policy_gradient_loss | -0.0435   |\n",
      "|    value_loss           | 0.273     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 915        |\n",
      "|    iterations           | 1281       |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 163968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49588147 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.0549     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.137      |\n",
      "|    n_updates            | 21760      |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    value_loss           | 1.46       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=6.23 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.23       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 164000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60099804 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0928    |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 21777      |\n",
      "|    policy_gradient_loss | -0.0944    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1282     |\n",
      "|    time_elapsed    | 179      |\n",
      "|    total_timesteps | 164096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1283      |\n",
      "|    time_elapsed         | 179       |\n",
      "|    total_timesteps      | 164224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4400652 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.124    |\n",
      "|    explained_variance   | -0.643    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.056    |\n",
      "|    n_updates            | 21794     |\n",
      "|    policy_gradient_loss | -0.0575   |\n",
      "|    value_loss           | 0.028     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1284       |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 164352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40895587 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0458    |\n",
      "|    explained_variance   | -0.609     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 21811      |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.0131     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 915       |\n",
      "|    iterations           | 1285      |\n",
      "|    time_elapsed         | 179       |\n",
      "|    total_timesteps      | 164480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.0898843 |\n",
      "|    clip_fraction        | 0.223     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0568   |\n",
      "|    explained_variance   | 0.0888    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 21828     |\n",
      "|    policy_gradient_loss | -0.0609   |\n",
      "|    value_loss           | 0.0162    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=164500, episode_reward=8.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 8.21      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 164500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4223659 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0918   |\n",
      "|    explained_variance   | -0.0114   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0119   |\n",
      "|    n_updates            | 21845     |\n",
      "|    policy_gradient_loss | -0.0501   |\n",
      "|    value_loss           | 0.0541    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 914      |\n",
      "|    iterations      | 1286     |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 164608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1287       |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 164736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24620473 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0543    |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00913   |\n",
      "|    n_updates            | 21862      |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 0.05       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 41.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 914      |\n",
      "|    iterations           | 1288     |\n",
      "|    time_elapsed         | 180      |\n",
      "|    total_timesteps      | 164864   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.376345 |\n",
      "|    clip_fraction        | 0.159    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.111   |\n",
      "|    explained_variance   | -0.201   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0375  |\n",
      "|    n_updates            | 21879    |\n",
      "|    policy_gradient_loss | -0.0554  |\n",
      "|    value_loss           | 0.218    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1289       |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 164992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39449835 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0729    |\n",
      "|    explained_variance   | 0.695      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00871    |\n",
      "|    n_updates            | 21896      |\n",
      "|    policy_gradient_loss | -0.0666    |\n",
      "|    value_loss           | 0.349      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=4.64 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.64       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 165000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44271418 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0887    |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0664    |\n",
      "|    n_updates            | 21913      |\n",
      "|    policy_gradient_loss | -0.0485    |\n",
      "|    value_loss           | 0.122      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1290     |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 165120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 1291       |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 165248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51262176 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0503    |\n",
      "|    n_updates            | 21930      |\n",
      "|    policy_gradient_loss | -0.0752    |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 914       |\n",
      "|    iterations           | 1292      |\n",
      "|    time_elapsed         | 180       |\n",
      "|    total_timesteps      | 165376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4969317 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0829   |\n",
      "|    explained_variance   | 0.344     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.135     |\n",
      "|    n_updates            | 21947     |\n",
      "|    policy_gradient_loss | -0.0423   |\n",
      "|    value_loss           | 0.523     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=165500, episode_reward=20.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 165500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12503904 |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.072     |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0291     |\n",
      "|    n_updates            | 21964      |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    value_loss           | 0.172      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 913      |\n",
      "|    iterations      | 1293     |\n",
      "|    time_elapsed    | 181      |\n",
      "|    total_timesteps | 165504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1294       |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 165632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40953064 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | -0.0489    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0523    |\n",
      "|    n_updates            | 21981      |\n",
      "|    policy_gradient_loss | -0.0655    |\n",
      "|    value_loss           | 0.0457     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1295       |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 165760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32734928 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.038     |\n",
      "|    explained_variance   | -0.0473    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0712    |\n",
      "|    n_updates            | 21998      |\n",
      "|    policy_gradient_loss | -0.0558    |\n",
      "|    value_loss           | 0.0161     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1296       |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33861014 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0434    |\n",
      "|    explained_variance   | 0.0231     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0507    |\n",
      "|    n_updates            | 22015      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=15.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 15.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 166000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3934758 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0818   |\n",
      "|    explained_variance   | 0.0213    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00321  |\n",
      "|    n_updates            | 22032     |\n",
      "|    policy_gradient_loss | -0.0471   |\n",
      "|    value_loss           | 0.0662    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1297     |\n",
      "|    time_elapsed    | 181      |\n",
      "|    total_timesteps | 166016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1298      |\n",
      "|    time_elapsed         | 181       |\n",
      "|    total_timesteps      | 166144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5435386 |\n",
      "|    clip_fraction        | 0.0818    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0603   |\n",
      "|    explained_variance   | 0.58      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0249   |\n",
      "|    n_updates            | 22049     |\n",
      "|    policy_gradient_loss | -0.027    |\n",
      "|    value_loss           | 0.0682    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1299       |\n",
      "|    time_elapsed         | 182        |\n",
      "|    total_timesteps      | 166272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23998266 |\n",
      "|    clip_fraction        | 0.0597     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0433    |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0349    |\n",
      "|    n_updates            | 22066      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.051      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1300      |\n",
      "|    time_elapsed         | 182       |\n",
      "|    total_timesteps      | 166400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3032421 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0953   |\n",
      "|    explained_variance   | 0.545     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0893    |\n",
      "|    n_updates            | 22083     |\n",
      "|    policy_gradient_loss | -0.0534   |\n",
      "|    value_loss           | 0.559     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=166500, episode_reward=7.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 7.1      |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 166500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.234977 |\n",
      "|    clip_fraction        | 0.129    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0983  |\n",
      "|    explained_variance   | 0.689    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0525  |\n",
      "|    n_updates            | 22100    |\n",
      "|    policy_gradient_loss | -0.0544  |\n",
      "|    value_loss           | 0.196    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1301     |\n",
      "|    time_elapsed    | 182      |\n",
      "|    total_timesteps | 166528   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 41.6     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1302     |\n",
      "|    time_elapsed         | 182      |\n",
      "|    total_timesteps      | 166656   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.339228 |\n",
      "|    clip_fraction        | 0.136    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.109   |\n",
      "|    explained_variance   | 0.0243   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0448  |\n",
      "|    n_updates            | 22117    |\n",
      "|    policy_gradient_loss | -0.0498  |\n",
      "|    value_loss           | 0.154    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1303      |\n",
      "|    time_elapsed         | 182       |\n",
      "|    total_timesteps      | 166784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6740703 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.423     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.377     |\n",
      "|    n_updates            | 22134     |\n",
      "|    policy_gradient_loss | -0.0674   |\n",
      "|    value_loss           | 0.997     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 41.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1304     |\n",
      "|    time_elapsed         | 182      |\n",
      "|    total_timesteps      | 166912   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.414459 |\n",
      "|    clip_fraction        | 0.108    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0667  |\n",
      "|    explained_variance   | 0.837    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0634   |\n",
      "|    n_updates            | 22151    |\n",
      "|    policy_gradient_loss | -0.0573  |\n",
      "|    value_loss           | 0.233    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=167000, episode_reward=7.90 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 7.9        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 167000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62253904 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0494    |\n",
      "|    explained_variance   | -0.0105    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0811    |\n",
      "|    n_updates            | 22168      |\n",
      "|    policy_gradient_loss | -0.0554    |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 1305     |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 167040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1306       |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 167168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.84304976 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0667    |\n",
      "|    explained_variance   | -0.118     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0588    |\n",
      "|    n_updates            | 22185      |\n",
      "|    policy_gradient_loss | -0.046     |\n",
      "|    value_loss           | 0.0202     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1307      |\n",
      "|    time_elapsed         | 183       |\n",
      "|    total_timesteps      | 167296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1130778 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0728   |\n",
      "|    explained_variance   | 0.0726    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0379   |\n",
      "|    n_updates            | 22202     |\n",
      "|    policy_gradient_loss | -0.0574   |\n",
      "|    value_loss           | 0.0354    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 41.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1308      |\n",
      "|    time_elapsed         | 183       |\n",
      "|    total_timesteps      | 167424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.7940469 |\n",
      "|    clip_fraction        | 0.296     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.081    |\n",
      "|    explained_variance   | -0.268    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 22219     |\n",
      "|    policy_gradient_loss | -0.0898   |\n",
      "|    value_loss           | 0.0405    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=167500, episode_reward=6.26 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.26       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 167500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50045896 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0951    |\n",
      "|    explained_variance   | -0.234     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0359    |\n",
      "|    n_updates            | 22236      |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.0651     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 1309     |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 167552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1310       |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 167680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54448116 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0842    |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0976    |\n",
      "|    n_updates            | 22253      |\n",
      "|    policy_gradient_loss | -0.0612    |\n",
      "|    value_loss           | 0.062      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1311       |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 167808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69928086 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.285      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0462    |\n",
      "|    n_updates            | 22270      |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.229      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1312       |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43529153 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0814    |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0111    |\n",
      "|    n_updates            | 22287      |\n",
      "|    policy_gradient_loss | -0.0451    |\n",
      "|    value_loss           | 0.27       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=7.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 7.14      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 168000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5339373 |\n",
      "|    clip_fraction        | 0.113     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0791   |\n",
      "|    explained_variance   | 0.668     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.072    |\n",
      "|    n_updates            | 22304     |\n",
      "|    policy_gradient_loss | -0.0399   |\n",
      "|    value_loss           | 0.0908    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 41.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 1313     |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 168064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 41.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1314       |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 168192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33261162 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0825    |\n",
      "|    explained_variance   | 0.792      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0636    |\n",
      "|    n_updates            | 22321      |\n",
      "|    policy_gradient_loss | -0.0738    |\n",
      "|    value_loss           | 0.155      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1315       |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 168320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.88500214 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0772    |\n",
      "|    explained_variance   | 0.592      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 22338      |\n",
      "|    policy_gradient_loss | -0.0614    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1316      |\n",
      "|    time_elapsed         | 184       |\n",
      "|    total_timesteps      | 168448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6166005 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0828   |\n",
      "|    explained_variance   | 0.712     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.056    |\n",
      "|    n_updates            | 22355     |\n",
      "|    policy_gradient_loss | -0.0486   |\n",
      "|    value_loss           | 0.0753    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=168500, episode_reward=-4.06 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -4.06     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 168500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6637109 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.083    |\n",
      "|    explained_variance   | -0.579    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0954   |\n",
      "|    n_updates            | 22372     |\n",
      "|    policy_gradient_loss | -0.0741   |\n",
      "|    value_loss           | 0.0841    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42       |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 1317     |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 168576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1318       |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 168704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45405018 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0996    |\n",
      "|    explained_variance   | -0.00579   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 22389      |\n",
      "|    policy_gradient_loss | -0.0697    |\n",
      "|    value_loss           | 0.034      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1319      |\n",
      "|    time_elapsed         | 185       |\n",
      "|    total_timesteps      | 168832    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2269592 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.136    |\n",
      "|    explained_variance   | -0.19     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0738   |\n",
      "|    n_updates            | 22406     |\n",
      "|    policy_gradient_loss | -0.0562   |\n",
      "|    value_loss           | 0.0565    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1320       |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 168960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22746885 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | 0.58       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0842    |\n",
      "|    n_updates            | 22423      |\n",
      "|    policy_gradient_loss | -0.0815    |\n",
      "|    value_loss           | 0.0803     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=169000, episode_reward=19.44 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 19.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 169000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4250277 |\n",
      "|    clip_fraction        | 0.0726    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0421   |\n",
      "|    explained_variance   | 0.768     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.03     |\n",
      "|    n_updates            | 22440     |\n",
      "|    policy_gradient_loss | -0.0299   |\n",
      "|    value_loss           | 0.0463    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1321     |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 169088   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1322       |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 169216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.80646265 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0963    |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0937    |\n",
      "|    n_updates            | 22457      |\n",
      "|    policy_gradient_loss | -0.0625    |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1323       |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 169344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18108979 |\n",
      "|    clip_fraction        | 0.0781     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0785    |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0131     |\n",
      "|    n_updates            | 22474      |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 1.19       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 42       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 912      |\n",
      "|    iterations           | 1324     |\n",
      "|    time_elapsed         | 185      |\n",
      "|    total_timesteps      | 169472   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.062497 |\n",
      "|    clip_fraction        | 0.158    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.081   |\n",
      "|    explained_variance   | 0.726    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0804  |\n",
      "|    n_updates            | 22491    |\n",
      "|    policy_gradient_loss | -0.0702  |\n",
      "|    value_loss           | 0.133    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=169500, episode_reward=16.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 169500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75071216 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0923    |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0405    |\n",
      "|    n_updates            | 22508      |\n",
      "|    policy_gradient_loss | -0.0612    |\n",
      "|    value_loss           | 0.0945     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42       |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1325     |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 169600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1326       |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 169728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21712889 |\n",
      "|    clip_fraction        | 0.0712     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0456    |\n",
      "|    explained_variance   | -0.121     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00829    |\n",
      "|    n_updates            | 22525      |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    value_loss           | 0.088      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1327      |\n",
      "|    time_elapsed         | 186       |\n",
      "|    total_timesteps      | 169856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6279671 |\n",
      "|    clip_fraction        | 0.0878    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0444   |\n",
      "|    explained_variance   | 0.941     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.019    |\n",
      "|    n_updates            | 22542     |\n",
      "|    policy_gradient_loss | -0.038    |\n",
      "|    value_loss           | 0.067     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1328       |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37411168 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0604    |\n",
      "|    explained_variance   | -0.152     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0708    |\n",
      "|    n_updates            | 22559      |\n",
      "|    policy_gradient_loss | -0.0618    |\n",
      "|    value_loss           | 0.0974     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=24.26 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 24.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 170000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4299761 |\n",
      "|    clip_fraction        | 0.113     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0419   |\n",
      "|    explained_variance   | 0.00786   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.034    |\n",
      "|    n_updates            | 22576     |\n",
      "|    policy_gradient_loss | -0.0512   |\n",
      "|    value_loss           | 0.0251    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1329     |\n",
      "|    time_elapsed    | 186      |\n",
      "|    total_timesteps | 170112   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1330       |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 170240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47191536 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0847    |\n",
      "|    explained_variance   | 0.0546     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0666    |\n",
      "|    n_updates            | 22593      |\n",
      "|    policy_gradient_loss | -0.0632    |\n",
      "|    value_loss           | 0.0232     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1331       |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 170368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51119405 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.129     |\n",
      "|    explained_variance   | -0.093     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0274    |\n",
      "|    n_updates            | 22610      |\n",
      "|    policy_gradient_loss | -0.0644    |\n",
      "|    value_loss           | 0.0998     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1332       |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 170496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54573154 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | 0.768      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0615    |\n",
      "|    n_updates            | 22627      |\n",
      "|    policy_gradient_loss | -0.0668    |\n",
      "|    value_loss           | 0.075      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=170500, episode_reward=25.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 25.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 170500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4083531 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0628   |\n",
      "|    explained_variance   | 0.676     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0595   |\n",
      "|    n_updates            | 22644     |\n",
      "|    policy_gradient_loss | -0.0604   |\n",
      "|    value_loss           | 0.0627    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1333     |\n",
      "|    time_elapsed    | 186      |\n",
      "|    total_timesteps | 170624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1334       |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 170752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17446113 |\n",
      "|    clip_fraction        | 0.0639     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0425    |\n",
      "|    explained_variance   | 0.733      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 22661      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1335      |\n",
      "|    time_elapsed         | 187       |\n",
      "|    total_timesteps      | 170880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5528232 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0737   |\n",
      "|    explained_variance   | 0.621     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0158    |\n",
      "|    n_updates            | 22678     |\n",
      "|    policy_gradient_loss | -0.0504   |\n",
      "|    value_loss           | 0.255     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=171000, episode_reward=-1.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -1.09      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 171000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45289242 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0715    |\n",
      "|    n_updates            | 22695      |\n",
      "|    policy_gradient_loss | -0.046     |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1336     |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 171008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 912        |\n",
      "|    iterations           | 1337       |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 171136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74803007 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0608    |\n",
      "|    explained_variance   | 0.259      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0272    |\n",
      "|    n_updates            | 22712      |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    value_loss           | 0.139      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1338      |\n",
      "|    time_elapsed         | 187       |\n",
      "|    total_timesteps      | 171264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3343393 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.094    |\n",
      "|    explained_variance   | 0.617     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0683    |\n",
      "|    n_updates            | 22729     |\n",
      "|    policy_gradient_loss | -0.0311   |\n",
      "|    value_loss           | 0.633     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1339       |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 171392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56452245 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0768    |\n",
      "|    explained_variance   | -0.312     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0253    |\n",
      "|    n_updates            | 22746      |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 0.0343     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=171500, episode_reward=7.98 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 7.98       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 171500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39370376 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0404    |\n",
      "|    explained_variance   | -0.22      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0212    |\n",
      "|    n_updates            | 22763      |\n",
      "|    policy_gradient_loss | -0.0413    |\n",
      "|    value_loss           | 0.0761     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1340     |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 171520   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 912       |\n",
      "|    iterations           | 1341      |\n",
      "|    time_elapsed         | 188       |\n",
      "|    total_timesteps      | 171648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6163553 |\n",
      "|    clip_fraction        | 0.0657    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0501   |\n",
      "|    explained_variance   | -0.488    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0329   |\n",
      "|    n_updates            | 22780     |\n",
      "|    policy_gradient_loss | -0.0167   |\n",
      "|    value_loss           | 0.0231    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1342      |\n",
      "|    time_elapsed         | 188       |\n",
      "|    total_timesteps      | 171776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5570462 |\n",
      "|    clip_fraction        | 0.293     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.116    |\n",
      "|    explained_variance   | 0.352     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0993   |\n",
      "|    n_updates            | 22797     |\n",
      "|    policy_gradient_loss | -0.076    |\n",
      "|    value_loss           | 0.064     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 42.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 913      |\n",
      "|    iterations           | 1343     |\n",
      "|    time_elapsed         | 188      |\n",
      "|    total_timesteps      | 171904   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.488711 |\n",
      "|    clip_fraction        | 0.181    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.116   |\n",
      "|    explained_variance   | 0.509    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.1     |\n",
      "|    n_updates            | 22814    |\n",
      "|    policy_gradient_loss | -0.0657  |\n",
      "|    value_loss           | 0.0894   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=52.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 52.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 172000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30805415 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.063     |\n",
      "|    explained_variance   | 0.684      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.067     |\n",
      "|    n_updates            | 22831      |\n",
      "|    policy_gradient_loss | -0.0443    |\n",
      "|    value_loss           | 0.0651     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 912      |\n",
      "|    iterations      | 1344     |\n",
      "|    time_elapsed    | 188      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1345       |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 172160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31942987 |\n",
      "|    clip_fraction        | 0.0616     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0239    |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.069     |\n",
      "|    n_updates            | 22848      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.059      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 913       |\n",
      "|    iterations           | 1346      |\n",
      "|    time_elapsed         | 188       |\n",
      "|    total_timesteps      | 172288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2583273 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.345     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0185    |\n",
      "|    n_updates            | 22865     |\n",
      "|    policy_gradient_loss | -0.0617   |\n",
      "|    value_loss           | 0.327     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 1347       |\n",
      "|    time_elapsed         | 188        |\n",
      "|    total_timesteps      | 172416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75478685 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.1       |\n",
      "|    explained_variance   | 0.562      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0438    |\n",
      "|    n_updates            | 22882      |\n",
      "|    policy_gradient_loss | -0.0513    |\n",
      "|    value_loss           | 0.134      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=172500, episode_reward=33.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 172500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.85971063 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0998    |\n",
      "|    explained_variance   | -0.00963   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0565    |\n",
      "|    n_updates            | 22899      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 1348     |\n",
      "|    time_elapsed    | 189      |\n",
      "|    total_timesteps | 172544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 1349       |\n",
      "|    time_elapsed         | 189        |\n",
      "|    total_timesteps      | 172672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42494595 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0864    |\n",
      "|    explained_variance   | -0.0308    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0978     |\n",
      "|    n_updates            | 22916      |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 1.55       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 1350       |\n",
      "|    time_elapsed         | 189        |\n",
      "|    total_timesteps      | 172800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52998453 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0478    |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0503    |\n",
      "|    n_updates            | 22933      |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    value_loss           | 0.0323     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 1351       |\n",
      "|    time_elapsed         | 189        |\n",
      "|    total_timesteps      | 172928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14956832 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0511    |\n",
      "|    explained_variance   | -0.887     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0638    |\n",
      "|    n_updates            | 22950      |\n",
      "|    policy_gradient_loss | -0.0577    |\n",
      "|    value_loss           | 0.0987     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=173000, episode_reward=-2.04 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | -2.04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 173000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.089861564 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0336     |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 22967       |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 911      |\n",
      "|    iterations      | 1352     |\n",
      "|    time_elapsed    | 189      |\n",
      "|    total_timesteps | 173056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 1353      |\n",
      "|    time_elapsed         | 190       |\n",
      "|    total_timesteps      | 173184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2525735 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0858   |\n",
      "|    explained_variance   | 0.366     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0539   |\n",
      "|    n_updates            | 22984     |\n",
      "|    policy_gradient_loss | -0.0393   |\n",
      "|    value_loss           | 0.0238    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 1354       |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 173312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27886468 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0467    |\n",
      "|    explained_variance   | -0.189     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0206    |\n",
      "|    n_updates            | 23001      |\n",
      "|    policy_gradient_loss | -0.0355    |\n",
      "|    value_loss           | 0.0407     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 1355       |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 173440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25435436 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0558    |\n",
      "|    explained_variance   | 0.674      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0691    |\n",
      "|    n_updates            | 23018      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.0756     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=173500, episode_reward=52.52 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 52.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 173500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14431459 |\n",
      "|    clip_fraction        | 0.034      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0201    |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0114    |\n",
      "|    n_updates            | 23035      |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 0.0621     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 1356     |\n",
      "|    time_elapsed    | 190      |\n",
      "|    total_timesteps | 173568   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 1357      |\n",
      "|    time_elapsed         | 190       |\n",
      "|    total_timesteps      | 173696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4513794 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0334   |\n",
      "|    explained_variance   | 0.245     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0468    |\n",
      "|    n_updates            | 23052     |\n",
      "|    policy_gradient_loss | -0.0456   |\n",
      "|    value_loss           | 0.4       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 1358       |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 173824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50095475 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.209      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 23069      |\n",
      "|    policy_gradient_loss | -0.0704    |\n",
      "|    value_loss           | 0.444      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 1359       |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 173952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67098284 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0993    |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0918    |\n",
      "|    n_updates            | 23086      |\n",
      "|    policy_gradient_loss | -0.0422    |\n",
      "|    value_loss           | 0.156      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=174000, episode_reward=37.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 37.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 174000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0580118 |\n",
      "|    clip_fraction        | 0.26      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.122    |\n",
      "|    explained_variance   | -0.201    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 1.25      |\n",
      "|    n_updates            | 23103     |\n",
      "|    policy_gradient_loss | -0.0634   |\n",
      "|    value_loss           | 2.09      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 1360     |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 174080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 1361       |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 174208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40482843 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0839    |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.098     |\n",
      "|    n_updates            | 23120      |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 0.122      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 910        |\n",
      "|    iterations           | 1362       |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 174336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65977466 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0656    |\n",
      "|    explained_variance   | -0.764     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0557    |\n",
      "|    n_updates            | 23137      |\n",
      "|    policy_gradient_loss | -0.0669    |\n",
      "|    value_loss           | 0.0422     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 911        |\n",
      "|    iterations           | 1363       |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 174464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91831267 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0806    |\n",
      "|    explained_variance   | -0.67      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.169     |\n",
      "|    n_updates            | 23154      |\n",
      "|    policy_gradient_loss | -0.0613    |\n",
      "|    value_loss           | 0.0177     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=174500, episode_reward=57.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 57.5     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 174500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.807069 |\n",
      "|    clip_fraction        | 0.231    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0968  |\n",
      "|    explained_variance   | -0.0617  |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.148   |\n",
      "|    n_updates            | 23171    |\n",
      "|    policy_gradient_loss | -0.0873  |\n",
      "|    value_loss           | 0.0189   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 910      |\n",
      "|    iterations      | 1364     |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 174592   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 1365      |\n",
      "|    time_elapsed         | 192       |\n",
      "|    total_timesteps      | 174720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4396253 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.13      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0249   |\n",
      "|    n_updates            | 23188     |\n",
      "|    policy_gradient_loss | -0.0486   |\n",
      "|    value_loss           | 0.0398    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1366       |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 174848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25033504 |\n",
      "|    clip_fraction        | 0.0882     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.064     |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0507    |\n",
      "|    n_updates            | 23205      |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    value_loss           | 0.0901     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1367       |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 174976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.87740993 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0687    |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0927    |\n",
      "|    n_updates            | 23222      |\n",
      "|    policy_gradient_loss | -0.0532    |\n",
      "|    value_loss           | 0.0673     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=57.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 57.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 175000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55230576 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0581    |\n",
      "|    explained_variance   | -0.276     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0995     |\n",
      "|    n_updates            | 23239      |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    value_loss           | 1.02       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 1368     |\n",
      "|    time_elapsed    | 192      |\n",
      "|    total_timesteps | 175104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1369       |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 175232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36843893 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0987    |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0102    |\n",
      "|    n_updates            | 23256      |\n",
      "|    policy_gradient_loss | -0.0491    |\n",
      "|    value_loss           | 0.321      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 42.9     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 909      |\n",
      "|    iterations           | 1370     |\n",
      "|    time_elapsed         | 192      |\n",
      "|    total_timesteps      | 175360   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.25167  |\n",
      "|    clip_fraction        | 0.147    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0908  |\n",
      "|    explained_variance   | 0.743    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.1     |\n",
      "|    n_updates            | 23273    |\n",
      "|    policy_gradient_loss | -0.0576  |\n",
      "|    value_loss           | 0.137    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 910       |\n",
      "|    iterations           | 1371      |\n",
      "|    time_elapsed         | 192       |\n",
      "|    total_timesteps      | 175488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4002887 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.119    |\n",
      "|    explained_variance   | -0.255    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.185     |\n",
      "|    n_updates            | 23290     |\n",
      "|    policy_gradient_loss | -0.0355   |\n",
      "|    value_loss           | 1.1       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=175500, episode_reward=53.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 175500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51909274 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0705    |\n",
      "|    explained_variance   | 0.722      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0175    |\n",
      "|    n_updates            | 23307      |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 1372     |\n",
      "|    time_elapsed    | 193      |\n",
      "|    total_timesteps | 175616   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 42.9     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 909      |\n",
      "|    iterations           | 1373     |\n",
      "|    time_elapsed         | 193      |\n",
      "|    total_timesteps      | 175744   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.523895 |\n",
      "|    clip_fraction        | 0.152    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0853  |\n",
      "|    explained_variance   | -0.424   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0985  |\n",
      "|    n_updates            | 23324    |\n",
      "|    policy_gradient_loss | -0.0556  |\n",
      "|    value_loss           | 0.0254   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 1374      |\n",
      "|    time_elapsed         | 193       |\n",
      "|    total_timesteps      | 175872    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7538461 |\n",
      "|    clip_fraction        | 0.186     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0699   |\n",
      "|    explained_variance   | -0.985    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0745   |\n",
      "|    n_updates            | 23341     |\n",
      "|    policy_gradient_loss | -0.0558   |\n",
      "|    value_loss           | 0.0118    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=41.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 176000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4091631 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.062    |\n",
      "|    explained_variance   | -0.369    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 23358     |\n",
      "|    policy_gradient_loss | -0.0599   |\n",
      "|    value_loss           | 0.0191    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 1375     |\n",
      "|    time_elapsed    | 193      |\n",
      "|    total_timesteps | 176000   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 42.9     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 908      |\n",
      "|    iterations           | 1376     |\n",
      "|    time_elapsed         | 193      |\n",
      "|    total_timesteps      | 176128   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.040446 |\n",
      "|    clip_fraction        | 0.322    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.113   |\n",
      "|    explained_variance   | 0.317    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0965  |\n",
      "|    n_updates            | 23375    |\n",
      "|    policy_gradient_loss | -0.0653  |\n",
      "|    value_loss           | 0.0145   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1377       |\n",
      "|    time_elapsed         | 194        |\n",
      "|    total_timesteps      | 176256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.94785404 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0743    |\n",
      "|    explained_variance   | 0.496      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0542    |\n",
      "|    n_updates            | 23392      |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    value_loss           | 0.0564     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 1378      |\n",
      "|    time_elapsed         | 194       |\n",
      "|    total_timesteps      | 176384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0643641 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0608   |\n",
      "|    explained_variance   | 0.608     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0796   |\n",
      "|    n_updates            | 23409     |\n",
      "|    policy_gradient_loss | -0.0496   |\n",
      "|    value_loss           | 0.0533    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=176500, episode_reward=-12.66 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -12.7      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 176500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22897308 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.072     |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0233    |\n",
      "|    n_updates            | 23426      |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.0713     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1379     |\n",
      "|    time_elapsed    | 194      |\n",
      "|    total_timesteps | 176512   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 1380      |\n",
      "|    time_elapsed         | 194       |\n",
      "|    total_timesteps      | 176640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7380609 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | -0.156    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0354    |\n",
      "|    n_updates            | 23443     |\n",
      "|    policy_gradient_loss | -0.0638   |\n",
      "|    value_loss           | 0.612     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 42.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 1381      |\n",
      "|    time_elapsed         | 194       |\n",
      "|    total_timesteps      | 176768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7871771 |\n",
      "|    clip_fraction        | 0.227     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.73      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 23460     |\n",
      "|    policy_gradient_loss | -0.0819   |\n",
      "|    value_loss           | 0.0727    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 42.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1382       |\n",
      "|    time_elapsed         | 194        |\n",
      "|    total_timesteps      | 176896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77522343 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.241      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0807    |\n",
      "|    n_updates            | 23477      |\n",
      "|    policy_gradient_loss | -0.0728    |\n",
      "|    value_loss           | 0.306      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=177000, episode_reward=4.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 4.02     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 177000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.83755  |\n",
      "|    clip_fraction        | 0.133    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0637  |\n",
      "|    explained_variance   | 0.404    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0176  |\n",
      "|    n_updates            | 23494    |\n",
      "|    policy_gradient_loss | -0.0501  |\n",
      "|    value_loss           | 0.314    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1383     |\n",
      "|    time_elapsed    | 194      |\n",
      "|    total_timesteps | 177024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 1384      |\n",
      "|    time_elapsed         | 195       |\n",
      "|    total_timesteps      | 177152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3971477 |\n",
      "|    clip_fraction        | 0.0965    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0621   |\n",
      "|    explained_variance   | 0.809     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.017    |\n",
      "|    n_updates            | 23511     |\n",
      "|    policy_gradient_loss | -0.0318   |\n",
      "|    value_loss           | 0.0155    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 1385      |\n",
      "|    time_elapsed         | 195       |\n",
      "|    total_timesteps      | 177280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0238932 |\n",
      "|    clip_fraction        | 0.179     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0669   |\n",
      "|    explained_variance   | 0.122     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0649   |\n",
      "|    n_updates            | 23528     |\n",
      "|    policy_gradient_loss | -0.0619   |\n",
      "|    value_loss           | 0.0625    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 43.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 908      |\n",
      "|    iterations           | 1386     |\n",
      "|    time_elapsed         | 195      |\n",
      "|    total_timesteps      | 177408   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 3.473225 |\n",
      "|    clip_fraction        | 0.102    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0339  |\n",
      "|    explained_variance   | 0.448    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0605  |\n",
      "|    n_updates            | 23545    |\n",
      "|    policy_gradient_loss | -0.0575  |\n",
      "|    value_loss           | 0.011    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=177500, episode_reward=2.41 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.41       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 177500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09469625 |\n",
      "|    clip_fraction        | 0.0717     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0541    |\n",
      "|    explained_variance   | -0.126     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0635    |\n",
      "|    n_updates            | 23562      |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    value_loss           | 0.0267     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1387     |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 177536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1388       |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 177664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23420471 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | -0.887     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0601    |\n",
      "|    n_updates            | 23579      |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.0972     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1389       |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 177792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98682606 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0765    |\n",
      "|    explained_variance   | 0.797      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.117     |\n",
      "|    n_updates            | 23596      |\n",
      "|    policy_gradient_loss | -0.0663    |\n",
      "|    value_loss           | 0.0365     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1390       |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 177920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06016713 |\n",
      "|    clip_fraction        | 0.0391     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0452    |\n",
      "|    explained_variance   | 0.756      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.026     |\n",
      "|    n_updates            | 23613      |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    value_loss           | 0.0565     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=-4.66 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -4.66      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 178000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42972362 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | -0.406     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0764    |\n",
      "|    n_updates            | 23630      |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    value_loss           | 0.487      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1391     |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 178048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1392       |\n",
      "|    time_elapsed         | 196        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32891127 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0999    |\n",
      "|    explained_variance   | 0.764      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0302    |\n",
      "|    n_updates            | 23647      |\n",
      "|    policy_gradient_loss | -0.0645    |\n",
      "|    value_loss           | 0.157      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 43.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 908      |\n",
      "|    iterations           | 1393     |\n",
      "|    time_elapsed         | 196      |\n",
      "|    total_timesteps      | 178304   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.650231 |\n",
      "|    clip_fraction        | 0.199    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.115   |\n",
      "|    explained_variance   | 0.21     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0716  |\n",
      "|    n_updates            | 23664    |\n",
      "|    policy_gradient_loss | -0.058   |\n",
      "|    value_loss           | 0.205    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 1394      |\n",
      "|    time_elapsed         | 196       |\n",
      "|    total_timesteps      | 178432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4615067 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0553   |\n",
      "|    explained_variance   | 0.137     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00473  |\n",
      "|    n_updates            | 23681     |\n",
      "|    policy_gradient_loss | -0.0443   |\n",
      "|    value_loss           | 0.531     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=178500, episode_reward=28.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 28.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 178500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5095737 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0563   |\n",
      "|    explained_variance   | 0.77      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0449   |\n",
      "|    n_updates            | 23698     |\n",
      "|    policy_gradient_loss | -0.0344   |\n",
      "|    value_loss           | 0.0737    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1395     |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 178560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 908       |\n",
      "|    iterations           | 1396      |\n",
      "|    time_elapsed         | 196       |\n",
      "|    total_timesteps      | 178688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3096863 |\n",
      "|    clip_fraction        | 0.0915    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0723   |\n",
      "|    explained_variance   | -0.0605   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0539   |\n",
      "|    n_updates            | 23715     |\n",
      "|    policy_gradient_loss | -0.0439   |\n",
      "|    value_loss           | 0.0981    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1397       |\n",
      "|    time_elapsed         | 196        |\n",
      "|    total_timesteps      | 178816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40182996 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.2        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0836    |\n",
      "|    n_updates            | 23732      |\n",
      "|    policy_gradient_loss | -0.0624    |\n",
      "|    value_loss           | 0.0343     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1398       |\n",
      "|    time_elapsed         | 196        |\n",
      "|    total_timesteps      | 178944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37582657 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0828    |\n",
      "|    explained_variance   | 0.0313     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0956    |\n",
      "|    n_updates            | 23749      |\n",
      "|    policy_gradient_loss | -0.0646    |\n",
      "|    value_loss           | 0.0419     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=179000, episode_reward=63.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 63.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 179000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1265327 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.075    |\n",
      "|    explained_variance   | 0.107     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.142    |\n",
      "|    n_updates            | 23766     |\n",
      "|    policy_gradient_loss | -0.0766   |\n",
      "|    value_loss           | 0.0623    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1399     |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 179072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1400       |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 179200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55904377 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0761    |\n",
      "|    explained_variance   | 0.716      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0746    |\n",
      "|    n_updates            | 23783      |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.0871     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1401       |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 179328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59066147 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0922    |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0553    |\n",
      "|    n_updates            | 23800      |\n",
      "|    policy_gradient_loss | -0.0511    |\n",
      "|    value_loss           | 0.0717     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1402       |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 179456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33288556 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0672    |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0941     |\n",
      "|    n_updates            | 23817      |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    value_loss           | 0.623      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=179500, episode_reward=27.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 27.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 179500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64264137 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0964    |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0573    |\n",
      "|    n_updates            | 23834      |\n",
      "|    policy_gradient_loss | -0.0727    |\n",
      "|    value_loss           | 0.294      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 908      |\n",
      "|    iterations      | 1403     |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 179584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1404       |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 179712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45685977 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0941    |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0301    |\n",
      "|    n_updates            | 23851      |\n",
      "|    policy_gradient_loss | -0.055     |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 908        |\n",
      "|    iterations           | 1405       |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 179840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39828923 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.15      |\n",
      "|    explained_variance   | 0.195      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.346      |\n",
      "|    n_updates            | 23868      |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 2.47       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 1406       |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 179968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45260286 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.646      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.334      |\n",
      "|    n_updates            | 23885      |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.786      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=16.69 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 16.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 180000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9975686 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0815   |\n",
      "|    explained_variance   | -0.0407   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0268   |\n",
      "|    n_updates            | 23902     |\n",
      "|    policy_gradient_loss | -0.0493   |\n",
      "|    value_loss           | 0.114     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 1407     |\n",
      "|    time_elapsed    | 198      |\n",
      "|    total_timesteps | 180096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 906       |\n",
      "|    iterations           | 1408      |\n",
      "|    time_elapsed         | 198       |\n",
      "|    total_timesteps      | 180224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.6386502 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0712   |\n",
      "|    explained_variance   | -0.625    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00566   |\n",
      "|    n_updates            | 23919     |\n",
      "|    policy_gradient_loss | -0.0536   |\n",
      "|    value_loss           | 0.0768    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 1409       |\n",
      "|    time_elapsed         | 198        |\n",
      "|    total_timesteps      | 180352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64211935 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0533    |\n",
      "|    explained_variance   | -0.197     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 23936      |\n",
      "|    policy_gradient_loss | -0.074     |\n",
      "|    value_loss           | 0.0281     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 1410      |\n",
      "|    time_elapsed         | 198       |\n",
      "|    total_timesteps      | 180480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2962379 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | -0.699    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0457   |\n",
      "|    n_updates            | 23953     |\n",
      "|    policy_gradient_loss | -0.0535   |\n",
      "|    value_loss           | 0.0483    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=180500, episode_reward=47.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 47.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 180500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46377385 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | -0.252     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0459    |\n",
      "|    n_updates            | 23970      |\n",
      "|    policy_gradient_loss | -0.0582    |\n",
      "|    value_loss           | 0.088      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 1411     |\n",
      "|    time_elapsed    | 199      |\n",
      "|    total_timesteps | 180608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 906        |\n",
      "|    iterations           | 1412       |\n",
      "|    time_elapsed         | 199        |\n",
      "|    total_timesteps      | 180736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23726657 |\n",
      "|    clip_fraction        | 0.0317     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0269    |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0648    |\n",
      "|    n_updates            | 23987      |\n",
      "|    policy_gradient_loss | -0.0221    |\n",
      "|    value_loss           | 0.0534     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 907        |\n",
      "|    iterations           | 1413       |\n",
      "|    time_elapsed         | 199        |\n",
      "|    total_timesteps      | 180864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26549375 |\n",
      "|    clip_fraction        | 0.0689     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0558    |\n",
      "|    explained_variance   | 0.581      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.021     |\n",
      "|    n_updates            | 24004      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 1414      |\n",
      "|    time_elapsed         | 199       |\n",
      "|    total_timesteps      | 180992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6870066 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0826   |\n",
      "|    explained_variance   | 0.332     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0282    |\n",
      "|    n_updates            | 24021     |\n",
      "|    policy_gradient_loss | -0.049    |\n",
      "|    value_loss           | 0.657     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=181000, episode_reward=15.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 15.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 181000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5686959 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0925   |\n",
      "|    explained_variance   | 0.671     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0607   |\n",
      "|    n_updates            | 24038     |\n",
      "|    policy_gradient_loss | -0.0593   |\n",
      "|    value_loss           | 0.124     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 1415     |\n",
      "|    time_elapsed    | 200      |\n",
      "|    total_timesteps | 181120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1416       |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 181248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30994827 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0862    |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0053    |\n",
      "|    n_updates            | 24055      |\n",
      "|    policy_gradient_loss | -0.047     |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1417       |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 181376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57973444 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.131     |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.169      |\n",
      "|    n_updates            | 24072      |\n",
      "|    policy_gradient_loss | -0.0799    |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=181500, episode_reward=53.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 181500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52712727 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | -0.536     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 24089      |\n",
      "|    policy_gradient_loss | -0.0757    |\n",
      "|    value_loss           | 0.059      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 1418     |\n",
      "|    time_elapsed    | 200      |\n",
      "|    total_timesteps | 181504   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 1419      |\n",
      "|    time_elapsed         | 200       |\n",
      "|    total_timesteps      | 181632    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3847775 |\n",
      "|    clip_fraction        | 0.12      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.08     |\n",
      "|    explained_variance   | 0.119     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0201   |\n",
      "|    n_updates            | 24106     |\n",
      "|    policy_gradient_loss | -0.0379   |\n",
      "|    value_loss           | 0.0538    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1420       |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 181760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21585816 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0933    |\n",
      "|    explained_variance   | -0.422     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 24123      |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    value_loss           | 0.0529     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1421       |\n",
      "|    time_elapsed         | 201        |\n",
      "|    total_timesteps      | 181888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49399984 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.105     |\n",
      "|    explained_variance   | -0.515     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0727    |\n",
      "|    n_updates            | 24140      |\n",
      "|    policy_gradient_loss | -0.0681    |\n",
      "|    value_loss           | 0.0357     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=59.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 59.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 182000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1627551 |\n",
      "|    clip_fraction        | 0.0836    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0667   |\n",
      "|    explained_variance   | 0.0949    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0559   |\n",
      "|    n_updates            | 24157     |\n",
      "|    policy_gradient_loss | -0.0413   |\n",
      "|    value_loss           | 0.06      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 1422     |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 182016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1423       |\n",
      "|    time_elapsed         | 201        |\n",
      "|    total_timesteps      | 182144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24768636 |\n",
      "|    clip_fraction        | 0.0478     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0247    |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.029     |\n",
      "|    n_updates            | 24174      |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 0.0409     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 1424      |\n",
      "|    time_elapsed         | 201       |\n",
      "|    total_timesteps      | 182272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5722066 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0631   |\n",
      "|    explained_variance   | 0.848     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0358   |\n",
      "|    n_updates            | 24191     |\n",
      "|    policy_gradient_loss | -0.0631   |\n",
      "|    value_loss           | 0.0516    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1425       |\n",
      "|    time_elapsed         | 201        |\n",
      "|    total_timesteps      | 182400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64621925 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0665    |\n",
      "|    explained_variance   | 0.176      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0408    |\n",
      "|    n_updates            | 24208      |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    value_loss           | 0.486      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=182500, episode_reward=72.92 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 72.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 182500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4576078 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0779   |\n",
      "|    explained_variance   | 0.728     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.07     |\n",
      "|    n_updates            | 24225     |\n",
      "|    policy_gradient_loss | -0.0569   |\n",
      "|    value_loss           | 0.146     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1426     |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 182528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1427       |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 182656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39170218 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0814    |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0459    |\n",
      "|    n_updates            | 24242      |\n",
      "|    policy_gradient_loss | -0.0429    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1428       |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 182784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40600228 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.188     |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.667      |\n",
      "|    n_updates            | 24259      |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 2.59       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1429       |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 182912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26157403 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | -0.0262    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0954    |\n",
      "|    n_updates            | 24276      |\n",
      "|    policy_gradient_loss | -0.0529    |\n",
      "|    value_loss           | 0.141      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=183000, episode_reward=52.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 52.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 183000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3019716 |\n",
      "|    clip_fraction        | 0.0846    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0683   |\n",
      "|    explained_variance   | -0.326    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0119   |\n",
      "|    n_updates            | 24293     |\n",
      "|    policy_gradient_loss | -0.0333   |\n",
      "|    value_loss           | 0.0773    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1430     |\n",
      "|    time_elapsed    | 202      |\n",
      "|    total_timesteps | 183040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1431      |\n",
      "|    time_elapsed         | 202       |\n",
      "|    total_timesteps      | 183168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3635166 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.187     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0416   |\n",
      "|    n_updates            | 24310     |\n",
      "|    policy_gradient_loss | -0.066    |\n",
      "|    value_loss           | 0.033     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1432       |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 183296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39632094 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0825    |\n",
      "|    explained_variance   | -0.51      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0461    |\n",
      "|    n_updates            | 24327      |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1433      |\n",
      "|    time_elapsed         | 203       |\n",
      "|    total_timesteps      | 183424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2266895 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | 0.0618    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 24344     |\n",
      "|    policy_gradient_loss | -0.0965   |\n",
      "|    value_loss           | 0.0849    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=183500, episode_reward=67.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 68         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 183500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42725387 |\n",
      "|    clip_fraction        | 0.0818     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0506    |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0454    |\n",
      "|    n_updates            | 24361      |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.0404     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1434     |\n",
      "|    time_elapsed    | 203      |\n",
      "|    total_timesteps | 183552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1435       |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 183680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30506235 |\n",
      "|    clip_fraction        | 0.0767     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0424    |\n",
      "|    explained_variance   | 0.906      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.123     |\n",
      "|    n_updates            | 24378      |\n",
      "|    policy_gradient_loss | -0.0369    |\n",
      "|    value_loss           | 0.062      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1436       |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 183808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48405594 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0671    |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0317     |\n",
      "|    n_updates            | 24395      |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    value_loss           | 0.582      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 43.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 903      |\n",
      "|    iterations           | 1437     |\n",
      "|    time_elapsed         | 203      |\n",
      "|    total_timesteps      | 183936   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.576672 |\n",
      "|    clip_fraction        | 0.131    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0819  |\n",
      "|    explained_variance   | 0.391    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0215  |\n",
      "|    n_updates            | 24412    |\n",
      "|    policy_gradient_loss | -0.0546  |\n",
      "|    value_loss           | 0.364    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=43.30 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 43.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 184000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71678126 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0827    |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.118     |\n",
      "|    n_updates            | 24429      |\n",
      "|    policy_gradient_loss | -0.0738    |\n",
      "|    value_loss           | 0.0778     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1438     |\n",
      "|    time_elapsed    | 203      |\n",
      "|    total_timesteps | 184064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1439       |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 184192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44147554 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.139     |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0218    |\n",
      "|    n_updates            | 24446      |\n",
      "|    policy_gradient_loss | -0.0695    |\n",
      "|    value_loss           | 0.562      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1440       |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27985784 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.151     |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 24463      |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    value_loss           | 0.483      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1441       |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 184448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38260058 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0815    |\n",
      "|    explained_variance   | 0.0286     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0536    |\n",
      "|    n_updates            | 24480      |\n",
      "|    policy_gradient_loss | -0.0633    |\n",
      "|    value_loss           | 0.0656     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=184500, episode_reward=50.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 50.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 184500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59504586 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0781    |\n",
      "|    explained_variance   | -0.153     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0927    |\n",
      "|    n_updates            | 24497      |\n",
      "|    policy_gradient_loss | -0.0673    |\n",
      "|    value_loss           | 0.0361     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1442     |\n",
      "|    time_elapsed    | 204      |\n",
      "|    total_timesteps | 184576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1443      |\n",
      "|    time_elapsed         | 204       |\n",
      "|    total_timesteps      | 184704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3363151 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0914   |\n",
      "|    explained_variance   | 0.164     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0785   |\n",
      "|    n_updates            | 24514     |\n",
      "|    policy_gradient_loss | -0.053    |\n",
      "|    value_loss           | 0.0523    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1444       |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 184832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31351867 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | -0.39      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0279    |\n",
      "|    n_updates            | 24531      |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.0705     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1445       |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 184960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28247356 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0727    |\n",
      "|    n_updates            | 24548      |\n",
      "|    policy_gradient_loss | -0.0494    |\n",
      "|    value_loss           | 0.0929     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=19.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 185000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28177023 |\n",
      "|    clip_fraction        | 0.0878     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0636    |\n",
      "|    explained_variance   | 0.889      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.044     |\n",
      "|    n_updates            | 24565      |\n",
      "|    policy_gradient_loss | -0.0425    |\n",
      "|    value_loss           | 0.0392     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1446     |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 185088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1447      |\n",
      "|    time_elapsed         | 205       |\n",
      "|    total_timesteps      | 185216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3063599 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0914   |\n",
      "|    explained_variance   | 0.389     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0171   |\n",
      "|    n_updates            | 24582     |\n",
      "|    policy_gradient_loss | -0.0678   |\n",
      "|    value_loss           | 0.6       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1448      |\n",
      "|    time_elapsed         | 205       |\n",
      "|    total_timesteps      | 185344    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4098473 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0935   |\n",
      "|    explained_variance   | 0.282     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.032     |\n",
      "|    n_updates            | 24599     |\n",
      "|    policy_gradient_loss | -0.0551   |\n",
      "|    value_loss           | 0.537     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1449      |\n",
      "|    time_elapsed         | 205       |\n",
      "|    total_timesteps      | 185472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0438365 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0693   |\n",
      "|    explained_variance   | 0.529     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 24616     |\n",
      "|    policy_gradient_loss | -0.0661   |\n",
      "|    value_loss           | 0.11      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=185500, episode_reward=25.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 185500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32239616 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.21       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0168     |\n",
      "|    n_updates            | 24633      |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    value_loss           | 0.49       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1450     |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 185600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1451       |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 185728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34592825 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.166     |\n",
      "|    explained_variance   | -0.31      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.414      |\n",
      "|    n_updates            | 24650      |\n",
      "|    policy_gradient_loss | -0.0846    |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 43.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1452     |\n",
      "|    time_elapsed         | 206      |\n",
      "|    total_timesteps      | 185856   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.456995 |\n",
      "|    clip_fraction        | 0.142    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0957  |\n",
      "|    explained_variance   | -0.301   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0867  |\n",
      "|    n_updates            | 24667    |\n",
      "|    policy_gradient_loss | -0.062   |\n",
      "|    value_loss           | 0.015    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1453       |\n",
      "|    time_elapsed         | 206        |\n",
      "|    total_timesteps      | 185984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44337228 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0935    |\n",
      "|    explained_variance   | 0.0428     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0908    |\n",
      "|    n_updates            | 24684      |\n",
      "|    policy_gradient_loss | -0.0706    |\n",
      "|    value_loss           | 0.0604     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=48.19 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 48.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 186000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77773494 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0982    |\n",
      "|    n_updates            | 24701      |\n",
      "|    policy_gradient_loss | -0.0738    |\n",
      "|    value_loss           | 0.024      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1454     |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 186112   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1455       |\n",
      "|    time_elapsed         | 206        |\n",
      "|    total_timesteps      | 186240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33589295 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | -0.375     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0423    |\n",
      "|    n_updates            | 24718      |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.0201     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1456       |\n",
      "|    time_elapsed         | 206        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36482367 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | -0.556     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0417    |\n",
      "|    n_updates            | 24735      |\n",
      "|    policy_gradient_loss | -0.05      |\n",
      "|    value_loss           | 0.0647     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1457      |\n",
      "|    time_elapsed         | 206       |\n",
      "|    total_timesteps      | 186496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3476567 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0576   |\n",
      "|    explained_variance   | 0.558     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0631   |\n",
      "|    n_updates            | 24752     |\n",
      "|    policy_gradient_loss | -0.0405   |\n",
      "|    value_loss           | 0.0764    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=186500, episode_reward=-2.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -2.49     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 186500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3669473 |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0611   |\n",
      "|    explained_variance   | 0.632     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0349   |\n",
      "|    n_updates            | 24769     |\n",
      "|    policy_gradient_loss | -0.0406   |\n",
      "|    value_loss           | 0.104     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1458     |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 186624   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1459      |\n",
      "|    time_elapsed         | 206       |\n",
      "|    total_timesteps      | 186752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4180431 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0741   |\n",
      "|    explained_variance   | 0.533     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0505   |\n",
      "|    n_updates            | 24786     |\n",
      "|    policy_gradient_loss | -0.0495   |\n",
      "|    value_loss           | 0.466     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1460      |\n",
      "|    time_elapsed         | 207       |\n",
      "|    total_timesteps      | 186880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6479736 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0621   |\n",
      "|    explained_variance   | 0.472     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0155   |\n",
      "|    n_updates            | 24803     |\n",
      "|    policy_gradient_loss | -0.0542   |\n",
      "|    value_loss           | 0.327     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=187000, episode_reward=60.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 60.3     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 187000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.437298 |\n",
      "|    clip_fraction        | 0.153    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0758  |\n",
      "|    explained_variance   | 0.171    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.135   |\n",
      "|    n_updates            | 24820    |\n",
      "|    policy_gradient_loss | -0.0518  |\n",
      "|    value_loss           | 0.246    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1461     |\n",
      "|    time_elapsed    | 207      |\n",
      "|    total_timesteps | 187008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1462       |\n",
      "|    time_elapsed         | 207        |\n",
      "|    total_timesteps      | 187136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.95888144 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | 0.508      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.249      |\n",
      "|    n_updates            | 24837      |\n",
      "|    policy_gradient_loss | -0.0586    |\n",
      "|    value_loss           | 0.774      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1463       |\n",
      "|    time_elapsed         | 207        |\n",
      "|    total_timesteps      | 187264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33859575 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.581      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.415      |\n",
      "|    n_updates            | 24854      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.713      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1464      |\n",
      "|    time_elapsed         | 207       |\n",
      "|    total_timesteps      | 187392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5227481 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0652   |\n",
      "|    explained_variance   | -0.196    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0446   |\n",
      "|    n_updates            | 24871     |\n",
      "|    policy_gradient_loss | -0.0431   |\n",
      "|    value_loss           | 0.0801    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=187500, episode_reward=27.87 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 27.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 187500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1940031 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0859   |\n",
      "|    explained_variance   | 0.258     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0409   |\n",
      "|    n_updates            | 24888     |\n",
      "|    policy_gradient_loss | -0.0489   |\n",
      "|    value_loss           | 0.0282    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1465     |\n",
      "|    time_elapsed    | 207      |\n",
      "|    total_timesteps | 187520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1466       |\n",
      "|    time_elapsed         | 207        |\n",
      "|    total_timesteps      | 187648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36218697 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0646    |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0438    |\n",
      "|    n_updates            | 24905      |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    value_loss           | 0.0295     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1467      |\n",
      "|    time_elapsed         | 207       |\n",
      "|    total_timesteps      | 187776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3964044 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.096    |\n",
      "|    explained_variance   | -0.149    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0624   |\n",
      "|    n_updates            | 24922     |\n",
      "|    policy_gradient_loss | -0.0647   |\n",
      "|    value_loss           | 0.1       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1468      |\n",
      "|    time_elapsed         | 208       |\n",
      "|    total_timesteps      | 187904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5483939 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0871   |\n",
      "|    explained_variance   | 0.68      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0959   |\n",
      "|    n_updates            | 24939     |\n",
      "|    policy_gradient_loss | -0.0481   |\n",
      "|    value_loss           | 0.0713    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=34.91 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 34.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 188000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3353839 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.702     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0478   |\n",
      "|    n_updates            | 24956     |\n",
      "|    policy_gradient_loss | -0.0498   |\n",
      "|    value_loss           | 0.158     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1469     |\n",
      "|    time_elapsed    | 208      |\n",
      "|    total_timesteps | 188032   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 43.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1470     |\n",
      "|    time_elapsed         | 208      |\n",
      "|    total_timesteps      | 188160   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.42467  |\n",
      "|    clip_fraction        | 0.117    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0931  |\n",
      "|    explained_variance   | 0.482    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.00718  |\n",
      "|    n_updates            | 24973    |\n",
      "|    policy_gradient_loss | -0.0359  |\n",
      "|    value_loss           | 0.462    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1471       |\n",
      "|    time_elapsed         | 208        |\n",
      "|    total_timesteps      | 188288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38406914 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0408     |\n",
      "|    n_updates            | 24990      |\n",
      "|    policy_gradient_loss | -0.0525    |\n",
      "|    value_loss           | 0.284      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1472      |\n",
      "|    time_elapsed         | 208       |\n",
      "|    total_timesteps      | 188416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4718884 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | 0.441     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0961   |\n",
      "|    n_updates            | 25007     |\n",
      "|    policy_gradient_loss | -0.076    |\n",
      "|    value_loss           | 0.205     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=188500, episode_reward=25.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 188500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69934475 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.153      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00417    |\n",
      "|    n_updates            | 25024      |\n",
      "|    policy_gradient_loss | -0.0773    |\n",
      "|    value_loss           | 0.365      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1473     |\n",
      "|    time_elapsed    | 209      |\n",
      "|    total_timesteps | 188544   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1474      |\n",
      "|    time_elapsed         | 209       |\n",
      "|    total_timesteps      | 188672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6856731 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0964   |\n",
      "|    explained_variance   | 0.233     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0782   |\n",
      "|    n_updates            | 25041     |\n",
      "|    policy_gradient_loss | -0.0571   |\n",
      "|    value_loss           | 0.161     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1475       |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 188800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43393242 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.087     |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0415    |\n",
      "|    n_updates            | 25058      |\n",
      "|    policy_gradient_loss | -0.0619    |\n",
      "|    value_loss           | 0.0563     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1476      |\n",
      "|    time_elapsed         | 209       |\n",
      "|    total_timesteps      | 188928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5347872 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.252     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0967   |\n",
      "|    n_updates            | 25075     |\n",
      "|    policy_gradient_loss | -0.0705   |\n",
      "|    value_loss           | 0.0398    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=189000, episode_reward=21.37 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 21.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 189000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47990927 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.1       |\n",
      "|    explained_variance   | 0.0866     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0926    |\n",
      "|    n_updates            | 25092      |\n",
      "|    policy_gradient_loss | -0.0574    |\n",
      "|    value_loss           | 0.0275     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1477     |\n",
      "|    time_elapsed    | 209      |\n",
      "|    total_timesteps | 189056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1478       |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 189184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.66895854 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | -0.113     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 25109      |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    value_loss           | 0.0927     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1479       |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 189312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54173964 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0864    |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0332    |\n",
      "|    n_updates            | 25126      |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    value_loss           | 0.0937     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 43.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1480      |\n",
      "|    time_elapsed         | 209       |\n",
      "|    total_timesteps      | 189440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7225145 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.817     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.096    |\n",
      "|    n_updates            | 25143     |\n",
      "|    policy_gradient_loss | -0.0701   |\n",
      "|    value_loss           | 0.0975    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=189500, episode_reward=40.51 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 189500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.99482685 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0968    |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0422     |\n",
      "|    n_updates            | 25160      |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    value_loss           | 0.293      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1481     |\n",
      "|    time_elapsed    | 210      |\n",
      "|    total_timesteps | 189568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1482       |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 189696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28630632 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0208     |\n",
      "|    n_updates            | 25177      |\n",
      "|    policy_gradient_loss | -0.0632    |\n",
      "|    value_loss           | 0.83       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1483       |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 189824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40930757 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0509    |\n",
      "|    n_updates            | 25194      |\n",
      "|    policy_gradient_loss | -0.0688    |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1484       |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 189952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42194864 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.164     |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.432      |\n",
      "|    n_updates            | 25211      |\n",
      "|    policy_gradient_loss | -0.0593    |\n",
      "|    value_loss           | 1.53       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=18.42 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 18.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 190000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2906254 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.151    |\n",
      "|    explained_variance   | 0.459     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0624    |\n",
      "|    n_updates            | 25228     |\n",
      "|    policy_gradient_loss | -0.0894   |\n",
      "|    value_loss           | 0.713     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1485     |\n",
      "|    time_elapsed    | 210      |\n",
      "|    total_timesteps | 190080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1486       |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 190208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50597817 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | -0.475     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.056     |\n",
      "|    n_updates            | 25245      |\n",
      "|    policy_gradient_loss | -0.0919    |\n",
      "|    value_loss           | 0.0478     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1487      |\n",
      "|    time_elapsed         | 210       |\n",
      "|    total_timesteps      | 190336    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6855197 |\n",
      "|    clip_fraction        | 0.174     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0963   |\n",
      "|    explained_variance   | 0.566     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0756   |\n",
      "|    n_updates            | 25262     |\n",
      "|    policy_gradient_loss | -0.0727   |\n",
      "|    value_loss           | 0.0425    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1488      |\n",
      "|    time_elapsed         | 210       |\n",
      "|    total_timesteps      | 190464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4403173 |\n",
      "|    clip_fraction        | 0.183     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.124    |\n",
      "|    explained_variance   | 0.126     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.084    |\n",
      "|    n_updates            | 25279     |\n",
      "|    policy_gradient_loss | -0.0495   |\n",
      "|    value_loss           | 0.045     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=190500, episode_reward=40.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 40.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 190500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0399684 |\n",
      "|    clip_fraction        | 0.215     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.126    |\n",
      "|    explained_variance   | -0.0617   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 25296     |\n",
      "|    policy_gradient_loss | -0.0793   |\n",
      "|    value_loss           | 0.0489    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1489     |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 190592   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1490       |\n",
      "|    time_elapsed         | 211        |\n",
      "|    total_timesteps      | 190720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30132508 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0723    |\n",
      "|    n_updates            | 25313      |\n",
      "|    policy_gradient_loss | -0.0706    |\n",
      "|    value_loss           | 0.0883     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1491       |\n",
      "|    time_elapsed         | 211        |\n",
      "|    total_timesteps      | 190848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28396234 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0944    |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0854    |\n",
      "|    n_updates            | 25330      |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 0.084      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1492      |\n",
      "|    time_elapsed         | 211       |\n",
      "|    total_timesteps      | 190976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2778777 |\n",
      "|    clip_fraction        | 0.101     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0833   |\n",
      "|    explained_variance   | 0.249     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0536   |\n",
      "|    n_updates            | 25347     |\n",
      "|    policy_gradient_loss | -0.0475   |\n",
      "|    value_loss           | 0.123     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=191000, episode_reward=24.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 24.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 191000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3347482 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.139    |\n",
      "|    explained_variance   | 0.596     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0961   |\n",
      "|    n_updates            | 25364     |\n",
      "|    policy_gradient_loss | -0.0664   |\n",
      "|    value_loss           | 0.314     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1493     |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 191104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1494       |\n",
      "|    time_elapsed         | 211        |\n",
      "|    total_timesteps      | 191232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42165425 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | 0.69       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0743    |\n",
      "|    n_updates            | 25381      |\n",
      "|    policy_gradient_loss | -0.0715    |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1495      |\n",
      "|    time_elapsed         | 211       |\n",
      "|    total_timesteps      | 191360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9591359 |\n",
      "|    clip_fraction        | 0.18      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.172     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.067    |\n",
      "|    n_updates            | 25398     |\n",
      "|    policy_gradient_loss | -0.0687   |\n",
      "|    value_loss           | 0.344     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1496       |\n",
      "|    time_elapsed         | 211        |\n",
      "|    total_timesteps      | 191488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42535985 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0663    |\n",
      "|    explained_variance   | 0.478      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0803     |\n",
      "|    n_updates            | 25415      |\n",
      "|    policy_gradient_loss | -0.0455    |\n",
      "|    value_loss           | 0.262      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=191500, episode_reward=5.26 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 5.26      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 191500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2545837 |\n",
      "|    clip_fraction        | 0.1       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0808   |\n",
      "|    explained_variance   | 0.823     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0133   |\n",
      "|    n_updates            | 25432     |\n",
      "|    policy_gradient_loss | -0.0396   |\n",
      "|    value_loss           | 0.126     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1497     |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 191616   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1498      |\n",
      "|    time_elapsed         | 212       |\n",
      "|    total_timesteps      | 191744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5356942 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0894   |\n",
      "|    explained_variance   | 0.209     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0729   |\n",
      "|    n_updates            | 25449     |\n",
      "|    policy_gradient_loss | -0.0664   |\n",
      "|    value_loss           | 0.0663    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1499       |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 191872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31474066 |\n",
      "|    clip_fraction        | 0.0892     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0805    |\n",
      "|    explained_variance   | -0.0532    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0379    |\n",
      "|    n_updates            | 25466      |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    value_loss           | 0.0177     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=42.82 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 42.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 192000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2714061 |\n",
      "|    clip_fraction        | 0.164     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.095    |\n",
      "|    explained_variance   | 0.0389    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0487   |\n",
      "|    n_updates            | 25483     |\n",
      "|    policy_gradient_loss | -0.0516   |\n",
      "|    value_loss           | 0.0224    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 192000   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1501      |\n",
      "|    time_elapsed         | 212       |\n",
      "|    total_timesteps      | 192128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9123368 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.119    |\n",
      "|    explained_variance   | -0.214    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0975   |\n",
      "|    n_updates            | 25500     |\n",
      "|    policy_gradient_loss | -0.0709   |\n",
      "|    value_loss           | 0.0738    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1502       |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 192256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41776705 |\n",
      "|    clip_fraction        | 0.0892     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0662    |\n",
      "|    explained_variance   | 0.592      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.039     |\n",
      "|    n_updates            | 25517      |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.058      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1503      |\n",
      "|    time_elapsed         | 213       |\n",
      "|    total_timesteps      | 192384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5919405 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0943   |\n",
      "|    explained_variance   | 0.51      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0395    |\n",
      "|    n_updates            | 25534     |\n",
      "|    policy_gradient_loss | -0.0475   |\n",
      "|    value_loss           | 0.273     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=192500, episode_reward=17.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 17.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 192500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17721337 |\n",
      "|    clip_fraction        | 0.085      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0704    |\n",
      "|    explained_variance   | 0.508      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0539    |\n",
      "|    n_updates            | 25551      |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 0.351      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1504     |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1505       |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 192640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64136505 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | 0.156      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.112     |\n",
      "|    n_updates            | 25568      |\n",
      "|    policy_gradient_loss | -0.057     |\n",
      "|    value_loss           | 0.306      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1506       |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 192768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34377277 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0835    |\n",
      "|    explained_variance   | -0.43      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0357    |\n",
      "|    n_updates            | 25585      |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.144      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1507       |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 192896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16106567 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0905     |\n",
      "|    n_updates            | 25602      |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    value_loss           | 0.979      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=193000, episode_reward=15.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 193000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21074547 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0606    |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0583     |\n",
      "|    n_updates            | 25619      |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.426      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1508     |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 193024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1509      |\n",
      "|    time_elapsed         | 214       |\n",
      "|    total_timesteps      | 193152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3279194 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | -0.0671   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0632   |\n",
      "|    n_updates            | 25636     |\n",
      "|    policy_gradient_loss | -0.0672   |\n",
      "|    value_loss           | 0.0451    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1510      |\n",
      "|    time_elapsed         | 214       |\n",
      "|    total_timesteps      | 193280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0973053 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | 0.275     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.119    |\n",
      "|    n_updates            | 25653     |\n",
      "|    policy_gradient_loss | -0.0698   |\n",
      "|    value_loss           | 0.055     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 44.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1511       |\n",
      "|    time_elapsed         | 214        |\n",
      "|    total_timesteps      | 193408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48798966 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.148     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0365    |\n",
      "|    n_updates            | 25670      |\n",
      "|    policy_gradient_loss | -0.0648    |\n",
      "|    value_loss           | 0.0398     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=193500, episode_reward=-6.83 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -6.83      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 193500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38331544 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.163     |\n",
      "|    explained_variance   | -0.779     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 25687      |\n",
      "|    policy_gradient_loss | -0.0697    |\n",
      "|    value_loss           | 0.0744     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1512     |\n",
      "|    time_elapsed    | 214      |\n",
      "|    total_timesteps | 193536   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1513      |\n",
      "|    time_elapsed         | 214       |\n",
      "|    total_timesteps      | 193664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3371768 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.142     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0914   |\n",
      "|    n_updates            | 25704     |\n",
      "|    policy_gradient_loss | -0.0594   |\n",
      "|    value_loss           | 0.089     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 44.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1514     |\n",
      "|    time_elapsed         | 214      |\n",
      "|    total_timesteps      | 193792   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.723836 |\n",
      "|    clip_fraction        | 0.124    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0589  |\n",
      "|    explained_variance   | 0.61     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0678  |\n",
      "|    n_updates            | 25721    |\n",
      "|    policy_gradient_loss | -0.0482  |\n",
      "|    value_loss           | 0.0806   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1515      |\n",
      "|    time_elapsed         | 214       |\n",
      "|    total_timesteps      | 193920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1318052 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0868   |\n",
      "|    explained_variance   | 0.115     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0269   |\n",
      "|    n_updates            | 25738     |\n",
      "|    policy_gradient_loss | -0.0569   |\n",
      "|    value_loss           | 0.156     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=67.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 67         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 194000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46348172 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0316    |\n",
      "|    n_updates            | 25755      |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.323      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1516     |\n",
      "|    time_elapsed    | 215      |\n",
      "|    total_timesteps | 194048   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 44.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1517      |\n",
      "|    time_elapsed         | 215       |\n",
      "|    total_timesteps      | 194176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8253273 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.233     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0916   |\n",
      "|    n_updates            | 25772     |\n",
      "|    policy_gradient_loss | -0.0723   |\n",
      "|    value_loss           | 0.0662    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1518      |\n",
      "|    time_elapsed         | 215       |\n",
      "|    total_timesteps      | 194304    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6716536 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    explained_variance   | -0.0993   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.376     |\n",
      "|    n_updates            | 25789     |\n",
      "|    policy_gradient_loss | -0.0526   |\n",
      "|    value_loss           | 1.35      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1519      |\n",
      "|    time_elapsed         | 215       |\n",
      "|    total_timesteps      | 194432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4943905 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.15     |\n",
      "|    explained_variance   | 0.284     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.193     |\n",
      "|    n_updates            | 25806     |\n",
      "|    policy_gradient_loss | -0.062    |\n",
      "|    value_loss           | 1.12      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=194500, episode_reward=89.35 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 89.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 194500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6130373 |\n",
      "|    clip_fraction        | 0.274     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.235     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0573   |\n",
      "|    n_updates            | 25823     |\n",
      "|    policy_gradient_loss | -0.0784   |\n",
      "|    value_loss           | 0.109     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1520     |\n",
      "|    time_elapsed    | 215      |\n",
      "|    total_timesteps | 194560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1521       |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 194688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35841227 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0786    |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0873    |\n",
      "|    n_updates            | 25840      |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    value_loss           | 0.0817     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1522       |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 194816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33093214 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.288      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 25857      |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.0379     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1523       |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 194944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31346318 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0759    |\n",
      "|    explained_variance   | -0.0239    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0488    |\n",
      "|    n_updates            | 25874      |\n",
      "|    policy_gradient_loss | -0.0557    |\n",
      "|    value_loss           | 0.0299     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=56.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 56.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 195000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1056281 |\n",
      "|    clip_fraction        | 0.0469    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.045    |\n",
      "|    explained_variance   | 0.113     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0327   |\n",
      "|    n_updates            | 25891     |\n",
      "|    policy_gradient_loss | -0.03     |\n",
      "|    value_loss           | 0.0808    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1524     |\n",
      "|    time_elapsed    | 216      |\n",
      "|    total_timesteps | 195072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1525       |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 195200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74373436 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0782    |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0883    |\n",
      "|    n_updates            | 25908      |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.0611     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1526      |\n",
      "|    time_elapsed         | 216       |\n",
      "|    total_timesteps      | 195328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2799272 |\n",
      "|    clip_fraction        | 0.0869    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0673   |\n",
      "|    explained_variance   | 0.223     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0606   |\n",
      "|    n_updates            | 25925     |\n",
      "|    policy_gradient_loss | -0.0436   |\n",
      "|    value_loss           | 0.101     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1527      |\n",
      "|    time_elapsed         | 216       |\n",
      "|    total_timesteps      | 195456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1145544 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.15     |\n",
      "|    explained_variance   | -0.0347   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0632   |\n",
      "|    n_updates            | 25942     |\n",
      "|    policy_gradient_loss | -0.0935   |\n",
      "|    value_loss           | 0.588     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=195500, episode_reward=89.56 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 89.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 195500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51180726 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.097     |\n",
      "|    explained_variance   | 0.221      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0786    |\n",
      "|    n_updates            | 25959      |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 0.26       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1528     |\n",
      "|    time_elapsed    | 216      |\n",
      "|    total_timesteps | 195584   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1529      |\n",
      "|    time_elapsed         | 216       |\n",
      "|    total_timesteps      | 195712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7614646 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.676     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0886   |\n",
      "|    n_updates            | 25976     |\n",
      "|    policy_gradient_loss | -0.0676   |\n",
      "|    value_loss           | 0.163     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1530       |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 195840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55117345 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0965    |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 1.4        |\n",
      "|    n_updates            | 25993      |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 3.8        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1531       |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 195968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38166344 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | 0.925      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0587    |\n",
      "|    n_updates            | 26010      |\n",
      "|    policy_gradient_loss | -0.0653    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=35.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 35.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 196000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4757128 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | 0.416     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0228   |\n",
      "|    n_updates            | 26027     |\n",
      "|    policy_gradient_loss | -0.0528   |\n",
      "|    value_loss           | 0.126     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1532     |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 196096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1533      |\n",
      "|    time_elapsed         | 217       |\n",
      "|    total_timesteps      | 196224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7418809 |\n",
      "|    clip_fraction        | 0.24      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.142    |\n",
      "|    explained_variance   | 0.15      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 26044     |\n",
      "|    policy_gradient_loss | -0.0874   |\n",
      "|    value_loss           | 0.0361    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1534       |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 196352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21278311 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.182     |\n",
      "|    explained_variance   | -0.623     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 26061      |\n",
      "|    policy_gradient_loss | -0.072     |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1535      |\n",
      "|    time_elapsed         | 217       |\n",
      "|    total_timesteps      | 196480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1598197 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.098    |\n",
      "|    explained_variance   | 0.556     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0311   |\n",
      "|    n_updates            | 26078     |\n",
      "|    policy_gradient_loss | -0.0498   |\n",
      "|    value_loss           | 0.0825    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=196500, episode_reward=30.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 196500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64839226 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 26095      |\n",
      "|    policy_gradient_loss | -0.0592    |\n",
      "|    value_loss           | 0.052      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1536     |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1537      |\n",
      "|    time_elapsed         | 217       |\n",
      "|    total_timesteps      | 196736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1888691 |\n",
      "|    clip_fraction        | 0.0841    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0693   |\n",
      "|    explained_variance   | 0.64      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0439   |\n",
      "|    n_updates            | 26112     |\n",
      "|    policy_gradient_loss | -0.0339   |\n",
      "|    value_loss           | 0.172     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 45.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 903      |\n",
      "|    iterations           | 1538     |\n",
      "|    time_elapsed         | 217      |\n",
      "|    total_timesteps      | 196864   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.775077 |\n",
      "|    clip_fraction        | 0.177    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.136   |\n",
      "|    explained_variance   | 0.24     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0501  |\n",
      "|    n_updates            | 26129    |\n",
      "|    policy_gradient_loss | -0.0676  |\n",
      "|    value_loss           | 0.607    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1539       |\n",
      "|    time_elapsed         | 217        |\n",
      "|    total_timesteps      | 196992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45474017 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0592    |\n",
      "|    n_updates            | 26146      |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 0.356      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=197000, episode_reward=26.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 26.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 197000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20478924 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.717      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.068     |\n",
      "|    n_updates            | 26163      |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1540     |\n",
      "|    time_elapsed    | 218      |\n",
      "|    total_timesteps | 197120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1541       |\n",
      "|    time_elapsed         | 218        |\n",
      "|    total_timesteps      | 197248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39961526 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.227     |\n",
      "|    explained_variance   | 0.206      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0189     |\n",
      "|    n_updates            | 26180      |\n",
      "|    policy_gradient_loss | -0.0813    |\n",
      "|    value_loss           | 0.599      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 1542      |\n",
      "|    time_elapsed         | 218       |\n",
      "|    total_timesteps      | 197376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7403668 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.139    |\n",
      "|    explained_variance   | 0.906     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0037   |\n",
      "|    n_updates            | 26197     |\n",
      "|    policy_gradient_loss | -0.0619   |\n",
      "|    value_loss           | 0.229     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=197500, episode_reward=49.23 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 197500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6987769 |\n",
      "|    clip_fraction        | 0.225     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.193    |\n",
      "|    explained_variance   | 0.0196    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0781   |\n",
      "|    n_updates            | 26214     |\n",
      "|    policy_gradient_loss | -0.0553   |\n",
      "|    value_loss           | 0.118     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1543     |\n",
      "|    time_elapsed    | 218      |\n",
      "|    total_timesteps | 197504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1544       |\n",
      "|    time_elapsed         | 218        |\n",
      "|    total_timesteps      | 197632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26933914 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.163     |\n",
      "|    explained_variance   | -0.0496    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0518    |\n",
      "|    n_updates            | 26231      |\n",
      "|    policy_gradient_loss | -0.075     |\n",
      "|    value_loss           | 0.0338     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 1545      |\n",
      "|    time_elapsed         | 218       |\n",
      "|    total_timesteps      | 197760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8180857 |\n",
      "|    clip_fraction        | 0.284     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.155    |\n",
      "|    explained_variance   | -0.112    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0921   |\n",
      "|    n_updates            | 26248     |\n",
      "|    policy_gradient_loss | -0.0806   |\n",
      "|    value_loss           | 0.0389    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 45.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 1546      |\n",
      "|    time_elapsed         | 218       |\n",
      "|    total_timesteps      | 197888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3835209 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.095    |\n",
      "|    explained_variance   | 0.251     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0349   |\n",
      "|    n_updates            | 26265     |\n",
      "|    policy_gradient_loss | -0.06     |\n",
      "|    value_loss           | 0.0688    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=56.63 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 56.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 198000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51561296 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0822    |\n",
      "|    explained_variance   | 0.771      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0851    |\n",
      "|    n_updates            | 26282      |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    value_loss           | 0.0802     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1547     |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 198016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1548       |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 198144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44543883 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0857    |\n",
      "|    explained_variance   | 0.835      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0701    |\n",
      "|    n_updates            | 26299      |\n",
      "|    policy_gradient_loss | -0.0523    |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1549       |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 198272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21983191 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.000173   |\n",
      "|    n_updates            | 26316      |\n",
      "|    policy_gradient_loss | -0.0227    |\n",
      "|    value_loss           | 0.374      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 45.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1550       |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 198400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35420632 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.051     |\n",
      "|    n_updates            | 26333      |\n",
      "|    policy_gradient_loss | -0.0561    |\n",
      "|    value_loss           | 0.453      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=198500, episode_reward=47.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 198500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25850195 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0811    |\n",
      "|    n_updates            | 26350      |\n",
      "|    policy_gradient_loss | -0.0534    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 45.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1551     |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 198528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1552       |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18195352 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0854    |\n",
      "|    explained_variance   | 0.66       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0406     |\n",
      "|    n_updates            | 26367      |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 0.257      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1553      |\n",
      "|    time_elapsed         | 219       |\n",
      "|    total_timesteps      | 198784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2701033 |\n",
      "|    clip_fraction        | 0.202     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.186    |\n",
      "|    explained_variance   | 0.392     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.126     |\n",
      "|    n_updates            | 26384     |\n",
      "|    policy_gradient_loss | -0.0747   |\n",
      "|    value_loss           | 1.56      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1554      |\n",
      "|    time_elapsed         | 220       |\n",
      "|    total_timesteps      | 198912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1944077 |\n",
      "|    clip_fraction        | 0.224     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0879   |\n",
      "|    explained_variance   | -0.445    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 26401     |\n",
      "|    policy_gradient_loss | -0.0904   |\n",
      "|    value_loss           | 0.0343    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=199000, episode_reward=63.99 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 64         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 199000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16587913 |\n",
      "|    clip_fraction        | 0.0777     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0606    |\n",
      "|    explained_variance   | -1.29      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0676    |\n",
      "|    n_updates            | 26418      |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.0729     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1555     |\n",
      "|    time_elapsed    | 220      |\n",
      "|    total_timesteps | 199040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1556       |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 199168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.85015196 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | -0.0289    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.067     |\n",
      "|    n_updates            | 26435      |\n",
      "|    policy_gradient_loss | -0.0782    |\n",
      "|    value_loss           | 0.0243     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1557       |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 199296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48499957 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0447    |\n",
      "|    n_updates            | 26452      |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.039      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1558       |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 199424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27774164 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | -0.984     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0316    |\n",
      "|    n_updates            | 26469      |\n",
      "|    policy_gradient_loss | -0.0472    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=199500, episode_reward=53.02 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 53        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 199500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3448906 |\n",
      "|    clip_fraction        | 0.112     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0668   |\n",
      "|    explained_variance   | 0.836     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.047    |\n",
      "|    n_updates            | 26486     |\n",
      "|    policy_gradient_loss | -0.0434   |\n",
      "|    value_loss           | 0.0654    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1559     |\n",
      "|    time_elapsed    | 220      |\n",
      "|    total_timesteps | 199552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1560       |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 199680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16436923 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.148     |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.073     |\n",
      "|    n_updates            | 26503      |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    value_loss           | 0.14       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 1561      |\n",
      "|    time_elapsed         | 221       |\n",
      "|    total_timesteps      | 199808    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5847531 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.521     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0288   |\n",
      "|    n_updates            | 26520     |\n",
      "|    policy_gradient_loss | -0.077    |\n",
      "|    value_loss           | 0.552     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1562      |\n",
      "|    time_elapsed         | 221       |\n",
      "|    total_timesteps      | 199936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6899158 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.151    |\n",
      "|    explained_variance   | 0.746     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0936   |\n",
      "|    n_updates            | 26537     |\n",
      "|    policy_gradient_loss | -0.0673   |\n",
      "|    value_loss           | 0.253     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=77.89 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 77.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 200000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29246724 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.703      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0693    |\n",
      "|    n_updates            | 26554      |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.293      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1563     |\n",
      "|    time_elapsed    | 221      |\n",
      "|    total_timesteps | 200064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1564       |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 200192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44690618 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.371      |\n",
      "|    n_updates            | 26571      |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    value_loss           | 2.57       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1565       |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 200320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25853708 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.123     |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0437    |\n",
      "|    n_updates            | 26588      |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1566       |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 200448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22177726 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | -0.316     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0221     |\n",
      "|    n_updates            | 26605      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.31       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=200500, episode_reward=79.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 79.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 200500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74325705 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 26622      |\n",
      "|    policy_gradient_loss | -0.0881    |\n",
      "|    value_loss           | 0.0378     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1567     |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 200576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1568      |\n",
      "|    time_elapsed         | 222       |\n",
      "|    total_timesteps      | 200704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7612576 |\n",
      "|    clip_fraction        | 0.247     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.13     |\n",
      "|    explained_variance   | -0.409    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.152    |\n",
      "|    n_updates            | 26639     |\n",
      "|    policy_gradient_loss | -0.11     |\n",
      "|    value_loss           | 0.0253    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1569       |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 200832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59084153 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.463      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0478    |\n",
      "|    n_updates            | 26656      |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 0.0354     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1570       |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 200960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13685653 |\n",
      "|    clip_fraction        | 0.0676     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0659    |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0714    |\n",
      "|    n_updates            | 26673      |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 0.0469     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=201000, episode_reward=35.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 201000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35897446 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0707    |\n",
      "|    n_updates            | 26690      |\n",
      "|    policy_gradient_loss | -0.0652    |\n",
      "|    value_loss           | 0.152      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1571     |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 201088   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1572       |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 201216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37598428 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0843    |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0392    |\n",
      "|    n_updates            | 26707      |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.369      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1573       |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 201344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29731706 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.077     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00935   |\n",
      "|    n_updates            | 26724      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.524      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1574       |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 201472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46218753 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0893    |\n",
      "|    explained_variance   | 0.615      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 26741      |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.25       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=201500, episode_reward=34.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 34.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 201500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29414704 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0601     |\n",
      "|    n_updates            | 26758      |\n",
      "|    policy_gradient_loss | -0.0577    |\n",
      "|    value_loss           | 0.424      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1575     |\n",
      "|    time_elapsed    | 223      |\n",
      "|    total_timesteps | 201600   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 46.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1576     |\n",
      "|    time_elapsed         | 223      |\n",
      "|    total_timesteps      | 201728   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.480216 |\n",
      "|    clip_fraction        | 0.244    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.11    |\n",
      "|    explained_variance   | 0.429    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0227  |\n",
      "|    n_updates            | 26775    |\n",
      "|    policy_gradient_loss | -0.0627  |\n",
      "|    value_loss           | 0.286    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1577       |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 201856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.91640234 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0927    |\n",
      "|    explained_variance   | -0.535     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0685    |\n",
      "|    n_updates            | 26792      |\n",
      "|    policy_gradient_loss | -0.0768    |\n",
      "|    value_loss           | 0.0705     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1578       |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 201984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28465104 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0738    |\n",
      "|    n_updates            | 26809      |\n",
      "|    policy_gradient_loss | -0.061     |\n",
      "|    value_loss           | 0.0355     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=202000, episode_reward=20.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 202000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22710288 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.222      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.056     |\n",
      "|    n_updates            | 26826      |\n",
      "|    policy_gradient_loss | -0.065     |\n",
      "|    value_loss           | 0.0372     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1579     |\n",
      "|    time_elapsed    | 224      |\n",
      "|    total_timesteps | 202112   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1580       |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 202240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24216956 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.131     |\n",
      "|    explained_variance   | -0.00742   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.047     |\n",
      "|    n_updates            | 26843      |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.118      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1581       |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 202368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64574075 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0626    |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0311    |\n",
      "|    n_updates            | 26860      |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 0.0585     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1582       |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 202496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47795877 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0766    |\n",
      "|    explained_variance   | 0.666      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.067     |\n",
      "|    n_updates            | 26877      |\n",
      "|    policy_gradient_loss | -0.0542    |\n",
      "|    value_loss           | 0.0861     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=202500, episode_reward=22.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 22.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 202500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19610667 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0897    |\n",
      "|    explained_variance   | 0.431      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0266    |\n",
      "|    n_updates            | 26894      |\n",
      "|    policy_gradient_loss | -0.0352    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1583     |\n",
      "|    time_elapsed    | 224      |\n",
      "|    total_timesteps | 202624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1584       |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36034682 |\n",
      "|    clip_fraction        | 0.0864     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0763    |\n",
      "|    explained_variance   | 0.655      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0727    |\n",
      "|    n_updates            | 26911      |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.382      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 46.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1585     |\n",
      "|    time_elapsed         | 224      |\n",
      "|    total_timesteps      | 202880   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.431947 |\n",
      "|    clip_fraction        | 0.111    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0908  |\n",
      "|    explained_variance   | 0.674    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.107   |\n",
      "|    n_updates            | 26928    |\n",
      "|    policy_gradient_loss | -0.0561  |\n",
      "|    value_loss           | 0.114    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=203000, episode_reward=23.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 23.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 203000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43590236 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0735    |\n",
      "|    explained_variance   | 0.834      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0383    |\n",
      "|    n_updates            | 26945      |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.132      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1586     |\n",
      "|    time_elapsed    | 225      |\n",
      "|    total_timesteps | 203008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1587       |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 203136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47597983 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0505     |\n",
      "|    n_updates            | 26962      |\n",
      "|    policy_gradient_loss | -0.0788    |\n",
      "|    value_loss           | 0.348      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1588      |\n",
      "|    time_elapsed         | 225       |\n",
      "|    total_timesteps      | 203264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2802511 |\n",
      "|    clip_fraction        | 0.245     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | 0.015     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0337   |\n",
      "|    n_updates            | 26979     |\n",
      "|    policy_gradient_loss | -0.0721   |\n",
      "|    value_loss           | 0.111     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1589       |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 203392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33950686 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.258      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.058     |\n",
      "|    n_updates            | 26996      |\n",
      "|    policy_gradient_loss | -0.0423    |\n",
      "|    value_loss           | 0.115      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=203500, episode_reward=72.65 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 72.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 203500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52014124 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.163     |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0632    |\n",
      "|    n_updates            | 27013      |\n",
      "|    policy_gradient_loss | -0.0657    |\n",
      "|    value_loss           | 0.0703     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1590     |\n",
      "|    time_elapsed    | 225      |\n",
      "|    total_timesteps | 203520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1591       |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 203648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25893742 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.164     |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0448    |\n",
      "|    n_updates            | 27030      |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1592       |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 203776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26448542 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0801    |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0366    |\n",
      "|    n_updates            | 27047      |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.041      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1593       |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 203904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48259568 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0769    |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0336    |\n",
      "|    n_updates            | 27064      |\n",
      "|    policy_gradient_loss | -0.0461    |\n",
      "|    value_loss           | 0.0759     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=204000, episode_reward=53.30 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 53.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 204000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8277699 |\n",
      "|    clip_fraction        | 0.189     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0863   |\n",
      "|    explained_variance   | 0.68      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0817   |\n",
      "|    n_updates            | 27081     |\n",
      "|    policy_gradient_loss | -0.0596   |\n",
      "|    value_loss           | 0.0871    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1594     |\n",
      "|    time_elapsed    | 226      |\n",
      "|    total_timesteps | 204032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1595       |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 204160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46587008 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.762      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0195     |\n",
      "|    n_updates            | 27098      |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    value_loss           | 0.58       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1596       |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 204288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38306487 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.872      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0908    |\n",
      "|    n_updates            | 27115      |\n",
      "|    policy_gradient_loss | -0.0529    |\n",
      "|    value_loss           | 0.131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1597       |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 204416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29507366 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.015     |\n",
      "|    n_updates            | 27132      |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    value_loss           | 0.278      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=204500, episode_reward=51.23 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 204500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34307373 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.158     |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.341      |\n",
      "|    n_updates            | 27149      |\n",
      "|    policy_gradient_loss | -0.0573    |\n",
      "|    value_loss           | 0.979      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1598     |\n",
      "|    time_elapsed    | 226      |\n",
      "|    total_timesteps | 204544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1599       |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 204672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44337165 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.173     |\n",
      "|    explained_variance   | 0.838      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 27166      |\n",
      "|    policy_gradient_loss | -0.0875    |\n",
      "|    value_loss           | 0.146      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1600      |\n",
      "|    time_elapsed         | 226       |\n",
      "|    total_timesteps      | 204800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6648939 |\n",
      "|    clip_fraction        | 0.191     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | 0.195     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0606   |\n",
      "|    n_updates            | 27183     |\n",
      "|    policy_gradient_loss | -0.0699   |\n",
      "|    value_loss           | 0.0497    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1601       |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 204928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28991836 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.206     |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 27200      |\n",
      "|    policy_gradient_loss | -0.0647    |\n",
      "|    value_loss           | 0.039      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=68.01 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 68        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 205000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5413692 |\n",
      "|    clip_fraction        | 0.247     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.172    |\n",
      "|    explained_variance   | -1.12     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 27217     |\n",
      "|    policy_gradient_loss | -0.0979   |\n",
      "|    value_loss           | 0.0232    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1602     |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 205056   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 46.4     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1603     |\n",
      "|    time_elapsed         | 227      |\n",
      "|    total_timesteps      | 205184   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.657606 |\n",
      "|    clip_fraction        | 0.162    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.12    |\n",
      "|    explained_variance   | 0.0474   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0767  |\n",
      "|    n_updates            | 27234    |\n",
      "|    policy_gradient_loss | -0.0684  |\n",
      "|    value_loss           | 0.0478   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1604      |\n",
      "|    time_elapsed         | 227       |\n",
      "|    total_timesteps      | 205312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2904665 |\n",
      "|    clip_fraction        | 0.0772    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.06     |\n",
      "|    explained_variance   | 0.559     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0752   |\n",
      "|    n_updates            | 27251     |\n",
      "|    policy_gradient_loss | -0.0468   |\n",
      "|    value_loss           | 0.0669    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1605      |\n",
      "|    time_elapsed         | 227       |\n",
      "|    total_timesteps      | 205440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6090736 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0724   |\n",
      "|    explained_variance   | 0.548     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 27268     |\n",
      "|    policy_gradient_loss | -0.0351   |\n",
      "|    value_loss           | 0.0536    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=205500, episode_reward=63.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 64         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 205500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06244184 |\n",
      "|    clip_fraction        | 0.045      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0546    |\n",
      "|    explained_variance   | 0.753      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00469    |\n",
      "|    n_updates            | 27285      |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.309      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1606     |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 205568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1607       |\n",
      "|    time_elapsed         | 227        |\n",
      "|    total_timesteps      | 205696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17858587 |\n",
      "|    clip_fraction        | 0.046      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0473    |\n",
      "|    explained_variance   | 0.819      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0142     |\n",
      "|    n_updates            | 27302      |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    value_loss           | 0.455      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1608       |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 205824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39449376 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.068     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0662    |\n",
      "|    n_updates            | 27319      |\n",
      "|    policy_gradient_loss | -0.0522    |\n",
      "|    value_loss           | 0.0758     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1609      |\n",
      "|    time_elapsed         | 228       |\n",
      "|    total_timesteps      | 205952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3933566 |\n",
      "|    clip_fraction        | 0.068     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0556   |\n",
      "|    explained_variance   | 0.745     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0545   |\n",
      "|    n_updates            | 27336     |\n",
      "|    policy_gradient_loss | -0.0349   |\n",
      "|    value_loss           | 0.305     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=206000, episode_reward=37.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 37.7     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 206000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.66661  |\n",
      "|    clip_fraction        | 0.216    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.168   |\n",
      "|    explained_variance   | 0.332    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.191    |\n",
      "|    n_updates            | 27353    |\n",
      "|    policy_gradient_loss | -0.0827  |\n",
      "|    value_loss           | 0.461    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1610     |\n",
      "|    time_elapsed    | 228      |\n",
      "|    total_timesteps | 206080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1611       |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 206208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43448424 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.0422     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0869    |\n",
      "|    n_updates            | 27370      |\n",
      "|    policy_gradient_loss | -0.0766    |\n",
      "|    value_loss           | 0.0347     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1612       |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 206336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45362455 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0959    |\n",
      "|    explained_variance   | -0.264     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0732    |\n",
      "|    n_updates            | 27387      |\n",
      "|    policy_gradient_loss | -0.0684    |\n",
      "|    value_loss           | 0.012      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1613       |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 206464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25039518 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.172     |\n",
      "|    explained_variance   | 0.068      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.052     |\n",
      "|    n_updates            | 27404      |\n",
      "|    policy_gradient_loss | -0.0665    |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=206500, episode_reward=28.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 28.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 206500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4809592 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.3       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.121     |\n",
      "|    n_updates            | 27421     |\n",
      "|    policy_gradient_loss | -0.07     |\n",
      "|    value_loss           | 0.043     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1614     |\n",
      "|    time_elapsed    | 228      |\n",
      "|    total_timesteps | 206592   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1615       |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 206720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29970962 |\n",
      "|    clip_fraction        | 0.0781     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.061     |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0115    |\n",
      "|    n_updates            | 27438      |\n",
      "|    policy_gradient_loss | -0.0346    |\n",
      "|    value_loss           | 0.0681     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1616       |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16385685 |\n",
      "|    clip_fraction        | 0.074      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.054     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0534    |\n",
      "|    n_updates            | 27455      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 0.0357     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1617       |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 206976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20200138 |\n",
      "|    clip_fraction        | 0.0708     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0659    |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0643    |\n",
      "|    n_updates            | 27472      |\n",
      "|    policy_gradient_loss | -0.0428    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=207000, episode_reward=8.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 8.08       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 207000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35148028 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0153    |\n",
      "|    n_updates            | 27489      |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    value_loss           | 0.472      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1618     |\n",
      "|    time_elapsed    | 229      |\n",
      "|    total_timesteps | 207104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1619       |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 207232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25728753 |\n",
      "|    clip_fraction        | 0.0947     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 27506      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.0872     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1620       |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 207360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20779325 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.131     |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0459    |\n",
      "|    n_updates            | 27523      |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    value_loss           | 0.521      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1621       |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 207488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24508896 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | -0.216     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0269    |\n",
      "|    n_updates            | 27540      |\n",
      "|    policy_gradient_loss | -0.0543    |\n",
      "|    value_loss           | 0.346      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=207500, episode_reward=24.99 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 207500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40519482 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.00928    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.083     |\n",
      "|    n_updates            | 27557      |\n",
      "|    policy_gradient_loss | -0.0717    |\n",
      "|    value_loss           | 0.0234     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1622     |\n",
      "|    time_elapsed    | 230      |\n",
      "|    total_timesteps | 207616   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1623      |\n",
      "|    time_elapsed         | 230       |\n",
      "|    total_timesteps      | 207744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2668717 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.0934    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0582   |\n",
      "|    n_updates            | 27574     |\n",
      "|    policy_gradient_loss | -0.0603   |\n",
      "|    value_loss           | 0.0616    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1624      |\n",
      "|    time_elapsed         | 230       |\n",
      "|    total_timesteps      | 207872    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4422245 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | 0.115     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0297   |\n",
      "|    n_updates            | 27591     |\n",
      "|    policy_gradient_loss | -0.0451   |\n",
      "|    value_loss           | 0.0275    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=36.23 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 36.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 208000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6375768 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.152    |\n",
      "|    explained_variance   | -0.444    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.109    |\n",
      "|    n_updates            | 27608     |\n",
      "|    policy_gradient_loss | -0.0891   |\n",
      "|    value_loss           | 0.0482    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1625     |\n",
      "|    time_elapsed    | 230      |\n",
      "|    total_timesteps | 208000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1626       |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 208128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35370067 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.0187     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.122     |\n",
      "|    n_updates            | 27625      |\n",
      "|    policy_gradient_loss | -0.066     |\n",
      "|    value_loss           | 0.0615     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1627       |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 208256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25998974 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.834      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.115     |\n",
      "|    n_updates            | 27642      |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.065      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1628       |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 208384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54766095 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.13      |\n",
      "|    explained_variance   | -0.237     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0686    |\n",
      "|    n_updates            | 27659      |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    value_loss           | 0.0728     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=208500, episode_reward=35.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 35.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 208500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4104493 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0843   |\n",
      "|    explained_variance   | 0.627     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.045     |\n",
      "|    n_updates            | 27676     |\n",
      "|    policy_gradient_loss | -0.0751   |\n",
      "|    value_loss           | 0.453     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1629     |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 208512   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1630      |\n",
      "|    time_elapsed         | 231       |\n",
      "|    total_timesteps      | 208640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4383124 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | 0.802     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0487   |\n",
      "|    n_updates            | 27693     |\n",
      "|    policy_gradient_loss | -0.057    |\n",
      "|    value_loss           | 0.137     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1631       |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 208768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22701502 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0966    |\n",
      "|    explained_variance   | 0.422      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 27710      |\n",
      "|    policy_gradient_loss | -0.0489    |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1632       |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 208896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62594247 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0958    |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0576    |\n",
      "|    n_updates            | 27727      |\n",
      "|    policy_gradient_loss | -0.0744    |\n",
      "|    value_loss           | 0.488      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=209000, episode_reward=45.56 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 45.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 209000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.6344585 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.148    |\n",
      "|    explained_variance   | 0.00051   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.052    |\n",
      "|    n_updates            | 27744     |\n",
      "|    policy_gradient_loss | -0.0888   |\n",
      "|    value_loss           | 0.146     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1633     |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 209024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1634      |\n",
      "|    time_elapsed         | 231       |\n",
      "|    total_timesteps      | 209152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6189836 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | 0.00848   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0558   |\n",
      "|    n_updates            | 27761     |\n",
      "|    policy_gradient_loss | -0.0563   |\n",
      "|    value_loss           | 0.0771    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1635       |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 209280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63392884 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0861    |\n",
      "|    explained_variance   | -0.172     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0751    |\n",
      "|    n_updates            | 27778      |\n",
      "|    policy_gradient_loss | -0.0626    |\n",
      "|    value_loss           | 0.028      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1636      |\n",
      "|    time_elapsed         | 232       |\n",
      "|    total_timesteps      | 209408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6353034 |\n",
      "|    clip_fraction        | 0.369     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | -0.277    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 27795     |\n",
      "|    policy_gradient_loss | -0.0693   |\n",
      "|    value_loss           | 0.0232    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=209500, episode_reward=19.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 209500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53292286 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0968    |\n",
      "|    explained_variance   | -0.0297    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0576    |\n",
      "|    n_updates            | 27812      |\n",
      "|    policy_gradient_loss | -0.069     |\n",
      "|    value_loss           | 0.0492     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1637     |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 209536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1638       |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 209664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22942397 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0815    |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0143    |\n",
      "|    n_updates            | 27829      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.0686     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1639       |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 209792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54087436 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | -0.0183    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0967    |\n",
      "|    n_updates            | 27846      |\n",
      "|    policy_gradient_loss | -0.0563    |\n",
      "|    value_loss           | 0.0669     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1640       |\n",
      "|    time_elapsed         | 232        |\n",
      "|    total_timesteps      | 209920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77320355 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0672    |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00657   |\n",
      "|    n_updates            | 27863      |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    value_loss           | 0.147      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=41.37 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 41.4     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 210000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.457802 |\n",
      "|    clip_fraction        | 0.173    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.135   |\n",
      "|    explained_variance   | 0.845    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0705  |\n",
      "|    n_updates            | 27880    |\n",
      "|    policy_gradient_loss | -0.081   |\n",
      "|    value_loss           | 0.174    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1641     |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 210048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1642       |\n",
      "|    time_elapsed         | 233        |\n",
      "|    total_timesteps      | 210176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38857514 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 27897      |\n",
      "|    policy_gradient_loss | -0.0674    |\n",
      "|    value_loss           | 0.0691     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1643       |\n",
      "|    time_elapsed         | 233        |\n",
      "|    total_timesteps      | 210304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43602374 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.168     |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.697      |\n",
      "|    n_updates            | 27914      |\n",
      "|    policy_gradient_loss | -0.0527    |\n",
      "|    value_loss           | 2.04       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1644      |\n",
      "|    time_elapsed         | 233       |\n",
      "|    total_timesteps      | 210432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2178641 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0972   |\n",
      "|    explained_variance   | 0.0558    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.176     |\n",
      "|    n_updates            | 27931     |\n",
      "|    policy_gradient_loss | -0.0282   |\n",
      "|    value_loss           | 0.792     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=210500, episode_reward=32.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 32.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 210500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25056177 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | -0.757     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0393    |\n",
      "|    n_updates            | 27948      |\n",
      "|    policy_gradient_loss | -0.0617    |\n",
      "|    value_loss           | 0.0512     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1645     |\n",
      "|    time_elapsed    | 233      |\n",
      "|    total_timesteps | 210560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1646      |\n",
      "|    time_elapsed         | 233       |\n",
      "|    total_timesteps      | 210688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0890869 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0518   |\n",
      "|    explained_variance   | -0.876    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0396   |\n",
      "|    n_updates            | 27965     |\n",
      "|    policy_gradient_loss | -0.0361   |\n",
      "|    value_loss           | 0.026     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1647      |\n",
      "|    time_elapsed         | 233       |\n",
      "|    total_timesteps      | 210816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4671557 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0707   |\n",
      "|    explained_variance   | -0.56     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.105    |\n",
      "|    n_updates            | 27982     |\n",
      "|    policy_gradient_loss | -0.0483   |\n",
      "|    value_loss           | 0.0168    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1648       |\n",
      "|    time_elapsed         | 233        |\n",
      "|    total_timesteps      | 210944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13810948 |\n",
      "|    clip_fraction        | 0.0446     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.037     |\n",
      "|    explained_variance   | 0.44       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0152    |\n",
      "|    n_updates            | 27999      |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 0.0385     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=211000, episode_reward=33.46 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 211000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49032393 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0746    |\n",
      "|    explained_variance   | 0.302      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 28016      |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.293      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1649     |\n",
      "|    time_elapsed    | 233      |\n",
      "|    total_timesteps | 211072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1650       |\n",
      "|    time_elapsed         | 234        |\n",
      "|    total_timesteps      | 211200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57419485 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.1       |\n",
      "|    n_updates            | 28033      |\n",
      "|    policy_gradient_loss | -0.0698    |\n",
      "|    value_loss           | 0.046      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1651       |\n",
      "|    time_elapsed         | 234        |\n",
      "|    total_timesteps      | 211328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27959275 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | -0.658     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0344     |\n",
      "|    n_updates            | 28050      |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    value_loss           | 0.754      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1652      |\n",
      "|    time_elapsed         | 234       |\n",
      "|    total_timesteps      | 211456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8242479 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0858   |\n",
      "|    explained_variance   | 0.797     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0616    |\n",
      "|    n_updates            | 28067     |\n",
      "|    policy_gradient_loss | -0.0591   |\n",
      "|    value_loss           | 0.463     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=211500, episode_reward=30.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 211500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24237621 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.675      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 28084      |\n",
      "|    policy_gradient_loss | -0.0557    |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1653     |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 211584   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1654      |\n",
      "|    time_elapsed         | 234       |\n",
      "|    total_timesteps      | 211712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1793512 |\n",
      "|    clip_fraction        | 0.0722    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0986   |\n",
      "|    explained_variance   | -0.567    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 1.57      |\n",
      "|    n_updates            | 28101     |\n",
      "|    policy_gradient_loss | -0.0318   |\n",
      "|    value_loss           | 2.99      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1655       |\n",
      "|    time_elapsed         | 234        |\n",
      "|    total_timesteps      | 211840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32943252 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.13      |\n",
      "|    explained_variance   | 0.0698     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0263    |\n",
      "|    n_updates            | 28118      |\n",
      "|    policy_gradient_loss | -0.0678    |\n",
      "|    value_loss           | 0.637      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1656       |\n",
      "|    time_elapsed         | 234        |\n",
      "|    total_timesteps      | 211968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21524848 |\n",
      "|    clip_fraction        | 0.0676     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0639    |\n",
      "|    explained_variance   | -1.36      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00463   |\n",
      "|    n_updates            | 28135      |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.0365     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=212000, episode_reward=21.47 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 21.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 212000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16624291 |\n",
      "|    clip_fraction        | 0.0666     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0736    |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0227    |\n",
      "|    n_updates            | 28152      |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.0279     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1657     |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 212096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1658      |\n",
      "|    time_elapsed         | 235       |\n",
      "|    total_timesteps      | 212224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3337856 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.132    |\n",
      "|    explained_variance   | 0.0167    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0651   |\n",
      "|    n_updates            | 28169     |\n",
      "|    policy_gradient_loss | -0.064    |\n",
      "|    value_loss           | 0.0198    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1659      |\n",
      "|    time_elapsed         | 235       |\n",
      "|    total_timesteps      | 212352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8036037 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | -0.262    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.067    |\n",
      "|    n_updates            | 28186     |\n",
      "|    policy_gradient_loss | -0.0626   |\n",
      "|    value_loss           | 0.12      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1660      |\n",
      "|    time_elapsed         | 235       |\n",
      "|    total_timesteps      | 212480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7395433 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.117     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0586   |\n",
      "|    n_updates            | 28203     |\n",
      "|    policy_gradient_loss | -0.054    |\n",
      "|    value_loss           | 0.0916    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=212500, episode_reward=53.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 53.3     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 212500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.226084 |\n",
      "|    clip_fraction        | 0.116    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.102   |\n",
      "|    explained_variance   | 0.778    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0957  |\n",
      "|    n_updates            | 28220    |\n",
      "|    policy_gradient_loss | -0.0576  |\n",
      "|    value_loss           | 0.0737   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1661     |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 212608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1662       |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 212736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31399843 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.257      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0766    |\n",
      "|    n_updates            | 28237      |\n",
      "|    policy_gradient_loss | -0.0573    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1663       |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 212864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76185036 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.096     |\n",
      "|    n_updates            | 28254      |\n",
      "|    policy_gradient_loss | -0.0774    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1664       |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46658447 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0166    |\n",
      "|    n_updates            | 28271      |\n",
      "|    policy_gradient_loss | -0.0583    |\n",
      "|    value_loss           | 0.144      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=213000, episode_reward=35.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 213000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22964497 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.138     |\n",
      "|    explained_variance   | 0.485      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0516    |\n",
      "|    n_updates            | 28288      |\n",
      "|    policy_gradient_loss | -0.0785    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1665     |\n",
      "|    time_elapsed    | 236      |\n",
      "|    total_timesteps | 213120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1666       |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 213248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30595288 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.201     |\n",
      "|    explained_variance   | 0.632      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.152      |\n",
      "|    n_updates            | 28305      |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    value_loss           | 1.42       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1667       |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 213376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46795928 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 28322      |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.0731     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=213500, episode_reward=69.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 69.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 213500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32521683 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.105     |\n",
      "|    explained_variance   | -0.613     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0887    |\n",
      "|    n_updates            | 28339      |\n",
      "|    policy_gradient_loss | -0.0731    |\n",
      "|    value_loss           | 0.0242     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1668     |\n",
      "|    time_elapsed    | 236      |\n",
      "|    total_timesteps | 213504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1669       |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 213632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.72988546 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | -0.786     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 28356      |\n",
      "|    policy_gradient_loss | -0.0872    |\n",
      "|    value_loss           | 0.0104     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1670       |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 213760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47963765 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | -0.359     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0466    |\n",
      "|    n_updates            | 28373      |\n",
      "|    policy_gradient_loss | -0.0598    |\n",
      "|    value_loss           | 0.0329     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1671      |\n",
      "|    time_elapsed         | 236       |\n",
      "|    total_timesteps      | 213888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6950594 |\n",
      "|    clip_fraction        | 0.208     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.106     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0283   |\n",
      "|    n_updates            | 28390     |\n",
      "|    policy_gradient_loss | -0.0706   |\n",
      "|    value_loss           | 0.0828    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=214000, episode_reward=38.82 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 38.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 214000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5454309 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.126    |\n",
      "|    explained_variance   | 0.878     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0961   |\n",
      "|    n_updates            | 28407     |\n",
      "|    policy_gradient_loss | -0.0636   |\n",
      "|    value_loss           | 0.0641    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1672     |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 214016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1673       |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 214144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36956975 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.151     |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.117     |\n",
      "|    n_updates            | 28424      |\n",
      "|    policy_gradient_loss | -0.0713    |\n",
      "|    value_loss           | 0.0492     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1674       |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 214272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44662595 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0937    |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0987    |\n",
      "|    n_updates            | 28441      |\n",
      "|    policy_gradient_loss | -0.0766    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1675      |\n",
      "|    time_elapsed         | 237       |\n",
      "|    total_timesteps      | 214400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8369262 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0972   |\n",
      "|    explained_variance   | 0.824     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0945   |\n",
      "|    n_updates            | 28458     |\n",
      "|    policy_gradient_loss | -0.0797   |\n",
      "|    value_loss           | 0.245     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=214500, episode_reward=29.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 214500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18060215 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0995    |\n",
      "|    n_updates            | 28475      |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1676     |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 214528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1677       |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 214656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42803943 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.157     |\n",
      "|    explained_variance   | 0.915      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000957  |\n",
      "|    n_updates            | 28492      |\n",
      "|    policy_gradient_loss | -0.0641    |\n",
      "|    value_loss           | 0.235      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1678      |\n",
      "|    time_elapsed         | 237       |\n",
      "|    total_timesteps      | 214784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3763818 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.132    |\n",
      "|    explained_variance   | 0.693     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0796   |\n",
      "|    n_updates            | 28509     |\n",
      "|    policy_gradient_loss | -0.0654   |\n",
      "|    value_loss           | 0.215     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1679      |\n",
      "|    time_elapsed         | 237       |\n",
      "|    total_timesteps      | 214912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2938246 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.177    |\n",
      "|    explained_variance   | -1.18     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0911   |\n",
      "|    n_updates            | 28526     |\n",
      "|    policy_gradient_loss | -0.0802   |\n",
      "|    value_loss           | 0.0438    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=11.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 11.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 215000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55361587 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.196     |\n",
      "|    explained_variance   | -0.0563    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 28543      |\n",
      "|    policy_gradient_loss | -0.0906    |\n",
      "|    value_loss           | 0.0316     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1680     |\n",
      "|    time_elapsed    | 238      |\n",
      "|    total_timesteps | 215040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1681       |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 215168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67051625 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.166     |\n",
      "|    explained_variance   | 0.0618     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0944    |\n",
      "|    n_updates            | 28560      |\n",
      "|    policy_gradient_loss | -0.0753    |\n",
      "|    value_loss           | 0.022      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1682       |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 215296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67917657 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0887    |\n",
      "|    explained_variance   | -0.715     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0823    |\n",
      "|    n_updates            | 28577      |\n",
      "|    policy_gradient_loss | -0.0792    |\n",
      "|    value_loss           | 0.0678     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1683       |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 215424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35095638 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0966    |\n",
      "|    n_updates            | 28594      |\n",
      "|    policy_gradient_loss | -0.0599    |\n",
      "|    value_loss           | 0.0644     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=215500, episode_reward=30.26 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 215500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37439376 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.152     |\n",
      "|    n_updates            | 28611      |\n",
      "|    policy_gradient_loss | -0.0774    |\n",
      "|    value_loss           | 0.074      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1684     |\n",
      "|    time_elapsed    | 238      |\n",
      "|    total_timesteps | 215552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1685       |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 215680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57117015 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.151     |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0962    |\n",
      "|    n_updates            | 28628      |\n",
      "|    policy_gradient_loss | -0.0646    |\n",
      "|    value_loss           | 0.234      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1686       |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 215808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43892634 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0941    |\n",
      "|    n_updates            | 28645      |\n",
      "|    policy_gradient_loss | -0.0868    |\n",
      "|    value_loss           | 0.307      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 1687       |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 215936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44091076 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | 0.327      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0403    |\n",
      "|    n_updates            | 28662      |\n",
      "|    policy_gradient_loss | -0.0644    |\n",
      "|    value_loss           | 0.159      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=216000, episode_reward=71.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 71.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 216000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25600237 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.562      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0516     |\n",
      "|    n_updates            | 28679      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.803      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1688     |\n",
      "|    time_elapsed    | 239      |\n",
      "|    total_timesteps | 216064   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 46.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 903      |\n",
      "|    iterations           | 1689     |\n",
      "|    time_elapsed         | 239      |\n",
      "|    total_timesteps      | 216192   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.51653  |\n",
      "|    clip_fraction        | 0.182    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.148   |\n",
      "|    explained_variance   | 0.221    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0523  |\n",
      "|    n_updates            | 28696    |\n",
      "|    policy_gradient_loss | -0.0796  |\n",
      "|    value_loss           | 0.345    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1690       |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 216320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47875044 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | -0.479     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0927    |\n",
      "|    n_updates            | 28713      |\n",
      "|    policy_gradient_loss | -0.0711    |\n",
      "|    value_loss           | 0.0386     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1691      |\n",
      "|    time_elapsed         | 239       |\n",
      "|    total_timesteps      | 216448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6851682 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.222    |\n",
      "|    explained_variance   | 0.463     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.167    |\n",
      "|    n_updates            | 28730     |\n",
      "|    policy_gradient_loss | -0.118    |\n",
      "|    value_loss           | 0.0231    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=216500, episode_reward=34.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 216500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41111678 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.196     |\n",
      "|    explained_variance   | 0.422      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.072     |\n",
      "|    n_updates            | 28747      |\n",
      "|    policy_gradient_loss | -0.0983    |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1692     |\n",
      "|    time_elapsed    | 239      |\n",
      "|    total_timesteps | 216576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1693       |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 216704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47943285 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | -0.0832    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0777    |\n",
      "|    n_updates            | 28764      |\n",
      "|    policy_gradient_loss | -0.0796    |\n",
      "|    value_loss           | 0.0225     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1694       |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 216832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41131118 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | -0.229     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0502    |\n",
      "|    n_updates            | 28781      |\n",
      "|    policy_gradient_loss | -0.0482    |\n",
      "|    value_loss           | 0.0471     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1695      |\n",
      "|    time_elapsed         | 240       |\n",
      "|    total_timesteps      | 216960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3731275 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.116    |\n",
      "|    explained_variance   | 0.723     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0514   |\n",
      "|    n_updates            | 28798     |\n",
      "|    policy_gradient_loss | -0.058    |\n",
      "|    value_loss           | 0.0896    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=217000, episode_reward=43.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 217000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16032207 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00197   |\n",
      "|    n_updates            | 28815      |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1696     |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 217088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1697      |\n",
      "|    time_elapsed         | 240       |\n",
      "|    total_timesteps      | 217216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1522638 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.49      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0165   |\n",
      "|    n_updates            | 28832     |\n",
      "|    policy_gradient_loss | -0.0606   |\n",
      "|    value_loss           | 0.479     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1698       |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 217344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33839884 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0346    |\n",
      "|    n_updates            | 28849      |\n",
      "|    policy_gradient_loss | -0.0762    |\n",
      "|    value_loss           | 0.312      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 1699      |\n",
      "|    time_elapsed         | 240       |\n",
      "|    total_timesteps      | 217472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2539593 |\n",
      "|    clip_fraction        | 0.091     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.515     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0722   |\n",
      "|    n_updates            | 28866     |\n",
      "|    policy_gradient_loss | -0.0468   |\n",
      "|    value_loss           | 0.28      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=217500, episode_reward=49.56 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 49.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 217500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35574645 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.159     |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.318      |\n",
      "|    n_updates            | 28883      |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 1.63       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 1700     |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 217600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 1701       |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 217728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63746834 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.16      |\n",
      "|    explained_variance   | 0.121      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0635    |\n",
      "|    n_updates            | 28900      |\n",
      "|    policy_gradient_loss | -0.0825    |\n",
      "|    value_loss           | 0.0651     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1702       |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 217856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39028138 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.162     |\n",
      "|    explained_variance   | -0.427     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.115     |\n",
      "|    n_updates            | 28917      |\n",
      "|    policy_gradient_loss | -0.0861    |\n",
      "|    value_loss           | 0.0259     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1703      |\n",
      "|    time_elapsed         | 241       |\n",
      "|    total_timesteps      | 217984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2616287 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0835   |\n",
      "|    explained_variance   | -0.274    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0444   |\n",
      "|    n_updates            | 28934     |\n",
      "|    policy_gradient_loss | -0.0472   |\n",
      "|    value_loss           | 0.0234    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=218000, episode_reward=51.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 51.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 218000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.84283835 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | -0.023     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.151     |\n",
      "|    n_updates            | 28951      |\n",
      "|    policy_gradient_loss | -0.0895    |\n",
      "|    value_loss           | 0.0161     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1704     |\n",
      "|    time_elapsed    | 241      |\n",
      "|    total_timesteps | 218112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1705      |\n",
      "|    time_elapsed         | 241       |\n",
      "|    total_timesteps      | 218240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3825429 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.206     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0104   |\n",
      "|    n_updates            | 28968     |\n",
      "|    policy_gradient_loss | -0.0624   |\n",
      "|    value_loss           | 0.07      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1706       |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 218368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35393348 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.83       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.068     |\n",
      "|    n_updates            | 28985      |\n",
      "|    policy_gradient_loss | -0.0712    |\n",
      "|    value_loss           | 0.0702     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1707       |\n",
      "|    time_elapsed         | 242        |\n",
      "|    total_timesteps      | 218496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27199185 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.123     |\n",
      "|    explained_variance   | 0.523      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0379    |\n",
      "|    n_updates            | 29002      |\n",
      "|    policy_gradient_loss | -0.073     |\n",
      "|    value_loss           | 0.0921     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=218500, episode_reward=10.99 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 11       |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 218500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.513076 |\n",
      "|    clip_fraction        | 0.15     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.107   |\n",
      "|    explained_variance   | 0.774    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0619  |\n",
      "|    n_updates            | 29019    |\n",
      "|    policy_gradient_loss | -0.0765  |\n",
      "|    value_loss           | 0.332    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1708     |\n",
      "|    time_elapsed    | 242      |\n",
      "|    total_timesteps | 218624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1709       |\n",
      "|    time_elapsed         | 242        |\n",
      "|    total_timesteps      | 218752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32368523 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0759    |\n",
      "|    explained_variance   | 0.586      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0254    |\n",
      "|    n_updates            | 29036      |\n",
      "|    policy_gradient_loss | -0.0508    |\n",
      "|    value_loss           | 0.256      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1710       |\n",
      "|    time_elapsed         | 242        |\n",
      "|    total_timesteps      | 218880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15666641 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.199     |\n",
      "|    explained_variance   | 0.476      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0639    |\n",
      "|    n_updates            | 29053      |\n",
      "|    policy_gradient_loss | -0.0798    |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=219000, episode_reward=20.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 219000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27131957 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.323      |\n",
      "|    n_updates            | 29070      |\n",
      "|    policy_gradient_loss | -0.0603    |\n",
      "|    value_loss           | 0.757      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1711     |\n",
      "|    time_elapsed    | 242      |\n",
      "|    total_timesteps | 219008   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1712      |\n",
      "|    time_elapsed         | 243       |\n",
      "|    total_timesteps      | 219136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7321107 |\n",
      "|    clip_fraction        | 0.194     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.143    |\n",
      "|    explained_variance   | 0.515     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0238   |\n",
      "|    n_updates            | 29087     |\n",
      "|    policy_gradient_loss | -0.0693   |\n",
      "|    value_loss           | 0.265     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1713       |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 219264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69910955 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.00314    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.152     |\n",
      "|    n_updates            | 29104      |\n",
      "|    policy_gradient_loss | -0.0589    |\n",
      "|    value_loss           | 0.0471     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1714       |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 219392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32445845 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | -1.37      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0698    |\n",
      "|    n_updates            | 29121      |\n",
      "|    policy_gradient_loss | -0.0591    |\n",
      "|    value_loss           | 0.0248     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=219500, episode_reward=37.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 37.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 219500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42790836 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0929    |\n",
      "|    explained_variance   | -0.971     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 29138      |\n",
      "|    policy_gradient_loss | -0.0735    |\n",
      "|    value_loss           | 0.0153     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1715     |\n",
      "|    time_elapsed    | 243      |\n",
      "|    total_timesteps | 219520   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1716      |\n",
      "|    time_elapsed         | 243       |\n",
      "|    total_timesteps      | 219648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7626169 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.13     |\n",
      "|    explained_variance   | -0.204    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.122    |\n",
      "|    n_updates            | 29155     |\n",
      "|    policy_gradient_loss | -0.0814   |\n",
      "|    value_loss           | 0.0744    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1717      |\n",
      "|    time_elapsed         | 243       |\n",
      "|    total_timesteps      | 219776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3492745 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.751     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 29172     |\n",
      "|    policy_gradient_loss | -0.0533   |\n",
      "|    value_loss           | 0.0614    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1718       |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 219904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58345693 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.773      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 29189      |\n",
      "|    policy_gradient_loss | -0.0812    |\n",
      "|    value_loss           | 0.0455     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=29.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 220000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46918038 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.726      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.115     |\n",
      "|    n_updates            | 29206      |\n",
      "|    policy_gradient_loss | -0.0784    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1719     |\n",
      "|    time_elapsed    | 244      |\n",
      "|    total_timesteps | 220032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1720       |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 220160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55148476 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0816    |\n",
      "|    explained_variance   | 0.0319     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0168     |\n",
      "|    n_updates            | 29223      |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    value_loss           | 0.566      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1721       |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 220288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33333185 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.139     |\n",
      "|    explained_variance   | 0.321      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0973    |\n",
      "|    n_updates            | 29240      |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1722      |\n",
      "|    time_elapsed         | 244       |\n",
      "|    total_timesteps      | 220416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4537982 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.655     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00244   |\n",
      "|    n_updates            | 29257     |\n",
      "|    policy_gradient_loss | -0.0499   |\n",
      "|    value_loss           | 0.403     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=220500, episode_reward=44.94 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 44.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 220500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5322822 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.105    |\n",
      "|    explained_variance   | 0.623     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0221   |\n",
      "|    n_updates            | 29274     |\n",
      "|    policy_gradient_loss | -0.0669   |\n",
      "|    value_loss           | 0.309     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1723     |\n",
      "|    time_elapsed    | 244      |\n",
      "|    total_timesteps | 220544   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1724      |\n",
      "|    time_elapsed         | 244       |\n",
      "|    total_timesteps      | 220672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6759144 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0996   |\n",
      "|    explained_variance   | 0.162     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.16     |\n",
      "|    n_updates            | 29291     |\n",
      "|    policy_gradient_loss | -0.0839   |\n",
      "|    value_loss           | 0.0142    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1725       |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 220800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39317837 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | -0.144     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 29308      |\n",
      "|    policy_gradient_loss | -0.0746    |\n",
      "|    value_loss           | 0.0118     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1726       |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 220928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29944307 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | -0.065     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0959    |\n",
      "|    n_updates            | 29325      |\n",
      "|    policy_gradient_loss | -0.0808    |\n",
      "|    value_loss           | 0.0215     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=221000, episode_reward=40.97 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 221000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5003863 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0959   |\n",
      "|    explained_variance   | 0.316     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0897   |\n",
      "|    n_updates            | 29342     |\n",
      "|    policy_gradient_loss | -0.0605   |\n",
      "|    value_loss           | 0.0728    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1727     |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 221056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1728      |\n",
      "|    time_elapsed         | 245       |\n",
      "|    total_timesteps      | 221184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8588118 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0747   |\n",
      "|    explained_variance   | 0.568     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0596   |\n",
      "|    n_updates            | 29359     |\n",
      "|    policy_gradient_loss | -0.0578   |\n",
      "|    value_loss           | 0.0588    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1729       |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 221312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62693286 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0932    |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.127     |\n",
      "|    n_updates            | 29376      |\n",
      "|    policy_gradient_loss | -0.0839    |\n",
      "|    value_loss           | 0.059      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1730      |\n",
      "|    time_elapsed         | 245       |\n",
      "|    total_timesteps      | 221440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2550279 |\n",
      "|    clip_fraction        | 0.0763    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0618   |\n",
      "|    explained_variance   | 0.595     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0169   |\n",
      "|    n_updates            | 29393     |\n",
      "|    policy_gradient_loss | -0.0373   |\n",
      "|    value_loss           | 0.0954    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=221500, episode_reward=42.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 42.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 221500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25285214 |\n",
      "|    clip_fraction        | 0.0593     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0789    |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0206     |\n",
      "|    n_updates            | 29410      |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    value_loss           | 0.655      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1731     |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 221568   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 46.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 1732     |\n",
      "|    time_elapsed         | 246      |\n",
      "|    total_timesteps      | 221696   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.625882 |\n",
      "|    clip_fraction        | 0.108    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0838  |\n",
      "|    explained_variance   | 0.696    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0691  |\n",
      "|    n_updates            | 29427    |\n",
      "|    policy_gradient_loss | -0.0443  |\n",
      "|    value_loss           | 0.132    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1733       |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 221824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43398887 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0279     |\n",
      "|    n_updates            | 29444      |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    value_loss           | 0.157      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1734       |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 221952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76300293 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0439    |\n",
      "|    n_updates            | 29461      |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    value_loss           | 0.414      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=222000, episode_reward=43.42 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 43.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 222000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49358898 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0888    |\n",
      "|    n_updates            | 29478      |\n",
      "|    policy_gradient_loss | -0.0711    |\n",
      "|    value_loss           | 0.0779     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1735     |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 222080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1736       |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 222208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30671507 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0849    |\n",
      "|    n_updates            | 29495      |\n",
      "|    policy_gradient_loss | -0.0684    |\n",
      "|    value_loss           | 0.0568     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1737      |\n",
      "|    time_elapsed         | 246       |\n",
      "|    total_timesteps      | 222336    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2712003 |\n",
      "|    clip_fraction        | 0.186     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.152    |\n",
      "|    explained_variance   | 0.526     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 29512     |\n",
      "|    policy_gradient_loss | -0.0684   |\n",
      "|    value_loss           | 0.0276    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1738       |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 222464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20655924 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0834    |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0855    |\n",
      "|    n_updates            | 29529      |\n",
      "|    policy_gradient_loss | -0.055     |\n",
      "|    value_loss           | 0.0202     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=222500, episode_reward=34.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 34.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 222500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40927908 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0881    |\n",
      "|    explained_variance   | 0.513      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0508    |\n",
      "|    n_updates            | 29546      |\n",
      "|    policy_gradient_loss | -0.0589    |\n",
      "|    value_loss           | 0.0646     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1739     |\n",
      "|    time_elapsed    | 247      |\n",
      "|    total_timesteps | 222592   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1740       |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 222720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18091369 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0694    |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.022     |\n",
      "|    n_updates            | 29563      |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 0.071      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1741       |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 222848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29899326 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0791    |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0818    |\n",
      "|    n_updates            | 29580      |\n",
      "|    policy_gradient_loss | -0.0734    |\n",
      "|    value_loss           | 0.0727     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1742       |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 222976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42519513 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.158     |\n",
      "|    explained_variance   | 0.71       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.125     |\n",
      "|    n_updates            | 29597      |\n",
      "|    policy_gradient_loss | -0.0727    |\n",
      "|    value_loss           | 0.325      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=223000, episode_reward=38.41 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 38.4     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 223000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.347446 |\n",
      "|    clip_fraction        | 0.113    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.128   |\n",
      "|    explained_variance   | 0.702    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0476  |\n",
      "|    n_updates            | 29614    |\n",
      "|    policy_gradient_loss | -0.0453  |\n",
      "|    value_loss           | 0.304    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1743     |\n",
      "|    time_elapsed    | 247      |\n",
      "|    total_timesteps | 223104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1744       |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16661727 |\n",
      "|    clip_fraction        | 0.0938     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0854    |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0435    |\n",
      "|    n_updates            | 29631      |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.146      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1745      |\n",
      "|    time_elapsed         | 247       |\n",
      "|    total_timesteps      | 223360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3163873 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.198    |\n",
      "|    explained_variance   | 0.524     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.271     |\n",
      "|    n_updates            | 29648     |\n",
      "|    policy_gradient_loss | -0.06     |\n",
      "|    value_loss           | 1.32      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1746      |\n",
      "|    time_elapsed         | 247       |\n",
      "|    total_timesteps      | 223488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2129038 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.141    |\n",
      "|    explained_variance   | 0.763     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0403    |\n",
      "|    n_updates            | 29665     |\n",
      "|    policy_gradient_loss | -0.0586   |\n",
      "|    value_loss           | 0.328     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=223500, episode_reward=4.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 4.55      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 223500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3020429 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.169    |\n",
      "|    explained_variance   | -0.0432   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0543   |\n",
      "|    n_updates            | 29682     |\n",
      "|    policy_gradient_loss | -0.0765   |\n",
      "|    value_loss           | 0.0478    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1747     |\n",
      "|    time_elapsed    | 248      |\n",
      "|    total_timesteps | 223616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1748       |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 223744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.54289997 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | 0.0648     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0933    |\n",
      "|    n_updates            | 29699      |\n",
      "|    policy_gradient_loss | -0.0609    |\n",
      "|    value_loss           | 0.0247     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1749       |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 223872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23109643 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0759    |\n",
      "|    explained_variance   | -0.781     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 29716      |\n",
      "|    policy_gradient_loss | -0.0634    |\n",
      "|    value_loss           | 0.0136     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=5.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 5.5      |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 224000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.949769 |\n",
      "|    clip_fraction        | 0.122    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0908  |\n",
      "|    explained_variance   | 0.563    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0964  |\n",
      "|    n_updates            | 29733    |\n",
      "|    policy_gradient_loss | -0.0532  |\n",
      "|    value_loss           | 0.0259   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1750     |\n",
      "|    time_elapsed    | 248      |\n",
      "|    total_timesteps | 224000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1751       |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 224128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20880881 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.105     |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0387    |\n",
      "|    n_updates            | 29750      |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.135      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 46.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1752      |\n",
      "|    time_elapsed         | 248       |\n",
      "|    total_timesteps      | 224256    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3466159 |\n",
      "|    clip_fraction        | 0.0616    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0595   |\n",
      "|    explained_variance   | 0.35      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0219   |\n",
      "|    n_updates            | 29767     |\n",
      "|    policy_gradient_loss | -0.0326   |\n",
      "|    value_loss           | 0.0481    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1753       |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 224384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36078256 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0857    |\n",
      "|    explained_variance   | 0.609      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 29784      |\n",
      "|    policy_gradient_loss | -0.0607    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=224500, episode_reward=5.13 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 5.13      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 224500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3497639 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.175    |\n",
      "|    explained_variance   | 0.432     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0638   |\n",
      "|    n_updates            | 29801     |\n",
      "|    policy_gradient_loss | -0.0497   |\n",
      "|    value_loss           | 0.537     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 46.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1754     |\n",
      "|    time_elapsed    | 249      |\n",
      "|    total_timesteps | 224512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1755       |\n",
      "|    time_elapsed         | 249        |\n",
      "|    total_timesteps      | 224640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37171683 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.158     |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0592    |\n",
      "|    n_updates            | 29818      |\n",
      "|    policy_gradient_loss | -0.0646    |\n",
      "|    value_loss           | 0.0896     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1756      |\n",
      "|    time_elapsed         | 249       |\n",
      "|    total_timesteps      | 224768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5434341 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.257     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0925    |\n",
      "|    n_updates            | 29835     |\n",
      "|    policy_gradient_loss | -0.0651   |\n",
      "|    value_loss           | 1.22      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1757       |\n",
      "|    time_elapsed         | 249        |\n",
      "|    total_timesteps      | 224896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42981386 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.174     |\n",
      "|    explained_variance   | 0.592      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0229     |\n",
      "|    n_updates            | 29852      |\n",
      "|    policy_gradient_loss | -0.0729    |\n",
      "|    value_loss           | 0.495      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=26.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 26.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 225000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46343035 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0692    |\n",
      "|    explained_variance   | -0.914     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.05      |\n",
      "|    n_updates            | 29869      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.033      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1758     |\n",
      "|    time_elapsed    | 249      |\n",
      "|    total_timesteps | 225024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1759       |\n",
      "|    time_elapsed         | 249        |\n",
      "|    total_timesteps      | 225152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37136018 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0431    |\n",
      "|    n_updates            | 29886      |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    value_loss           | 0.0569     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1760       |\n",
      "|    time_elapsed         | 250        |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26314262 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.0658     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 29903      |\n",
      "|    policy_gradient_loss | -0.0847    |\n",
      "|    value_loss           | 0.02       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1761       |\n",
      "|    time_elapsed         | 250        |\n",
      "|    total_timesteps      | 225408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65380013 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0862    |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00897   |\n",
      "|    n_updates            | 29920      |\n",
      "|    policy_gradient_loss | -0.0553    |\n",
      "|    value_loss           | 0.0557     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=225500, episode_reward=12.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 12        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 225500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7305527 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.119    |\n",
      "|    explained_variance   | 0.741     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0515   |\n",
      "|    n_updates            | 29937     |\n",
      "|    policy_gradient_loss | -0.0423   |\n",
      "|    value_loss           | 0.0813    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1762     |\n",
      "|    time_elapsed    | 250      |\n",
      "|    total_timesteps | 225536   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1763      |\n",
      "|    time_elapsed         | 250       |\n",
      "|    total_timesteps      | 225664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8326421 |\n",
      "|    clip_fraction        | 0.215     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0884   |\n",
      "|    explained_variance   | 0.539     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.131    |\n",
      "|    n_updates            | 29954     |\n",
      "|    policy_gradient_loss | -0.0753   |\n",
      "|    value_loss           | 0.0466    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1764       |\n",
      "|    time_elapsed         | 250        |\n",
      "|    total_timesteps      | 225792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33909106 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 29971      |\n",
      "|    policy_gradient_loss | -0.0629    |\n",
      "|    value_loss           | 0.079      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1765      |\n",
      "|    time_elapsed         | 250       |\n",
      "|    total_timesteps      | 225920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1861238 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0977   |\n",
      "|    explained_variance   | -0.00989  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.195     |\n",
      "|    n_updates            | 29988     |\n",
      "|    policy_gradient_loss | -0.0494   |\n",
      "|    value_loss           | 1.47      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=226000, episode_reward=20.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 20.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 226000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3952887 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.173    |\n",
      "|    explained_variance   | 0.671     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0898   |\n",
      "|    n_updates            | 30005     |\n",
      "|    policy_gradient_loss | -0.0817   |\n",
      "|    value_loss           | 0.211     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1766     |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 226048   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1767      |\n",
      "|    time_elapsed         | 251       |\n",
      "|    total_timesteps      | 226176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.4408948 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.762     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.134    |\n",
      "|    n_updates            | 30022     |\n",
      "|    policy_gradient_loss | -0.063    |\n",
      "|    value_loss           | 0.139     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 47.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 1768     |\n",
      "|    time_elapsed         | 251      |\n",
      "|    total_timesteps      | 226304   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.267306 |\n",
      "|    clip_fraction        | 0.156    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.142   |\n",
      "|    explained_variance   | 0.454    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 1.5      |\n",
      "|    n_updates            | 30039    |\n",
      "|    policy_gradient_loss | -0.0538  |\n",
      "|    value_loss           | 2.51     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1769      |\n",
      "|    time_elapsed         | 251       |\n",
      "|    total_timesteps      | 226432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7658802 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0946   |\n",
      "|    explained_variance   | 0.624     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.113     |\n",
      "|    n_updates            | 30056     |\n",
      "|    policy_gradient_loss | -0.0471   |\n",
      "|    value_loss           | 0.124     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=226500, episode_reward=38.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 38.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 226500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24161892 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0915    |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0269    |\n",
      "|    n_updates            | 30073      |\n",
      "|    policy_gradient_loss | -0.0416    |\n",
      "|    value_loss           | 0.0642     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1770     |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 226560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1771      |\n",
      "|    time_elapsed         | 251       |\n",
      "|    total_timesteps      | 226688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2594962 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.157    |\n",
      "|    explained_variance   | -0.193    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0851   |\n",
      "|    n_updates            | 30090     |\n",
      "|    policy_gradient_loss | -0.0635   |\n",
      "|    value_loss           | 0.0174    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1772      |\n",
      "|    time_elapsed         | 251       |\n",
      "|    total_timesteps      | 226816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7785239 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0902   |\n",
      "|    explained_variance   | -0.457    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.149    |\n",
      "|    n_updates            | 30107     |\n",
      "|    policy_gradient_loss | -0.0613   |\n",
      "|    value_loss           | 0.0173    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1773      |\n",
      "|    time_elapsed         | 251       |\n",
      "|    total_timesteps      | 226944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8180311 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0815   |\n",
      "|    explained_variance   | -0.0312   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.026    |\n",
      "|    n_updates            | 30124     |\n",
      "|    policy_gradient_loss | -0.0402   |\n",
      "|    value_loss           | 0.094     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=227000, episode_reward=49.64 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 49.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 227000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60346395 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0799    |\n",
      "|    explained_variance   | 0.759      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0925    |\n",
      "|    n_updates            | 30141      |\n",
      "|    policy_gradient_loss | -0.0555    |\n",
      "|    value_loss           | 0.0899     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1774     |\n",
      "|    time_elapsed    | 252      |\n",
      "|    total_timesteps | 227072   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1775      |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 227200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7200551 |\n",
      "|    clip_fraction        | 0.191     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0965   |\n",
      "|    explained_variance   | 0.428     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0993   |\n",
      "|    n_updates            | 30158     |\n",
      "|    policy_gradient_loss | -0.0548   |\n",
      "|    value_loss           | 0.085     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1776      |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 227328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6210661 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.474     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0569   |\n",
      "|    n_updates            | 30175     |\n",
      "|    policy_gradient_loss | -0.0617   |\n",
      "|    value_loss           | 0.464     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1777       |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 227456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60877067 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.866      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0932    |\n",
      "|    n_updates            | 30192      |\n",
      "|    policy_gradient_loss | -0.0728    |\n",
      "|    value_loss           | 0.249      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=227500, episode_reward=9.39 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 9.39      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 227500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5952288 |\n",
      "|    clip_fraction        | 0.19      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.128    |\n",
      "|    explained_variance   | 0.507     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0953   |\n",
      "|    n_updates            | 30209     |\n",
      "|    policy_gradient_loss | -0.074    |\n",
      "|    value_loss           | 0.0855    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1778     |\n",
      "|    time_elapsed    | 252      |\n",
      "|    total_timesteps | 227584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1779       |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 227712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26769647 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.167     |\n",
      "|    explained_variance   | 0.664      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.609      |\n",
      "|    n_updates            | 30226      |\n",
      "|    policy_gradient_loss | -0.0661    |\n",
      "|    value_loss           | 1.15       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1780      |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 227840    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2920438 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0997   |\n",
      "|    explained_variance   | 0.446     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0695   |\n",
      "|    n_updates            | 30243     |\n",
      "|    policy_gradient_loss | -0.0547   |\n",
      "|    value_loss           | 0.116     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1781      |\n",
      "|    time_elapsed         | 253       |\n",
      "|    total_timesteps      | 227968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2713448 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.148     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0594   |\n",
      "|    n_updates            | 30260     |\n",
      "|    policy_gradient_loss | -0.0629   |\n",
      "|    value_loss           | 0.0584    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=228000, episode_reward=15.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 228000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22372651 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | -0.505     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 30277      |\n",
      "|    policy_gradient_loss | -0.0646    |\n",
      "|    value_loss           | 0.0241     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1782     |\n",
      "|    time_elapsed    | 253      |\n",
      "|    total_timesteps | 228096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1783       |\n",
      "|    time_elapsed         | 253        |\n",
      "|    total_timesteps      | 228224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73956794 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | -0.502     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 30294      |\n",
      "|    policy_gradient_loss | -0.0714    |\n",
      "|    value_loss           | 0.014      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1784      |\n",
      "|    time_elapsed         | 253       |\n",
      "|    total_timesteps      | 228352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0201514 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0587   |\n",
      "|    explained_variance   | -0.179    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0797   |\n",
      "|    n_updates            | 30311     |\n",
      "|    policy_gradient_loss | -0.0568   |\n",
      "|    value_loss           | 0.0565    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1785      |\n",
      "|    time_elapsed         | 253       |\n",
      "|    total_timesteps      | 228480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5630038 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.738     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0534   |\n",
      "|    n_updates            | 30328     |\n",
      "|    policy_gradient_loss | -0.0466   |\n",
      "|    value_loss           | 0.0896    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=228500, episode_reward=30.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 228500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46298566 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.093     |\n",
      "|    explained_variance   | 0.513      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0921    |\n",
      "|    n_updates            | 30345      |\n",
      "|    policy_gradient_loss | -0.0668    |\n",
      "|    value_loss           | 0.0557     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1786     |\n",
      "|    time_elapsed    | 253      |\n",
      "|    total_timesteps | 228608   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1787      |\n",
      "|    time_elapsed         | 253       |\n",
      "|    total_timesteps      | 228736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2884576 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | 0.598     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.034    |\n",
      "|    n_updates            | 30362     |\n",
      "|    policy_gradient_loss | -0.0544   |\n",
      "|    value_loss           | 0.235     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 47.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 1788     |\n",
      "|    time_elapsed         | 254      |\n",
      "|    total_timesteps      | 228864   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.289738 |\n",
      "|    clip_fraction        | 0.112    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.148   |\n",
      "|    explained_variance   | 0.75     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.0632   |\n",
      "|    n_updates            | 30379    |\n",
      "|    policy_gradient_loss | -0.0571  |\n",
      "|    value_loss           | 0.535    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1789       |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 228992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45923814 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.183     |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 30396      |\n",
      "|    policy_gradient_loss | -0.0871    |\n",
      "|    value_loss           | 0.0961     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=229000, episode_reward=18.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 18.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 229000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23310098 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0104    |\n",
      "|    n_updates            | 30413      |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.817      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1790     |\n",
      "|    time_elapsed    | 254      |\n",
      "|    total_timesteps | 229120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 47.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 900         |\n",
      "|    iterations           | 1791        |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 229248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038537443 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0325     |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0379      |\n",
      "|    n_updates            | 30430       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1792      |\n",
      "|    time_elapsed         | 254       |\n",
      "|    total_timesteps      | 229376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7484328 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | -0.287    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0827   |\n",
      "|    n_updates            | 30447     |\n",
      "|    policy_gradient_loss | -0.0453   |\n",
      "|    value_loss           | 0.0347    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=229500, episode_reward=23.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 23.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 229500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12327875 |\n",
      "|    clip_fraction        | 0.0846     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000219  |\n",
      "|    n_updates            | 30464      |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    value_loss           | 0.0666     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1793     |\n",
      "|    time_elapsed    | 254      |\n",
      "|    total_timesteps | 229504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1794       |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 229632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.81479347 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.13      |\n",
      "|    explained_variance   | -2         |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0917    |\n",
      "|    n_updates            | 30481      |\n",
      "|    policy_gradient_loss | -0.0643    |\n",
      "|    value_loss           | 0.031      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1795      |\n",
      "|    time_elapsed         | 255       |\n",
      "|    total_timesteps      | 229760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4661402 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0721   |\n",
      "|    explained_variance   | 0.305     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0524   |\n",
      "|    n_updates            | 30498     |\n",
      "|    policy_gradient_loss | -0.0429   |\n",
      "|    value_loss           | 0.028     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1796       |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 229888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42533627 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0628    |\n",
      "|    n_updates            | 30515      |\n",
      "|    policy_gradient_loss | -0.0625    |\n",
      "|    value_loss           | 0.0811     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=2.51 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.51       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 230000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37154347 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 30532      |\n",
      "|    policy_gradient_loss | -0.068     |\n",
      "|    value_loss           | 0.0711     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1797     |\n",
      "|    time_elapsed    | 255      |\n",
      "|    total_timesteps | 230016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1798       |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 230144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19789028 |\n",
      "|    clip_fraction        | 0.0588     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0452    |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0724    |\n",
      "|    n_updates            | 30549      |\n",
      "|    policy_gradient_loss | -0.0451    |\n",
      "|    value_loss           | 0.143      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1799       |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 230272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26977783 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0756    |\n",
      "|    explained_variance   | 0.156      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0894    |\n",
      "|    n_updates            | 30566      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.325      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1800       |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 230400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20640783 |\n",
      "|    clip_fraction        | 0.0634     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0685    |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00047    |\n",
      "|    n_updates            | 30583      |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230500, episode_reward=10.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 10.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 230500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75296813 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.877      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 30600      |\n",
      "|    policy_gradient_loss | -0.0842    |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1801     |\n",
      "|    time_elapsed    | 255      |\n",
      "|    total_timesteps | 230528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1802      |\n",
      "|    time_elapsed         | 256       |\n",
      "|    total_timesteps      | 230656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1837255 |\n",
      "|    clip_fraction        | 0.0735    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0883   |\n",
      "|    explained_variance   | 0.441     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.239     |\n",
      "|    n_updates            | 30617     |\n",
      "|    policy_gradient_loss | -0.0541   |\n",
      "|    value_loss           | 1.2       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1803       |\n",
      "|    time_elapsed         | 256        |\n",
      "|    total_timesteps      | 230784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39573756 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0905    |\n",
      "|    explained_variance   | -0.0764    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0118    |\n",
      "|    n_updates            | 30634      |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.0518     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1804       |\n",
      "|    time_elapsed         | 256        |\n",
      "|    total_timesteps      | 230912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24849638 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | -0.597     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 30651      |\n",
      "|    policy_gradient_loss | -0.0613    |\n",
      "|    value_loss           | 0.0835     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=231000, episode_reward=-5.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -5.96      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 231000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22855629 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.071     |\n",
      "|    explained_variance   | -0.328     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0201    |\n",
      "|    n_updates            | 30668      |\n",
      "|    policy_gradient_loss | -0.0417    |\n",
      "|    value_loss           | 0.0261     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1805     |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 231040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1806      |\n",
      "|    time_elapsed         | 256       |\n",
      "|    total_timesteps      | 231168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6706077 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | -0.41     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0468   |\n",
      "|    n_updates            | 30685     |\n",
      "|    policy_gradient_loss | -0.0728   |\n",
      "|    value_loss           | 0.0264    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 47.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 1807     |\n",
      "|    time_elapsed         | 256      |\n",
      "|    total_timesteps      | 231296   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.021914 |\n",
      "|    clip_fraction        | 0.185    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.108   |\n",
      "|    explained_variance   | 0.372    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0979  |\n",
      "|    n_updates            | 30702    |\n",
      "|    policy_gradient_loss | -0.0615  |\n",
      "|    value_loss           | 0.0723   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1808       |\n",
      "|    time_elapsed         | 256        |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33781105 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0873    |\n",
      "|    n_updates            | 30719      |\n",
      "|    policy_gradient_loss | -0.0458    |\n",
      "|    value_loss           | 0.0654     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=231500, episode_reward=5.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 5.77      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 231500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2830743 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0826   |\n",
      "|    explained_variance   | 0.791     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0606   |\n",
      "|    n_updates            | 30736     |\n",
      "|    policy_gradient_loss | -0.0504   |\n",
      "|    value_loss           | 0.0446    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1809     |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 231552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1810       |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 231680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.70463693 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.091     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0208    |\n",
      "|    n_updates            | 30753      |\n",
      "|    policy_gradient_loss | -0.0609    |\n",
      "|    value_loss           | 0.478      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 47.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1811       |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 231808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31707013 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0526    |\n",
      "|    n_updates            | 30770      |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    value_loss           | 0.266      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 47.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1812      |\n",
      "|    time_elapsed         | 257       |\n",
      "|    total_timesteps      | 231936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1946324 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.514     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0573   |\n",
      "|    n_updates            | 30787     |\n",
      "|    policy_gradient_loss | -0.042    |\n",
      "|    value_loss           | 0.162     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=232000, episode_reward=-12.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -12.2      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 232000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23163456 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00219   |\n",
      "|    n_updates            | 30804      |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    value_loss           | 0.336      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1813     |\n",
      "|    time_elapsed    | 257      |\n",
      "|    total_timesteps | 232064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1814       |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 232192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22161579 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0852    |\n",
      "|    explained_variance   | 0.0713     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0181    |\n",
      "|    n_updates            | 30821      |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1815       |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 232320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69911826 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | -0.106     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.128     |\n",
      "|    n_updates            | 30838      |\n",
      "|    policy_gradient_loss | -0.0877    |\n",
      "|    value_loss           | 0.059      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1816       |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 232448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34649724 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.551     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0682    |\n",
      "|    n_updates            | 30855      |\n",
      "|    policy_gradient_loss | -0.0711    |\n",
      "|    value_loss           | 0.0295     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=232500, episode_reward=34.98 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 35        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 232500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8336224 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0825   |\n",
      "|    explained_variance   | -0.33     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0849   |\n",
      "|    n_updates            | 30872     |\n",
      "|    policy_gradient_loss | -0.0345   |\n",
      "|    value_loss           | 0.0203    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1817     |\n",
      "|    time_elapsed    | 258      |\n",
      "|    total_timesteps | 232576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1818      |\n",
      "|    time_elapsed         | 258       |\n",
      "|    total_timesteps      | 232704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7109246 |\n",
      "|    clip_fraction        | 0.186     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.105    |\n",
      "|    explained_variance   | 0.201     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.103    |\n",
      "|    n_updates            | 30889     |\n",
      "|    policy_gradient_loss | -0.0716   |\n",
      "|    value_loss           | 0.0391    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1819       |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 232832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48715773 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0974    |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.069     |\n",
      "|    n_updates            | 30906      |\n",
      "|    policy_gradient_loss | -0.0628    |\n",
      "|    value_loss           | 0.0615     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1820       |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 232960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31983137 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0959    |\n",
      "|    explained_variance   | 0.808      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0455    |\n",
      "|    n_updates            | 30923      |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.04       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=233000, episode_reward=33.72 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 233000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47686872 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | 0.406      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0271    |\n",
      "|    n_updates            | 30940      |\n",
      "|    policy_gradient_loss | -0.0775    |\n",
      "|    value_loss           | 0.301      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1821     |\n",
      "|    time_elapsed    | 258      |\n",
      "|    total_timesteps | 233088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1822      |\n",
      "|    time_elapsed         | 258       |\n",
      "|    total_timesteps      | 233216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5611342 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | 0.815     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0987   |\n",
      "|    n_updates            | 30957     |\n",
      "|    policy_gradient_loss | -0.0557   |\n",
      "|    value_loss           | 0.272     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1823       |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 233344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13029686 |\n",
      "|    clip_fraction        | 0.0804     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0898    |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.076     |\n",
      "|    n_updates            | 30974      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1824       |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07813614 |\n",
      "|    clip_fraction        | 0.0561     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.183      |\n",
      "|    n_updates            | 30991      |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 1.03       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=233500, episode_reward=45.84 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 45.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 233500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2977631 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.123    |\n",
      "|    explained_variance   | -0.0848   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0245    |\n",
      "|    n_updates            | 31008     |\n",
      "|    policy_gradient_loss | -0.0559   |\n",
      "|    value_loss           | 0.475     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1825     |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 233600   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1826      |\n",
      "|    time_elapsed         | 259       |\n",
      "|    total_timesteps      | 233728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5145992 |\n",
      "|    clip_fraction        | 0.164     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | -0.33     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0552   |\n",
      "|    n_updates            | 31025     |\n",
      "|    policy_gradient_loss | -0.0715   |\n",
      "|    value_loss           | 0.0253    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1827       |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 233856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41790292 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.129     |\n",
      "|    explained_variance   | -0.791     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 31042      |\n",
      "|    policy_gradient_loss | -0.0731    |\n",
      "|    value_loss           | 0.0274     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1828      |\n",
      "|    time_elapsed         | 259       |\n",
      "|    total_timesteps      | 233984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2592126 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.178    |\n",
      "|    explained_variance   | -1.03     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0837   |\n",
      "|    n_updates            | 31059     |\n",
      "|    policy_gradient_loss | -0.063    |\n",
      "|    value_loss           | 0.00971   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=234000, episode_reward=54.46 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 234000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6728268 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0734   |\n",
      "|    explained_variance   | 0.0854    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0802   |\n",
      "|    n_updates            | 31076     |\n",
      "|    policy_gradient_loss | -0.065    |\n",
      "|    value_loss           | 0.0191    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1829     |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 234112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1830      |\n",
      "|    time_elapsed         | 259       |\n",
      "|    total_timesteps      | 234240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6911288 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.514     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0708   |\n",
      "|    n_updates            | 31093     |\n",
      "|    policy_gradient_loss | -0.0634   |\n",
      "|    value_loss           | 0.0375    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1831      |\n",
      "|    time_elapsed         | 259       |\n",
      "|    total_timesteps      | 234368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3830818 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.123    |\n",
      "|    explained_variance   | 0.828     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0484   |\n",
      "|    n_updates            | 31110     |\n",
      "|    policy_gradient_loss | -0.0594   |\n",
      "|    value_loss           | 0.0428    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1832      |\n",
      "|    time_elapsed         | 260       |\n",
      "|    total_timesteps      | 234496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3806197 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.152    |\n",
      "|    explained_variance   | 0.406     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.139    |\n",
      "|    n_updates            | 31127     |\n",
      "|    policy_gradient_loss | -0.089    |\n",
      "|    value_loss           | 0.116     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=234500, episode_reward=15.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 16        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 234500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3447398 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.119    |\n",
      "|    explained_variance   | 0.505     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0393   |\n",
      "|    n_updates            | 31144     |\n",
      "|    policy_gradient_loss | -0.0694   |\n",
      "|    value_loss           | 0.535     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1833     |\n",
      "|    time_elapsed    | 260      |\n",
      "|    total_timesteps | 234624   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 48.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1834      |\n",
      "|    time_elapsed         | 260       |\n",
      "|    total_timesteps      | 234752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2876785 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.147    |\n",
      "|    explained_variance   | 0.629     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0905   |\n",
      "|    n_updates            | 31161     |\n",
      "|    policy_gradient_loss | -0.0478   |\n",
      "|    value_loss           | 0.107     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1835       |\n",
      "|    time_elapsed         | 260        |\n",
      "|    total_timesteps      | 234880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46366596 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0854    |\n",
      "|    n_updates            | 31178      |\n",
      "|    policy_gradient_loss | -0.0809    |\n",
      "|    value_loss           | 0.231      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=11.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 11.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 235000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1682146 |\n",
      "|    clip_fraction        | 0.096     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.479     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.138     |\n",
      "|    n_updates            | 31195     |\n",
      "|    policy_gradient_loss | -0.0433   |\n",
      "|    value_loss           | 1.22      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1836     |\n",
      "|    time_elapsed    | 260      |\n",
      "|    total_timesteps | 235008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1837       |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 235136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45700118 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0935    |\n",
      "|    n_updates            | 31212      |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.143      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 48.8     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 1838     |\n",
      "|    time_elapsed         | 261      |\n",
      "|    total_timesteps      | 235264   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.672851 |\n",
      "|    clip_fraction        | 0.182    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.149   |\n",
      "|    explained_variance   | -0.119   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0666  |\n",
      "|    n_updates            | 31229    |\n",
      "|    policy_gradient_loss | -0.0686  |\n",
      "|    value_loss           | 0.0596   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1839       |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 235392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26660085 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | -0.735     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0821    |\n",
      "|    n_updates            | 31246      |\n",
      "|    policy_gradient_loss | -0.0526    |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=235500, episode_reward=29.16 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 235500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55546975 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | -0.27      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.119     |\n",
      "|    n_updates            | 31263      |\n",
      "|    policy_gradient_loss | -0.0777    |\n",
      "|    value_loss           | 0.0126     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1840     |\n",
      "|    time_elapsed    | 261      |\n",
      "|    total_timesteps | 235520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1841       |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 235648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42328927 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0638    |\n",
      "|    n_updates            | 31280      |\n",
      "|    policy_gradient_loss | -0.0626    |\n",
      "|    value_loss           | 0.0584     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1842       |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 235776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24077035 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0853    |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.114     |\n",
      "|    n_updates            | 31297      |\n",
      "|    policy_gradient_loss | -0.0455    |\n",
      "|    value_loss           | 0.0511     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1843       |\n",
      "|    time_elapsed         | 261        |\n",
      "|    total_timesteps      | 235904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.66552305 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.16      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 31314      |\n",
      "|    policy_gradient_loss | -0.0943    |\n",
      "|    value_loss           | 0.0699     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=236000, episode_reward=15.49 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 236000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31133515 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.505      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0402    |\n",
      "|    n_updates            | 31331      |\n",
      "|    policy_gradient_loss | -0.0681    |\n",
      "|    value_loss           | 0.432      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 48.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1844     |\n",
      "|    time_elapsed    | 261      |\n",
      "|    total_timesteps | 236032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 48.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1845       |\n",
      "|    time_elapsed         | 262        |\n",
      "|    total_timesteps      | 236160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09794383 |\n",
      "|    clip_fraction        | 0.0602     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0643    |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0718    |\n",
      "|    n_updates            | 31348      |\n",
      "|    policy_gradient_loss | -0.0357    |\n",
      "|    value_loss           | 0.283      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 48.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 901         |\n",
      "|    iterations           | 1846        |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 236288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.093928754 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.126      |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.057      |\n",
      "|    n_updates            | 31365       |\n",
      "|    policy_gradient_loss | -0.0661     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 49.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1847       |\n",
      "|    time_elapsed         | 262        |\n",
      "|    total_timesteps      | 236416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44583818 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.61       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0948     |\n",
      "|    n_updates            | 31382      |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=236500, episode_reward=1.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 1.8        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 236500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37678182 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0791    |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0215     |\n",
      "|    n_updates            | 31399      |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 0.308      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1848     |\n",
      "|    time_elapsed    | 262      |\n",
      "|    total_timesteps | 236544   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1849      |\n",
      "|    time_elapsed         | 262       |\n",
      "|    total_timesteps      | 236672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6958063 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0564   |\n",
      "|    explained_variance   | -0.614    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0616   |\n",
      "|    n_updates            | 31416     |\n",
      "|    policy_gradient_loss | -0.0396   |\n",
      "|    value_loss           | 0.0335    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1850      |\n",
      "|    time_elapsed         | 262       |\n",
      "|    total_timesteps      | 236800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1741056 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0823   |\n",
      "|    explained_variance   | 0.11      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0602   |\n",
      "|    n_updates            | 31433     |\n",
      "|    policy_gradient_loss | -0.0641   |\n",
      "|    value_loss           | 0.00891   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 49.2     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 1851     |\n",
      "|    time_elapsed         | 262      |\n",
      "|    total_timesteps      | 236928   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.585177 |\n",
      "|    clip_fraction        | 0.177    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0873  |\n",
      "|    explained_variance   | 0.478    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0682  |\n",
      "|    n_updates            | 31450    |\n",
      "|    policy_gradient_loss | -0.0616  |\n",
      "|    value_loss           | 0.00815  |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=237000, episode_reward=33.16 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 33.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 237000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5823559 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0962   |\n",
      "|    explained_variance   | 0.205     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0585   |\n",
      "|    n_updates            | 31467     |\n",
      "|    policy_gradient_loss | -0.0558   |\n",
      "|    value_loss           | 0.0519    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1852     |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 237056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1853      |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 237184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3807758 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0769   |\n",
      "|    explained_variance   | 0.736     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0899   |\n",
      "|    n_updates            | 31484     |\n",
      "|    policy_gradient_loss | -0.0498   |\n",
      "|    value_loss           | 0.0686    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1854      |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 237312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3969188 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.135    |\n",
      "|    explained_variance   | 0.469     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0846   |\n",
      "|    n_updates            | 31501     |\n",
      "|    policy_gradient_loss | -0.0677   |\n",
      "|    value_loss           | 0.0848    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1855      |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 237440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8102813 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.695     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 31518     |\n",
      "|    policy_gradient_loss | -0.0877   |\n",
      "|    value_loss           | 0.188     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=237500, episode_reward=-3.07 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -3.07      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 237500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52722335 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.074     |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0416    |\n",
      "|    n_updates            | 31535      |\n",
      "|    policy_gradient_loss | -0.0445    |\n",
      "|    value_loss           | 0.265      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1856     |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1857      |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 237696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9061763 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.144    |\n",
      "|    explained_variance   | 0.387     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 31552     |\n",
      "|    policy_gradient_loss | -0.0825   |\n",
      "|    value_loss           | 0.186     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 49.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1858       |\n",
      "|    time_elapsed         | 263        |\n",
      "|    total_timesteps      | 237824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12374597 |\n",
      "|    clip_fraction        | 0.0804     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0915    |\n",
      "|    explained_variance   | 0.104      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0642     |\n",
      "|    n_updates            | 31569      |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 1.27       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1859      |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 237952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4037062 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0993   |\n",
      "|    explained_variance   | 0.192     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.133     |\n",
      "|    n_updates            | 31586     |\n",
      "|    policy_gradient_loss | -0.0487   |\n",
      "|    value_loss           | 1.16      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=238000, episode_reward=20.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 238000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.69130117 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0767    |\n",
      "|    explained_variance   | -1.27      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.112     |\n",
      "|    n_updates            | 31603      |\n",
      "|    policy_gradient_loss | -0.0759    |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1860     |\n",
      "|    time_elapsed    | 264      |\n",
      "|    total_timesteps | 238080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 49.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1861       |\n",
      "|    time_elapsed         | 264        |\n",
      "|    total_timesteps      | 238208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35927016 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0944    |\n",
      "|    explained_variance   | -0.453     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.14      |\n",
      "|    n_updates            | 31620      |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    value_loss           | 0.0254     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1862      |\n",
      "|    time_elapsed         | 264       |\n",
      "|    total_timesteps      | 238336    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9277806 |\n",
      "|    clip_fraction        | 0.245     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | 0.241     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.163    |\n",
      "|    n_updates            | 31637     |\n",
      "|    policy_gradient_loss | -0.0901   |\n",
      "|    value_loss           | 0.0107    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 49.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 1863     |\n",
      "|    time_elapsed         | 264      |\n",
      "|    total_timesteps      | 238464   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.135522 |\n",
      "|    clip_fraction        | 0.256    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0577  |\n",
      "|    explained_variance   | 0.347    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0846  |\n",
      "|    n_updates            | 31654    |\n",
      "|    policy_gradient_loss | -0.063   |\n",
      "|    value_loss           | 0.0619   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=238500, episode_reward=23.64 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 23.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 238500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76029825 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.512      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0306    |\n",
      "|    n_updates            | 31671      |\n",
      "|    policy_gradient_loss | -0.0548    |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1864     |\n",
      "|    time_elapsed    | 264      |\n",
      "|    total_timesteps | 238592   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 49.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 1865     |\n",
      "|    time_elapsed         | 264      |\n",
      "|    total_timesteps      | 238720   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.390688 |\n",
      "|    clip_fraction        | 0.137    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.108   |\n",
      "|    explained_variance   | -0.109   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0539  |\n",
      "|    n_updates            | 31688    |\n",
      "|    policy_gradient_loss | -0.0501  |\n",
      "|    value_loss           | 0.0703   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 49.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 1866     |\n",
      "|    time_elapsed         | 265      |\n",
      "|    total_timesteps      | 238848   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.448047 |\n",
      "|    clip_fraction        | 0.15     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.123   |\n",
      "|    explained_variance   | -0.784   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0497  |\n",
      "|    n_updates            | 31705    |\n",
      "|    policy_gradient_loss | -0.066   |\n",
      "|    value_loss           | 0.0936   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 49.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1867      |\n",
      "|    time_elapsed         | 265       |\n",
      "|    total_timesteps      | 238976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5358451 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0982   |\n",
      "|    explained_variance   | -0.56     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0434   |\n",
      "|    n_updates            | 31722     |\n",
      "|    policy_gradient_loss | -0.0557   |\n",
      "|    value_loss           | 0.324     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=239000, episode_reward=19.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 239000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25505018 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.168     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 31739      |\n",
      "|    policy_gradient_loss | -0.0526    |\n",
      "|    value_loss           | 0.0949     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1868     |\n",
      "|    time_elapsed    | 265      |\n",
      "|    total_timesteps | 239104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 49.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1869       |\n",
      "|    time_elapsed         | 265        |\n",
      "|    total_timesteps      | 239232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39253807 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.406      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0637    |\n",
      "|    n_updates            | 31756      |\n",
      "|    policy_gradient_loss | -0.0793    |\n",
      "|    value_loss           | 0.25       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 50          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 901         |\n",
      "|    iterations           | 1870        |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 239360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124658056 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0587     |\n",
      "|    explained_variance   | -0.714      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0333      |\n",
      "|    n_updates            | 31773       |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 0.451       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1871      |\n",
      "|    time_elapsed         | 265       |\n",
      "|    total_timesteps      | 239488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7647182 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0838   |\n",
      "|    explained_variance   | 0.678     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.123     |\n",
      "|    n_updates            | 31790     |\n",
      "|    policy_gradient_loss | -0.0386   |\n",
      "|    value_loss           | 0.237     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=239500, episode_reward=46.19 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 46.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 239500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30147538 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0943    |\n",
      "|    explained_variance   | 0.0716     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0534    |\n",
      "|    n_updates            | 31807      |\n",
      "|    policy_gradient_loss | -0.061     |\n",
      "|    value_loss           | 0.0576     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1872     |\n",
      "|    time_elapsed    | 265      |\n",
      "|    total_timesteps | 239616   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1873      |\n",
      "|    time_elapsed         | 265       |\n",
      "|    total_timesteps      | 239744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.7260203 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0602   |\n",
      "|    explained_variance   | 0.452     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0963   |\n",
      "|    n_updates            | 31824     |\n",
      "|    policy_gradient_loss | -0.0617   |\n",
      "|    value_loss           | 0.00913   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1874       |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 239872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.74289346 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0882    |\n",
      "|    explained_variance   | -0.328     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0378    |\n",
      "|    n_updates            | 31841      |\n",
      "|    policy_gradient_loss | -0.0582    |\n",
      "|    value_loss           | 0.0137     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=16.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 240000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67006606 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0931    |\n",
      "|    explained_variance   | 0.246      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 31858      |\n",
      "|    policy_gradient_loss | -0.0763    |\n",
      "|    value_loss           | 0.067      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1875     |\n",
      "|    time_elapsed    | 266      |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1876       |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 240128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39962375 |\n",
      "|    clip_fraction        | 0.0735     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.057     |\n",
      "|    explained_variance   | 0.657      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0733    |\n",
      "|    n_updates            | 31875      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.0467     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1877       |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 240256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18047567 |\n",
      "|    clip_fraction        | 0.0915     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.075     |\n",
      "|    explained_variance   | -0.229     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0513    |\n",
      "|    n_updates            | 31892      |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    value_loss           | 0.0989     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1878      |\n",
      "|    time_elapsed         | 266       |\n",
      "|    total_timesteps      | 240384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2552115 |\n",
      "|    clip_fraction        | 0.101     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0731   |\n",
      "|    explained_variance   | 0.158     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.000658  |\n",
      "|    n_updates            | 31909     |\n",
      "|    policy_gradient_loss | -0.0333   |\n",
      "|    value_loss           | 0.246     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=240500, episode_reward=29.37 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 240500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16905268 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0923    |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0796    |\n",
      "|    n_updates            | 31926      |\n",
      "|    policy_gradient_loss | -0.0631    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1879     |\n",
      "|    time_elapsed    | 266      |\n",
      "|    total_timesteps | 240512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1880       |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 240640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31813183 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0587    |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0145    |\n",
      "|    n_updates            | 31943      |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1881       |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 240768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43764323 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0878    |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.277      |\n",
      "|    n_updates            | 31960      |\n",
      "|    policy_gradient_loss | -0.0566    |\n",
      "|    value_loss           | 0.57       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1882       |\n",
      "|    time_elapsed         | 267        |\n",
      "|    total_timesteps      | 240896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.87290233 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0969    |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00981    |\n",
      "|    n_updates            | 31977      |\n",
      "|    policy_gradient_loss | -0.0655    |\n",
      "|    value_loss           | 0.521      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=241000, episode_reward=36.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 241000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62076277 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0886    |\n",
      "|    explained_variance   | -0.766     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0992    |\n",
      "|    n_updates            | 31994      |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.0736     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1883     |\n",
      "|    time_elapsed    | 267      |\n",
      "|    total_timesteps | 241024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1884      |\n",
      "|    time_elapsed         | 267       |\n",
      "|    total_timesteps      | 241152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6313509 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.154    |\n",
      "|    explained_variance   | -0.125    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.132    |\n",
      "|    n_updates            | 32011     |\n",
      "|    policy_gradient_loss | -0.0695   |\n",
      "|    value_loss           | 0.0284    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 50.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1885     |\n",
      "|    time_elapsed         | 267      |\n",
      "|    total_timesteps      | 241280   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.269676 |\n",
      "|    clip_fraction        | 0.168    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0841  |\n",
      "|    explained_variance   | -0.16    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0494  |\n",
      "|    n_updates            | 32028    |\n",
      "|    policy_gradient_loss | -0.0569  |\n",
      "|    value_loss           | 0.0159   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1886       |\n",
      "|    time_elapsed         | 267        |\n",
      "|    total_timesteps      | 241408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.86227727 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0876    |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0453    |\n",
      "|    n_updates            | 32045      |\n",
      "|    policy_gradient_loss | -0.0651    |\n",
      "|    value_loss           | 0.056      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=241500, episode_reward=-9.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -9.68     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 241500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1766235 |\n",
      "|    clip_fraction        | 0.08      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0651   |\n",
      "|    explained_variance   | 0.675     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0432   |\n",
      "|    n_updates            | 32062     |\n",
      "|    policy_gradient_loss | -0.0248   |\n",
      "|    value_loss           | 0.0467    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1887     |\n",
      "|    time_elapsed    | 267      |\n",
      "|    total_timesteps | 241536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1888       |\n",
      "|    time_elapsed         | 267        |\n",
      "|    total_timesteps      | 241664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35201517 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.0621     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 32079      |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    value_loss           | 0.053      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1889       |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 241792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.90172184 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0751    |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00986   |\n",
      "|    n_updates            | 32096      |\n",
      "|    policy_gradient_loss | -0.0375    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1890      |\n",
      "|    time_elapsed         | 268       |\n",
      "|    total_timesteps      | 241920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1681741 |\n",
      "|    clip_fraction        | 0.0836    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0947   |\n",
      "|    explained_variance   | 0.174     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0121   |\n",
      "|    n_updates            | 32113     |\n",
      "|    policy_gradient_loss | -0.0304   |\n",
      "|    value_loss           | 0.356     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=242000, episode_reward=8.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 8.53       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 242000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24281898 |\n",
      "|    clip_fraction        | 0.0818     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0898    |\n",
      "|    explained_variance   | 0.717      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0623    |\n",
      "|    n_updates            | 32130      |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1891     |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 242048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1892       |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 242176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22197388 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.684      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.016     |\n",
      "|    n_updates            | 32147      |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.366      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1893       |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 242304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38086987 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.154      |\n",
      "|    n_updates            | 32164      |\n",
      "|    policy_gradient_loss | -0.0625    |\n",
      "|    value_loss           | 1.4        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1894      |\n",
      "|    time_elapsed         | 268       |\n",
      "|    total_timesteps      | 242432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6723603 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.138    |\n",
      "|    explained_variance   | 0.0054    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.1      |\n",
      "|    n_updates            | 32181     |\n",
      "|    policy_gradient_loss | -0.0765   |\n",
      "|    value_loss           | 0.0226    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=242500, episode_reward=22.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 22.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 242500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4283686 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.126    |\n",
      "|    explained_variance   | -0.331    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0801   |\n",
      "|    n_updates            | 32198     |\n",
      "|    policy_gradient_loss | -0.0752   |\n",
      "|    value_loss           | 0.0385    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1895     |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 242560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1896       |\n",
      "|    time_elapsed         | 268        |\n",
      "|    total_timesteps      | 242688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15346307 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.151     |\n",
      "|    explained_variance   | -0.862     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 32215      |\n",
      "|    policy_gradient_loss | -0.0653    |\n",
      "|    value_loss           | 0.0178     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1897      |\n",
      "|    time_elapsed         | 269       |\n",
      "|    total_timesteps      | 242816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3097878 |\n",
      "|    clip_fraction        | 0.1       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0811   |\n",
      "|    explained_variance   | -0.167    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0364   |\n",
      "|    n_updates            | 32232     |\n",
      "|    policy_gradient_loss | -0.0426   |\n",
      "|    value_loss           | 0.0355    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1898      |\n",
      "|    time_elapsed         | 269       |\n",
      "|    total_timesteps      | 242944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6622275 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.543     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0755   |\n",
      "|    n_updates            | 32249     |\n",
      "|    policy_gradient_loss | -0.0833   |\n",
      "|    value_loss           | 0.0617    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=243000, episode_reward=4.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.27       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 243000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33902276 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0901    |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0734    |\n",
      "|    n_updates            | 32266      |\n",
      "|    policy_gradient_loss | -0.0706    |\n",
      "|    value_loss           | 0.0402     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1899     |\n",
      "|    time_elapsed    | 269      |\n",
      "|    total_timesteps | 243072   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1900      |\n",
      "|    time_elapsed         | 269       |\n",
      "|    total_timesteps      | 243200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3783752 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | -0.551    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0662   |\n",
      "|    n_updates            | 32283     |\n",
      "|    policy_gradient_loss | -0.0432   |\n",
      "|    value_loss           | 0.0748    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1901      |\n",
      "|    time_elapsed         | 269       |\n",
      "|    total_timesteps      | 243328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3073111 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.739     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0417    |\n",
      "|    n_updates            | 32300     |\n",
      "|    policy_gradient_loss | -0.0503   |\n",
      "|    value_loss           | 0.331     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1902       |\n",
      "|    time_elapsed         | 269        |\n",
      "|    total_timesteps      | 243456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17332268 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.838      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.049     |\n",
      "|    n_updates            | 32317      |\n",
      "|    policy_gradient_loss | -0.038     |\n",
      "|    value_loss           | 0.118      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=243500, episode_reward=36.25 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 36.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 243500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.61229444 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.655      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0813    |\n",
      "|    n_updates            | 32334      |\n",
      "|    policy_gradient_loss | -0.0848    |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1903     |\n",
      "|    time_elapsed    | 269      |\n",
      "|    total_timesteps | 243584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1904       |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 243712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.63181674 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0728    |\n",
      "|    explained_variance   | 0.779      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0624     |\n",
      "|    n_updates            | 32351      |\n",
      "|    policy_gradient_loss | -0.0461    |\n",
      "|    value_loss           | 0.41       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1905      |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 243840    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4505942 |\n",
      "|    clip_fraction        | 0.271     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.149    |\n",
      "|    explained_variance   | 0.206     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.136    |\n",
      "|    n_updates            | 32368     |\n",
      "|    policy_gradient_loss | -0.0746   |\n",
      "|    value_loss           | 0.0737    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1906      |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 243968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3912778 |\n",
      "|    clip_fraction        | 0.236     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.174    |\n",
      "|    explained_variance   | -0.887    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0738   |\n",
      "|    n_updates            | 32385     |\n",
      "|    policy_gradient_loss | -0.0626   |\n",
      "|    value_loss           | 0.0458    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=244000, episode_reward=33.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 33.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 244000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2312577 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.155    |\n",
      "|    explained_variance   | -0.448    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0915   |\n",
      "|    n_updates            | 32402     |\n",
      "|    policy_gradient_loss | -0.0688   |\n",
      "|    value_loss           | 0.00869   |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1907     |\n",
      "|    time_elapsed    | 270      |\n",
      "|    total_timesteps | 244096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1908      |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 244224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.5747337 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0682   |\n",
      "|    explained_variance   | -0.491    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.162    |\n",
      "|    n_updates            | 32419     |\n",
      "|    policy_gradient_loss | -0.108    |\n",
      "|    value_loss           | 0.0107    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1909      |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 244352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5199149 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0997   |\n",
      "|    explained_variance   | 0.407     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0298   |\n",
      "|    n_updates            | 32436     |\n",
      "|    policy_gradient_loss | -0.0658   |\n",
      "|    value_loss           | 0.0605    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1910       |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 244480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12267473 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.743      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0657    |\n",
      "|    n_updates            | 32453      |\n",
      "|    policy_gradient_loss | -0.0554    |\n",
      "|    value_loss           | 0.0321     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=244500, episode_reward=13.65 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 13.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 244500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4465654 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0835   |\n",
      "|    explained_variance   | -0.185    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.061    |\n",
      "|    n_updates            | 32470     |\n",
      "|    policy_gradient_loss | -0.0486   |\n",
      "|    value_loss           | 0.0749    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 1911     |\n",
      "|    time_elapsed    | 271      |\n",
      "|    total_timesteps | 244608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1912       |\n",
      "|    time_elapsed         | 271        |\n",
      "|    total_timesteps      | 244736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30575415 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00693   |\n",
      "|    n_updates            | 32487      |\n",
      "|    policy_gradient_loss | -0.0454    |\n",
      "|    value_loss           | 0.261      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1913      |\n",
      "|    time_elapsed         | 271       |\n",
      "|    total_timesteps      | 244864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5769204 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.126    |\n",
      "|    explained_variance   | 0.757     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0057    |\n",
      "|    n_updates            | 32504     |\n",
      "|    policy_gradient_loss | -0.0576   |\n",
      "|    value_loss           | 0.144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 1914       |\n",
      "|    time_elapsed         | 271        |\n",
      "|    total_timesteps      | 244992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49198705 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 32521      |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=46.30 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 46.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 245000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26191407 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.742      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.127      |\n",
      "|    n_updates            | 32538      |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    value_loss           | 0.515      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1915     |\n",
      "|    time_elapsed    | 271      |\n",
      "|    total_timesteps | 245120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1916       |\n",
      "|    time_elapsed         | 271        |\n",
      "|    total_timesteps      | 245248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.58833337 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0237    |\n",
      "|    n_updates            | 32555      |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    value_loss           | 0.352      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1917       |\n",
      "|    time_elapsed         | 272        |\n",
      "|    total_timesteps      | 245376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42946196 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.128     |\n",
      "|    explained_variance   | -0.161     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0751    |\n",
      "|    n_updates            | 32572      |\n",
      "|    policy_gradient_loss | -0.0958    |\n",
      "|    value_loss           | 0.0781     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=245500, episode_reward=35.71 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 35.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 245500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2787962 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.186    |\n",
      "|    explained_variance   | -0.0239   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.103    |\n",
      "|    n_updates            | 32589     |\n",
      "|    policy_gradient_loss | -0.0588   |\n",
      "|    value_loss           | 0.0386    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1918     |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 245504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1919       |\n",
      "|    time_elapsed         | 272        |\n",
      "|    total_timesteps      | 245632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62303376 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0672    |\n",
      "|    explained_variance   | -0.236     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 32606      |\n",
      "|    policy_gradient_loss | -0.0767    |\n",
      "|    value_loss           | 0.011      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1920       |\n",
      "|    time_elapsed         | 272        |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.89211583 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0902    |\n",
      "|    explained_variance   | 0.207      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.098     |\n",
      "|    n_updates            | 32623      |\n",
      "|    policy_gradient_loss | -0.074     |\n",
      "|    value_loss           | 0.0745     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1921      |\n",
      "|    time_elapsed         | 272       |\n",
      "|    total_timesteps      | 245888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7656235 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0992   |\n",
      "|    explained_variance   | -0.172    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0238   |\n",
      "|    n_updates            | 32640     |\n",
      "|    policy_gradient_loss | -0.0368   |\n",
      "|    value_loss           | 0.0634    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=246000, episode_reward=41.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 246000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3434149 |\n",
      "|    clip_fraction        | 0.198     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0961   |\n",
      "|    explained_variance   | 0.535     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 32657     |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.0702    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1922     |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 246016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1923      |\n",
      "|    time_elapsed         | 273       |\n",
      "|    total_timesteps      | 246144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3758832 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.116    |\n",
      "|    explained_variance   | 0.74      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0597   |\n",
      "|    n_updates            | 32674     |\n",
      "|    policy_gradient_loss | -0.0558   |\n",
      "|    value_loss           | 0.225     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 50.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1924       |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 246272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.98258674 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.664      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 32691      |\n",
      "|    policy_gradient_loss | -0.0647    |\n",
      "|    value_loss           | 0.303      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 50.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1925      |\n",
      "|    time_elapsed         | 273       |\n",
      "|    total_timesteps      | 246400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2661493 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.142    |\n",
      "|    explained_variance   | 0.628     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0715   |\n",
      "|    n_updates            | 32708     |\n",
      "|    policy_gradient_loss | -0.0507   |\n",
      "|    value_loss           | 0.148     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=246500, episode_reward=27.82 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 27.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 246500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12729664 |\n",
      "|    clip_fraction        | 0.097      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0698     |\n",
      "|    n_updates            | 32725      |\n",
      "|    policy_gradient_loss | -0.0352    |\n",
      "|    value_loss           | 0.554      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1926     |\n",
      "|    time_elapsed    | 273      |\n",
      "|    total_timesteps | 246528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1927      |\n",
      "|    time_elapsed         | 273       |\n",
      "|    total_timesteps      | 246656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7571912 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0826   |\n",
      "|    explained_variance   | 0.118     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0791    |\n",
      "|    n_updates            | 32742     |\n",
      "|    policy_gradient_loss | -0.0434   |\n",
      "|    value_loss           | 0.664     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 51       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 1928     |\n",
      "|    time_elapsed         | 273      |\n",
      "|    total_timesteps      | 246784   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.834872 |\n",
      "|    clip_fraction        | 0.158    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.102   |\n",
      "|    explained_variance   | 0.051    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0766  |\n",
      "|    n_updates            | 32759    |\n",
      "|    policy_gradient_loss | -0.0601  |\n",
      "|    value_loss           | 0.0183   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1929       |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 246912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34414196 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.162     |\n",
      "|    explained_variance   | -0.265     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0815    |\n",
      "|    n_updates            | 32776      |\n",
      "|    policy_gradient_loss | -0.0729    |\n",
      "|    value_loss           | 0.0243     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=247000, episode_reward=54.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 247000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77911854 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | -0.26      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.1       |\n",
      "|    n_updates            | 32793      |\n",
      "|    policy_gradient_loss | -0.0662    |\n",
      "|    value_loss           | 0.00992    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1930     |\n",
      "|    time_elapsed    | 274      |\n",
      "|    total_timesteps | 247040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1931      |\n",
      "|    time_elapsed         | 274       |\n",
      "|    total_timesteps      | 247168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.1645133 |\n",
      "|    clip_fraction        | 0.262     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | 0.331     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 32810     |\n",
      "|    policy_gradient_loss | -0.0808   |\n",
      "|    value_loss           | 0.0251    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1932       |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 247296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22159854 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0969    |\n",
      "|    n_updates            | 32827      |\n",
      "|    policy_gradient_loss | -0.0696    |\n",
      "|    value_loss           | 0.061      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1933       |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 247424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30175355 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0676    |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.102     |\n",
      "|    n_updates            | 32844      |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.0469     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=247500, episode_reward=37.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 37.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 247500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42429757 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | 0.0888     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.119     |\n",
      "|    n_updates            | 32861      |\n",
      "|    policy_gradient_loss | -0.0888    |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1934     |\n",
      "|    time_elapsed    | 274      |\n",
      "|    total_timesteps | 247552   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1935      |\n",
      "|    time_elapsed         | 274       |\n",
      "|    total_timesteps      | 247680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1931049 |\n",
      "|    clip_fraction        | 0.0859    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0669   |\n",
      "|    explained_variance   | 0.457     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0046    |\n",
      "|    n_updates            | 32878     |\n",
      "|    policy_gradient_loss | -0.0401   |\n",
      "|    value_loss           | 0.301     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1936       |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 247808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52500165 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.154     |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0784    |\n",
      "|    n_updates            | 32895      |\n",
      "|    policy_gradient_loss | -0.0592    |\n",
      "|    value_loss           | 0.116      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1937       |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 247936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19505656 |\n",
      "|    clip_fraction        | 0.0767     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0798    |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 4.42e-05   |\n",
      "|    n_updates            | 32912      |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 0.228      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=248000, episode_reward=16.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 248000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42246252 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0446    |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 32929      |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.304      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1938     |\n",
      "|    time_elapsed    | 275      |\n",
      "|    total_timesteps | 248064   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1939      |\n",
      "|    time_elapsed         | 275       |\n",
      "|    total_timesteps      | 248192    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0787649 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.1      |\n",
      "|    explained_variance   | -0.123    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.021    |\n",
      "|    n_updates            | 32946     |\n",
      "|    policy_gradient_loss | -0.042    |\n",
      "|    value_loss           | 0.0333    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1940       |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 248320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30102444 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0938    |\n",
      "|    explained_variance   | -0.607     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0924    |\n",
      "|    n_updates            | 32963      |\n",
      "|    policy_gradient_loss | -0.064     |\n",
      "|    value_loss           | 0.0436     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1941       |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 248448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20843002 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | 0.0265     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0562    |\n",
      "|    n_updates            | 32980      |\n",
      "|    policy_gradient_loss | -0.0636    |\n",
      "|    value_loss           | 0.0263     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=248500, episode_reward=21.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 21.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 248500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0002325 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0642   |\n",
      "|    explained_variance   | 0.19      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0886   |\n",
      "|    n_updates            | 32997     |\n",
      "|    policy_gradient_loss | -0.0667   |\n",
      "|    value_loss           | 0.0223    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1942     |\n",
      "|    time_elapsed    | 275      |\n",
      "|    total_timesteps | 248576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1943      |\n",
      "|    time_elapsed         | 275       |\n",
      "|    total_timesteps      | 248704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2909725 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.325     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0987   |\n",
      "|    n_updates            | 33014     |\n",
      "|    policy_gradient_loss | -0.057    |\n",
      "|    value_loss           | 0.0427    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1944       |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 248832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38673803 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0714    |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 33031      |\n",
      "|    policy_gradient_loss | -0.0532    |\n",
      "|    value_loss           | 0.0331     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1945       |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 248960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34860137 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 33048      |\n",
      "|    policy_gradient_loss | -0.0707    |\n",
      "|    value_loss           | 0.07       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=249000, episode_reward=21.01 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 21         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 249000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37151828 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0641    |\n",
      "|    explained_variance   | -0.117     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0346    |\n",
      "|    n_updates            | 33065      |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    value_loss           | 0.368      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1946     |\n",
      "|    time_elapsed    | 276      |\n",
      "|    total_timesteps | 249088   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1947       |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 249216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45720804 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0561    |\n",
      "|    n_updates            | 33082      |\n",
      "|    policy_gradient_loss | -0.0461    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 1948      |\n",
      "|    time_elapsed         | 276       |\n",
      "|    total_timesteps      | 249344    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3135792 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0802   |\n",
      "|    explained_variance   | 0.844     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0466   |\n",
      "|    n_updates            | 33099     |\n",
      "|    policy_gradient_loss | -0.0488   |\n",
      "|    value_loss           | 0.113     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1949       |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 249472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15219128 |\n",
      "|    clip_fraction        | 0.08       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0619    |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.000428   |\n",
      "|    n_updates            | 33116      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=249500, episode_reward=14.04 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 14        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 249500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5158609 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0687   |\n",
      "|    explained_variance   | 0.875     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0339   |\n",
      "|    n_updates            | 33133     |\n",
      "|    policy_gradient_loss | -0.0319   |\n",
      "|    value_loss           | 0.108     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1950     |\n",
      "|    time_elapsed    | 276      |\n",
      "|    total_timesteps | 249600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1951       |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 249728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18550858 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.163     |\n",
      "|    explained_variance   | -0.355     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0248    |\n",
      "|    n_updates            | 33150      |\n",
      "|    policy_gradient_loss | -0.0801    |\n",
      "|    value_loss           | 0.0941     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1952       |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27407032 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0608    |\n",
      "|    n_updates            | 33167      |\n",
      "|    policy_gradient_loss | -0.0514    |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 1953      |\n",
      "|    time_elapsed         | 277       |\n",
      "|    total_timesteps      | 249984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6548801 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | -0.104    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.062    |\n",
      "|    n_updates            | 33184     |\n",
      "|    policy_gradient_loss | -0.0531   |\n",
      "|    value_loss           | 0.0148    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=34.47 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 34.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 250000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0305448 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.078    |\n",
      "|    explained_variance   | 0.0824    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0362   |\n",
      "|    n_updates            | 33201     |\n",
      "|    policy_gradient_loss | -0.0632   |\n",
      "|    value_loss           | 0.051     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1954     |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 250112   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1955       |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 250240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49455422 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0692    |\n",
      "|    n_updates            | 33218      |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    value_loss           | 0.0354     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 1956       |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 250368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27757365 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | -0.345     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0723    |\n",
      "|    n_updates            | 33235      |\n",
      "|    policy_gradient_loss | -0.0711    |\n",
      "|    value_loss           | 0.056      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 51.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 1957     |\n",
      "|    time_elapsed         | 277      |\n",
      "|    total_timesteps      | 250496   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.159589 |\n",
      "|    clip_fraction        | 0.154    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0871  |\n",
      "|    explained_variance   | 0.218    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0607  |\n",
      "|    n_updates            | 33252    |\n",
      "|    policy_gradient_loss | -0.0587  |\n",
      "|    value_loss           | 0.144    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=250500, episode_reward=23.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 23.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 250500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5744711 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.117    |\n",
      "|    explained_variance   | -0.236    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.112     |\n",
      "|    n_updates            | 33269     |\n",
      "|    policy_gradient_loss | -0.0613   |\n",
      "|    value_loss           | 0.5       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 1958     |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 250624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1959       |\n",
      "|    time_elapsed         | 278        |\n",
      "|    total_timesteps      | 250752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11235385 |\n",
      "|    clip_fraction        | 0.0735     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0681    |\n",
      "|    explained_variance   | 0.838      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.026     |\n",
      "|    n_updates            | 33286      |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1960       |\n",
      "|    time_elapsed         | 278        |\n",
      "|    total_timesteps      | 250880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23976815 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.133     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0823    |\n",
      "|    n_updates            | 33303      |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    value_loss           | 0.257      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=251000, episode_reward=42.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 42         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 251000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39040944 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0598    |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.129      |\n",
      "|    n_updates            | 33320      |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 0.37       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 1961     |\n",
      "|    time_elapsed    | 278      |\n",
      "|    total_timesteps | 251008   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 1962      |\n",
      "|    time_elapsed         | 279       |\n",
      "|    total_timesteps      | 251136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5790186 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.152    |\n",
      "|    explained_variance   | 0.00278   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0874   |\n",
      "|    n_updates            | 33337     |\n",
      "|    policy_gradient_loss | -0.0742   |\n",
      "|    value_loss           | 0.0429    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1963       |\n",
      "|    time_elapsed         | 279        |\n",
      "|    total_timesteps      | 251264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14898613 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.166     |\n",
      "|    explained_variance   | -0.071     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 33354      |\n",
      "|    policy_gradient_loss | -0.0747    |\n",
      "|    value_loss           | 0.0822     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1964       |\n",
      "|    time_elapsed         | 279        |\n",
      "|    total_timesteps      | 251392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43858346 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0541    |\n",
      "|    n_updates            | 33371      |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.0204     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=251500, episode_reward=20.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 251500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50012314 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.046     |\n",
      "|    explained_variance   | 0.0614     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0276    |\n",
      "|    n_updates            | 33388      |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 0.0506     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 1965     |\n",
      "|    time_elapsed    | 279      |\n",
      "|    total_timesteps | 251520   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 51.3     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 899      |\n",
      "|    iterations           | 1966     |\n",
      "|    time_elapsed         | 279      |\n",
      "|    total_timesteps      | 251648   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.625739 |\n",
      "|    clip_fraction        | 0.174    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.12    |\n",
      "|    explained_variance   | 0.768    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.14    |\n",
      "|    n_updates            | 33405    |\n",
      "|    policy_gradient_loss | -0.0575  |\n",
      "|    value_loss           | 0.0342   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1967       |\n",
      "|    time_elapsed         | 279        |\n",
      "|    total_timesteps      | 251776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35447517 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0694    |\n",
      "|    explained_variance   | 0.44       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0347    |\n",
      "|    n_updates            | 33422      |\n",
      "|    policy_gradient_loss | -0.0372    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1968      |\n",
      "|    time_elapsed         | 279       |\n",
      "|    total_timesteps      | 251904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7402928 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.64      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.131    |\n",
      "|    n_updates            | 33439     |\n",
      "|    policy_gradient_loss | -0.0718   |\n",
      "|    value_loss           | 0.0707    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=252000, episode_reward=2.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 2.15      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 252000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2955668 |\n",
      "|    clip_fraction        | 0.105     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0867   |\n",
      "|    explained_variance   | 0.584     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00574  |\n",
      "|    n_updates            | 33456     |\n",
      "|    policy_gradient_loss | -0.0429   |\n",
      "|    value_loss           | 0.408     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 1969     |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 252032   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1970      |\n",
      "|    time_elapsed         | 280       |\n",
      "|    total_timesteps      | 252160    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3166892 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.766     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.085    |\n",
      "|    n_updates            | 33473     |\n",
      "|    policy_gradient_loss | -0.0411   |\n",
      "|    value_loss           | 0.115     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1971       |\n",
      "|    time_elapsed         | 280        |\n",
      "|    total_timesteps      | 252288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37919876 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0126    |\n",
      "|    n_updates            | 33490      |\n",
      "|    policy_gradient_loss | -0.0514    |\n",
      "|    value_loss           | 0.285      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1972      |\n",
      "|    time_elapsed         | 280       |\n",
      "|    total_timesteps      | 252416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4352637 |\n",
      "|    clip_fraction        | 0.0974    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0688   |\n",
      "|    explained_variance   | 0.0525    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0519    |\n",
      "|    n_updates            | 33507     |\n",
      "|    policy_gradient_loss | -0.034    |\n",
      "|    value_loss           | 0.848     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=252500, episode_reward=15.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 15.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 252500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6199175 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0914   |\n",
      "|    explained_variance   | 0.922     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0507   |\n",
      "|    n_updates            | 33524     |\n",
      "|    policy_gradient_loss | -0.0693   |\n",
      "|    value_loss           | 0.0508    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1973     |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 252544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1974       |\n",
      "|    time_elapsed         | 280        |\n",
      "|    total_timesteps      | 252672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48026603 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.0107     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0469    |\n",
      "|    n_updates            | 33541      |\n",
      "|    policy_gradient_loss | -0.0806    |\n",
      "|    value_loss           | 0.0263     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1975      |\n",
      "|    time_elapsed         | 280       |\n",
      "|    total_timesteps      | 252800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2966406 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0681   |\n",
      "|    explained_variance   | 0.42      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0569   |\n",
      "|    n_updates            | 33558     |\n",
      "|    policy_gradient_loss | -0.0518   |\n",
      "|    value_loss           | 0.0128    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1976       |\n",
      "|    time_elapsed         | 280        |\n",
      "|    total_timesteps      | 252928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35493442 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0814    |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0839    |\n",
      "|    n_updates            | 33575      |\n",
      "|    policy_gradient_loss | -0.0493    |\n",
      "|    value_loss           | 0.0166     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=253000, episode_reward=-3.20 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -3.2     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 253000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.964238 |\n",
      "|    clip_fraction        | 0.155    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0856  |\n",
      "|    explained_variance   | 0.352    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0592  |\n",
      "|    n_updates            | 33592    |\n",
      "|    policy_gradient_loss | -0.0647  |\n",
      "|    value_loss           | 0.0691   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1977     |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 253056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1978       |\n",
      "|    time_elapsed         | 281        |\n",
      "|    total_timesteps      | 253184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21779211 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.028     |\n",
      "|    explained_variance   | 0.806      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0194    |\n",
      "|    n_updates            | 33609      |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.0476     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1979      |\n",
      "|    time_elapsed         | 281       |\n",
      "|    total_timesteps      | 253312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8818541 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0745   |\n",
      "|    explained_variance   | 0.35      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0495   |\n",
      "|    n_updates            | 33626     |\n",
      "|    policy_gradient_loss | -0.0469   |\n",
      "|    value_loss           | 0.0703    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1980      |\n",
      "|    time_elapsed         | 281       |\n",
      "|    total_timesteps      | 253440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1720717 |\n",
      "|    clip_fraction        | 0.245     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.142    |\n",
      "|    explained_variance   | 0.7       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0984   |\n",
      "|    n_updates            | 33643     |\n",
      "|    policy_gradient_loss | -0.0687   |\n",
      "|    value_loss           | 0.19      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=253500, episode_reward=16.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 253500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51945734 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.546      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0953    |\n",
      "|    n_updates            | 33660      |\n",
      "|    policy_gradient_loss | -0.0818    |\n",
      "|    value_loss           | 0.233      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1981     |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 253568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1982       |\n",
      "|    time_elapsed         | 281        |\n",
      "|    total_timesteps      | 253696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44529408 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.105     |\n",
      "|    explained_variance   | 0.816      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0567    |\n",
      "|    n_updates            | 33677      |\n",
      "|    policy_gradient_loss | -0.0578    |\n",
      "|    value_loss           | 0.152      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1983      |\n",
      "|    time_elapsed         | 281       |\n",
      "|    total_timesteps      | 253824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.428418  |\n",
      "|    clip_fraction        | 0.12      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0874   |\n",
      "|    explained_variance   | -7.64e-05 |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0821    |\n",
      "|    n_updates            | 33694     |\n",
      "|    policy_gradient_loss | -0.0583   |\n",
      "|    value_loss           | 0.821     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1984      |\n",
      "|    time_elapsed         | 282       |\n",
      "|    total_timesteps      | 253952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3232625 |\n",
      "|    clip_fraction        | 0.0997    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.543     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.236     |\n",
      "|    n_updates            | 33711     |\n",
      "|    policy_gradient_loss | -0.045    |\n",
      "|    value_loss           | 0.572     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=254000, episode_reward=59.29 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 59.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 254000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6035914 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.126    |\n",
      "|    explained_variance   | -0.252    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 33728     |\n",
      "|    policy_gradient_loss | -0.0749   |\n",
      "|    value_loss           | 0.0348    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1985     |\n",
      "|    time_elapsed    | 282      |\n",
      "|    total_timesteps | 254080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1986       |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 254208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.87868655 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | -0.5       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.124     |\n",
      "|    n_updates            | 33745      |\n",
      "|    policy_gradient_loss | -0.0723    |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1987       |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 254336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57872605 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0823    |\n",
      "|    explained_variance   | -0.0471    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0865    |\n",
      "|    n_updates            | 33762      |\n",
      "|    policy_gradient_loss | -0.0677    |\n",
      "|    value_loss           | 0.0145     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1988      |\n",
      "|    time_elapsed         | 282       |\n",
      "|    total_timesteps      | 254464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1954082 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0969   |\n",
      "|    explained_variance   | -0.336    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0839   |\n",
      "|    n_updates            | 33779     |\n",
      "|    policy_gradient_loss | -0.0548   |\n",
      "|    value_loss           | 0.0703    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=254500, episode_reward=57.92 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 57.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 254500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41242537 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0846    |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0606    |\n",
      "|    n_updates            | 33796      |\n",
      "|    policy_gradient_loss | -0.0516    |\n",
      "|    value_loss           | 0.0503     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1989     |\n",
      "|    time_elapsed    | 282      |\n",
      "|    total_timesteps | 254592   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1990       |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 254720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34135786 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0943    |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0405    |\n",
      "|    n_updates            | 33813      |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 0.0342     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1991       |\n",
      "|    time_elapsed         | 283        |\n",
      "|    total_timesteps      | 254848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46528387 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | -0.0129    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.246      |\n",
      "|    n_updates            | 33830      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.856      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1992      |\n",
      "|    time_elapsed         | 283       |\n",
      "|    total_timesteps      | 254976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3569618 |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.135    |\n",
      "|    explained_variance   | -0.0973   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0153   |\n",
      "|    n_updates            | 33847     |\n",
      "|    policy_gradient_loss | -0.0423   |\n",
      "|    value_loss           | 0.549     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=30.80 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 255000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40203613 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.72       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0789    |\n",
      "|    n_updates            | 33864      |\n",
      "|    policy_gradient_loss | -0.0666    |\n",
      "|    value_loss           | 0.217      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 1993     |\n",
      "|    time_elapsed    | 283      |\n",
      "|    total_timesteps | 255104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1994       |\n",
      "|    time_elapsed         | 283        |\n",
      "|    total_timesteps      | 255232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14295746 |\n",
      "|    clip_fraction        | 0.0676     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0503    |\n",
      "|    explained_variance   | 0.216      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 1.94       |\n",
      "|    n_updates            | 33881      |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 3.54       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 1995      |\n",
      "|    time_elapsed         | 283       |\n",
      "|    total_timesteps      | 255360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5356511 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | 0.36      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.116     |\n",
      "|    n_updates            | 33898     |\n",
      "|    policy_gradient_loss | -0.0626   |\n",
      "|    value_loss           | 1.04      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1996       |\n",
      "|    time_elapsed         | 283        |\n",
      "|    total_timesteps      | 255488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42088485 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0995    |\n",
      "|    explained_variance   | -0.401     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0537    |\n",
      "|    n_updates            | 33915      |\n",
      "|    policy_gradient_loss | -0.0659    |\n",
      "|    value_loss           | 0.102      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=255500, episode_reward=67.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 67.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 255500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53910476 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.063     |\n",
      "|    n_updates            | 33932      |\n",
      "|    policy_gradient_loss | -0.039     |\n",
      "|    value_loss           | 0.0533     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 1997     |\n",
      "|    time_elapsed    | 284      |\n",
      "|    total_timesteps | 255616   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 1998      |\n",
      "|    time_elapsed         | 284       |\n",
      "|    total_timesteps      | 255744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0417594 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0838   |\n",
      "|    explained_variance   | 0.0831    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 33949     |\n",
      "|    policy_gradient_loss | -0.0646   |\n",
      "|    value_loss           | 0.0296    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 1999       |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 255872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.96112335 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0863    |\n",
      "|    explained_variance   | -1.13      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0606    |\n",
      "|    n_updates            | 33966      |\n",
      "|    policy_gradient_loss | -0.0789    |\n",
      "|    value_loss           | 0.0408     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=8.44 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 8.44      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 256000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7640276 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.181    |\n",
      "|    explained_variance   | 0.493     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 33983     |\n",
      "|    policy_gradient_loss | -0.104    |\n",
      "|    value_loss           | 0.0948    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 284      |\n",
      "|    total_timesteps | 256000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 2001       |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 256128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16118853 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0561    |\n",
      "|    explained_variance   | 0.652      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0201    |\n",
      "|    n_updates            | 34000      |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    value_loss           | 0.0412     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 51.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 899      |\n",
      "|    iterations           | 2002     |\n",
      "|    time_elapsed         | 284      |\n",
      "|    total_timesteps      | 256256   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.418764 |\n",
      "|    clip_fraction        | 0.0708   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0413  |\n",
      "|    explained_variance   | 0.67     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0779  |\n",
      "|    n_updates            | 34017    |\n",
      "|    policy_gradient_loss | -0.0384  |\n",
      "|    value_loss           | 0.141    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 899       |\n",
      "|    iterations           | 2003      |\n",
      "|    time_elapsed         | 284       |\n",
      "|    total_timesteps      | 256384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7693304 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.476     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0755   |\n",
      "|    n_updates            | 34034     |\n",
      "|    policy_gradient_loss | -0.0837   |\n",
      "|    value_loss           | 0.302     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=256500, episode_reward=50.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 50.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 256500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16115902 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0749    |\n",
      "|    n_updates            | 34051      |\n",
      "|    policy_gradient_loss | -0.0582    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2004     |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 256512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 2005       |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 256640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25188792 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0923    |\n",
      "|    explained_variance   | 0.217      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0389    |\n",
      "|    n_updates            | 34068      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.273      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 2006       |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 256768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37995625 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.601      |\n",
      "|    n_updates            | 34085      |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    value_loss           | 1.66       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2007      |\n",
      "|    time_elapsed         | 285       |\n",
      "|    total_timesteps      | 256896    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4843501 |\n",
      "|    clip_fraction        | 0.18      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.13     |\n",
      "|    explained_variance   | -1.14     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0577   |\n",
      "|    n_updates            | 34102     |\n",
      "|    policy_gradient_loss | -0.0685   |\n",
      "|    value_loss           | 0.123     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=257000, episode_reward=40.62 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 257000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37528563 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0919    |\n",
      "|    explained_variance   | -0.26      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0235    |\n",
      "|    n_updates            | 34119      |\n",
      "|    policy_gradient_loss | -0.0676    |\n",
      "|    value_loss           | 0.0971     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2008     |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 257024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 2009       |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 257152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41474617 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0891    |\n",
      "|    explained_variance   | 0.1        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0541    |\n",
      "|    n_updates            | 34136      |\n",
      "|    policy_gradient_loss | -0.0598    |\n",
      "|    value_loss           | 0.0213     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2010       |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 257280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29134187 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0966    |\n",
      "|    explained_variance   | 0.0589     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0536    |\n",
      "|    n_updates            | 34153      |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    value_loss           | 0.024      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2011       |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 257408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59762657 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | -0.0397    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.055     |\n",
      "|    n_updates            | 34170      |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.0557     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=257500, episode_reward=23.52 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 23.5     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 257500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.248156 |\n",
      "|    clip_fraction        | 0.0997   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0651  |\n",
      "|    explained_variance   | 0.618    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0704  |\n",
      "|    n_updates            | 34187    |\n",
      "|    policy_gradient_loss | -0.0584  |\n",
      "|    value_loss           | 0.0609   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2012     |\n",
      "|    time_elapsed    | 286      |\n",
      "|    total_timesteps | 257536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2013       |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 257664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41428345 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0787    |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0536    |\n",
      "|    n_updates            | 34204      |\n",
      "|    policy_gradient_loss | -0.0458    |\n",
      "|    value_loss           | 0.0974     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2014       |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 257792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44223693 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0457    |\n",
      "|    n_updates            | 34221      |\n",
      "|    policy_gradient_loss | -0.0564    |\n",
      "|    value_loss           | 0.43       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2015       |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 257920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06946264 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0595     |\n",
      "|    n_updates            | 34238      |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    value_loss           | 0.611      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=258000, episode_reward=11.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 11.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 258000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7150044 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.772     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.131    |\n",
      "|    n_updates            | 34255     |\n",
      "|    policy_gradient_loss | -0.0771   |\n",
      "|    value_loss           | 0.126     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2016     |\n",
      "|    time_elapsed    | 286      |\n",
      "|    total_timesteps | 258048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 2017       |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 258176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13593796 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.277      |\n",
      "|    n_updates            | 34272      |\n",
      "|    policy_gradient_loss | -0.0496    |\n",
      "|    value_loss           | 2.17       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2018       |\n",
      "|    time_elapsed         | 286        |\n",
      "|    total_timesteps      | 258304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38930964 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.164     |\n",
      "|    explained_variance   | 0.808      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.113     |\n",
      "|    n_updates            | 34289      |\n",
      "|    policy_gradient_loss | -0.0863    |\n",
      "|    value_loss           | 0.22       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2019      |\n",
      "|    time_elapsed         | 287       |\n",
      "|    total_timesteps      | 258432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5842641 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0956   |\n",
      "|    explained_variance   | -1.18     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0744   |\n",
      "|    n_updates            | 34306     |\n",
      "|    policy_gradient_loss | -0.0579   |\n",
      "|    value_loss           | 0.0577    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=258500, episode_reward=45.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 45.9     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 258500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.675724 |\n",
      "|    clip_fraction        | 0.193    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.114   |\n",
      "|    explained_variance   | -0.389   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0961  |\n",
      "|    n_updates            | 34323    |\n",
      "|    policy_gradient_loss | -0.0677  |\n",
      "|    value_loss           | 0.0197   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2020     |\n",
      "|    time_elapsed    | 287      |\n",
      "|    total_timesteps | 258560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2021      |\n",
      "|    time_elapsed         | 287       |\n",
      "|    total_timesteps      | 258688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8963918 |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0825   |\n",
      "|    explained_variance   | 0.043     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0978   |\n",
      "|    n_updates            | 34340     |\n",
      "|    policy_gradient_loss | -0.0746   |\n",
      "|    value_loss           | 0.0137    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2022       |\n",
      "|    time_elapsed         | 287        |\n",
      "|    total_timesteps      | 258816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.72267395 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0962    |\n",
      "|    n_updates            | 34357      |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.0371     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2023       |\n",
      "|    time_elapsed         | 287        |\n",
      "|    total_timesteps      | 258944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33616292 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0837    |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.059     |\n",
      "|    n_updates            | 34374      |\n",
      "|    policy_gradient_loss | -0.0534    |\n",
      "|    value_loss           | 0.0485     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=259000, episode_reward=25.99 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 26        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 259000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0577815 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0754   |\n",
      "|    explained_variance   | 5.74e-05  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 34391     |\n",
      "|    policy_gradient_loss | -0.0614   |\n",
      "|    value_loss           | 0.066     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2024     |\n",
      "|    time_elapsed    | 287      |\n",
      "|    total_timesteps | 259072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2025       |\n",
      "|    time_elapsed         | 287        |\n",
      "|    total_timesteps      | 259200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33443603 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | -0.128     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0272     |\n",
      "|    n_updates            | 34408      |\n",
      "|    policy_gradient_loss | -0.07      |\n",
      "|    value_loss           | 0.591      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 51.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2026      |\n",
      "|    time_elapsed         | 287       |\n",
      "|    total_timesteps      | 259328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5953665 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.171    |\n",
      "|    explained_variance   | 0.35      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 34425     |\n",
      "|    policy_gradient_loss | -0.0774   |\n",
      "|    value_loss           | 0.472     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2027       |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 259456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20535477 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0375    |\n",
      "|    n_updates            | 34442      |\n",
      "|    policy_gradient_loss | -0.0569    |\n",
      "|    value_loss           | 0.149      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=259500, episode_reward=38.41 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 38.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 259500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32917866 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0792    |\n",
      "|    explained_variance   | 0.104      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.214      |\n",
      "|    n_updates            | 34459      |\n",
      "|    policy_gradient_loss | -0.0514    |\n",
      "|    value_loss           | 1          |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2028     |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 259584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2029       |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 259712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23093458 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0334     |\n",
      "|    n_updates            | 34476      |\n",
      "|    policy_gradient_loss | -0.0523    |\n",
      "|    value_loss           | 0.302      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 52.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 2030     |\n",
      "|    time_elapsed         | 288      |\n",
      "|    total_timesteps      | 259840   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.575921 |\n",
      "|    clip_fraction        | 0.239    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.1     |\n",
      "|    explained_variance   | 0.0769   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0322  |\n",
      "|    n_updates            | 34493    |\n",
      "|    policy_gradient_loss | -0.0776  |\n",
      "|    value_loss           | 0.0303   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2031      |\n",
      "|    time_elapsed         | 288       |\n",
      "|    total_timesteps      | 259968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4229033 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0936   |\n",
      "|    explained_variance   | -0.139    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0772   |\n",
      "|    n_updates            | 34510     |\n",
      "|    policy_gradient_loss | -0.065    |\n",
      "|    value_loss           | 0.0218    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=5.85 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 5.85      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 260000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5837478 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0696   |\n",
      "|    explained_variance   | 0.000123  |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 34527     |\n",
      "|    policy_gradient_loss | -0.061    |\n",
      "|    value_loss           | 0.0103    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2032     |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2033      |\n",
      "|    time_elapsed         | 288       |\n",
      "|    total_timesteps      | 260224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0447403 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0774   |\n",
      "|    explained_variance   | 0.425     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0872   |\n",
      "|    n_updates            | 34544     |\n",
      "|    policy_gradient_loss | -0.0587   |\n",
      "|    value_loss           | 0.0509    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2034      |\n",
      "|    time_elapsed         | 289       |\n",
      "|    total_timesteps      | 260352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0006148 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | 0.718     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.102    |\n",
      "|    n_updates            | 34561     |\n",
      "|    policy_gradient_loss | -0.0581   |\n",
      "|    value_loss           | 0.0228    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2035       |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 260480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15302314 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0581    |\n",
      "|    explained_variance   | 0.466      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0465    |\n",
      "|    n_updates            | 34578      |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 0.0358     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=260500, episode_reward=-0.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -0.748    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 260500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6938423 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.594     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0264   |\n",
      "|    n_updates            | 34595     |\n",
      "|    policy_gradient_loss | -0.045    |\n",
      "|    value_loss           | 0.0913    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2036     |\n",
      "|    time_elapsed    | 289      |\n",
      "|    total_timesteps | 260608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2037       |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 260736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41956717 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.156     |\n",
      "|    explained_variance   | 0.651      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0812    |\n",
      "|    n_updates            | 34612      |\n",
      "|    policy_gradient_loss | -0.0786    |\n",
      "|    value_loss           | 0.531      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2038       |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 260864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21637471 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0415    |\n",
      "|    n_updates            | 34629      |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.152      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2039       |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 260992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29148498 |\n",
      "|    clip_fraction        | 0.0767     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0538    |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.027     |\n",
      "|    n_updates            | 34646      |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=261000, episode_reward=11.59 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 11.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 261000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47392046 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 34663      |\n",
      "|    policy_gradient_loss | -0.0531    |\n",
      "|    value_loss           | 0.857      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2040     |\n",
      "|    time_elapsed    | 289      |\n",
      "|    total_timesteps | 261120   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2041      |\n",
      "|    time_elapsed         | 290       |\n",
      "|    total_timesteps      | 261248    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6355115 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.625     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0649   |\n",
      "|    n_updates            | 34680     |\n",
      "|    policy_gradient_loss | -0.0529   |\n",
      "|    value_loss           | 0.0867    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2042       |\n",
      "|    time_elapsed         | 290        |\n",
      "|    total_timesteps      | 261376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.88319075 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | -0.0696    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0741    |\n",
      "|    n_updates            | 34697      |\n",
      "|    policy_gradient_loss | -0.0686    |\n",
      "|    value_loss           | 0.014      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=261500, episode_reward=45.46 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 45.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 261500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71595013 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0988    |\n",
      "|    explained_variance   | -0.524     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.118     |\n",
      "|    n_updates            | 34714      |\n",
      "|    policy_gradient_loss | -0.0712    |\n",
      "|    value_loss           | 0.0116     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2043     |\n",
      "|    time_elapsed    | 290      |\n",
      "|    total_timesteps | 261504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2044       |\n",
      "|    time_elapsed         | 290        |\n",
      "|    total_timesteps      | 261632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51701266 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0937    |\n",
      "|    explained_variance   | 0.0475     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.02      |\n",
      "|    n_updates            | 34731      |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 0.0125     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2045       |\n",
      "|    time_elapsed         | 290        |\n",
      "|    total_timesteps      | 261760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47583047 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0572    |\n",
      "|    n_updates            | 34748      |\n",
      "|    policy_gradient_loss | -0.0473    |\n",
      "|    value_loss           | 0.0527     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2046       |\n",
      "|    time_elapsed         | 290        |\n",
      "|    total_timesteps      | 261888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29229355 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0421    |\n",
      "|    explained_variance   | 0.665      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0587    |\n",
      "|    n_updates            | 34765      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.0393     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=262000, episode_reward=17.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 17.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 262000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5888387 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0804   |\n",
      "|    explained_variance   | 0.686     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0677   |\n",
      "|    n_updates            | 34782     |\n",
      "|    policy_gradient_loss | -0.0574   |\n",
      "|    value_loss           | 0.0604    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2047     |\n",
      "|    time_elapsed    | 291      |\n",
      "|    total_timesteps | 262016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2048       |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41840485 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.651      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0561    |\n",
      "|    n_updates            | 34799      |\n",
      "|    policy_gradient_loss | -0.049     |\n",
      "|    value_loss           | 0.271      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2049       |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 262272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21297173 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.131     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0407    |\n",
      "|    n_updates            | 34816      |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 0.299      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2050       |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 262400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71575433 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.07      |\n",
      "|    n_updates            | 34833      |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=262500, episode_reward=22.88 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 22.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 262500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18222433 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.757      |\n",
      "|    n_updates            | 34850      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 1.59       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2051     |\n",
      "|    time_elapsed    | 291      |\n",
      "|    total_timesteps | 262528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2052       |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 262656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33668616 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.02       |\n",
      "|    n_updates            | 34867      |\n",
      "|    policy_gradient_loss | -0.0418    |\n",
      "|    value_loss           | 0.65       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2053      |\n",
      "|    time_elapsed         | 291       |\n",
      "|    total_timesteps      | 262784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3056446 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.155    |\n",
      "|    explained_variance   | -0.977    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.099    |\n",
      "|    n_updates            | 34884     |\n",
      "|    policy_gradient_loss | -0.0634   |\n",
      "|    value_loss           | 0.0666    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 52.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 900      |\n",
      "|    iterations           | 2054     |\n",
      "|    time_elapsed         | 291      |\n",
      "|    total_timesteps      | 262912   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.922652 |\n",
      "|    clip_fraction        | 0.193    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.131   |\n",
      "|    explained_variance   | -0.167   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0932  |\n",
      "|    n_updates            | 34901    |\n",
      "|    policy_gradient_loss | -0.0628  |\n",
      "|    value_loss           | 0.0185   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=263000, episode_reward=40.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 263000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32051644 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.105     |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0916    |\n",
      "|    n_updates            | 34918      |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    value_loss           | 0.0125     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2055     |\n",
      "|    time_elapsed    | 292      |\n",
      "|    total_timesteps | 263040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2056      |\n",
      "|    time_elapsed         | 292       |\n",
      "|    total_timesteps      | 263168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4287232 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.152    |\n",
      "|    explained_variance   | 0.385     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.148    |\n",
      "|    n_updates            | 34935     |\n",
      "|    policy_gradient_loss | -0.071    |\n",
      "|    value_loss           | 0.0854    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2057       |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 263296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20318079 |\n",
      "|    clip_fraction        | 0.0634     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0617    |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0464    |\n",
      "|    n_updates            | 34952      |\n",
      "|    policy_gradient_loss | -0.0418    |\n",
      "|    value_loss           | 0.0432     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 52.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2058       |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 263424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.62867737 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0977    |\n",
      "|    explained_variance   | 0.505      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0764    |\n",
      "|    n_updates            | 34969      |\n",
      "|    policy_gradient_loss | -0.0627    |\n",
      "|    value_loss           | 0.056      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=263500, episode_reward=51.45 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 263500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5351193 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.264     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 34986     |\n",
      "|    policy_gradient_loss | -0.057    |\n",
      "|    value_loss           | 0.207     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 52.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2059     |\n",
      "|    time_elapsed    | 292      |\n",
      "|    total_timesteps | 263552   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2060      |\n",
      "|    time_elapsed         | 292       |\n",
      "|    total_timesteps      | 263680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3822479 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.171    |\n",
      "|    explained_variance   | 0.706     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0362    |\n",
      "|    n_updates            | 35003     |\n",
      "|    policy_gradient_loss | -0.0586   |\n",
      "|    value_loss           | 0.357     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 52.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2061      |\n",
      "|    time_elapsed         | 293       |\n",
      "|    total_timesteps      | 263808    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6024294 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.134    |\n",
      "|    explained_variance   | 0.825     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0885   |\n",
      "|    n_updates            | 35020     |\n",
      "|    policy_gradient_loss | -0.0669   |\n",
      "|    value_loss           | 0.128     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2062       |\n",
      "|    time_elapsed         | 293        |\n",
      "|    total_timesteps      | 263936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32941604 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.151     |\n",
      "|    explained_variance   | 0.176      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0205     |\n",
      "|    n_updates            | 35037      |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 1.24       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=264000, episode_reward=22.31 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 22.3     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 264000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.682527 |\n",
      "|    clip_fraction        | 0.166    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.144   |\n",
      "|    explained_variance   | 0.219    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | 0.376    |\n",
      "|    n_updates            | 35054    |\n",
      "|    policy_gradient_loss | -0.0801  |\n",
      "|    value_loss           | 1.04     |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2063     |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 264064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2064       |\n",
      "|    time_elapsed         | 293        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33752894 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0915    |\n",
      "|    explained_variance   | -0.592     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0241    |\n",
      "|    n_updates            | 35071      |\n",
      "|    policy_gradient_loss | -0.0527    |\n",
      "|    value_loss           | 0.0184     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2065       |\n",
      "|    time_elapsed         | 293        |\n",
      "|    total_timesteps      | 264320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25463888 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0953    |\n",
      "|    explained_variance   | -1.13      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0148    |\n",
      "|    n_updates            | 35088      |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 0.0715     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2066      |\n",
      "|    time_elapsed         | 293       |\n",
      "|    total_timesteps      | 264448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0404959 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.0663    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0796   |\n",
      "|    n_updates            | 35105     |\n",
      "|    policy_gradient_loss | -0.0827   |\n",
      "|    value_loss           | 0.031     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=264500, episode_reward=70.32 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 70.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 264500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49893424 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | 0.288      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0725    |\n",
      "|    n_updates            | 35122      |\n",
      "|    policy_gradient_loss | -0.0612    |\n",
      "|    value_loss           | 0.0619     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2067     |\n",
      "|    time_elapsed    | 294      |\n",
      "|    total_timesteps | 264576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 899        |\n",
      "|    iterations           | 2068       |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 264704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65301013 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0962    |\n",
      "|    n_updates            | 35139      |\n",
      "|    policy_gradient_loss | -0.0671    |\n",
      "|    value_loss           | 0.0337     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2069      |\n",
      "|    time_elapsed         | 294       |\n",
      "|    total_timesteps      | 264832    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5952663 |\n",
      "|    clip_fraction        | 0.0841    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0494   |\n",
      "|    explained_variance   | 0.303     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0815   |\n",
      "|    n_updates            | 35156     |\n",
      "|    policy_gradient_loss | -0.0331   |\n",
      "|    value_loss           | 0.0593    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2070       |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 264960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29217315 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.074     |\n",
      "|    explained_variance   | 0.0519     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0316    |\n",
      "|    n_updates            | 35173      |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 0.141      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=57.70 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 57.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 265000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28551173 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0933    |\n",
      "|    explained_variance   | 0.501      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0442     |\n",
      "|    n_updates            | 35190      |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.593      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    fps             | 899      |\n",
      "|    iterations      | 2071     |\n",
      "|    time_elapsed    | 294      |\n",
      "|    total_timesteps | 265088   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 53          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 900         |\n",
      "|    iterations           | 2072        |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 265216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075470544 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.112      |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.00209    |\n",
      "|    n_updates            | 35207       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2073       |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 265344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43970534 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0905    |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0253     |\n",
      "|    n_updates            | 35224      |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.316      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2074      |\n",
      "|    time_elapsed         | 294       |\n",
      "|    total_timesteps      | 265472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2895367 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.133    |\n",
      "|    explained_variance   | 0.129     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.511     |\n",
      "|    n_updates            | 35241     |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 1.63      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=265500, episode_reward=58.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 58.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 265500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42293966 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.157     |\n",
      "|    explained_variance   | 0.679      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.115     |\n",
      "|    n_updates            | 35258      |\n",
      "|    policy_gradient_loss | -0.0899    |\n",
      "|    value_loss           | 0.0324     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2075     |\n",
      "|    time_elapsed    | 295      |\n",
      "|    total_timesteps | 265600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2076       |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 265728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17313808 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0785    |\n",
      "|    explained_variance   | -1.39      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0503    |\n",
      "|    n_updates            | 35275      |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2077      |\n",
      "|    time_elapsed         | 295       |\n",
      "|    total_timesteps      | 265856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4736882 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.1      |\n",
      "|    explained_variance   | 0.17      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0567   |\n",
      "|    n_updates            | 35292     |\n",
      "|    policy_gradient_loss | -0.0478   |\n",
      "|    value_loss           | 0.0165    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2078       |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 265984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23115143 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.217      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.12      |\n",
      "|    n_updates            | 35309      |\n",
      "|    policy_gradient_loss | -0.0675    |\n",
      "|    value_loss           | 0.00982    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=266000, episode_reward=16.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 266000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18761727 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.786      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 35326      |\n",
      "|    policy_gradient_loss | -0.0566    |\n",
      "|    value_loss           | 0.0661     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2079     |\n",
      "|    time_elapsed    | 295      |\n",
      "|    total_timesteps | 266112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2080      |\n",
      "|    time_elapsed         | 295       |\n",
      "|    total_timesteps      | 266240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4115753 |\n",
      "|    clip_fraction        | 0.0717    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0353   |\n",
      "|    explained_variance   | 0.822     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0333   |\n",
      "|    n_updates            | 35343     |\n",
      "|    policy_gradient_loss | -0.0243   |\n",
      "|    value_loss           | 0.0267    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2081       |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 266368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30142197 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0632    |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0328    |\n",
      "|    n_updates            | 35360      |\n",
      "|    policy_gradient_loss | -0.0507    |\n",
      "|    value_loss           | 0.072      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2082      |\n",
      "|    time_elapsed         | 295       |\n",
      "|    total_timesteps      | 266496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8473204 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.113    |\n",
      "|    explained_variance   | 0.686     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0751   |\n",
      "|    n_updates            | 35377     |\n",
      "|    policy_gradient_loss | -0.0642   |\n",
      "|    value_loss           | 0.184     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=266500, episode_reward=35.19 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 266500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20711783 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0963    |\n",
      "|    explained_variance   | 0.695      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0143    |\n",
      "|    n_updates            | 35394      |\n",
      "|    policy_gradient_loss | -0.0511    |\n",
      "|    value_loss           | 0.382      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2083     |\n",
      "|    time_elapsed    | 296      |\n",
      "|    total_timesteps | 266624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2084       |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 266752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34122145 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0965    |\n",
      "|    explained_variance   | 0.743      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0243    |\n",
      "|    n_updates            | 35411      |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2085       |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 266880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25446054 |\n",
      "|    clip_fraction        | 0.0905     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.0408     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.469      |\n",
      "|    n_updates            | 35428      |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 1.53       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=267000, episode_reward=41.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 41.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 267000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21319292 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.121     |\n",
      "|    explained_variance   | 0.579      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0705    |\n",
      "|    n_updates            | 35445      |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 0.279      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2086     |\n",
      "|    time_elapsed    | 296      |\n",
      "|    total_timesteps | 267008   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2087      |\n",
      "|    time_elapsed         | 296       |\n",
      "|    total_timesteps      | 267136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7178576 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.122    |\n",
      "|    explained_variance   | -1.61     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0292   |\n",
      "|    n_updates            | 35462     |\n",
      "|    policy_gradient_loss | -0.0676   |\n",
      "|    value_loss           | 0.0513    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2088       |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 267264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32804975 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | -0.318     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.074     |\n",
      "|    n_updates            | 35479      |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.019      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2089      |\n",
      "|    time_elapsed         | 296       |\n",
      "|    total_timesteps      | 267392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3979823 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.18     |\n",
      "|    explained_variance   | -0.159    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0739   |\n",
      "|    n_updates            | 35496     |\n",
      "|    policy_gradient_loss | -0.0754   |\n",
      "|    value_loss           | 0.0152    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=267500, episode_reward=58.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 58.8     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 267500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.821985 |\n",
      "|    clip_fraction        | 0.185    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.127   |\n",
      "|    explained_variance   | 0.102    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0823  |\n",
      "|    n_updates            | 35513    |\n",
      "|    policy_gradient_loss | -0.0862  |\n",
      "|    value_loss           | 0.0542   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2090     |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 267520   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2091      |\n",
      "|    time_elapsed         | 297       |\n",
      "|    total_timesteps      | 267648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5174611 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0841   |\n",
      "|    explained_variance   | 0.594     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0784   |\n",
      "|    n_updates            | 35530     |\n",
      "|    policy_gradient_loss | -0.0426   |\n",
      "|    value_loss           | 0.0306    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2092      |\n",
      "|    time_elapsed         | 297       |\n",
      "|    total_timesteps      | 267776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0802453 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0945   |\n",
      "|    explained_variance   | 0.206     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0749   |\n",
      "|    n_updates            | 35547     |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.166     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2093       |\n",
      "|    time_elapsed         | 297        |\n",
      "|    total_timesteps      | 267904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33167166 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0814    |\n",
      "|    explained_variance   | 0.0494     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0555    |\n",
      "|    n_updates            | 35564      |\n",
      "|    policy_gradient_loss | -0.0524    |\n",
      "|    value_loss           | 0.225      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=268000, episode_reward=51.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 268000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6573283 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | 0.501     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 35581     |\n",
      "|    policy_gradient_loss | -0.0593   |\n",
      "|    value_loss           | 0.247     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2094     |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 268032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2095       |\n",
      "|    time_elapsed         | 297        |\n",
      "|    total_timesteps      | 268160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15761228 |\n",
      "|    clip_fraction        | 0.0717     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0757    |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0764    |\n",
      "|    n_updates            | 35598      |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.277      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 900        |\n",
      "|    iterations           | 2096       |\n",
      "|    time_elapsed         | 297        |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06579966 |\n",
      "|    clip_fraction        | 0.0368     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0421    |\n",
      "|    explained_variance   | -0.154     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 2.28       |\n",
      "|    n_updates            | 35615      |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    value_loss           | 4.36       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2097       |\n",
      "|    time_elapsed         | 297        |\n",
      "|    total_timesteps      | 268416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22690435 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0991    |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.427      |\n",
      "|    n_updates            | 35632      |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 1.02       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=268500, episode_reward=16.92 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 268500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.59471315 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0712    |\n",
      "|    explained_variance   | -0.681     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0562    |\n",
      "|    n_updates            | 35649      |\n",
      "|    policy_gradient_loss | -0.0506    |\n",
      "|    value_loss           | 0.0165     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2098     |\n",
      "|    time_elapsed    | 298      |\n",
      "|    total_timesteps | 268544   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2099      |\n",
      "|    time_elapsed         | 298       |\n",
      "|    total_timesteps      | 268672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4431006 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0941   |\n",
      "|    explained_variance   | -1.05     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0338   |\n",
      "|    n_updates            | 35666     |\n",
      "|    policy_gradient_loss | -0.0398   |\n",
      "|    value_loss           | 0.0148    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2100       |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 268800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56387925 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | -0.226     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0788    |\n",
      "|    n_updates            | 35683      |\n",
      "|    policy_gradient_loss | -0.0504    |\n",
      "|    value_loss           | 0.0133     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2101      |\n",
      "|    time_elapsed         | 298       |\n",
      "|    total_timesteps      | 268928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2838363 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.128    |\n",
      "|    explained_variance   | 0.217     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0888   |\n",
      "|    n_updates            | 35700     |\n",
      "|    policy_gradient_loss | -0.0542   |\n",
      "|    value_loss           | 0.0247    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=269000, episode_reward=18.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 18.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 269000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46550706 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0703    |\n",
      "|    n_updates            | 35717      |\n",
      "|    policy_gradient_loss | -0.0473    |\n",
      "|    value_loss           | 0.0705     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2102     |\n",
      "|    time_elapsed    | 298      |\n",
      "|    total_timesteps | 269056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2103      |\n",
      "|    time_elapsed         | 298       |\n",
      "|    total_timesteps      | 269184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2819088 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0866   |\n",
      "|    explained_variance   | 0.352     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0562   |\n",
      "|    n_updates            | 35734     |\n",
      "|    policy_gradient_loss | -0.0532   |\n",
      "|    value_loss           | 0.0772    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2104       |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 269312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36628753 |\n",
      "|    clip_fraction        | 0.0754     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0531    |\n",
      "|    explained_variance   | -0.583     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0366     |\n",
      "|    n_updates            | 35751      |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 0.262      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2105       |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 269440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16348247 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.189      |\n",
      "|    n_updates            | 35768      |\n",
      "|    policy_gradient_loss | -0.0453    |\n",
      "|    value_loss           | 2.5        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=269500, episode_reward=13.90 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 13.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 269500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16455048 |\n",
      "|    clip_fraction        | 0.0951     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.099     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.139     |\n",
      "|    n_updates            | 35785      |\n",
      "|    policy_gradient_loss | -0.0531    |\n",
      "|    value_loss           | 0.251      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2106     |\n",
      "|    time_elapsed    | 299      |\n",
      "|    total_timesteps | 269568   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 53.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 901         |\n",
      "|    iterations           | 2107        |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 269696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082914546 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0614     |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 35802       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.332       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2108       |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 269824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27519056 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.901      |\n",
      "|    n_updates            | 35819      |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    value_loss           | 3.14       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2109       |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 269952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26885533 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0532    |\n",
      "|    n_updates            | 35836      |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    value_loss           | 0.0769     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=21.78 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 21.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 270000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47176847 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | 0.0407     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0806    |\n",
      "|    n_updates            | 35853      |\n",
      "|    policy_gradient_loss | -0.0621    |\n",
      "|    value_loss           | 0.0309     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2110     |\n",
      "|    time_elapsed    | 299      |\n",
      "|    total_timesteps | 270080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2111       |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 270208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45466387 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0908    |\n",
      "|    explained_variance   | -0.326     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0541    |\n",
      "|    n_updates            | 35870      |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.0167     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2112       |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27169752 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | -0.629     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0749    |\n",
      "|    n_updates            | 35887      |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.0226     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2113       |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 270464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.73568976 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0839    |\n",
      "|    n_updates            | 35904      |\n",
      "|    policy_gradient_loss | -0.0582    |\n",
      "|    value_loss           | 0.0804     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=270500, episode_reward=-4.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -4.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 270500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20780413 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0676    |\n",
      "|    explained_variance   | 0.795      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0593    |\n",
      "|    n_updates            | 35921      |\n",
      "|    policy_gradient_loss | -0.0402    |\n",
      "|    value_loss           | 0.0447     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2114     |\n",
      "|    time_elapsed    | 300      |\n",
      "|    total_timesteps | 270592   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2115      |\n",
      "|    time_elapsed         | 300       |\n",
      "|    total_timesteps      | 270720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4820478 |\n",
      "|    clip_fraction        | 0.188     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.54      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.119    |\n",
      "|    n_updates            | 35938     |\n",
      "|    policy_gradient_loss | -0.0755   |\n",
      "|    value_loss           | 0.218     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2116       |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 270848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21956941 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0528     |\n",
      "|    n_updates            | 35955      |\n",
      "|    policy_gradient_loss | -0.0559    |\n",
      "|    value_loss           | 0.741      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2117       |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 270976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16466418 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.484      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0766     |\n",
      "|    n_updates            | 35972      |\n",
      "|    policy_gradient_loss | -0.0443    |\n",
      "|    value_loss           | 0.971      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=271000, episode_reward=8.98 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 8.98       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 271000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.76577425 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.517      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0799    |\n",
      "|    n_updates            | 35989      |\n",
      "|    policy_gradient_loss | -0.0578    |\n",
      "|    value_loss           | 0.233      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2118     |\n",
      "|    time_elapsed    | 300      |\n",
      "|    total_timesteps | 271104   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2119      |\n",
      "|    time_elapsed         | 300       |\n",
      "|    total_timesteps      | 271232    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4559547 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.16     |\n",
      "|    explained_variance   | -0.421    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0557   |\n",
      "|    n_updates            | 36006     |\n",
      "|    policy_gradient_loss | -0.0665   |\n",
      "|    value_loss           | 0.336     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2120       |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 271360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29985604 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0926    |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.027     |\n",
      "|    n_updates            | 36023      |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2121       |\n",
      "|    time_elapsed         | 301        |\n",
      "|    total_timesteps      | 271488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37309742 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | -0.82      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.15      |\n",
      "|    n_updates            | 36040      |\n",
      "|    policy_gradient_loss | -0.0817    |\n",
      "|    value_loss           | 0.0505     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=271500, episode_reward=30.34 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 30.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 271500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.92100257 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | -0.0165    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 36057      |\n",
      "|    policy_gradient_loss | -0.081     |\n",
      "|    value_loss           | 0.0428     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2122     |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 271616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2123       |\n",
      "|    time_elapsed         | 301        |\n",
      "|    total_timesteps      | 271744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57774746 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | -0.171     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.142     |\n",
      "|    n_updates            | 36074      |\n",
      "|    policy_gradient_loss | -0.0991    |\n",
      "|    value_loss           | 0.0208     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2124       |\n",
      "|    time_elapsed         | 301        |\n",
      "|    total_timesteps      | 271872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33832347 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.0946     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0513    |\n",
      "|    n_updates            | 36091      |\n",
      "|    policy_gradient_loss | -0.0548    |\n",
      "|    value_loss           | 0.135      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=20.15 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 20.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 272000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4070964 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0965   |\n",
      "|    explained_variance   | 0.722     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0931   |\n",
      "|    n_updates            | 36108     |\n",
      "|    policy_gradient_loss | -0.0531   |\n",
      "|    value_loss           | 0.0613    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2125     |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 272000   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 900       |\n",
      "|    iterations           | 2126      |\n",
      "|    time_elapsed         | 302       |\n",
      "|    total_timesteps      | 272128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5648279 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.155    |\n",
      "|    explained_variance   | 0.679     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0696   |\n",
      "|    n_updates            | 36125     |\n",
      "|    policy_gradient_loss | -0.0836   |\n",
      "|    value_loss           | 0.0797    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2127       |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 272256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23158914 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.0884     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0197     |\n",
      "|    n_updates            | 36142      |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 0.547      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2128       |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28196174 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.549      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0237    |\n",
      "|    n_updates            | 36159      |\n",
      "|    policy_gradient_loss | -0.0534    |\n",
      "|    value_loss           | 0.484      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=272500, episode_reward=10.89 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 10.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 272500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34763283 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.123     |\n",
      "|    explained_variance   | 0.393      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0157    |\n",
      "|    n_updates            | 36176      |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    value_loss           | 0.395      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2129     |\n",
      "|    time_elapsed    | 302      |\n",
      "|    total_timesteps | 272512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2130       |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 272640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39794764 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0953    |\n",
      "|    explained_variance   | -0.0763    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.149      |\n",
      "|    n_updates            | 36193      |\n",
      "|    policy_gradient_loss | -0.0531    |\n",
      "|    value_loss           | 0.77       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2131       |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 272768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27144274 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.087     |\n",
      "|    explained_variance   | 0.911      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0109     |\n",
      "|    n_updates            | 36210      |\n",
      "|    policy_gradient_loss | -0.0425    |\n",
      "|    value_loss           | 0.382      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2132      |\n",
      "|    time_elapsed         | 302       |\n",
      "|    total_timesteps      | 272896    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5398379 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.128    |\n",
      "|    explained_variance   | -0.746    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0251   |\n",
      "|    n_updates            | 36227     |\n",
      "|    policy_gradient_loss | -0.0742   |\n",
      "|    value_loss           | 0.0238    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=273000, episode_reward=11.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 11.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 273000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39630505 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | -0.213     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0973    |\n",
      "|    n_updates            | 36244      |\n",
      "|    policy_gradient_loss | -0.0798    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2133     |\n",
      "|    time_elapsed    | 302      |\n",
      "|    total_timesteps | 273024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2134      |\n",
      "|    time_elapsed         | 303       |\n",
      "|    total_timesteps      | 273152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0021307 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | 0.169     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0584   |\n",
      "|    n_updates            | 36261     |\n",
      "|    policy_gradient_loss | -0.0753   |\n",
      "|    value_loss           | 0.0346    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2135       |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 273280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67855483 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.156     |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0759    |\n",
      "|    n_updates            | 36278      |\n",
      "|    policy_gradient_loss | -0.0713    |\n",
      "|    value_loss           | 0.0508     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2136       |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 273408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28237894 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.188     |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0876    |\n",
      "|    n_updates            | 36295      |\n",
      "|    policy_gradient_loss | -0.0856    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=273500, episode_reward=40.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 273500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36722857 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0902    |\n",
      "|    n_updates            | 36312      |\n",
      "|    policy_gradient_loss | -0.0676    |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2137     |\n",
      "|    time_elapsed    | 303      |\n",
      "|    total_timesteps | 273536   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2138      |\n",
      "|    time_elapsed         | 303       |\n",
      "|    total_timesteps      | 273664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4531337 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0849   |\n",
      "|    explained_variance   | 0.546     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0811    |\n",
      "|    n_updates            | 36329     |\n",
      "|    policy_gradient_loss | -0.0528   |\n",
      "|    value_loss           | 0.425     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2139      |\n",
      "|    time_elapsed         | 303       |\n",
      "|    total_timesteps      | 273792    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2126469 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.141    |\n",
      "|    explained_variance   | 0.522     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0149   |\n",
      "|    n_updates            | 36346     |\n",
      "|    policy_gradient_loss | -0.0559   |\n",
      "|    value_loss           | 0.734     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2140      |\n",
      "|    time_elapsed         | 303       |\n",
      "|    total_timesteps      | 273920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3696681 |\n",
      "|    clip_fraction        | 0.0942    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.068    |\n",
      "|    explained_variance   | 0.801     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0566   |\n",
      "|    n_updates            | 36363     |\n",
      "|    policy_gradient_loss | -0.0422   |\n",
      "|    value_loss           | 0.218     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=274000, episode_reward=41.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 245         |\n",
      "|    mean_reward          | 41.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 274000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090176195 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.0472     |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0591      |\n",
      "|    n_updates            | 36380       |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.612       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2141     |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 274048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2142       |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 274176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06646489 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | -0.0679    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 1.51       |\n",
      "|    n_updates            | 36397      |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 3.24       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2143       |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 274304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37103397 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.469      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.08      |\n",
      "|    n_updates            | 36414      |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 53.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2144      |\n",
      "|    time_elapsed         | 304       |\n",
      "|    total_timesteps      | 274432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0141103 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0731   |\n",
      "|    explained_variance   | -0.258    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0983   |\n",
      "|    n_updates            | 36431     |\n",
      "|    policy_gradient_loss | -0.0771   |\n",
      "|    value_loss           | 0.0435    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=274500, episode_reward=52.60 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 52.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 274500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32518494 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | -0.243     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0286    |\n",
      "|    n_updates            | 36448      |\n",
      "|    policy_gradient_loss | -0.0511    |\n",
      "|    value_loss           | 0.035      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2145     |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 274560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2146       |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 274688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41157147 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.206     |\n",
      "|    explained_variance   | -0.275     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.117     |\n",
      "|    n_updates            | 36465      |\n",
      "|    policy_gradient_loss | -0.0688    |\n",
      "|    value_loss           | 0.037      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2147       |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 274816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30461574 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0686    |\n",
      "|    n_updates            | 36482      |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.0935     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2148       |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 274944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35397446 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.063     |\n",
      "|    explained_variance   | -0.64      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0332    |\n",
      "|    n_updates            | 36499      |\n",
      "|    policy_gradient_loss | -0.0596    |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=40.95 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 41        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 275000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5263272 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.11     |\n",
      "|    explained_variance   | 0.654     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0647   |\n",
      "|    n_updates            | 36516     |\n",
      "|    policy_gradient_loss | -0.0638   |\n",
      "|    value_loss           | 0.161     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 53.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2149     |\n",
      "|    time_elapsed    | 305      |\n",
      "|    total_timesteps | 275072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2150       |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 275200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25929254 |\n",
      "|    clip_fraction        | 0.0947     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.18       |\n",
      "|    n_updates            | 36533      |\n",
      "|    policy_gradient_loss | -0.0392    |\n",
      "|    value_loss           | 1.63       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2151       |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 275328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33018646 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.074     |\n",
      "|    n_updates            | 36550      |\n",
      "|    policy_gradient_loss | -0.0804    |\n",
      "|    value_loss           | 0.517      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 53.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2152       |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 275456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26560798 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0612    |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0972    |\n",
      "|    n_updates            | 36567      |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    value_loss           | 0.378      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=275500, episode_reward=33.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 275500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23528072 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 3.12       |\n",
      "|    n_updates            | 36584      |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 3.74       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2153     |\n",
      "|    time_elapsed    | 305      |\n",
      "|    total_timesteps | 275584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2154       |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 275712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21579866 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.14       |\n",
      "|    n_updates            | 36601      |\n",
      "|    policy_gradient_loss | -0.0526    |\n",
      "|    value_loss           | 0.534      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 54       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 901      |\n",
      "|    iterations           | 2155     |\n",
      "|    time_elapsed         | 305      |\n",
      "|    total_timesteps      | 275840   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.554161 |\n",
      "|    clip_fraction        | 0.215    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.171   |\n",
      "|    explained_variance   | -1.65    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0811  |\n",
      "|    n_updates            | 36618    |\n",
      "|    policy_gradient_loss | -0.0772  |\n",
      "|    value_loss           | 0.0937   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2156      |\n",
      "|    time_elapsed         | 305       |\n",
      "|    total_timesteps      | 275968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9129076 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.139    |\n",
      "|    explained_variance   | 0.25      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0538   |\n",
      "|    n_updates            | 36635     |\n",
      "|    policy_gradient_loss | -0.0572   |\n",
      "|    value_loss           | 0.0313    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=276000, episode_reward=2.97 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.97       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 276000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34963784 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | -0.258     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0749    |\n",
      "|    n_updates            | 36652      |\n",
      "|    policy_gradient_loss | -0.0588    |\n",
      "|    value_loss           | 0.0299     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2157     |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 276096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2158       |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 276224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18183944 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.178      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0742    |\n",
      "|    n_updates            | 36669      |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2159      |\n",
      "|    time_elapsed         | 306       |\n",
      "|    total_timesteps      | 276352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5571933 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0786   |\n",
      "|    explained_variance   | 0.605     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.104    |\n",
      "|    n_updates            | 36686     |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.108     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2160       |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23852597 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.821      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.074     |\n",
      "|    n_updates            | 36703      |\n",
      "|    policy_gradient_loss | -0.0672    |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=276500, episode_reward=-0.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -0.788    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 276500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9419244 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0867   |\n",
      "|    explained_variance   | -0.25     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.275     |\n",
      "|    n_updates            | 36720     |\n",
      "|    policy_gradient_loss | -0.0476   |\n",
      "|    value_loss           | 0.745     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2161     |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 276608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2162       |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 276736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25594407 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0861    |\n",
      "|    explained_variance   | 0.549      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0032    |\n",
      "|    n_updates            | 36737      |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    value_loss           | 0.535      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2163      |\n",
      "|    time_elapsed         | 306       |\n",
      "|    total_timesteps      | 276864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9482541 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.636     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.118    |\n",
      "|    n_updates            | 36754     |\n",
      "|    policy_gradient_loss | -0.0779   |\n",
      "|    value_loss           | 0.204     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2164      |\n",
      "|    time_elapsed         | 307       |\n",
      "|    total_timesteps      | 276992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3018289 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.132    |\n",
      "|    explained_variance   | 0.465     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.128     |\n",
      "|    n_updates            | 36771     |\n",
      "|    policy_gradient_loss | -0.0573   |\n",
      "|    value_loss           | 1.44      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=277000, episode_reward=20.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 277000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28665435 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.117     |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0127    |\n",
      "|    n_updates            | 36788      |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    value_loss           | 0.348      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2165     |\n",
      "|    time_elapsed    | 307      |\n",
      "|    total_timesteps | 277120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2166       |\n",
      "|    time_elapsed         | 307        |\n",
      "|    total_timesteps      | 277248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27620184 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0856    |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0319    |\n",
      "|    n_updates            | 36805      |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.0256     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2167      |\n",
      "|    time_elapsed         | 307       |\n",
      "|    total_timesteps      | 277376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9473521 |\n",
      "|    clip_fraction        | 0.194     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.124    |\n",
      "|    explained_variance   | -0.292    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0899   |\n",
      "|    n_updates            | 36822     |\n",
      "|    policy_gradient_loss | -0.076    |\n",
      "|    value_loss           | 0.0318    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=277500, episode_reward=13.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 13.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 277500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3269003 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.286     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0356   |\n",
      "|    n_updates            | 36839     |\n",
      "|    policy_gradient_loss | -0.061    |\n",
      "|    value_loss           | 0.0287    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2168     |\n",
      "|    time_elapsed    | 307      |\n",
      "|    total_timesteps | 277504   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2169      |\n",
      "|    time_elapsed         | 307       |\n",
      "|    total_timesteps      | 277632    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3056533 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.167    |\n",
      "|    explained_variance   | 0.0615    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0984   |\n",
      "|    n_updates            | 36856     |\n",
      "|    policy_gradient_loss | -0.0722   |\n",
      "|    value_loss           | 0.0584    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2170       |\n",
      "|    time_elapsed         | 307        |\n",
      "|    total_timesteps      | 277760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56425434 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0709    |\n",
      "|    n_updates            | 36873      |\n",
      "|    policy_gradient_loss | -0.077     |\n",
      "|    value_loss           | 0.0881     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2171       |\n",
      "|    time_elapsed         | 307        |\n",
      "|    total_timesteps      | 277888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68578273 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0923    |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0729    |\n",
      "|    n_updates            | 36890      |\n",
      "|    policy_gradient_loss | -0.0789    |\n",
      "|    value_loss           | 0.0678     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=278000, episode_reward=34.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 34.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 278000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3848824 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.293     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0139   |\n",
      "|    n_updates            | 36907     |\n",
      "|    policy_gradient_loss | -0.0566   |\n",
      "|    value_loss           | 0.183     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2172     |\n",
      "|    time_elapsed    | 308      |\n",
      "|    total_timesteps | 278016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2173      |\n",
      "|    time_elapsed         | 308       |\n",
      "|    total_timesteps      | 278144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2374528 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | 0.525     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0986    |\n",
      "|    n_updates            | 36924     |\n",
      "|    policy_gradient_loss | -0.0737   |\n",
      "|    value_loss           | 0.931     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2174      |\n",
      "|    time_elapsed         | 308       |\n",
      "|    total_timesteps      | 278272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9302521 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0959   |\n",
      "|    explained_variance   | 0.714     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 36941     |\n",
      "|    policy_gradient_loss | -0.0694   |\n",
      "|    value_loss           | 0.175     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2175       |\n",
      "|    time_elapsed         | 308        |\n",
      "|    total_timesteps      | 278400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25684747 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.095     |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.06       |\n",
      "|    n_updates            | 36958      |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.765      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=278500, episode_reward=37.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 37.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 278500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4016446 |\n",
      "|    clip_fraction        | 0.197     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.127    |\n",
      "|    explained_variance   | 0.119     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0415    |\n",
      "|    n_updates            | 36975     |\n",
      "|    policy_gradient_loss | -0.0577   |\n",
      "|    value_loss           | 0.899     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2176     |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2177      |\n",
      "|    time_elapsed         | 309       |\n",
      "|    total_timesteps      | 278656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8766284 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0791   |\n",
      "|    explained_variance   | -0.915    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.118    |\n",
      "|    n_updates            | 36992     |\n",
      "|    policy_gradient_loss | -0.082    |\n",
      "|    value_loss           | 0.0498    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2178       |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 278784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10622534 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0728    |\n",
      "|    explained_variance   | -0.343     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00213    |\n",
      "|    n_updates            | 37009      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.0542     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2179       |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 278912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29572588 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.205      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0381    |\n",
      "|    n_updates            | 37026      |\n",
      "|    policy_gradient_loss | -0.063     |\n",
      "|    value_loss           | 0.0677     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=279000, episode_reward=11.18 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 11.2      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 279000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3719693 |\n",
      "|    clip_fraction        | 0.235     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.157    |\n",
      "|    explained_variance   | -0.69     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0742   |\n",
      "|    n_updates            | 37043     |\n",
      "|    policy_gradient_loss | -0.0646   |\n",
      "|    value_loss           | 0.0421    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2180     |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 279040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2181       |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 279168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20192748 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00911    |\n",
      "|    n_updates            | 37060      |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2182       |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 279296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49673656 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.072     |\n",
      "|    explained_variance   | 0.751      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0396    |\n",
      "|    n_updates            | 37077      |\n",
      "|    policy_gradient_loss | -0.0498    |\n",
      "|    value_loss           | 0.0517     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2183       |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 279424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.61652935 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0693    |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0329    |\n",
      "|    n_updates            | 37094      |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=279500, episode_reward=2.57 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.57       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 279500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35677534 |\n",
      "|    clip_fraction        | 0.0864     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0803    |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.204      |\n",
      "|    n_updates            | 37111      |\n",
      "|    policy_gradient_loss | -0.0399    |\n",
      "|    value_loss           | 0.651      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2184     |\n",
      "|    time_elapsed    | 310      |\n",
      "|    total_timesteps | 279552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2185       |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 279680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42250645 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.062     |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00442   |\n",
      "|    n_updates            | 37128      |\n",
      "|    policy_gradient_loss | -0.0498    |\n",
      "|    value_loss           | 0.398      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2186       |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 279808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49629346 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.071     |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0802    |\n",
      "|    n_updates            | 37145      |\n",
      "|    policy_gradient_loss | -0.0625    |\n",
      "|    value_loss           | 0.149      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2187      |\n",
      "|    time_elapsed         | 310       |\n",
      "|    total_timesteps      | 279936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0671303 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.133    |\n",
      "|    explained_variance   | -0.197    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.187     |\n",
      "|    n_updates            | 37162     |\n",
      "|    policy_gradient_loss | -0.0809   |\n",
      "|    value_loss           | 1.07      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-11.81 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -11.8      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 280000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42090166 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.899      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0195    |\n",
      "|    n_updates            | 37179      |\n",
      "|    policy_gradient_loss | -0.0889    |\n",
      "|    value_loss           | 0.327      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2188     |\n",
      "|    time_elapsed    | 310      |\n",
      "|    total_timesteps | 280064   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2189      |\n",
      "|    time_elapsed         | 310       |\n",
      "|    total_timesteps      | 280192    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3482626 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0813   |\n",
      "|    explained_variance   | -0.926    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0968   |\n",
      "|    n_updates            | 37196     |\n",
      "|    policy_gradient_loss | -0.0497   |\n",
      "|    value_loss           | 0.0425    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2190      |\n",
      "|    time_elapsed         | 311       |\n",
      "|    total_timesteps      | 280320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4911227 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.096    |\n",
      "|    explained_variance   | 0.17      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 37213     |\n",
      "|    policy_gradient_loss | -0.0671   |\n",
      "|    value_loss           | 0.0185    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2191      |\n",
      "|    time_elapsed         | 311       |\n",
      "|    total_timesteps      | 280448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9478294 |\n",
      "|    clip_fraction        | 0.293     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    explained_variance   | -0.425    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0909   |\n",
      "|    n_updates            | 37230     |\n",
      "|    policy_gradient_loss | -0.0847   |\n",
      "|    value_loss           | 0.0268    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=280500, episode_reward=-6.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -6        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 280500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5249679 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.147    |\n",
      "|    explained_variance   | 0.254     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0676   |\n",
      "|    n_updates            | 37247     |\n",
      "|    policy_gradient_loss | -0.0629   |\n",
      "|    value_loss           | 0.0853    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2192     |\n",
      "|    time_elapsed    | 311      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2193       |\n",
      "|    time_elapsed         | 311        |\n",
      "|    total_timesteps      | 280704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42553526 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0785    |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 37264      |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 0.0557     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2194       |\n",
      "|    time_elapsed         | 311        |\n",
      "|    total_timesteps      | 280832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15827051 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0834    |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0574    |\n",
      "|    n_updates            | 37281      |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    value_loss           | 0.0691     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2195      |\n",
      "|    time_elapsed         | 311       |\n",
      "|    total_timesteps      | 280960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5923955 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0853   |\n",
      "|    explained_variance   | 0.0431    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0928   |\n",
      "|    n_updates            | 37298     |\n",
      "|    policy_gradient_loss | -0.0762   |\n",
      "|    value_loss           | 0.107     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=281000, episode_reward=-2.88 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -2.88    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 281000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.169257 |\n",
      "|    clip_fraction        | 0.11     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.132   |\n",
      "|    explained_variance   | 0.775    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0556  |\n",
      "|    n_updates            | 37315    |\n",
      "|    policy_gradient_loss | -0.0374  |\n",
      "|    value_loss           | 0.273    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2196     |\n",
      "|    time_elapsed    | 311      |\n",
      "|    total_timesteps | 281088   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2197      |\n",
      "|    time_elapsed         | 311       |\n",
      "|    total_timesteps      | 281216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3016629 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | 0.745     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.11     |\n",
      "|    n_updates            | 37332     |\n",
      "|    policy_gradient_loss | -0.05     |\n",
      "|    value_loss           | 0.137     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2198       |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 281344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24213801 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0588     |\n",
      "|    n_updates            | 37349      |\n",
      "|    policy_gradient_loss | -0.049     |\n",
      "|    value_loss           | 0.892      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2199       |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 281472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13124579 |\n",
      "|    clip_fraction        | 0.0648     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0708    |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0592    |\n",
      "|    n_updates            | 37366      |\n",
      "|    policy_gradient_loss | -0.0589    |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=281500, episode_reward=-2.64 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -2.64      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 281500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27785316 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.11      |\n",
      "|    explained_variance   | 0.012      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0859    |\n",
      "|    n_updates            | 37383      |\n",
      "|    policy_gradient_loss | -0.0726    |\n",
      "|    value_loss           | 0.0333     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2200     |\n",
      "|    time_elapsed    | 312      |\n",
      "|    total_timesteps | 281600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2201       |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 281728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56794417 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 37400      |\n",
      "|    policy_gradient_loss | -0.0683    |\n",
      "|    value_loss           | 0.0184     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2202       |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 281856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75926775 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.173     |\n",
      "|    explained_variance   | 0.0452     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0122    |\n",
      "|    n_updates            | 37417      |\n",
      "|    policy_gradient_loss | -0.0791    |\n",
      "|    value_loss           | 0.024      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2203       |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 281984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42944527 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.174     |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0813    |\n",
      "|    n_updates            | 37434      |\n",
      "|    policy_gradient_loss | -0.0686    |\n",
      "|    value_loss           | 0.0487     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=282000, episode_reward=11.98 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 12         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 282000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35977778 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.704      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0878    |\n",
      "|    n_updates            | 37451      |\n",
      "|    policy_gradient_loss | -0.0742    |\n",
      "|    value_loss           | 0.0689     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2204     |\n",
      "|    time_elapsed    | 313      |\n",
      "|    total_timesteps | 282112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2205      |\n",
      "|    time_elapsed         | 313       |\n",
      "|    total_timesteps      | 282240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5967622 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0825   |\n",
      "|    explained_variance   | 0.657     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0534   |\n",
      "|    n_updates            | 37468     |\n",
      "|    policy_gradient_loss | -0.0566   |\n",
      "|    value_loss           | 0.0324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2206      |\n",
      "|    time_elapsed         | 313       |\n",
      "|    total_timesteps      | 282368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1287744 |\n",
      "|    clip_fraction        | 0.101     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.111    |\n",
      "|    explained_variance   | 0.454     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00214   |\n",
      "|    n_updates            | 37485     |\n",
      "|    policy_gradient_loss | -0.0499   |\n",
      "|    value_loss           | 0.238     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2207       |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 282496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32233185 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.154     |\n",
      "|    explained_variance   | 0.744      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 37502      |\n",
      "|    policy_gradient_loss | -0.0645    |\n",
      "|    value_loss           | 0.666      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=282500, episode_reward=26.24 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 282500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42577246 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.848      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0471    |\n",
      "|    n_updates            | 37519      |\n",
      "|    policy_gradient_loss | -0.0633    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2208     |\n",
      "|    time_elapsed    | 313      |\n",
      "|    total_timesteps | 282624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2209       |\n",
      "|    time_elapsed         | 313        |\n",
      "|    total_timesteps      | 282752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23898143 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.143     |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0704     |\n",
      "|    n_updates            | 37536      |\n",
      "|    policy_gradient_loss | -0.0672    |\n",
      "|    value_loss           | 0.849      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2210      |\n",
      "|    time_elapsed         | 313       |\n",
      "|    total_timesteps      | 282880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4830423 |\n",
      "|    clip_fraction        | 0.198     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.17     |\n",
      "|    explained_variance   | 0.3       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.125     |\n",
      "|    n_updates            | 37553     |\n",
      "|    policy_gradient_loss | -0.0892   |\n",
      "|    value_loss           | 0.708     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=283000, episode_reward=4.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.36       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 283000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49910378 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0809    |\n",
      "|    n_updates            | 37570      |\n",
      "|    policy_gradient_loss | -0.0821    |\n",
      "|    value_loss           | 0.0338     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2211     |\n",
      "|    time_elapsed    | 314      |\n",
      "|    total_timesteps | 283008   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2212       |\n",
      "|    time_elapsed         | 314        |\n",
      "|    total_timesteps      | 283136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33350137 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | -0.194     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0434    |\n",
      "|    n_updates            | 37587      |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0175     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2213      |\n",
      "|    time_elapsed         | 314       |\n",
      "|    total_timesteps      | 283264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4302597 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0958   |\n",
      "|    explained_variance   | -0.0712   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.047    |\n",
      "|    n_updates            | 37604     |\n",
      "|    policy_gradient_loss | -0.0744   |\n",
      "|    value_loss           | 0.0364    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2214      |\n",
      "|    time_elapsed         | 314       |\n",
      "|    total_timesteps      | 283392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5798146 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | -0.129    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0252   |\n",
      "|    n_updates            | 37621     |\n",
      "|    policy_gradient_loss | -0.0437   |\n",
      "|    value_loss           | 0.0158    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=283500, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 0.793    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 283500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.354941 |\n",
      "|    clip_fraction        | 0.101    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0952  |\n",
      "|    explained_variance   | -0.113   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0175  |\n",
      "|    n_updates            | 37638    |\n",
      "|    policy_gradient_loss | -0.0365  |\n",
      "|    value_loss           | 0.0963   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 900      |\n",
      "|    iterations      | 2215     |\n",
      "|    time_elapsed    | 314      |\n",
      "|    total_timesteps | 283520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2216       |\n",
      "|    time_elapsed         | 314        |\n",
      "|    total_timesteps      | 283648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60465634 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0806    |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0648    |\n",
      "|    n_updates            | 37655      |\n",
      "|    policy_gradient_loss | -0.0571    |\n",
      "|    value_loss           | 0.0423     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2217       |\n",
      "|    time_elapsed         | 314        |\n",
      "|    total_timesteps      | 283776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32152075 |\n",
      "|    clip_fraction        | 0.0951     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0888    |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0575    |\n",
      "|    n_updates            | 37672      |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2218      |\n",
      "|    time_elapsed         | 314       |\n",
      "|    total_timesteps      | 283904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6797341 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0953   |\n",
      "|    explained_variance   | 0.678     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0452   |\n",
      "|    n_updates            | 37689     |\n",
      "|    policy_gradient_loss | -0.055    |\n",
      "|    value_loss           | 0.472     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=284000, episode_reward=-17.32 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -17.3      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 284000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22018415 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.156     |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0586    |\n",
      "|    n_updates            | 37706      |\n",
      "|    policy_gradient_loss | -0.0525    |\n",
      "|    value_loss           | 0.281      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2219     |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 284032   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2220      |\n",
      "|    time_elapsed         | 315       |\n",
      "|    total_timesteps      | 284160    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2300774 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0975   |\n",
      "|    explained_variance   | 0.899     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0621   |\n",
      "|    n_updates            | 37723     |\n",
      "|    policy_gradient_loss | -0.0635   |\n",
      "|    value_loss           | 0.131     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2221      |\n",
      "|    time_elapsed         | 315       |\n",
      "|    total_timesteps      | 284288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4451917 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.112    |\n",
      "|    explained_variance   | 0.201     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.29      |\n",
      "|    n_updates            | 37740     |\n",
      "|    policy_gradient_loss | -0.0565   |\n",
      "|    value_loss           | 0.824     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2222      |\n",
      "|    time_elapsed         | 315       |\n",
      "|    total_timesteps      | 284416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3112142 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.909     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0314   |\n",
      "|    n_updates            | 37757     |\n",
      "|    policy_gradient_loss | -0.0477   |\n",
      "|    value_loss           | 0.138     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=284500, episode_reward=-7.57 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -7.57      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 284500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.86517644 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.129     |\n",
      "|    explained_variance   | -0.273     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0484    |\n",
      "|    n_updates            | 37774      |\n",
      "|    policy_gradient_loss | -0.0864    |\n",
      "|    value_loss           | 0.0159     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2223     |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 284544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2224       |\n",
      "|    time_elapsed         | 315        |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35152918 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0522    |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0281    |\n",
      "|    n_updates            | 37791      |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    value_loss           | 0.0155     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2225       |\n",
      "|    time_elapsed         | 315        |\n",
      "|    total_timesteps      | 284800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38478333 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0863    |\n",
      "|    n_updates            | 37808      |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    value_loss           | 0.015      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2226      |\n",
      "|    time_elapsed         | 315       |\n",
      "|    total_timesteps      | 284928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3138958 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.125    |\n",
      "|    explained_variance   | 0.0257    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0731   |\n",
      "|    n_updates            | 37825     |\n",
      "|    policy_gradient_loss | -0.0577   |\n",
      "|    value_loss           | 0.105     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-7.11 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -7.11    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 285000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.605197 |\n",
      "|    clip_fraction        | 0.172    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.115   |\n",
      "|    explained_variance   | 0.763    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0923  |\n",
      "|    n_updates            | 37842    |\n",
      "|    policy_gradient_loss | -0.06    |\n",
      "|    value_loss           | 0.0824   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2227     |\n",
      "|    time_elapsed    | 316      |\n",
      "|    total_timesteps | 285056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2228       |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 285184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23632884 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.515      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 37859      |\n",
      "|    policy_gradient_loss | -0.0618    |\n",
      "|    value_loss           | 0.0393     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2229       |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 285312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41057843 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0962    |\n",
      "|    explained_variance   | 0.172      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00441   |\n",
      "|    n_updates            | 37876      |\n",
      "|    policy_gradient_loss | -0.0508    |\n",
      "|    value_loss           | 0.287      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2230       |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 285440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42234266 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.637      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0895    |\n",
      "|    n_updates            | 37893      |\n",
      "|    policy_gradient_loss | -0.0604    |\n",
      "|    value_loss           | 0.273      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=285500, episode_reward=-24.30 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -24.3      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 285500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46557933 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0996    |\n",
      "|    explained_variance   | 0.874      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0368    |\n",
      "|    n_updates            | 37910      |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2231     |\n",
      "|    time_elapsed    | 316      |\n",
      "|    total_timesteps | 285568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2232       |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 285696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38894036 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.181     |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.135      |\n",
      "|    n_updates            | 37927      |\n",
      "|    policy_gradient_loss | -0.0637    |\n",
      "|    value_loss           | 0.548      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 901        |\n",
      "|    iterations           | 2233       |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 285824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.51293766 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0332    |\n",
      "|    n_updates            | 37944      |\n",
      "|    policy_gradient_loss | -0.0709    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2234       |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 285952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20521995 |\n",
      "|    clip_fraction        | 0.0988     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.0389     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 37961      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.0484     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=286000, episode_reward=-9.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | -9.54    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 286000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.474683 |\n",
      "|    clip_fraction        | 0.134    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0857  |\n",
      "|    explained_variance   | 0.133    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.061   |\n",
      "|    n_updates            | 37978    |\n",
      "|    policy_gradient_loss | -0.0733  |\n",
      "|    value_loss           | 0.0559   |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2235     |\n",
      "|    time_elapsed    | 317      |\n",
      "|    total_timesteps | 286080   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2236      |\n",
      "|    time_elapsed         | 317       |\n",
      "|    total_timesteps      | 286208    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2142254 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | 0.123     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0223   |\n",
      "|    n_updates            | 37995     |\n",
      "|    policy_gradient_loss | -0.0422   |\n",
      "|    value_loss           | 0.0577    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2237      |\n",
      "|    time_elapsed         | 317       |\n",
      "|    total_timesteps      | 286336    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6237693 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.096    |\n",
      "|    explained_variance   | 0.235     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0782   |\n",
      "|    n_updates            | 38012     |\n",
      "|    policy_gradient_loss | -0.0506   |\n",
      "|    value_loss           | 0.0562    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2238       |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 286464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31451696 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0936    |\n",
      "|    explained_variance   | 0.598      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0591    |\n",
      "|    n_updates            | 38029      |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 0.06       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=286500, episode_reward=-0.40 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -0.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 286500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3131592 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0693   |\n",
      "|    explained_variance   | 0.445     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.13     |\n",
      "|    n_updates            | 38046     |\n",
      "|    policy_gradient_loss | -0.0463   |\n",
      "|    value_loss           | 0.0452    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2239     |\n",
      "|    time_elapsed    | 317      |\n",
      "|    total_timesteps | 286592   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 901       |\n",
      "|    iterations           | 2240      |\n",
      "|    time_elapsed         | 317       |\n",
      "|    total_timesteps      | 286720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5258081 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.07     |\n",
      "|    explained_variance   | 0.32      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0767   |\n",
      "|    n_updates            | 38063     |\n",
      "|    policy_gradient_loss | -0.055    |\n",
      "|    value_loss           | 0.13      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2241       |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 286848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29645878 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.496      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00701    |\n",
      "|    n_updates            | 38080      |\n",
      "|    policy_gradient_loss | -0.0542    |\n",
      "|    value_loss           | 0.334      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2242       |\n",
      "|    time_elapsed         | 318        |\n",
      "|    total_timesteps      | 286976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24525848 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0763    |\n",
      "|    explained_variance   | 0.899      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 38097      |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    value_loss           | 0.0652     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=287000, episode_reward=4.93 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 4.93       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 287000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21880065 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0891    |\n",
      "|    explained_variance   | 0.391      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.439      |\n",
      "|    n_updates            | 38114      |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 1.22       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2243     |\n",
      "|    time_elapsed    | 318      |\n",
      "|    total_timesteps | 287104   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2244      |\n",
      "|    time_elapsed         | 318       |\n",
      "|    total_timesteps      | 287232    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6082454 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0927   |\n",
      "|    explained_variance   | 0.69      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0373   |\n",
      "|    n_updates            | 38131     |\n",
      "|    policy_gradient_loss | -0.05     |\n",
      "|    value_loss           | 0.482     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2245      |\n",
      "|    time_elapsed         | 318       |\n",
      "|    total_timesteps      | 287360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6715352 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0881   |\n",
      "|    explained_variance   | -0.0879   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0117   |\n",
      "|    n_updates            | 38148     |\n",
      "|    policy_gradient_loss | -0.0495   |\n",
      "|    value_loss           | 0.178     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2246      |\n",
      "|    time_elapsed         | 318       |\n",
      "|    total_timesteps      | 287488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5795714 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0791   |\n",
      "|    explained_variance   | 0.272     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0824   |\n",
      "|    n_updates            | 38165     |\n",
      "|    policy_gradient_loss | -0.0441   |\n",
      "|    value_loss           | 0.152     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=287500, episode_reward=7.60 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 7.6       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 287500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5484511 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.088    |\n",
      "|    explained_variance   | 0.0767    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0202   |\n",
      "|    n_updates            | 38182     |\n",
      "|    policy_gradient_loss | -0.0648   |\n",
      "|    value_loss           | 0.0473    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2247     |\n",
      "|    time_elapsed    | 318      |\n",
      "|    total_timesteps | 287616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2248       |\n",
      "|    time_elapsed         | 318        |\n",
      "|    total_timesteps      | 287744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18462288 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.148     |\n",
      "|    explained_variance   | -0.00932   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 38199      |\n",
      "|    policy_gradient_loss | -0.0496    |\n",
      "|    value_loss           | 0.0233     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2249       |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 287872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37114364 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0666    |\n",
      "|    n_updates            | 38216      |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.0866     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=9.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 9.28       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 288000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.71104187 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0601    |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.122     |\n",
      "|    n_updates            | 38233      |\n",
      "|    policy_gradient_loss | -0.0623    |\n",
      "|    value_loss           | 0.0897     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2250     |\n",
      "|    time_elapsed    | 319      |\n",
      "|    total_timesteps | 288000   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 2251     |\n",
      "|    time_elapsed         | 319      |\n",
      "|    total_timesteps      | 288128   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.379327 |\n",
      "|    clip_fraction        | 0.149    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.113   |\n",
      "|    explained_variance   | 0.517    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0969  |\n",
      "|    n_updates            | 38250    |\n",
      "|    policy_gradient_loss | -0.0638  |\n",
      "|    value_loss           | 0.0888   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2252       |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 288256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36112213 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0537    |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0385    |\n",
      "|    n_updates            | 38267      |\n",
      "|    policy_gradient_loss | -0.0558    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 2253     |\n",
      "|    time_elapsed         | 319      |\n",
      "|    total_timesteps      | 288384   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.686766 |\n",
      "|    clip_fraction        | 0.157    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.154   |\n",
      "|    explained_variance   | 0.52     |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.108   |\n",
      "|    n_updates            | 38284    |\n",
      "|    policy_gradient_loss | -0.0686  |\n",
      "|    value_loss           | 0.329    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=288500, episode_reward=-9.18 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -9.18      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 288500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24980494 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.068     |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0466    |\n",
      "|    n_updates            | 38301      |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2254     |\n",
      "|    time_elapsed    | 319      |\n",
      "|    total_timesteps | 288512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2255       |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 288640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15117426 |\n",
      "|    clip_fraction        | 0.0777     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.088     |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 38318      |\n",
      "|    policy_gradient_loss | -0.0196    |\n",
      "|    value_loss           | 1.27       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2256       |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 288768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45253426 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.903      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000314  |\n",
      "|    n_updates            | 38335      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.172      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2257       |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 288896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38040212 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.0439    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0914    |\n",
      "|    n_updates            | 38352      |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.042      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=289000, episode_reward=19.75 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 19.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 289000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1580591 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.1      |\n",
      "|    explained_variance   | -0.0645   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0888   |\n",
      "|    n_updates            | 38369     |\n",
      "|    policy_gradient_loss | -0.0776   |\n",
      "|    value_loss           | 0.0276    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2258     |\n",
      "|    time_elapsed    | 320      |\n",
      "|    total_timesteps | 289024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2259       |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 289152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31490394 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 0.000904   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0537    |\n",
      "|    n_updates            | 38386      |\n",
      "|    policy_gradient_loss | -0.0737    |\n",
      "|    value_loss           | 0.0272     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2260       |\n",
      "|    time_elapsed         | 320        |\n",
      "|    total_timesteps      | 289280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44844562 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | -0.142     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0302    |\n",
      "|    n_updates            | 38403      |\n",
      "|    policy_gradient_loss | -0.0492    |\n",
      "|    value_loss           | 0.0709     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2261      |\n",
      "|    time_elapsed         | 320       |\n",
      "|    total_timesteps      | 289408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9638299 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.098    |\n",
      "|    explained_variance   | 0.71      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.135    |\n",
      "|    n_updates            | 38420     |\n",
      "|    policy_gradient_loss | -0.0814   |\n",
      "|    value_loss           | 0.0547    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=289500, episode_reward=17.82 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 17.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 289500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30655146 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.108     |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0928    |\n",
      "|    n_updates            | 38437      |\n",
      "|    policy_gradient_loss | -0.0485    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2262     |\n",
      "|    time_elapsed    | 320      |\n",
      "|    total_timesteps | 289536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2263       |\n",
      "|    time_elapsed         | 321        |\n",
      "|    total_timesteps      | 289664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32330218 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.095     |\n",
      "|    explained_variance   | 0.0163     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00133    |\n",
      "|    n_updates            | 38454      |\n",
      "|    policy_gradient_loss | -0.0271    |\n",
      "|    value_loss           | 0.778      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2264      |\n",
      "|    time_elapsed         | 321       |\n",
      "|    total_timesteps      | 289792    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3363806 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.153    |\n",
      "|    explained_variance   | 0.617     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0442    |\n",
      "|    n_updates            | 38471     |\n",
      "|    policy_gradient_loss | -0.052    |\n",
      "|    value_loss           | 0.61      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2265       |\n",
      "|    time_elapsed         | 321        |\n",
      "|    total_timesteps      | 289920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40375435 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0807    |\n",
      "|    explained_variance   | 0.827      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0911    |\n",
      "|    n_updates            | 38488      |\n",
      "|    policy_gradient_loss | -0.0568    |\n",
      "|    value_loss           | 0.0705     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=7.68 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 7.68       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 290000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06639713 |\n",
      "|    clip_fraction        | 0.0616     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.672      |\n",
      "|    n_updates            | 38505      |\n",
      "|    policy_gradient_loss | -0.0402    |\n",
      "|    value_loss           | 2.1        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2266     |\n",
      "|    time_elapsed    | 321      |\n",
      "|    total_timesteps | 290048   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2267       |\n",
      "|    time_elapsed         | 321        |\n",
      "|    total_timesteps      | 290176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34211558 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.655      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0112    |\n",
      "|    n_updates            | 38522      |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.345      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2268      |\n",
      "|    time_elapsed         | 321       |\n",
      "|    total_timesteps      | 290304    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3555625 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.168    |\n",
      "|    explained_variance   | 0.343     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0344   |\n",
      "|    n_updates            | 38539     |\n",
      "|    policy_gradient_loss | -0.0632   |\n",
      "|    value_loss           | 0.116     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2269      |\n",
      "|    time_elapsed         | 321       |\n",
      "|    total_timesteps      | 290432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9724801 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | -0.175    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0552   |\n",
      "|    n_updates            | 38556     |\n",
      "|    policy_gradient_loss | -0.0564   |\n",
      "|    value_loss           | 0.105     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=290500, episode_reward=3.70 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 3.7       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 290500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4915859 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.187    |\n",
      "|    explained_variance   | 0.215     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 38573     |\n",
      "|    policy_gradient_loss | -0.0904   |\n",
      "|    value_loss           | 0.0491    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2270     |\n",
      "|    time_elapsed    | 322      |\n",
      "|    total_timesteps | 290560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2271       |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 290688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36775106 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.174     |\n",
      "|    explained_variance   | -0.713     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.093     |\n",
      "|    n_updates            | 38590      |\n",
      "|    policy_gradient_loss | -0.0742    |\n",
      "|    value_loss           | 0.0506     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2272       |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 290816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48250496 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.152     |\n",
      "|    explained_variance   | -0.182     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0661    |\n",
      "|    n_updates            | 38607      |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2273      |\n",
      "|    time_elapsed         | 322       |\n",
      "|    total_timesteps      | 290944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9880341 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0701   |\n",
      "|    explained_variance   | 0.791     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0979   |\n",
      "|    n_updates            | 38624     |\n",
      "|    policy_gradient_loss | -0.0657   |\n",
      "|    value_loss           | 0.0406    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=291000, episode_reward=2.73 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 2.73       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 291000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23817028 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.131     |\n",
      "|    explained_variance   | 0.359      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0517    |\n",
      "|    n_updates            | 38641      |\n",
      "|    policy_gradient_loss | -0.0761    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2274     |\n",
      "|    time_elapsed    | 322      |\n",
      "|    total_timesteps | 291072   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2275      |\n",
      "|    time_elapsed         | 322       |\n",
      "|    total_timesteps      | 291200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2909687 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.188    |\n",
      "|    explained_variance   | 0.611     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0101   |\n",
      "|    n_updates            | 38658     |\n",
      "|    policy_gradient_loss | -0.0636   |\n",
      "|    value_loss           | 0.892     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2276       |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 291328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31269717 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0763    |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0544    |\n",
      "|    n_updates            | 38675      |\n",
      "|    policy_gradient_loss | -0.0531    |\n",
      "|    value_loss           | 0.248      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2277       |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 291456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16113666 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.173     |\n",
      "|    explained_variance   | 0.452      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0585    |\n",
      "|    n_updates            | 38692      |\n",
      "|    policy_gradient_loss | -0.0572    |\n",
      "|    value_loss           | 0.456      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=291500, episode_reward=-17.28 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -17.3      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 291500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34468567 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0437    |\n",
      "|    n_updates            | 38709      |\n",
      "|    policy_gradient_loss | -0.0738    |\n",
      "|    value_loss           | 0.31       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2278     |\n",
      "|    time_elapsed    | 323      |\n",
      "|    total_timesteps | 291584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2279       |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 291712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75680643 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.182     |\n",
      "|    explained_variance   | -0.312     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0971    |\n",
      "|    n_updates            | 38726      |\n",
      "|    policy_gradient_loss | -0.0972    |\n",
      "|    value_loss           | 0.0636     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2280       |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 291840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11458947 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0988    |\n",
      "|    explained_variance   | 0.403      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0371    |\n",
      "|    n_updates            | 38743      |\n",
      "|    policy_gradient_loss | -0.0576    |\n",
      "|    value_loss           | 0.0477     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55.2     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 2281     |\n",
      "|    time_elapsed         | 323      |\n",
      "|    total_timesteps      | 291968   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.38425  |\n",
      "|    clip_fraction        | 0.174    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.194   |\n",
      "|    explained_variance   | 0.156    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.188   |\n",
      "|    n_updates            | 38760    |\n",
      "|    policy_gradient_loss | -0.0813  |\n",
      "|    value_loss           | 0.0389   |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=292000, episode_reward=-15.52 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -15.5      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 292000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22591138 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.264     |\n",
      "|    explained_variance   | -1.34      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.091     |\n",
      "|    n_updates            | 38777      |\n",
      "|    policy_gradient_loss | -0.0738    |\n",
      "|    value_loss           | 0.0456     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2282     |\n",
      "|    time_elapsed    | 323      |\n",
      "|    total_timesteps | 292096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2283       |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 292224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29486865 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.182     |\n",
      "|    explained_variance   | 0.00985    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0678    |\n",
      "|    n_updates            | 38794      |\n",
      "|    policy_gradient_loss | -0.0567    |\n",
      "|    value_loss           | 0.0648     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2284       |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 292352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29476166 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0767    |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0109    |\n",
      "|    n_updates            | 38811      |\n",
      "|    policy_gradient_loss | -0.0361    |\n",
      "|    value_loss           | 0.0384     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2285      |\n",
      "|    time_elapsed         | 324       |\n",
      "|    total_timesteps      | 292480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7293362 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.084    |\n",
      "|    explained_variance   | 0.549     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0222   |\n",
      "|    n_updates            | 38828     |\n",
      "|    policy_gradient_loss | -0.0784   |\n",
      "|    value_loss           | 0.0867    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=292500, episode_reward=14.89 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 14.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 292500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14606386 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.16      |\n",
      "|    explained_variance   | 0.588      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00943    |\n",
      "|    n_updates            | 38845      |\n",
      "|    policy_gradient_loss | -0.0546    |\n",
      "|    value_loss           | 0.564      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2286     |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 292608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2287       |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 292736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23842897 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0878    |\n",
      "|    explained_variance   | 0.84       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.021     |\n",
      "|    n_updates            | 38862      |\n",
      "|    policy_gradient_loss | -0.0455    |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2288       |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53714114 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.783      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0797    |\n",
      "|    n_updates            | 38879      |\n",
      "|    policy_gradient_loss | -0.0713    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2289       |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 292992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21148452 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.208     |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0279    |\n",
      "|    n_updates            | 38896      |\n",
      "|    policy_gradient_loss | -0.0658    |\n",
      "|    value_loss           | 0.22       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=293000, episode_reward=-0.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -0.117    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 293000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4790131 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.107    |\n",
      "|    explained_variance   | 0.495     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0374   |\n",
      "|    n_updates            | 38913     |\n",
      "|    policy_gradient_loss | -0.0661   |\n",
      "|    value_loss           | 0.0767    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2290     |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 293120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2291       |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 293248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38057208 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.13      |\n",
      "|    explained_variance   | 0.313      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0875    |\n",
      "|    n_updates            | 38930      |\n",
      "|    policy_gradient_loss | -0.0809    |\n",
      "|    value_loss           | 0.0766     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2292      |\n",
      "|    time_elapsed         | 325       |\n",
      "|    total_timesteps      | 293376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4120987 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.109    |\n",
      "|    explained_variance   | 0.539     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0639   |\n",
      "|    n_updates            | 38947     |\n",
      "|    policy_gradient_loss | -0.0505   |\n",
      "|    value_loss           | 0.0164    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=293500, episode_reward=10.56 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 10.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 293500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24901862 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | -0.604     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.079     |\n",
      "|    n_updates            | 38964      |\n",
      "|    policy_gradient_loss | -0.0631    |\n",
      "|    value_loss           | 0.0137     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 901      |\n",
      "|    iterations      | 2293     |\n",
      "|    time_elapsed    | 325      |\n",
      "|    total_timesteps | 293504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2294       |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 293632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.56477875 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 38981      |\n",
      "|    policy_gradient_loss | -0.0922    |\n",
      "|    value_loss           | 0.0729     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2295      |\n",
      "|    time_elapsed         | 325       |\n",
      "|    total_timesteps      | 293760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3563267 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0775   |\n",
      "|    explained_variance   | 0.856     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0263   |\n",
      "|    n_updates            | 38998     |\n",
      "|    policy_gradient_loss | -0.0457   |\n",
      "|    value_loss           | 0.0348    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2296      |\n",
      "|    time_elapsed         | 325       |\n",
      "|    total_timesteps      | 293888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6562726 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0786   |\n",
      "|    explained_variance   | 0.543     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0817   |\n",
      "|    n_updates            | 39015     |\n",
      "|    policy_gradient_loss | -0.0654   |\n",
      "|    value_loss           | 0.0918    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=294000, episode_reward=-18.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -18.5     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 294000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6916579 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.103    |\n",
      "|    explained_variance   | 0.462     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.078    |\n",
      "|    n_updates            | 39032     |\n",
      "|    policy_gradient_loss | -0.0526   |\n",
      "|    value_loss           | 0.24      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2297     |\n",
      "|    time_elapsed    | 325      |\n",
      "|    total_timesteps | 294016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2298       |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 294144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13122846 |\n",
      "|    clip_fraction        | 0.0947     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0791    |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0457    |\n",
      "|    n_updates            | 39049      |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.472      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2299      |\n",
      "|    time_elapsed         | 326       |\n",
      "|    total_timesteps      | 294272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6752095 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.058    |\n",
      "|    explained_variance   | 0.906     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0166   |\n",
      "|    n_updates            | 39066     |\n",
      "|    policy_gradient_loss | -0.0484   |\n",
      "|    value_loss           | 0.0448    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2300      |\n",
      "|    time_elapsed         | 326       |\n",
      "|    total_timesteps      | 294400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2872765 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.182    |\n",
      "|    explained_variance   | 0.439     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.209     |\n",
      "|    n_updates            | 39083     |\n",
      "|    policy_gradient_loss | -0.0656   |\n",
      "|    value_loss           | 0.626     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=294500, episode_reward=-5.09 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -5.09     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 294500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7127964 |\n",
      "|    clip_fraction        | 0.18      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | 0.639     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0241   |\n",
      "|    n_updates            | 39100     |\n",
      "|    policy_gradient_loss | -0.0541   |\n",
      "|    value_loss           | 0.208     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2301     |\n",
      "|    time_elapsed    | 326      |\n",
      "|    total_timesteps | 294528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2302       |\n",
      "|    time_elapsed         | 326        |\n",
      "|    total_timesteps      | 294656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30712357 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.09      |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0155    |\n",
      "|    n_updates            | 39117      |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.0428     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2303       |\n",
      "|    time_elapsed         | 326        |\n",
      "|    total_timesteps      | 294784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14295875 |\n",
      "|    clip_fraction        | 0.0915     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0687    |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0317    |\n",
      "|    n_updates            | 39134      |\n",
      "|    policy_gradient_loss | -0.0549    |\n",
      "|    value_loss           | 0.062      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2304       |\n",
      "|    time_elapsed         | 326        |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16130315 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0627    |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0445    |\n",
      "|    n_updates            | 39151      |\n",
      "|    policy_gradient_loss | -0.0497    |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-10.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -10        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 295000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26304558 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0975    |\n",
      "|    explained_variance   | -0.0449    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0788    |\n",
      "|    n_updates            | 39168      |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    value_loss           | 0.0882     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2305     |\n",
      "|    time_elapsed    | 326      |\n",
      "|    total_timesteps | 295040   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2306      |\n",
      "|    time_elapsed         | 327       |\n",
      "|    total_timesteps      | 295168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2773186 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.132    |\n",
      "|    explained_variance   | 0.137     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.105    |\n",
      "|    n_updates            | 39185     |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 0.0477    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2307       |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 295296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41976133 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0625    |\n",
      "|    explained_variance   | 0.72       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0556    |\n",
      "|    n_updates            | 39202      |\n",
      "|    policy_gradient_loss | -0.0485    |\n",
      "|    value_loss           | 0.0601     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2308      |\n",
      "|    time_elapsed         | 327       |\n",
      "|    total_timesteps      | 295424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3130531 |\n",
      "|    clip_fraction        | 0.0855    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0442   |\n",
      "|    explained_variance   | 0.0526    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0756   |\n",
      "|    n_updates            | 39219     |\n",
      "|    policy_gradient_loss | -0.0428   |\n",
      "|    value_loss           | 0.109     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=295500, episode_reward=-22.73 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | -22.7      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 295500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20937693 |\n",
      "|    clip_fraction        | 0.0726     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0724    |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0785    |\n",
      "|    n_updates            | 39236      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.373      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2309     |\n",
      "|    time_elapsed    | 327      |\n",
      "|    total_timesteps | 295552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2310       |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 295680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28567374 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0678    |\n",
      "|    explained_variance   | 0.795      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0838    |\n",
      "|    n_updates            | 39253      |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    value_loss           | 0.0838     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2311       |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 295808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79237044 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | -0.263     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0786    |\n",
      "|    n_updates            | 39270      |\n",
      "|    policy_gradient_loss | -0.0708    |\n",
      "|    value_loss           | 0.277      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2312       |\n",
      "|    time_elapsed         | 327        |\n",
      "|    total_timesteps      | 295936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33699095 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0351     |\n",
      "|    n_updates            | 39287      |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=296000, episode_reward=33.78 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 33.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 296000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0148429 |\n",
      "|    clip_fraction        | 0.238     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | -0.15     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0982   |\n",
      "|    n_updates            | 39304     |\n",
      "|    policy_gradient_loss | -0.085    |\n",
      "|    value_loss           | 0.0278    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2313     |\n",
      "|    time_elapsed    | 327      |\n",
      "|    total_timesteps | 296064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2314       |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 296192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30167076 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0938    |\n",
      "|    explained_variance   | -0.433     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.00546   |\n",
      "|    n_updates            | 39321      |\n",
      "|    policy_gradient_loss | -0.0501    |\n",
      "|    value_loss           | 0.102      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2315       |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 296320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18394673 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.118     |\n",
      "|    explained_variance   | -0.0329    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.051     |\n",
      "|    n_updates            | 39338      |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.019      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2316       |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 296448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35090992 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0909    |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0627    |\n",
      "|    n_updates            | 39355      |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    value_loss           | 0.0255     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=296500, episode_reward=53.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 296500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20081373 |\n",
      "|    clip_fraction        | 0.0938     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0735    |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0395    |\n",
      "|    n_updates            | 39372      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.0602     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2317     |\n",
      "|    time_elapsed    | 328      |\n",
      "|    total_timesteps | 296576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2318       |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 296704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31052887 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0894    |\n",
      "|    explained_variance   | 0.83       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0789    |\n",
      "|    n_updates            | 39389      |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 0.0397     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2319       |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 296832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52125734 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0731    |\n",
      "|    explained_variance   | -0.292     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0593    |\n",
      "|    n_updates            | 39406      |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    value_loss           | 0.172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2320      |\n",
      "|    time_elapsed         | 328       |\n",
      "|    total_timesteps      | 296960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0375205 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.067    |\n",
      "|    explained_variance   | 0.188     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0461   |\n",
      "|    n_updates            | 39423     |\n",
      "|    policy_gradient_loss | -0.0555   |\n",
      "|    value_loss           | 0.3       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=297000, episode_reward=64.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 64.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 297000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2642413 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | 0.685     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.125    |\n",
      "|    n_updates            | 39440     |\n",
      "|    policy_gradient_loss | -0.0835   |\n",
      "|    value_loss           | 0.259     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2321     |\n",
      "|    time_elapsed    | 329      |\n",
      "|    total_timesteps | 297088   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2322       |\n",
      "|    time_elapsed         | 329        |\n",
      "|    total_timesteps      | 297216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64931864 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0839    |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.012     |\n",
      "|    n_updates            | 39457      |\n",
      "|    policy_gradient_loss | -0.0563    |\n",
      "|    value_loss           | 0.327      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2323       |\n",
      "|    time_elapsed         | 329        |\n",
      "|    total_timesteps      | 297344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28821602 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.107      |\n",
      "|    n_updates            | 39474      |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 0.587      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2324      |\n",
      "|    time_elapsed         | 329       |\n",
      "|    total_timesteps      | 297472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5371393 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.105    |\n",
      "|    explained_variance   | 0.428     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.259     |\n",
      "|    n_updates            | 39491     |\n",
      "|    policy_gradient_loss | -0.0349   |\n",
      "|    value_loss           | 0.389     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=297500, episode_reward=49.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 49.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 297500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46342754 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.131     |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0446    |\n",
      "|    n_updates            | 39508      |\n",
      "|    policy_gradient_loss | -0.047     |\n",
      "|    value_loss           | 0.0738     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2325     |\n",
      "|    time_elapsed    | 329      |\n",
      "|    total_timesteps | 297600   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2326      |\n",
      "|    time_elapsed         | 329       |\n",
      "|    total_timesteps      | 297728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5477457 |\n",
      "|    clip_fraction        | 0.162     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | -0.407    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0673   |\n",
      "|    n_updates            | 39525     |\n",
      "|    policy_gradient_loss | -0.0459   |\n",
      "|    value_loss           | 0.0164    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2327       |\n",
      "|    time_elapsed         | 329        |\n",
      "|    total_timesteps      | 297856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.67934316 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.148     |\n",
      "|    explained_variance   | 0.0835     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 39542      |\n",
      "|    policy_gradient_loss | -0.0638    |\n",
      "|    value_loss           | 0.0171     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2328      |\n",
      "|    time_elapsed         | 329       |\n",
      "|    total_timesteps      | 297984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3643776 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.174    |\n",
      "|    explained_variance   | 0.245     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.122    |\n",
      "|    n_updates            | 39559     |\n",
      "|    policy_gradient_loss | -0.0637   |\n",
      "|    value_loss           | 0.0773    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=298000, episode_reward=52.96 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 53         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 298000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49649113 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0749    |\n",
      "|    explained_variance   | 0.83       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.049     |\n",
      "|    n_updates            | 39576      |\n",
      "|    policy_gradient_loss | -0.0569    |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2329     |\n",
      "|    time_elapsed    | 330      |\n",
      "|    total_timesteps | 298112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2330      |\n",
      "|    time_elapsed         | 330       |\n",
      "|    total_timesteps      | 298240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4035439 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0966   |\n",
      "|    explained_variance   | 0.448     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0987   |\n",
      "|    n_updates            | 39593     |\n",
      "|    policy_gradient_loss | -0.0599   |\n",
      "|    value_loss           | 0.0746    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2331      |\n",
      "|    time_elapsed         | 330       |\n",
      "|    total_timesteps      | 298368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5592884 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.385     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0693   |\n",
      "|    n_updates            | 39610     |\n",
      "|    policy_gradient_loss | -0.0633   |\n",
      "|    value_loss           | 0.167     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2332       |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 298496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30815262 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0521    |\n",
      "|    n_updates            | 39627      |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    value_loss           | 0.302      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=298500, episode_reward=37.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 37.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 298500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3807239 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0612   |\n",
      "|    explained_variance   | 0.856     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0826   |\n",
      "|    n_updates            | 39644     |\n",
      "|    policy_gradient_loss | -0.0545   |\n",
      "|    value_loss           | 0.0722    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2333     |\n",
      "|    time_elapsed    | 330      |\n",
      "|    total_timesteps | 298624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2334       |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 298752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39409631 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0827    |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.166      |\n",
      "|    n_updates            | 39661      |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    value_loss           | 0.527      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2335      |\n",
      "|    time_elapsed         | 330       |\n",
      "|    total_timesteps      | 298880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7799001 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.173    |\n",
      "|    explained_variance   | 0.517     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0372   |\n",
      "|    n_updates            | 39678     |\n",
      "|    policy_gradient_loss | -0.0783   |\n",
      "|    value_loss           | 0.343     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=299000, episode_reward=85.16 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 85.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 299000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37334132 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0571    |\n",
      "|    n_updates            | 39695      |\n",
      "|    policy_gradient_loss | -0.0671    |\n",
      "|    value_loss           | 0.0705     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2336     |\n",
      "|    time_elapsed    | 331      |\n",
      "|    total_timesteps | 299008   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2337      |\n",
      "|    time_elapsed         | 331       |\n",
      "|    total_timesteps      | 299136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2515563 |\n",
      "|    clip_fraction        | 0.0846    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0902   |\n",
      "|    explained_variance   | -0.141    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0319   |\n",
      "|    n_updates            | 39712     |\n",
      "|    policy_gradient_loss | -0.0303   |\n",
      "|    value_loss           | 0.025     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2338      |\n",
      "|    time_elapsed         | 331       |\n",
      "|    total_timesteps      | 299264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3678805 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.0212    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.061    |\n",
      "|    n_updates            | 39729     |\n",
      "|    policy_gradient_loss | -0.0595   |\n",
      "|    value_loss           | 0.0155    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2339      |\n",
      "|    time_elapsed         | 331       |\n",
      "|    total_timesteps      | 299392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3099888 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.141    |\n",
      "|    explained_variance   | -1.63     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.118    |\n",
      "|    n_updates            | 39746     |\n",
      "|    policy_gradient_loss | -0.0584   |\n",
      "|    value_loss           | 0.0413    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=299500, episode_reward=64.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 64.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 299500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7433866 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0813   |\n",
      "|    explained_variance   | 0.45      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0812   |\n",
      "|    n_updates            | 39763     |\n",
      "|    policy_gradient_loss | -0.0553   |\n",
      "|    value_loss           | 0.0624    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2340     |\n",
      "|    time_elapsed    | 331      |\n",
      "|    total_timesteps | 299520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2341       |\n",
      "|    time_elapsed         | 331        |\n",
      "|    total_timesteps      | 299648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32139444 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.059     |\n",
      "|    explained_variance   | 0.484      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.116     |\n",
      "|    n_updates            | 39780      |\n",
      "|    policy_gradient_loss | -0.0604    |\n",
      "|    value_loss           | 0.0466     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2342       |\n",
      "|    time_elapsed         | 331        |\n",
      "|    total_timesteps      | 299776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34201884 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0932    |\n",
      "|    explained_variance   | -0.754     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0284    |\n",
      "|    n_updates            | 39797      |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    value_loss           | 0.305      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2343       |\n",
      "|    time_elapsed         | 331        |\n",
      "|    total_timesteps      | 299904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44406807 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | 0.507      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0387    |\n",
      "|    n_updates            | 39814      |\n",
      "|    policy_gradient_loss | -0.0531    |\n",
      "|    value_loss           | 0.431      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=16.48 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 16.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 300000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23432317 |\n",
      "|    clip_fraction        | 0.0827     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0654    |\n",
      "|    explained_variance   | 0.742      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0477    |\n",
      "|    n_updates            | 39831      |\n",
      "|    policy_gradient_loss | -0.0346    |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2344     |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 300032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2345       |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 300160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19932403 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.152     |\n",
      "|    explained_variance   | -0.215     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.055     |\n",
      "|    n_updates            | 39848      |\n",
      "|    policy_gradient_loss | -0.0799    |\n",
      "|    value_loss           | 0.576      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2346       |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 300288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39051363 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.215     |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0321     |\n",
      "|    n_updates            | 39865      |\n",
      "|    policy_gradient_loss | -0.0851    |\n",
      "|    value_loss           | 0.383      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2347       |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 300416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19379666 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | -0.272     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0571    |\n",
      "|    n_updates            | 39882      |\n",
      "|    policy_gradient_loss | -0.0621    |\n",
      "|    value_loss           | 0.0365     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=300500, episode_reward=44.46 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 44.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 300500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14202088 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.187      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0618    |\n",
      "|    n_updates            | 39899      |\n",
      "|    policy_gradient_loss | -0.05      |\n",
      "|    value_loss           | 0.0533     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2348     |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 300544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2349       |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 300672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16389501 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.0547     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0766    |\n",
      "|    n_updates            | 39916      |\n",
      "|    policy_gradient_loss | -0.0607    |\n",
      "|    value_loss           | 0.0145     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2350      |\n",
      "|    time_elapsed         | 333       |\n",
      "|    total_timesteps      | 300800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4859109 |\n",
      "|    clip_fraction        | 0.181     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.18     |\n",
      "|    explained_variance   | 0.247     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 39933     |\n",
      "|    policy_gradient_loss | -0.0563   |\n",
      "|    value_loss           | 0.0435    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2351      |\n",
      "|    time_elapsed         | 333       |\n",
      "|    total_timesteps      | 300928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2013907 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.136    |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0322   |\n",
      "|    n_updates            | 39950     |\n",
      "|    policy_gradient_loss | -0.0481   |\n",
      "|    value_loss           | 0.062     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=301000, episode_reward=29.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 301000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.83569115 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0669    |\n",
      "|    explained_variance   | 0.839      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0739    |\n",
      "|    n_updates            | 39967      |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.025      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2352     |\n",
      "|    time_elapsed    | 333      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2353      |\n",
      "|    time_elapsed         | 333       |\n",
      "|    total_timesteps      | 301184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5270348 |\n",
      "|    clip_fraction        | 0.202     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | 0.361     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.055    |\n",
      "|    n_updates            | 39984     |\n",
      "|    policy_gradient_loss | -0.0719   |\n",
      "|    value_loss           | 0.127     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2354       |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 301312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37782612 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.515      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.122     |\n",
      "|    n_updates            | 40001      |\n",
      "|    policy_gradient_loss | -0.0877    |\n",
      "|    value_loss           | 0.492      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2355      |\n",
      "|    time_elapsed         | 333       |\n",
      "|    total_timesteps      | 301440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6260944 |\n",
      "|    clip_fraction        | 0.189     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | 0.745     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0395   |\n",
      "|    n_updates            | 40018     |\n",
      "|    policy_gradient_loss | -0.0762   |\n",
      "|    value_loss           | 0.283     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=301500, episode_reward=20.38 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 301500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43318918 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0779    |\n",
      "|    n_updates            | 40035      |\n",
      "|    policy_gradient_loss | -0.042     |\n",
      "|    value_loss           | 0.257      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2356     |\n",
      "|    time_elapsed    | 333      |\n",
      "|    total_timesteps | 301568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2357       |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 301696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17501548 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.209     |\n",
      "|    explained_variance   | 0.523      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.131      |\n",
      "|    n_updates            | 40052      |\n",
      "|    policy_gradient_loss | -0.0396    |\n",
      "|    value_loss           | 0.754      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2358      |\n",
      "|    time_elapsed         | 334       |\n",
      "|    total_timesteps      | 301824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3048197 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.162    |\n",
      "|    explained_variance   | -0.000565 |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0367   |\n",
      "|    n_updates            | 40069     |\n",
      "|    policy_gradient_loss | -0.0655   |\n",
      "|    value_loss           | 0.153     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2359       |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 301952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35941172 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0448    |\n",
      "|    n_updates            | 40086      |\n",
      "|    policy_gradient_loss | -0.0709    |\n",
      "|    value_loss           | 0.0994     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=302000, episode_reward=23.79 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 23.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 302000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29961094 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | -0.228     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0696    |\n",
      "|    n_updates            | 40103      |\n",
      "|    policy_gradient_loss | -0.0568    |\n",
      "|    value_loss           | 0.0199     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2360     |\n",
      "|    time_elapsed    | 334      |\n",
      "|    total_timesteps | 302080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2361       |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 302208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44813302 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.202     |\n",
      "|    explained_variance   | -0.343     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.122     |\n",
      "|    n_updates            | 40120      |\n",
      "|    policy_gradient_loss | -0.0733    |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2362       |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 302336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22785282 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.188     |\n",
      "|    explained_variance   | -0.186     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0581    |\n",
      "|    n_updates            | 40137      |\n",
      "|    policy_gradient_loss | -0.0939    |\n",
      "|    value_loss           | 0.0782     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2363      |\n",
      "|    time_elapsed         | 334       |\n",
      "|    total_timesteps      | 302464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6777003 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.093    |\n",
      "|    explained_variance   | 0.776     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0732   |\n",
      "|    n_updates            | 40154     |\n",
      "|    policy_gradient_loss | -0.0573   |\n",
      "|    value_loss           | 0.044     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=302500, episode_reward=45.92 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 45.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 302500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4246782 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0953   |\n",
      "|    explained_variance   | 0.3       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0849   |\n",
      "|    n_updates            | 40171     |\n",
      "|    policy_gradient_loss | -0.034    |\n",
      "|    value_loss           | 0.145     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2364     |\n",
      "|    time_elapsed    | 335      |\n",
      "|    total_timesteps | 302592   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2365       |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 302720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20414704 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0319    |\n",
      "|    n_updates            | 40188      |\n",
      "|    policy_gradient_loss | -0.0648    |\n",
      "|    value_loss           | 0.313      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2366       |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 302848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32389057 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.141     |\n",
      "|    explained_variance   | 0.839      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0775    |\n",
      "|    n_updates            | 40205      |\n",
      "|    policy_gradient_loss | -0.0476    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2367       |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 302976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40525872 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.839      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0648    |\n",
      "|    n_updates            | 40222      |\n",
      "|    policy_gradient_loss | -0.0615    |\n",
      "|    value_loss           | 0.0876     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=303000, episode_reward=19.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 303000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11518521 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.202     |\n",
      "|    explained_variance   | 0.74       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0699     |\n",
      "|    n_updates            | 40239      |\n",
      "|    policy_gradient_loss | -0.0599    |\n",
      "|    value_loss           | 0.947      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2368     |\n",
      "|    time_elapsed    | 335      |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2369       |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 303232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16668741 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.133     |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.393      |\n",
      "|    n_updates            | 40256      |\n",
      "|    policy_gradient_loss | -0.0477    |\n",
      "|    value_loss           | 1.02       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2370       |\n",
      "|    time_elapsed         | 335        |\n",
      "|    total_timesteps      | 303360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28070349 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.148     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0956    |\n",
      "|    n_updates            | 40273      |\n",
      "|    policy_gradient_loss | -0.0859    |\n",
      "|    value_loss           | 0.0471     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2371      |\n",
      "|    time_elapsed         | 335       |\n",
      "|    total_timesteps      | 303488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2723652 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.126    |\n",
      "|    explained_variance   | 0.396     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0531   |\n",
      "|    n_updates            | 40290     |\n",
      "|    policy_gradient_loss | -0.0378   |\n",
      "|    value_loss           | 0.0236    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=303500, episode_reward=52.65 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 52.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 303500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42395702 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | -0.158     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0879    |\n",
      "|    n_updates            | 40307      |\n",
      "|    policy_gradient_loss | -0.0704    |\n",
      "|    value_loss           | 0.0219     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2372     |\n",
      "|    time_elapsed    | 336      |\n",
      "|    total_timesteps | 303616   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2373       |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 303744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40690613 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.172     |\n",
      "|    explained_variance   | -0.113     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 40324      |\n",
      "|    policy_gradient_loss | -0.0722    |\n",
      "|    value_loss           | 0.0291     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2374       |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 303872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24647075 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0587    |\n",
      "|    n_updates            | 40341      |\n",
      "|    policy_gradient_loss | -0.0541    |\n",
      "|    value_loss           | 0.0388     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=15.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 15.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 304000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32751986 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0737    |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0522    |\n",
      "|    n_updates            | 40358      |\n",
      "|    policy_gradient_loss | -0.0542    |\n",
      "|    value_loss           | 0.0257     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2375     |\n",
      "|    time_elapsed    | 336      |\n",
      "|    total_timesteps | 304000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2376       |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 304128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21532595 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0941    |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0992    |\n",
      "|    n_updates            | 40375      |\n",
      "|    policy_gradient_loss | -0.0513    |\n",
      "|    value_loss           | 0.162      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2377       |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 304256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34273064 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0985    |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0285    |\n",
      "|    n_updates            | 40392      |\n",
      "|    policy_gradient_loss | -0.047     |\n",
      "|    value_loss           | 0.645      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2378       |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 304384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23659241 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.114     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0411    |\n",
      "|    n_updates            | 40409      |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    value_loss           | 0.0815     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=304500, episode_reward=18.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 18.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 304500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1904313 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.18     |\n",
      "|    explained_variance   | 0.243     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.181     |\n",
      "|    n_updates            | 40426     |\n",
      "|    policy_gradient_loss | -0.0618   |\n",
      "|    value_loss           | 1.61      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2379     |\n",
      "|    time_elapsed    | 337      |\n",
      "|    total_timesteps | 304512   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2380      |\n",
      "|    time_elapsed         | 337       |\n",
      "|    total_timesteps      | 304640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2535616 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.172    |\n",
      "|    explained_variance   | 0.276     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.398     |\n",
      "|    n_updates            | 40443     |\n",
      "|    policy_gradient_loss | -0.0786   |\n",
      "|    value_loss           | 1.1       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2381       |\n",
      "|    time_elapsed         | 337        |\n",
      "|    total_timesteps      | 304768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31052715 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | -0.00038   |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0567    |\n",
      "|    n_updates            | 40460      |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    value_loss           | 0.05       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2382       |\n",
      "|    time_elapsed         | 337        |\n",
      "|    total_timesteps      | 304896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17592162 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0767    |\n",
      "|    explained_variance   | 0.4        |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.000795  |\n",
      "|    n_updates            | 40477      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.077      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=40.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 305000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46627003 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.219      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 40494      |\n",
      "|    policy_gradient_loss | -0.0848    |\n",
      "|    value_loss           | 0.0192     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2383     |\n",
      "|    time_elapsed    | 337      |\n",
      "|    total_timesteps | 305024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2384      |\n",
      "|    time_elapsed         | 337       |\n",
      "|    total_timesteps      | 305152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6136689 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | -0.0484   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0661   |\n",
      "|    n_updates            | 40511     |\n",
      "|    policy_gradient_loss | -0.0538   |\n",
      "|    value_loss           | 0.0387    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2385      |\n",
      "|    time_elapsed         | 337       |\n",
      "|    total_timesteps      | 305280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2558781 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | -0.846    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.072    |\n",
      "|    n_updates            | 40528     |\n",
      "|    policy_gradient_loss | -0.0581   |\n",
      "|    value_loss           | 0.0331    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2386      |\n",
      "|    time_elapsed         | 337       |\n",
      "|    total_timesteps      | 305408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5990842 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0785   |\n",
      "|    explained_variance   | 0.744     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0442   |\n",
      "|    n_updates            | 40545     |\n",
      "|    policy_gradient_loss | -0.0642   |\n",
      "|    value_loss           | 0.0494    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=305500, episode_reward=45.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 45.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 305500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.83281255 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.079     |\n",
      "|    explained_variance   | 0.634      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.1       |\n",
      "|    n_updates            | 40562      |\n",
      "|    policy_gradient_loss | -0.0577    |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2387     |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 305536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2388       |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 305664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35253936 |\n",
      "|    clip_fraction        | 0.0666     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0791    |\n",
      "|    explained_variance   | 0.15       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0631     |\n",
      "|    n_updates            | 40579      |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    value_loss           | 0.315      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2389       |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 305792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39709702 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0617    |\n",
      "|    n_updates            | 40596      |\n",
      "|    policy_gradient_loss | -0.0794    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2390       |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 305920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20000787 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.136     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0518    |\n",
      "|    n_updates            | 40613      |\n",
      "|    policy_gradient_loss | -0.0643    |\n",
      "|    value_loss           | 0.215      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=306000, episode_reward=55.98 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 56        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 306000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2416997 |\n",
      "|    clip_fraction        | 0.103     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.165    |\n",
      "|    explained_variance   | 0.0448    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.309     |\n",
      "|    n_updates            | 40630     |\n",
      "|    policy_gradient_loss | -0.0583   |\n",
      "|    value_loss           | 1.8       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2391     |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 306048   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2392      |\n",
      "|    time_elapsed         | 338       |\n",
      "|    total_timesteps      | 306176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5641814 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.146    |\n",
      "|    explained_variance   | 0.785     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.169     |\n",
      "|    n_updates            | 40647     |\n",
      "|    policy_gradient_loss | -0.0519   |\n",
      "|    value_loss           | 0.275     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2393       |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 306304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34826022 |\n",
      "|    clip_fraction        | 0.0864     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0736    |\n",
      "|    explained_variance   | 0.599      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0232    |\n",
      "|    n_updates            | 40664      |\n",
      "|    policy_gradient_loss | -0.0376    |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2394       |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 306432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12556496 |\n",
      "|    clip_fraction        | 0.0818     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0764    |\n",
      "|    explained_variance   | -0.000655  |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0125    |\n",
      "|    n_updates            | 40681      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.0267     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=306500, episode_reward=22.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 22.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 306500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36627394 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0888    |\n",
      "|    explained_variance   | -0.178     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0681    |\n",
      "|    n_updates            | 40698      |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2395     |\n",
      "|    time_elapsed    | 339      |\n",
      "|    total_timesteps | 306560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 54.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2396       |\n",
      "|    time_elapsed         | 339        |\n",
      "|    total_timesteps      | 306688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26709843 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.139     |\n",
      "|    explained_variance   | -0.511     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0478    |\n",
      "|    n_updates            | 40715      |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    value_loss           | 0.0362     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2397      |\n",
      "|    time_elapsed         | 339       |\n",
      "|    total_timesteps      | 306816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3869803 |\n",
      "|    clip_fraction        | 0.126     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0866   |\n",
      "|    explained_variance   | 0.935     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0323   |\n",
      "|    n_updates            | 40732     |\n",
      "|    policy_gradient_loss | -0.0358   |\n",
      "|    value_loss           | 0.0237    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2398      |\n",
      "|    time_elapsed         | 339       |\n",
      "|    total_timesteps      | 306944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4652267 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.101    |\n",
      "|    explained_variance   | 0.856     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0303   |\n",
      "|    n_updates            | 40749     |\n",
      "|    policy_gradient_loss | -0.0533   |\n",
      "|    value_loss           | 0.0969    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=307000, episode_reward=71.10 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 71.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 307000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09030496 |\n",
      "|    clip_fraction        | 0.0653     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0908    |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0289    |\n",
      "|    n_updates            | 40766      |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.495      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 54.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2399     |\n",
      "|    time_elapsed    | 339      |\n",
      "|    total_timesteps | 307072   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2400      |\n",
      "|    time_elapsed         | 339       |\n",
      "|    total_timesteps      | 307200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2675773 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.104    |\n",
      "|    explained_variance   | 0.795     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0882   |\n",
      "|    n_updates            | 40783     |\n",
      "|    policy_gradient_loss | -0.0689   |\n",
      "|    value_loss           | 0.268     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 54.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2401      |\n",
      "|    time_elapsed         | 339       |\n",
      "|    total_timesteps      | 307328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.2401956 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0884   |\n",
      "|    explained_variance   | 0.626     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0976   |\n",
      "|    n_updates            | 40800     |\n",
      "|    policy_gradient_loss | -0.0757   |\n",
      "|    value_loss           | 0.111     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2402       |\n",
      "|    time_elapsed         | 340        |\n",
      "|    total_timesteps      | 307456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26652926 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.224     |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00441    |\n",
      "|    n_updates            | 40817      |\n",
      "|    policy_gradient_loss | -0.076     |\n",
      "|    value_loss           | 0.54       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=307500, episode_reward=62.35 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 62.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 307500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29187578 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.207      |\n",
      "|    n_updates            | 40834      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.615      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2403     |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 307584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2404       |\n",
      "|    time_elapsed         | 340        |\n",
      "|    total_timesteps      | 307712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10274105 |\n",
      "|    clip_fraction        | 0.0882     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.063     |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0061    |\n",
      "|    n_updates            | 40851      |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 0.0397     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 904      |\n",
      "|    iterations           | 2405     |\n",
      "|    time_elapsed         | 340      |\n",
      "|    total_timesteps      | 307840   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.849104 |\n",
      "|    clip_fraction        | 0.243    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.123   |\n",
      "|    explained_variance   | 0.318    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.128   |\n",
      "|    n_updates            | 40868    |\n",
      "|    policy_gradient_loss | -0.0768  |\n",
      "|    value_loss           | 0.0212   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2406      |\n",
      "|    time_elapsed         | 340       |\n",
      "|    total_timesteps      | 307968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0521394 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0807   |\n",
      "|    explained_variance   | -0.303    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0685   |\n",
      "|    n_updates            | 40885     |\n",
      "|    policy_gradient_loss | -0.0853   |\n",
      "|    value_loss           | 0.0222    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=308000, episode_reward=75.08 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 75.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 308000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.87175643 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | -0.112     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0966    |\n",
      "|    n_updates            | 40902      |\n",
      "|    policy_gradient_loss | -0.0825    |\n",
      "|    value_loss           | 0.0424     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2407     |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 308096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2408       |\n",
      "|    time_elapsed         | 340        |\n",
      "|    total_timesteps      | 308224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33180183 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.089     |\n",
      "|    explained_variance   | 0.674      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0864    |\n",
      "|    n_updates            | 40919      |\n",
      "|    policy_gradient_loss | -0.0503    |\n",
      "|    value_loss           | 0.033      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2409       |\n",
      "|    time_elapsed         | 341        |\n",
      "|    total_timesteps      | 308352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52865916 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0686    |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0937    |\n",
      "|    n_updates            | 40936      |\n",
      "|    policy_gradient_loss | -0.0664    |\n",
      "|    value_loss           | 0.0557     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2410      |\n",
      "|    time_elapsed         | 341       |\n",
      "|    total_timesteps      | 308480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2545107 |\n",
      "|    clip_fraction        | 0.0965    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0687   |\n",
      "|    explained_variance   | 0.335     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0442   |\n",
      "|    n_updates            | 40953     |\n",
      "|    policy_gradient_loss | -0.0451   |\n",
      "|    value_loss           | 0.536     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=308500, episode_reward=76.12 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 76.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 308500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17289777 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0963    |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0609    |\n",
      "|    n_updates            | 40970      |\n",
      "|    policy_gradient_loss | -0.043     |\n",
      "|    value_loss           | 0.215      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2411     |\n",
      "|    time_elapsed    | 341      |\n",
      "|    total_timesteps | 308608   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2412      |\n",
      "|    time_elapsed         | 341       |\n",
      "|    total_timesteps      | 308736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7563987 |\n",
      "|    clip_fraction        | 0.191     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0951   |\n",
      "|    explained_variance   | 0.318     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0822   |\n",
      "|    n_updates            | 40987     |\n",
      "|    policy_gradient_loss | -0.0534   |\n",
      "|    value_loss           | 0.149     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2413       |\n",
      "|    time_elapsed         | 341        |\n",
      "|    total_timesteps      | 308864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27419615 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.133      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.93       |\n",
      "|    n_updates            | 41004      |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 2.76       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2414       |\n",
      "|    time_elapsed         | 341        |\n",
      "|    total_timesteps      | 308992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18316539 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.293      |\n",
      "|    n_updates            | 41021      |\n",
      "|    policy_gradient_loss | -0.0547    |\n",
      "|    value_loss           | 1.23       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=309000, episode_reward=51.88 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 51.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 309000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2741644 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0953   |\n",
      "|    explained_variance   | -0.383    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0637   |\n",
      "|    n_updates            | 41038     |\n",
      "|    policy_gradient_loss | -0.0551   |\n",
      "|    value_loss           | 0.0394    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2415     |\n",
      "|    time_elapsed    | 342      |\n",
      "|    total_timesteps | 309120   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2416      |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 309248    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2927103 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.105    |\n",
      "|    explained_variance   | 0.203     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0124   |\n",
      "|    n_updates            | 41055     |\n",
      "|    policy_gradient_loss | -0.0572   |\n",
      "|    value_loss           | 0.135     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2417       |\n",
      "|    time_elapsed         | 342        |\n",
      "|    total_timesteps      | 309376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49526605 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | -0.105     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0293    |\n",
      "|    n_updates            | 41072      |\n",
      "|    policy_gradient_loss | -0.0551    |\n",
      "|    value_loss           | 0.0195     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=309500, episode_reward=79.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 79.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 309500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0934157 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0765   |\n",
      "|    explained_variance   | -1.28     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.115    |\n",
      "|    n_updates            | 41089     |\n",
      "|    policy_gradient_loss | -0.0411   |\n",
      "|    value_loss           | 0.0272    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2418     |\n",
      "|    time_elapsed    | 342      |\n",
      "|    total_timesteps | 309504   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55.1     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 903      |\n",
      "|    iterations           | 2419     |\n",
      "|    time_elapsed         | 342      |\n",
      "|    total_timesteps      | 309632   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.402538 |\n",
      "|    clip_fraction        | 0.186    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.131   |\n",
      "|    explained_variance   | 0.645    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0651  |\n",
      "|    n_updates            | 41106    |\n",
      "|    policy_gradient_loss | -0.0652  |\n",
      "|    value_loss           | 0.055    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2420      |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 309760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5776185 |\n",
      "|    clip_fraction        | 0.114     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0518   |\n",
      "|    explained_variance   | 0.694     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0162   |\n",
      "|    n_updates            | 41123     |\n",
      "|    policy_gradient_loss | -0.0286   |\n",
      "|    value_loss           | 0.0554    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2421      |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 309888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3896521 |\n",
      "|    clip_fraction        | 0.101     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0774   |\n",
      "|    explained_variance   | 0.485     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0568   |\n",
      "|    n_updates            | 41140     |\n",
      "|    policy_gradient_loss | -0.0394   |\n",
      "|    value_loss           | 0.205     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=90.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 90        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 310000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2923116 |\n",
      "|    clip_fraction        | 0.0869    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0654   |\n",
      "|    explained_variance   | -0.286    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00729   |\n",
      "|    n_updates            | 41157     |\n",
      "|    policy_gradient_loss | -0.0498   |\n",
      "|    value_loss           | 0.862     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2422     |\n",
      "|    time_elapsed    | 343      |\n",
      "|    total_timesteps | 310016   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2423      |\n",
      "|    time_elapsed         | 343       |\n",
      "|    total_timesteps      | 310144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2755117 |\n",
      "|    clip_fraction        | 0.0892    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0717   |\n",
      "|    explained_variance   | 0.457     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.00296   |\n",
      "|    n_updates            | 41174     |\n",
      "|    policy_gradient_loss | -0.035    |\n",
      "|    value_loss           | 0.341     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2424       |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 310272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15895614 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.07      |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0199    |\n",
      "|    n_updates            | 41191      |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2425       |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 310400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42874455 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0994    |\n",
      "|    explained_variance   | 0.258      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 1.03       |\n",
      "|    n_updates            | 41208      |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 3.46       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=310500, episode_reward=55.52 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 310500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27384144 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.123     |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0303     |\n",
      "|    n_updates            | 41225      |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2426     |\n",
      "|    time_elapsed    | 343      |\n",
      "|    total_timesteps | 310528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2427      |\n",
      "|    time_elapsed         | 343       |\n",
      "|    total_timesteps      | 310656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5321052 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.154    |\n",
      "|    explained_variance   | 0.43      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0519   |\n",
      "|    n_updates            | 41242     |\n",
      "|    policy_gradient_loss | -0.0728   |\n",
      "|    value_loss           | 0.0791    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2428      |\n",
      "|    time_elapsed         | 343       |\n",
      "|    total_timesteps      | 310784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6908123 |\n",
      "|    clip_fraction        | 0.231     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.146    |\n",
      "|    explained_variance   | 0.0498    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0852   |\n",
      "|    n_updates            | 41259     |\n",
      "|    policy_gradient_loss | -0.0733   |\n",
      "|    value_loss           | 0.0293    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2429       |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 310912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27315798 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | -0.464     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0427    |\n",
      "|    n_updates            | 41276      |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0203     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=311000, episode_reward=79.99 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 80         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 311000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50262433 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | -0.233     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.116     |\n",
      "|    n_updates            | 41293      |\n",
      "|    policy_gradient_loss | -0.0571    |\n",
      "|    value_loss           | 0.0637     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2430     |\n",
      "|    time_elapsed    | 344      |\n",
      "|    total_timesteps | 311040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2431       |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 311168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44143158 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0581    |\n",
      "|    n_updates            | 41310      |\n",
      "|    policy_gradient_loss | -0.0583    |\n",
      "|    value_loss           | 0.0963     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2432      |\n",
      "|    time_elapsed         | 344       |\n",
      "|    total_timesteps      | 311296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6812453 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.069    |\n",
      "|    explained_variance   | 0.803     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.099    |\n",
      "|    n_updates            | 41327     |\n",
      "|    policy_gradient_loss | -0.0543   |\n",
      "|    value_loss           | 0.0947    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2433       |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 311424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15476385 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | -0.0463    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0248     |\n",
      "|    n_updates            | 41344      |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 1.13       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=311500, episode_reward=38.53 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 38.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 311500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43016756 |\n",
      "|    clip_fraction        | 0.0878     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0944    |\n",
      "|    explained_variance   | 0.707      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0189    |\n",
      "|    n_updates            | 41361      |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 0.409      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2434     |\n",
      "|    time_elapsed    | 344      |\n",
      "|    total_timesteps | 311552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2435       |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 311680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48677272 |\n",
      "|    clip_fraction        | 0.0988     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0727    |\n",
      "|    explained_variance   | 0.791      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0843    |\n",
      "|    n_updates            | 41378      |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    value_loss           | 0.115      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2436       |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 311808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20095347 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.145     |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 41395      |\n",
      "|    policy_gradient_loss | -0.0547    |\n",
      "|    value_loss           | 1.77       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2437       |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 311936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27689993 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.139     |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.288      |\n",
      "|    n_updates            | 41412      |\n",
      "|    policy_gradient_loss | -0.0596    |\n",
      "|    value_loss           | 0.652      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=312000, episode_reward=82.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 82.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 312000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17136745 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.088     |\n",
      "|    n_updates            | 41429      |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.0479     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2438     |\n",
      "|    time_elapsed    | 345      |\n",
      "|    total_timesteps | 312064   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2439      |\n",
      "|    time_elapsed         | 345       |\n",
      "|    total_timesteps      | 312192    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3199264 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | -0.897    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.112    |\n",
      "|    n_updates            | 41446     |\n",
      "|    policy_gradient_loss | -0.066    |\n",
      "|    value_loss           | 0.0306    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2440      |\n",
      "|    time_elapsed         | 345       |\n",
      "|    total_timesteps      | 312320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0863587 |\n",
      "|    clip_fraction        | 0.259     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.122    |\n",
      "|    explained_variance   | 0.0319    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.158    |\n",
      "|    n_updates            | 41463     |\n",
      "|    policy_gradient_loss | -0.0878   |\n",
      "|    value_loss           | 0.0147    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2441      |\n",
      "|    time_elapsed         | 345       |\n",
      "|    total_timesteps      | 312448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3990341 |\n",
      "|    clip_fraction        | 0.316     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | 0.221     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.135    |\n",
      "|    n_updates            | 41480     |\n",
      "|    policy_gradient_loss | -0.0893   |\n",
      "|    value_loss           | 0.0536    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=312500, episode_reward=23.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 245      |\n",
      "|    mean_reward          | 23.8     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 312500   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.812816 |\n",
      "|    clip_fraction        | 0.238    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.129   |\n",
      "|    explained_variance   | -0.567   |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.057   |\n",
      "|    n_updates            | 41497    |\n",
      "|    policy_gradient_loss | -0.0642  |\n",
      "|    value_loss           | 0.11     |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2442     |\n",
      "|    time_elapsed    | 345      |\n",
      "|    total_timesteps | 312576   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2443      |\n",
      "|    time_elapsed         | 345       |\n",
      "|    total_timesteps      | 312704    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9040216 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0654   |\n",
      "|    explained_variance   | 0.933     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.113    |\n",
      "|    n_updates            | 41514     |\n",
      "|    policy_gradient_loss | -0.0553   |\n",
      "|    value_loss           | 0.0619    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2444       |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 312832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14772488 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.232      |\n",
      "|    n_updates            | 41531      |\n",
      "|    policy_gradient_loss | -0.049     |\n",
      "|    value_loss           | 0.798      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2445       |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 312960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21941894 |\n",
      "|    clip_fraction        | 0.0639     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0572     |\n",
      "|    n_updates            | 41548      |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.389      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=313000, episode_reward=6.27 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 6.27      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 313000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3681519 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0808   |\n",
      "|    explained_variance   | 0.783     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0909   |\n",
      "|    n_updates            | 41565     |\n",
      "|    policy_gradient_loss | -0.0739   |\n",
      "|    value_loss           | 0.119     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2446     |\n",
      "|    time_elapsed    | 346      |\n",
      "|    total_timesteps | 313088   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2447       |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 313216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21540603 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.193     |\n",
      "|    explained_variance   | 0.422      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00969    |\n",
      "|    n_updates            | 41582      |\n",
      "|    policy_gradient_loss | -0.0676    |\n",
      "|    value_loss           | 0.546      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2448       |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 313344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25139606 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.725      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.139      |\n",
      "|    n_updates            | 41599      |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    value_loss           | 0.468      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2449       |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 313472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26850966 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | -0.25      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0819    |\n",
      "|    n_updates            | 41616      |\n",
      "|    policy_gradient_loss | -0.0752    |\n",
      "|    value_loss           | 0.0375     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=313500, episode_reward=1.39 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 1.39       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 313500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27091956 |\n",
      "|    clip_fraction        | 0.0781     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0806    |\n",
      "|    explained_variance   | -0.0248    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0541    |\n",
      "|    n_updates            | 41633      |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    value_loss           | 0.0487     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2450     |\n",
      "|    time_elapsed    | 346      |\n",
      "|    total_timesteps | 313600   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2451      |\n",
      "|    time_elapsed         | 346       |\n",
      "|    total_timesteps      | 313728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5292437 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0753   |\n",
      "|    explained_variance   | -0.662    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0229   |\n",
      "|    n_updates            | 41650     |\n",
      "|    policy_gradient_loss | -0.0398   |\n",
      "|    value_loss           | 0.027     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2452      |\n",
      "|    time_elapsed         | 346       |\n",
      "|    total_timesteps      | 313856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5937784 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.139    |\n",
      "|    explained_variance   | 0.187     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0922   |\n",
      "|    n_updates            | 41667     |\n",
      "|    policy_gradient_loss | -0.067    |\n",
      "|    value_loss           | 0.0229    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2453       |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 313984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17556918 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.426      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.12      |\n",
      "|    n_updates            | 41684      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.071      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=314000, episode_reward=10.77 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 10.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 314000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5045502 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.072    |\n",
      "|    explained_variance   | 0.802     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0721   |\n",
      "|    n_updates            | 41701     |\n",
      "|    policy_gradient_loss | -0.0683   |\n",
      "|    value_loss           | 0.0452    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2454     |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 314112   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2455      |\n",
      "|    time_elapsed         | 347       |\n",
      "|    total_timesteps      | 314240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3734318 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0896   |\n",
      "|    explained_variance   | 0.715     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.103    |\n",
      "|    n_updates            | 41718     |\n",
      "|    policy_gradient_loss | -0.0736   |\n",
      "|    value_loss           | 0.112     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55.5     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 904      |\n",
      "|    iterations           | 2456     |\n",
      "|    time_elapsed         | 347      |\n",
      "|    total_timesteps      | 314368   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.09577  |\n",
      "|    clip_fraction        | 0.0818   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.1     |\n",
      "|    explained_variance   | -0.00474 |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0185  |\n",
      "|    n_updates            | 41735    |\n",
      "|    policy_gradient_loss | -0.0365  |\n",
      "|    value_loss           | 0.623    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2457       |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 314496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25845295 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.115     |\n",
      "|    explained_variance   | 0.475      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0715    |\n",
      "|    n_updates            | 41752      |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=314500, episode_reward=25.14 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 314500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39116645 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.168     |\n",
      "|    explained_variance   | 0.524      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0249     |\n",
      "|    n_updates            | 41769      |\n",
      "|    policy_gradient_loss | -0.0663    |\n",
      "|    value_loss           | 0.416      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2458     |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 314624   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2459       |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 314752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25362974 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.183     |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0228     |\n",
      "|    n_updates            | 41786      |\n",
      "|    policy_gradient_loss | -0.0843    |\n",
      "|    value_loss           | 0.603      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2460       |\n",
      "|    time_elapsed         | 348        |\n",
      "|    total_timesteps      | 314880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49804825 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.184     |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0373    |\n",
      "|    n_updates            | 41803      |\n",
      "|    policy_gradient_loss | -0.0615    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=25.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 25.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 315000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6180307 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.196    |\n",
      "|    explained_variance   | 0.195     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.122    |\n",
      "|    n_updates            | 41820     |\n",
      "|    policy_gradient_loss | -0.108    |\n",
      "|    value_loss           | 0.0329    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2461     |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 315008   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2462      |\n",
      "|    time_elapsed         | 348       |\n",
      "|    total_timesteps      | 315136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5261508 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.143    |\n",
      "|    explained_variance   | -0.807    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0941   |\n",
      "|    n_updates            | 41837     |\n",
      "|    policy_gradient_loss | -0.0691   |\n",
      "|    value_loss           | 0.0199    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2463       |\n",
      "|    time_elapsed         | 348        |\n",
      "|    total_timesteps      | 315264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.75602496 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.17      |\n",
      "|    explained_variance   | -0.169     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 41854      |\n",
      "|    policy_gradient_loss | -0.075     |\n",
      "|    value_loss           | 0.0281     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2464      |\n",
      "|    time_elapsed         | 348       |\n",
      "|    total_timesteps      | 315392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4213282 |\n",
      "|    clip_fraction        | 0.196     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.156    |\n",
      "|    explained_variance   | 0.282     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0952   |\n",
      "|    n_updates            | 41871     |\n",
      "|    policy_gradient_loss | -0.0759   |\n",
      "|    value_loss           | 0.068     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=315500, episode_reward=18.07 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 18.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 315500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49447706 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0885    |\n",
      "|    explained_variance   | 0.828      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0925    |\n",
      "|    n_updates            | 41888      |\n",
      "|    policy_gradient_loss | -0.0556    |\n",
      "|    value_loss           | 0.0388     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2465     |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 315520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2466       |\n",
      "|    time_elapsed         | 348        |\n",
      "|    total_timesteps      | 315648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24821383 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.081     |\n",
      "|    explained_variance   | 0.762      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.113     |\n",
      "|    n_updates            | 41905      |\n",
      "|    policy_gradient_loss | -0.0681    |\n",
      "|    value_loss           | 0.0906     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2467       |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 315776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49789345 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.545      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 41922      |\n",
      "|    policy_gradient_loss | -0.0885    |\n",
      "|    value_loss           | 0.486      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2468       |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 315904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34170598 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0711    |\n",
      "|    n_updates            | 41939      |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 0.33       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=316000, episode_reward=44.36 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 44.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 316000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23090762 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0585    |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0667    |\n",
      "|    n_updates            | 41956      |\n",
      "|    policy_gradient_loss | -0.047     |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2469     |\n",
      "|    time_elapsed    | 349      |\n",
      "|    total_timesteps | 316032   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2470      |\n",
      "|    time_elapsed         | 349       |\n",
      "|    total_timesteps      | 316160    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4892246 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.164    |\n",
      "|    explained_variance   | 0.783     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0111    |\n",
      "|    n_updates            | 41973     |\n",
      "|    policy_gradient_loss | -0.0493   |\n",
      "|    value_loss           | 0.329     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2471       |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 316288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28885216 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0474     |\n",
      "|    n_updates            | 41990      |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    value_loss           | 0.428      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2472       |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 316416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44695938 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0992    |\n",
      "|    explained_variance   | -0.441     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0801    |\n",
      "|    n_updates            | 42007      |\n",
      "|    policy_gradient_loss | -0.0563    |\n",
      "|    value_loss           | 0.0262     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=316500, episode_reward=22.67 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 22.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 316500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5674479 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | -0.521    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0945   |\n",
      "|    n_updates            | 42024     |\n",
      "|    policy_gradient_loss | -0.0667   |\n",
      "|    value_loss           | 0.024     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 904      |\n",
      "|    iterations      | 2473     |\n",
      "|    time_elapsed    | 350      |\n",
      "|    total_timesteps | 316544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 2474       |\n",
      "|    time_elapsed         | 350        |\n",
      "|    total_timesteps      | 316672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.57163423 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.0268    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0563    |\n",
      "|    n_updates            | 42041      |\n",
      "|    policy_gradient_loss | -0.0489    |\n",
      "|    value_loss           | 0.0154     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 904       |\n",
      "|    iterations           | 2475      |\n",
      "|    time_elapsed         | 350       |\n",
      "|    total_timesteps      | 316800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8692912 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.148    |\n",
      "|    explained_variance   | 0.114     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.1      |\n",
      "|    n_updates            | 42058     |\n",
      "|    policy_gradient_loss | -0.0828   |\n",
      "|    value_loss           | 0.0755    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2476       |\n",
      "|    time_elapsed         | 350        |\n",
      "|    total_timesteps      | 316928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32569292 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.159     |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 42075      |\n",
      "|    policy_gradient_loss | -0.0743    |\n",
      "|    value_loss           | 0.0709     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=317000, episode_reward=26.46 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 317000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33443373 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0719    |\n",
      "|    explained_variance   | 0.835      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0513    |\n",
      "|    n_updates            | 42092      |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    value_loss           | 0.0835     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2477     |\n",
      "|    time_elapsed    | 350      |\n",
      "|    total_timesteps | 317056   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2478       |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 317184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20422158 |\n",
      "|    clip_fraction        | 0.0823     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.637      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0535    |\n",
      "|    n_updates            | 42109      |\n",
      "|    policy_gradient_loss | -0.0446    |\n",
      "|    value_loss           | 0.309      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2479      |\n",
      "|    time_elapsed         | 351       |\n",
      "|    total_timesteps      | 317312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4100158 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.106    |\n",
      "|    explained_variance   | 0.24      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.093    |\n",
      "|    n_updates            | 42126     |\n",
      "|    policy_gradient_loss | -0.0549   |\n",
      "|    value_loss           | 0.783     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2480       |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21125126 |\n",
      "|    clip_fraction        | 0.074      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0378    |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0115    |\n",
      "|    n_updates            | 42143      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=317500, episode_reward=20.55 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 20.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 317500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47437304 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0856    |\n",
      "|    n_updates            | 42160      |\n",
      "|    policy_gradient_loss | -0.0767    |\n",
      "|    value_loss           | 0.363      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2481     |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 317568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2482       |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 317696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.95437235 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.091     |\n",
      "|    explained_variance   | 0.774      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.00129    |\n",
      "|    n_updates            | 42177      |\n",
      "|    policy_gradient_loss | -0.0524    |\n",
      "|    value_loss           | 0.501      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2483      |\n",
      "|    time_elapsed         | 351       |\n",
      "|    total_timesteps      | 317824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9750215 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    explained_variance   | -0.103    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0904   |\n",
      "|    n_updates            | 42194     |\n",
      "|    policy_gradient_loss | -0.0935   |\n",
      "|    value_loss           | 0.0178    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2484       |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 317952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33315265 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | -0.057     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.057     |\n",
      "|    n_updates            | 42211      |\n",
      "|    policy_gradient_loss | -0.0603    |\n",
      "|    value_loss           | 0.0391     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=318000, episode_reward=19.47 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 19.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 318000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31099203 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.026      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.116     |\n",
      "|    n_updates            | 42228      |\n",
      "|    policy_gradient_loss | -0.0838    |\n",
      "|    value_loss           | 0.0119     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2485     |\n",
      "|    time_elapsed    | 352      |\n",
      "|    total_timesteps | 318080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2486       |\n",
      "|    time_elapsed         | 352        |\n",
      "|    total_timesteps      | 318208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60628206 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 42245      |\n",
      "|    policy_gradient_loss | -0.0651    |\n",
      "|    value_loss           | 0.0373     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 55.7     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 903      |\n",
      "|    iterations           | 2487     |\n",
      "|    time_elapsed         | 352      |\n",
      "|    total_timesteps      | 318336   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.76836  |\n",
      "|    clip_fraction        | 0.24     |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.147   |\n",
      "|    explained_variance   | -0.0459  |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.0499  |\n",
      "|    n_updates            | 42262    |\n",
      "|    policy_gradient_loss | -0.0679  |\n",
      "|    value_loss           | 0.0429   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2488       |\n",
      "|    time_elapsed         | 352        |\n",
      "|    total_timesteps      | 318464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.77101105 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0828    |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.081     |\n",
      "|    n_updates            | 42279      |\n",
      "|    policy_gradient_loss | -0.0651    |\n",
      "|    value_loss           | 0.0623     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=318500, episode_reward=-3.33 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -3.33     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 318500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.3848956 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0997   |\n",
      "|    explained_variance   | 0.633     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0362   |\n",
      "|    n_updates            | 42296     |\n",
      "|    policy_gradient_loss | -0.0502   |\n",
      "|    value_loss           | 0.0808    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 55.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2489     |\n",
      "|    time_elapsed    | 352      |\n",
      "|    total_timesteps | 318592   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2490       |\n",
      "|    time_elapsed         | 352        |\n",
      "|    total_timesteps      | 318720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18055458 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0105    |\n",
      "|    n_updates            | 42313      |\n",
      "|    policy_gradient_loss | -0.0623    |\n",
      "|    value_loss           | 0.681      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 55.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2491       |\n",
      "|    time_elapsed         | 352        |\n",
      "|    total_timesteps      | 318848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13797683 |\n",
      "|    clip_fraction        | 0.0547     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0502    |\n",
      "|    explained_variance   | 0.132      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0601     |\n",
      "|    n_updates            | 42330      |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    value_loss           | 0.584      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 55.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2492      |\n",
      "|    time_elapsed         | 352       |\n",
      "|    total_timesteps      | 318976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7671983 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | 0.325     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.078    |\n",
      "|    n_updates            | 42347     |\n",
      "|    policy_gradient_loss | -0.0633   |\n",
      "|    value_loss           | 0.221     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=319000, episode_reward=-7.31 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -7.31     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 319000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3391485 |\n",
      "|    clip_fraction        | 0.177     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.15     |\n",
      "|    explained_variance   | 0.5       |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.104     |\n",
      "|    n_updates            | 42364     |\n",
      "|    policy_gradient_loss | -0.0601   |\n",
      "|    value_loss           | 0.88      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2493     |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 319104   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2494      |\n",
      "|    time_elapsed         | 353       |\n",
      "|    total_timesteps      | 319232    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5670539 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.174    |\n",
      "|    explained_variance   | 0.936     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0412   |\n",
      "|    n_updates            | 42381     |\n",
      "|    policy_gradient_loss | -0.0635   |\n",
      "|    value_loss           | 0.101     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2495      |\n",
      "|    time_elapsed         | 353       |\n",
      "|    total_timesteps      | 319360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2885736 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0997   |\n",
      "|    explained_variance   | -0.18     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0896   |\n",
      "|    n_updates            | 42398     |\n",
      "|    policy_gradient_loss | -0.0477   |\n",
      "|    value_loss           | 0.02      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2496      |\n",
      "|    time_elapsed         | 353       |\n",
      "|    total_timesteps      | 319488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3873305 |\n",
      "|    clip_fraction        | 0.168     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | -0.735    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.00879  |\n",
      "|    n_updates            | 42415     |\n",
      "|    policy_gradient_loss | -0.0561   |\n",
      "|    value_loss           | 0.0117    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=319500, episode_reward=41.58 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 41.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 319500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29987708 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.199     |\n",
      "|    explained_variance   | -0.0752    |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 42432      |\n",
      "|    policy_gradient_loss | -0.0813    |\n",
      "|    value_loss           | 0.0161     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2497     |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 319616   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2498      |\n",
      "|    time_elapsed         | 353       |\n",
      "|    total_timesteps      | 319744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3631823 |\n",
      "|    clip_fraction        | 0.194     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.17     |\n",
      "|    explained_variance   | -0.108    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0428   |\n",
      "|    n_updates            | 42449     |\n",
      "|    policy_gradient_loss | -0.0797   |\n",
      "|    value_loss           | 0.0549    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2499       |\n",
      "|    time_elapsed         | 353        |\n",
      "|    total_timesteps      | 319872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34893206 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.124     |\n",
      "|    explained_variance   | 0.816      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0952    |\n",
      "|    n_updates            | 42466      |\n",
      "|    policy_gradient_loss | -0.0657    |\n",
      "|    value_loss           | 0.0626     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=25.89 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 320000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.48406953 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0745    |\n",
      "|    n_updates            | 42483      |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    value_loss           | 0.0945     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56       |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2500     |\n",
      "|    time_elapsed    | 354      |\n",
      "|    total_timesteps | 320000   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2501      |\n",
      "|    time_elapsed         | 354       |\n",
      "|    total_timesteps      | 320128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6855314 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.167    |\n",
      "|    explained_variance   | 0.645     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0342   |\n",
      "|    n_updates            | 42500     |\n",
      "|    policy_gradient_loss | -0.0444   |\n",
      "|    value_loss           | 0.408     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2502       |\n",
      "|    time_elapsed         | 354        |\n",
      "|    total_timesteps      | 320256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49702987 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.179     |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0419    |\n",
      "|    n_updates            | 42517      |\n",
      "|    policy_gradient_loss | -0.0774    |\n",
      "|    value_loss           | 0.38       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2503      |\n",
      "|    time_elapsed         | 354       |\n",
      "|    total_timesteps      | 320384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5325921 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.128    |\n",
      "|    explained_variance   | -0.335    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 42534     |\n",
      "|    policy_gradient_loss | -0.0697   |\n",
      "|    value_loss           | 0.142     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=320500, episode_reward=29.22 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 29.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 320500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44439527 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.155     |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 1.06       |\n",
      "|    n_updates            | 42551      |\n",
      "|    policy_gradient_loss | -0.0604    |\n",
      "|    value_loss           | 1.58       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2504     |\n",
      "|    time_elapsed    | 354      |\n",
      "|    total_timesteps | 320512   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2505       |\n",
      "|    time_elapsed         | 354        |\n",
      "|    total_timesteps      | 320640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29255694 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.137      |\n",
      "|    n_updates            | 42568      |\n",
      "|    policy_gradient_loss | -0.0618    |\n",
      "|    value_loss           | 0.365      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2506      |\n",
      "|    time_elapsed         | 354       |\n",
      "|    total_timesteps      | 320768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7567986 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    explained_variance   | -0.0649   |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0564   |\n",
      "|    n_updates            | 42585     |\n",
      "|    policy_gradient_loss | -0.0627   |\n",
      "|    value_loss           | 0.0352    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2507       |\n",
      "|    time_elapsed         | 355        |\n",
      "|    total_timesteps      | 320896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.46453544 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | -0.207     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.109     |\n",
      "|    n_updates            | 42602      |\n",
      "|    policy_gradient_loss | -0.0725    |\n",
      "|    value_loss           | 0.0132     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=321000, episode_reward=33.03 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 33        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 321000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6534586 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.151    |\n",
      "|    explained_variance   | -0.116    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.146    |\n",
      "|    n_updates            | 42619     |\n",
      "|    policy_gradient_loss | -0.0982   |\n",
      "|    value_loss           | 0.00909   |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2508     |\n",
      "|    time_elapsed    | 355      |\n",
      "|    total_timesteps | 321024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2509       |\n",
      "|    time_elapsed         | 355        |\n",
      "|    total_timesteps      | 321152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28505906 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0468    |\n",
      "|    n_updates            | 42636      |\n",
      "|    policy_gradient_loss | -0.0551    |\n",
      "|    value_loss           | 0.0639     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2510      |\n",
      "|    time_elapsed         | 355       |\n",
      "|    total_timesteps      | 321280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3122152 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.154    |\n",
      "|    explained_variance   | 0.646     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.072    |\n",
      "|    n_updates            | 42653     |\n",
      "|    policy_gradient_loss | -0.0464   |\n",
      "|    value_loss           | 0.0613    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2511       |\n",
      "|    time_elapsed         | 355        |\n",
      "|    total_timesteps      | 321408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37707382 |\n",
      "|    clip_fraction        | 0.0942     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0676    |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0313    |\n",
      "|    n_updates            | 42670      |\n",
      "|    policy_gradient_loss | -0.0392    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=321500, episode_reward=46.54 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 46.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 321500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40323046 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0892    |\n",
      "|    n_updates            | 42687      |\n",
      "|    policy_gradient_loss | -0.0587    |\n",
      "|    value_loss           | 0.239      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2512     |\n",
      "|    time_elapsed    | 355      |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2513       |\n",
      "|    time_elapsed         | 355        |\n",
      "|    total_timesteps      | 321664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16182739 |\n",
      "|    clip_fraction        | 0.0781     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0923    |\n",
      "|    explained_variance   | 0.0154     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0894     |\n",
      "|    n_updates            | 42704      |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 0.565      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2514       |\n",
      "|    time_elapsed         | 356        |\n",
      "|    total_timesteps      | 321792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27541837 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0801    |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0595    |\n",
      "|    n_updates            | 42721      |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 0.0883     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2515       |\n",
      "|    time_elapsed         | 356        |\n",
      "|    total_timesteps      | 321920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14128506 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0868    |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.402      |\n",
      "|    n_updates            | 42738      |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    value_loss           | 1.24       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=322000, episode_reward=71.00 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 71        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 322000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8741384 |\n",
      "|    clip_fraction        | 0.212     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.16     |\n",
      "|    explained_variance   | 0.843     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.237     |\n",
      "|    n_updates            | 42755     |\n",
      "|    policy_gradient_loss | -0.0785   |\n",
      "|    value_loss           | 0.656     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2516     |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 322048   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2517      |\n",
      "|    time_elapsed         | 356       |\n",
      "|    total_timesteps      | 322176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5018486 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    explained_variance   | -0.703    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.116    |\n",
      "|    n_updates            | 42772     |\n",
      "|    policy_gradient_loss | -0.0704   |\n",
      "|    value_loss           | 0.0321    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2518       |\n",
      "|    time_elapsed         | 356        |\n",
      "|    total_timesteps      | 322304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.61352575 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0823    |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0933    |\n",
      "|    n_updates            | 42789      |\n",
      "|    policy_gradient_loss | -0.0835    |\n",
      "|    value_loss           | 0.0295     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 903       |\n",
      "|    iterations           | 2519      |\n",
      "|    time_elapsed         | 356       |\n",
      "|    total_timesteps      | 322432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7837267 |\n",
      "|    clip_fraction        | 0.227     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.138    |\n",
      "|    explained_variance   | -0.21     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0672   |\n",
      "|    n_updates            | 42806     |\n",
      "|    policy_gradient_loss | -0.0892   |\n",
      "|    value_loss           | 0.0228    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=322500, episode_reward=55.76 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 55.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 322500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8501557 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.133    |\n",
      "|    explained_variance   | 0.538     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.09     |\n",
      "|    n_updates            | 42823     |\n",
      "|    policy_gradient_loss | -0.0676   |\n",
      "|    value_loss           | 0.031     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 903      |\n",
      "|    iterations      | 2520     |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 322560   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2521      |\n",
      "|    time_elapsed         | 357       |\n",
      "|    total_timesteps      | 322688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5934465 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.135    |\n",
      "|    explained_variance   | 0.442     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.127    |\n",
      "|    n_updates            | 42840     |\n",
      "|    policy_gradient_loss | -0.103    |\n",
      "|    value_loss           | 0.0703    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2522       |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 322816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33797616 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.097     |\n",
      "|    explained_variance   | 0.863      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0847    |\n",
      "|    n_updates            | 42857      |\n",
      "|    policy_gradient_loss | -0.0554    |\n",
      "|    value_loss           | 0.0805     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2523       |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 322944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36600193 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.06      |\n",
      "|    n_updates            | 42874      |\n",
      "|    policy_gradient_loss | -0.0624    |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=323000, episode_reward=31.61 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 31.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 323000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3093103 |\n",
      "|    clip_fraction        | 0.167     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.191    |\n",
      "|    explained_variance   | 0.303     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0218   |\n",
      "|    n_updates            | 42891     |\n",
      "|    policy_gradient_loss | -0.0618   |\n",
      "|    value_loss           | 0.583     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2524     |\n",
      "|    time_elapsed    | 357      |\n",
      "|    total_timesteps | 323072   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2525      |\n",
      "|    time_elapsed         | 357       |\n",
      "|    total_timesteps      | 323200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2381842 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.133    |\n",
      "|    explained_variance   | 0.416     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.103    |\n",
      "|    n_updates            | 42908     |\n",
      "|    policy_gradient_loss | -0.0535   |\n",
      "|    value_loss           | 0.15      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 903        |\n",
      "|    iterations           | 2526       |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 323328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39716527 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | 0.562      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0709    |\n",
      "|    n_updates            | 42925      |\n",
      "|    policy_gradient_loss | -0.0622    |\n",
      "|    value_loss           | 0.234      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2527       |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 323456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11918734 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0768    |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.238      |\n",
      "|    n_updates            | 42942      |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    value_loss           | 0.715      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=323500, episode_reward=6.21 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 6.21       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 323500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47301883 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0755    |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0309    |\n",
      "|    n_updates            | 42959      |\n",
      "|    policy_gradient_loss | -0.049     |\n",
      "|    value_loss           | 0.0869     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2528     |\n",
      "|    time_elapsed    | 358      |\n",
      "|    total_timesteps | 323584   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2529       |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 323712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52604616 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.0448     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.094     |\n",
      "|    n_updates            | 42976      |\n",
      "|    policy_gradient_loss | -0.0628    |\n",
      "|    value_loss           | 0.0752     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2530       |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 323840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19948953 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0586    |\n",
      "|    explained_variance   | -0.885     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0547    |\n",
      "|    n_updates            | 42993      |\n",
      "|    policy_gradient_loss | -0.0499    |\n",
      "|    value_loss           | 0.0203     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2531      |\n",
      "|    time_elapsed         | 358       |\n",
      "|    total_timesteps      | 323968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6476095 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0888   |\n",
      "|    explained_variance   | 0.0535    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0305   |\n",
      "|    n_updates            | 43010     |\n",
      "|    policy_gradient_loss | -0.0406   |\n",
      "|    value_loss           | 0.0266    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=324000, episode_reward=40.50 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 40.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 324000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27276593 |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0977    |\n",
      "|    explained_variance   | -0.367     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0456    |\n",
      "|    n_updates            | 43027      |\n",
      "|    policy_gradient_loss | -0.0425    |\n",
      "|    value_loss           | 0.0815     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2532     |\n",
      "|    time_elapsed    | 359      |\n",
      "|    total_timesteps | 324096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2533      |\n",
      "|    time_elapsed         | 359       |\n",
      "|    total_timesteps      | 324224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3995726 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.102    |\n",
      "|    explained_variance   | 0.768     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0482   |\n",
      "|    n_updates            | 43044     |\n",
      "|    policy_gradient_loss | -0.0546   |\n",
      "|    value_loss           | 0.0476    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 56.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2534      |\n",
      "|    time_elapsed         | 359       |\n",
      "|    total_timesteps      | 324352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2705783 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | 0.735     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0768   |\n",
      "|    n_updates            | 43061     |\n",
      "|    policy_gradient_loss | -0.0702   |\n",
      "|    value_loss           | 0.0833    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2535       |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 324480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24105476 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0737    |\n",
      "|    explained_variance   | 0.446      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0245     |\n",
      "|    n_updates            | 43078      |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    value_loss           | 0.314      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=324500, episode_reward=33.05 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 245        |\n",
      "|    mean_reward          | 33         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 324500     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37976328 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.113     |\n",
      "|    explained_variance   | 0.646      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0545    |\n",
      "|    n_updates            | 43095      |\n",
      "|    policy_gradient_loss | -0.0604    |\n",
      "|    value_loss           | 0.304      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 56.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2536     |\n",
      "|    time_elapsed    | 359      |\n",
      "|    total_timesteps | 324608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 56.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2537       |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 324736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31306633 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.14      |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.0233     |\n",
      "|    n_updates            | 43112      |\n",
      "|    policy_gradient_loss | -0.0722    |\n",
      "|    value_loss           | 0.26       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2538       |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 324864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11192024 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.168      |\n",
      "|    n_updates            | 43129      |\n",
      "|    policy_gradient_loss | -0.0529    |\n",
      "|    value_loss           | 0.98       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2539       |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 324992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39481875 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.127      |\n",
      "|    n_updates            | 43146      |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    value_loss           | 0.406      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=34.44 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 34.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 325000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0933421 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | -0.962    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0866   |\n",
      "|    n_updates            | 43163     |\n",
      "|    policy_gradient_loss | -0.0719   |\n",
      "|    value_loss           | 0.0641    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 57       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2540     |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 325120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2541       |\n",
      "|    time_elapsed         | 360        |\n",
      "|    total_timesteps      | 325248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33500582 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0823    |\n",
      "|    explained_variance   | -0.176     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0553    |\n",
      "|    n_updates            | 43180      |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 0.0454     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2542       |\n",
      "|    time_elapsed         | 360        |\n",
      "|    total_timesteps      | 325376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43328485 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.053     |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0218    |\n",
      "|    n_updates            | 43197      |\n",
      "|    policy_gradient_loss | -0.0622    |\n",
      "|    value_loss           | 0.0224     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=325500, episode_reward=14.74 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 14.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 325500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7450436 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.144    |\n",
      "|    explained_variance   | 0.211     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0974   |\n",
      "|    n_updates            | 43214     |\n",
      "|    policy_gradient_loss | -0.0808   |\n",
      "|    value_loss           | 0.0802    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 57       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2543     |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 325504   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2544       |\n",
      "|    time_elapsed         | 360        |\n",
      "|    total_timesteps      | 325632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41061214 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0901    |\n",
      "|    explained_variance   | 0.58       |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0724    |\n",
      "|    n_updates            | 43231      |\n",
      "|    policy_gradient_loss | -0.0467    |\n",
      "|    value_loss           | 0.0459     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1.45e+03 |\n",
      "|    ep_rew_mean          | 57       |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 2545     |\n",
      "|    time_elapsed         | 360      |\n",
      "|    total_timesteps      | 325760   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.484103 |\n",
      "|    clip_fraction        | 0.125    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -0.0918  |\n",
      "|    explained_variance   | 0.797    |\n",
      "|    learning_rate        | 0.000735 |\n",
      "|    loss                 | -0.065   |\n",
      "|    n_updates            | 43248    |\n",
      "|    policy_gradient_loss | -0.0539  |\n",
      "|    value_loss           | 0.0674   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 57        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2546      |\n",
      "|    time_elapsed         | 360       |\n",
      "|    total_timesteps      | 325888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3238121 |\n",
      "|    clip_fraction        | 0.0979    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0788   |\n",
      "|    explained_variance   | 0.425     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0171    |\n",
      "|    n_updates            | 43265     |\n",
      "|    policy_gradient_loss | -0.036    |\n",
      "|    value_loss           | 0.231     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=326000, episode_reward=28.43 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 28.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 326000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3805731 |\n",
      "|    clip_fraction        | 0.0643    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0903   |\n",
      "|    explained_variance   | 0.286     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | 0.0395    |\n",
      "|    n_updates            | 43282     |\n",
      "|    policy_gradient_loss | -0.035    |\n",
      "|    value_loss           | 0.555     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 57       |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2547     |\n",
      "|    time_elapsed    | 361      |\n",
      "|    total_timesteps | 326016   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2548       |\n",
      "|    time_elapsed         | 361        |\n",
      "|    total_timesteps      | 326144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28318834 |\n",
      "|    clip_fraction        | 0.0938     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.103     |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 43299      |\n",
      "|    policy_gradient_loss | -0.0513    |\n",
      "|    value_loss           | 0.264      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2549       |\n",
      "|    time_elapsed         | 361        |\n",
      "|    total_timesteps      | 326272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30468336 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.162     |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0249    |\n",
      "|    n_updates            | 43316      |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 0.484      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2550       |\n",
      "|    time_elapsed         | 361        |\n",
      "|    total_timesteps      | 326400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55682325 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0383    |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | 0.053      |\n",
      "|    n_updates            | 43333      |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=326500, episode_reward=17.51 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | 17.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 326500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4441005 |\n",
      "|    clip_fraction        | 0.0993    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.0639   |\n",
      "|    explained_variance   | 0.06      |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.051    |\n",
      "|    n_updates            | 43350     |\n",
      "|    policy_gradient_loss | -0.032    |\n",
      "|    value_loss           | 0.0283    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 57.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2551     |\n",
      "|    time_elapsed    | 361      |\n",
      "|    total_timesteps | 326528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2552       |\n",
      "|    time_elapsed         | 361        |\n",
      "|    total_timesteps      | 326656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44238502 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | 0.427      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0979    |\n",
      "|    n_updates            | 43367      |\n",
      "|    policy_gradient_loss | -0.0603    |\n",
      "|    value_loss           | 0.0344     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 57.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2553      |\n",
      "|    time_elapsed         | 362       |\n",
      "|    total_timesteps      | 326784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4203707 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | -0.667    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0932   |\n",
      "|    n_updates            | 43384     |\n",
      "|    policy_gradient_loss | -0.0637   |\n",
      "|    value_loss           | 0.0324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | 57.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 902       |\n",
      "|    iterations           | 2554      |\n",
      "|    time_elapsed         | 362       |\n",
      "|    total_timesteps      | 326912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5409167 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.129    |\n",
      "|    explained_variance   | 0.322     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.119    |\n",
      "|    n_updates            | 43401     |\n",
      "|    policy_gradient_loss | -0.0522   |\n",
      "|    value_loss           | 0.0411    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=327000, episode_reward=-1.37 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -1.37     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 327000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2976173 |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.171    |\n",
      "|    explained_variance   | -0.502    |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0747   |\n",
      "|    n_updates            | 43418     |\n",
      "|    policy_gradient_loss | -0.0644   |\n",
      "|    value_loss           | 0.0978    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 57.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 902      |\n",
      "|    iterations      | 2555     |\n",
      "|    time_elapsed    | 362      |\n",
      "|    total_timesteps | 327040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2556       |\n",
      "|    time_elapsed         | 362        |\n",
      "|    total_timesteps      | 327168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22813836 |\n",
      "|    clip_fraction        | 0.0846     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0717    |\n",
      "|    explained_variance   | 0.814      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.0471    |\n",
      "|    n_updates            | 43435      |\n",
      "|    policy_gradient_loss | -0.0372    |\n",
      "|    value_loss           | 0.0559     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | 57.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 902        |\n",
      "|    iterations           | 2557       |\n",
      "|    time_elapsed         | 362        |\n",
      "|    total_timesteps      | 327296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37705702 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -0.0797    |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.000735   |\n",
      "|    loss                 | -0.07      |\n",
      "|    n_updates            | 43452      |\n",
      "|    policy_gradient_loss | -0.0497    |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 57.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 902         |\n",
      "|    iterations           | 2558        |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 327424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062420845 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -0.131      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 0.0745      |\n",
      "|    n_updates            | 43469       |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=327500, episode_reward=-11.16 +/- 0.00\n",
      "Episode length: 245.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 245       |\n",
      "|    mean_reward          | -11.2     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 327500    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3137252 |\n",
      "|    clip_fraction        | 0.164     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -0.141    |\n",
      "|    explained_variance   | 0.757     |\n",
      "|    learning_rate        | 0.000735  |\n",
      "|    loss                 | -0.0184   |\n",
      "|    n_updates            | 43486     |\n",
      "|    policy_gradient_loss | -0.0627   |\n",
      "|    value_loss           | 0.212     |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Train the final model\n",
    "best_params = study.best_params\n",
    "\n",
    "\n",
    "train_env = CustomStocksEnv(df=train_df, window_size=window_size, frame_bound=(window_size, len(train_df)))\n",
    "val_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "val_env = Monitor(val_env)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "        val_env,\n",
    "        best_model_save_path='./logs/best_model/',\n",
    "        log_path='./logs/results/',\n",
    "        eval_freq=500,  # Evaluate every 500 timesteps.\n",
    "        deterministic=True,\n",
    "        render=False\n",
    "    )\n",
    "\n",
    "final_model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    n_steps=best_params[\"n_steps\"],\n",
    "    gamma=best_params[\"gamma\"],\n",
    "    ent_coef=best_params[\"ent_coef\"],\n",
    "    clip_range=best_params[\"clip_range\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    gae_lambda=best_params[\"gae_lambda\"],\n",
    "    n_epochs=best_params[\"n_epochs\"],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "final_model.learn(total_timesteps=500_000, callback=eval_callback)\n",
    "final_model.save(\"ppo_stocks_model\")\n",
    "\n",
    "#Load best model\n",
    "final_model = PPO.load(\"./logs/best_model/best_model.zip\")\n",
    "\n",
    "\n",
    "#val_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "mean_reward, std_reward = evaluate_policy(final_model, val_env, n_eval_episodes=20, deterministic=False)\n",
    "\n",
    "print(f\"Final model evaluation on validation set: Mean Reward = {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "\n",
    "train_env.close()\n",
    "val_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136cf19-5e02-43bc-8941-4062687ab01e",
   "metadata": {},
   "source": [
    "## c. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3025335f-539f-4d0f-9a0e-2f74d2eeb0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final info: {'total_reward': np.float32(5.1399765), 'total_profit': np.float32(1.0162286), 'position': <Positions.Short: 0>}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_env = CustomStocksEnv(df=test_df, window_size=window_size, frame_bound=(window_size, len(test_df)))\n",
    "final_model = PPO.load(\"./logs/best_model/best_model.zip\")#load(\"ppo_stocks_model\", env=test_env)\n",
    "\n",
    "obs, info = test_env.reset()\n",
    "rewards = []\n",
    "while True:\n",
    "    action, _states = final_model.predict(obs, deterministic=True)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    #print(reward)\n",
    "    #print(action)\n",
    "    #print(info)\n",
    "    #rewards.append(reward)\n",
    "    if done:\n",
    "        print(\"Final info:\", info)\n",
    "        break\n",
    "\n",
    "# (Optional) Render the final trading history\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.cla()\n",
    "test_env.unwrapped.render_all()\n",
    "plt.show()\n",
    "\n",
    "# Close the environment to free resources\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2920e6b1-93d4-42e7-89a6-7a776bd28f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final info: {'total_reward': np.float32(109.24083), 'total_profit': np.float32(3.4856975), 'position': <Positions.Short: 0>}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Performance on train_df\n",
    "test_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "final_model = PPO.load(\"./logs/best_model/best_model.zip\")#load(\"ppo_stocks_model\", env=test_env)\n",
    "\n",
    "obs, info = test_env.reset()\n",
    "rewards = []\n",
    "while True:\n",
    "    action, _states = final_model.predict(obs, deterministic=True)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        print(\"Final info:\", info)\n",
    "        break\n",
    "\n",
    "# (Optional) Render the final trading history\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.cla()\n",
    "test_env.unwrapped.render_all()\n",
    "plt.show()\n",
    "\n",
    "# Close the environment to free resources\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea825b-7740-428a-9bb8-2be0b0849fc9",
   "metadata": {},
   "source": [
    "# 4. RecurrentPPO Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ca9eb-0ccb-4980-8e63-de61b9effdf9",
   "metadata": {},
   "source": [
    "Because RecurrentPPO is an extension of PPO, we can reused hyperparameters from PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514c584-085e-4518-a0d2-589faca20e13",
   "metadata": {},
   "source": [
    "## a. Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6985aec-4932-4f24-a5c0-8872613ba4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ppo_best_params.pkl\", \"rb\") as f:\n",
    "    ppo_best_params = pickle.load(f)\n",
    "\n",
    "def recurrent_ppo_objective(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Fine tuning using Bayesian Optimization from optuna\n",
    "    \"\"\"\n",
    "    if ppo_best_params is not None:\n",
    "        # Sample LSTM hyperparams\n",
    "        n_lstm_layers = trial.suggest_int(\"n_lstm_layers\", 1, 3)\n",
    "        hidden_size  = trial.suggest_categorical(\"hidden_size\", [32, 64, 128, 256])\n",
    "        dropout      = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    \n",
    "        # PPO hyperparams\n",
    "        learning_rate = ppo_best_params['learning_rate']\n",
    "        n_steps       = ppo_best_params['n_steps']\n",
    "        gamma         = ppo_best_params['gamma']\n",
    "        ent_coef      = ppo_best_params['ent_coef']\n",
    "        clip_range    = ppo_best_params['clip_range']\n",
    "        batch_size       = ppo_best_params['batch_size']\n",
    "        gae_lambda       = ppo_best_params['gae_lambda']\n",
    "        n_epochs       = ppo_best_params['n_epochs']\n",
    "        \n",
    "    else:\n",
    "        # Sample LSTM hyperparams\n",
    "        n_lstm_layers = trial.suggest_int(\"n_lstm_layers\", 1, 3)\n",
    "        hidden_size  = trial.suggest_categorical(\"hidden_size\", [32, 64, 128, 256])\n",
    "        dropout      = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    \n",
    "        # PPO hyperparams\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2,log=True)\n",
    "        n_steps       = trial.suggest_int(\"n_steps\", 128, 2048, step=128)\n",
    "        gamma         = trial.suggest_float(\"gamma\", 0.90, 0.99, step=0.01)\n",
    "        ent_coef      = trial.suggest_float(\"ent_coef\", 1e-8, 0.1, log=True)\n",
    "        clip_range    = trial.suggest_float(\"clip_range\", 0.1, 0.4, step=0.05)\n",
    "    \n",
    "        #Less important hyperparameters:\n",
    "        batch_size       = trial.suggest_categorical(\"batch_size\", [32,64])\n",
    "        gae_lambda       = trial.suggest_float(\"gae_lambda\", 0.8, 0.98)\n",
    "        n_epochs       = trial.suggest_int(\"n_epochs\", 5, 20)\n",
    "\n",
    "\n",
    "    # --- Create the environment ---\n",
    "    train_env = CustomStocksEnv(df=train_df, window_size=window_size, frame_bound=(window_size, len(train_df)))\n",
    "    val_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "    val_env = Monitor(val_env)\n",
    "\n",
    "    eval_callback_ft = EvalCallback(\n",
    "        val_env,\n",
    "        best_model_save_path='./logs/best_model_ft_lstm/',\n",
    "        log_path='./logs/results_ft/',\n",
    "        eval_freq=500,  # Evaluate every 500 timesteps.\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Build policy_kwargs with a LSTM\n",
    "    policy_kwargs = dict(\n",
    "        #rnn_class=nn.GRU,\n",
    "        n_lstm_layers=n_lstm_layers,\n",
    "        lstm_hidden_size = hidden_size,\n",
    "        lstm_kwargs=dict(\n",
    "            dropout=dropout\n",
    "        ),\n",
    "        # after GRU, we add a small MLP\n",
    "        net_arch=dict(pi=[64], vf=[64])\n",
    "    )\n",
    "\n",
    "    # Build the RecurrentPPO model\n",
    "    model = RecurrentPPO( \n",
    "        policy=\"MlpLstmPolicy\", \n",
    "        env=train_env, \n",
    "        verbose=0, \n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=batch_size,\n",
    "        gae_lambda=gae_lambda,\n",
    "        gamma=gamma,\n",
    "        n_epochs=n_epochs, \n",
    "        ent_coef=ent_coef,\n",
    "        clip_range=clip_range,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "    #Keep it short - 50,000 steps also make sense\n",
    "    model.learn(total_timesteps=100_000, callback=eval_callback_ft)\n",
    "\n",
    "    model = RecurrentPPO.load(\"./logs/best_model_ft_lstm/best_model.zip\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, val_env, n_eval_episodes=10, deterministic=False)\n",
    "\n",
    "    # Cleanup the environments\n",
    "    train_env.close()\n",
    "    val_env.close()\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "def run_lstm_optimization():\n",
    "    n_trials = 50 if ppo_best_params is not None else 100\n",
    "    study = optuna.create_study(direction=\"maximize\")  \n",
    "    study.optimize(recurrent_ppo_objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best value (objective):\", study.best_value)\n",
    "\n",
    "    return study\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0113f-b97a-4718-80df-5d03e2a8fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run fine tuning\n",
    "lstm_study = run_lstm_optimization()\n",
    "\n",
    "lstm_best_params = lstm_study.best_params\n",
    "\n",
    "if ppo_best_params is not None:\n",
    "    lstm_best_params.update(ppo_best_params)\n",
    "\n",
    "with open(\"lstm_best_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lstm_best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388c1ed-7dcd-493f-a568-da472a383196",
   "metadata": {},
   "source": [
    "## b. Training final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efaa9cc-69f1-441f-834a-a989bfdba4c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lstm_env = CustomStocksEnv(df=train_df, window_size=window_size, frame_bound=(window_size, len(train_df)))\n",
    "val_lstm_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "val_lstm_env = Monitor(val_lstm_env)\n",
    "\n",
    "lstm_eval_callback = EvalCallback(\n",
    "        val_lstm_env,\n",
    "        best_model_save_path='./logs/best_model_lstm/',\n",
    "        log_path='./logs/results/',\n",
    "        eval_freq=500,  # Evaluate every 500 timesteps.\n",
    "        deterministic=True,\n",
    "        render=False\n",
    "    )\n",
    "\n",
    "final_policy_kwargs = dict(\n",
    "    n_lstm_layers=lstm_best_params[\"n_lstm_layers\"],\n",
    "    lstm_hidden_size = lstm_best_params[\"hidden_size\"],\n",
    "    lstm_kwargs=dict(\n",
    "        dropout=lstm_best_params[\"dropout\"]\n",
    "    ),\n",
    "    net_arch=dict(pi=[64], vf=[64])\n",
    ")\n",
    "\n",
    "final_lstm_model = RecurrentPPO(\n",
    "    policy=\"MlpLstmPolicy\",\n",
    "    env=train_lstm_env,\n",
    "    learning_rate=lstm_best_params[\"learning_rate\"],\n",
    "    n_steps=lstm_best_params[\"n_steps\"],\n",
    "    gamma=lstm_best_params[\"gamma\"],\n",
    "    ent_coef=lstm_best_params[\"ent_coef\"],\n",
    "    clip_range=lstm_best_params[\"clip_range\"],\n",
    "    batch_size=lstm_best_params[\"batch_size\"],\n",
    "    gae_lambda=lstm_best_params[\"gae_lambda\"],\n",
    "    n_epochs=lstm_best_params[\"n_epochs\"],\n",
    "    policy_kwargs=final_policy_kwargs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "final_lstm_model.learn(total_timesteps=100_000, callback= lstm_eval_callback)\n",
    "final_lstm_model.save(\"recurrent_ppo_stocks_model\")\n",
    "\n",
    "final_model = RecurrentPPO.load(\"./logs/best_model_lstm/best_model.zip\")\n",
    "\n",
    "#val_lstm_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "mean_reward, std_reward = evaluate_policy(final_lstm_model, val_lstm_env, n_eval_episodes=20, deterministic=False)\n",
    "\n",
    "print(f\"Final model evaluation on validation set: Mean Reward = {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "\n",
    "train_lstm_env.close()\n",
    "val_lstm_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272b0f8-0d07-4d58-9460-789913b5b442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c1c288-2b1b-4dec-a73b-1846591b0a1f",
   "metadata": {},
   "source": [
    "## c. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0473dc61-1942-4784-9549-dc9385f6b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final info: {'total_reward': np.float32(-1.3300095), 'total_profit': np.float32(0.9746087), 'position': <Positions.Short: 0>}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_lstm_env = CustomStocksEnv(df=test_df, window_size=window_size, frame_bound=(window_size, len(test_df)))\n",
    "final_lstm_model = RecurrentPPO.load(\"./logs/best_model_lstm/best_model.zip\")#.load(\"recurrent_ppo_stocks_model\", env=test_lstm_env)\n",
    "\n",
    "obs, info = test_lstm_env.reset()\n",
    "rewards = []\n",
    "while True:\n",
    "    action, _states = final_lstm_model.predict(obs, deterministic=True)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = test_lstm_env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    #print(reward)\n",
    "    #print(action)\n",
    "    #print(info)\n",
    "    #rewards.append(reward)\n",
    "    if done:\n",
    "        print(\"Final info:\", info)\n",
    "        break\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.cla()\n",
    "test_lstm_env.unwrapped.render_all()\n",
    "plt.show()\n",
    "\n",
    "test_lstm_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d92d34-4939-4cb3-9b6a-22d34ce226c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ed9ebf9-2d7a-4d62-9cb3-061a6fe3358e",
   "metadata": {},
   "source": [
    "# 5. A2C Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754884d-5167-44e1-b45e-4bc3d4c762c3",
   "metadata": {},
   "source": [
    "## a. Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c87899-1087-4faa-ad7d-f46ed20b14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2c_objective(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Fine tuning using Bayesian Optimization from optuna\n",
    "    \"\"\"\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    # A2C typically uses smaller n_steps than PPO since it updates synchronously\n",
    "    n_steps       = trial.suggest_int(\"n_steps\", 5, 130, step=5)\n",
    "    gamma         = trial.suggest_float(\"gamma\", 0.90, 0.99, step=0.01)\n",
    "    ent_coef      = trial.suggest_float(\"ent_coef\", 1e-8, 0.1, log=True)\n",
    "    gae_lambda    = trial.suggest_float(\"gae_lambda\", 0.8, 0.98)\n",
    "    # A2C-specific hyperparameters:\n",
    "    vf_coef       = trial.suggest_float(\"vf_coef\", 0.1, 1.0, step=0.1)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, step=0.1)\n",
    "\n",
    "\n",
    "    # --- Create the environment ---\n",
    "    train_env = CustomStocksEnv(df=train_df, window_size=window_size, frame_bound=(window_size, len(train_df)))\n",
    "    val_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "    val_env = Monitor(val_env)\n",
    "\n",
    "    eval_callback_ft = EvalCallback(\n",
    "        val_env,\n",
    "        best_model_save_path='./logs/best_model_ft_a2c/',\n",
    "        log_path='./logs/results_ft_a2c/',\n",
    "        eval_freq=500,  # Evaluate every 500 timesteps.\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Build the A2C model\n",
    "    model = A2C(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=train_env,\n",
    "        verbose=0,\n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        gae_lambda=gae_lambda,\n",
    "        ent_coef=ent_coef,\n",
    "        vf_coef=vf_coef,\n",
    "        max_grad_norm=max_grad_norm\n",
    "    )\n",
    "\n",
    "    #Keep it short - 50,000 steps also make sense\n",
    "    model.learn(total_timesteps=100_000, callback=eval_callback_ft)\n",
    "\n",
    "    model = PPO.load(\"./logs/best_model_ft_a2c/best_model.zip\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, val_env, n_eval_episodes=10, deterministic=False)\n",
    "\n",
    "    # Cleanup the environments\n",
    "    train_env.close()\n",
    "    val_env.close()\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "def run_a2c_optimization():\n",
    "    study = optuna.create_study(direction=\"maximize\")  \n",
    "    study.optimize(a2c_objective, n_trials=300)\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best value (objective):\", study.best_value)\n",
    "\n",
    "    return study\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7176e9b-1c3d-4cd7-b409-b6d542e90270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run fine tuning\n",
    "a2c_study = run_a2c_optimization()\n",
    "\n",
    "with open(\"a2c_best_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(a2c_study.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5598be-e04c-4c4d-9d91-bf0d8ad20288",
   "metadata": {},
   "source": [
    "## b. Training final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fe065-1609-4637-adef-1403ee573429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train the final model\n",
    "a2c_best_params = a2c_study.best_params\n",
    "\n",
    "\n",
    "train_a2c_env = CustomStocksEnv(df=train_df, window_size=window_size, frame_bound=(window_size, len(train_df)))\n",
    "val_a2c_env = CustomStocksEnv(df=val_df, window_size=window_size, frame_bound=(window_size, len(val_df)))\n",
    "val_a2c_env = Monitor(val_a2c_env)\n",
    "\n",
    "eval_callback_a2c = EvalCallback(\n",
    "        val_a2c_env,\n",
    "        best_model_save_path='./logs/best_model_a2c/',\n",
    "        log_path='./logs/results/',\n",
    "        eval_freq=500,  # Evaluate every 500 timesteps.\n",
    "        deterministic=True,\n",
    "        render=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "final_a2c_model = A2C(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=train_a2c_env,\n",
    "        verbose=1,\n",
    "        learning_rate=a2c_best_params['learning_rate'],\n",
    "        n_steps=a2c_best_params['n_steps'],\n",
    "        gamma=a2c_best_params['gamma'],\n",
    "        gae_lambda=a2c_best_params['gae_lambda'],\n",
    "        ent_coef=a2c_best_params['ent_coef'],\n",
    "        vf_coef=a2c_best_params['vf_coef'],\n",
    "        max_grad_norm=a2c_best_params['max_grad_norm']\n",
    "    )\n",
    "\n",
    "\n",
    "final_a2c_model.learn(total_timesteps=500_000, callback=eval_callback_a2c)\n",
    "final_a2c_model.save(\"a2c_stocks_model\")\n",
    "\n",
    "#Load best model\n",
    "final_a2c_model = A2C.load(\"./logs/best_model_a2c/best_model.zip\")\n",
    "\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(final_a2c_model, val_a2c_env, n_eval_episodes=20, deterministic=False)\n",
    "\n",
    "print(f\"Final model evaluation on validation set: Mean Reward = {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "\n",
    "train_env.close()\n",
    "val_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239ca40-4e9a-40e1-99e4-cbe77b9ded1d",
   "metadata": {},
   "source": [
    "## c. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e5106e2-63f5-4df6-ad08-269f02569290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final info: {'total_reward': np.float32(-5.0999985), 'total_profit': np.float32(0.94984543), 'position': <Positions.Short: 0>}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_a2c_env = CustomStocksEnv(df=test_df, window_size=window_size, frame_bound=(window_size, len(test_df)))\n",
    "final_a2c_model = PPO.load(\"./logs/best_model_a2c/best_model.zip\")#load(\"a2c_stocks_model\", env=test_a2c_env)\n",
    "\n",
    "obs, info = test_a2c_env.reset()\n",
    "while True:\n",
    "    action, _states = final_a2c_model.predict(obs, deterministic=True)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = test_a2c_env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    if done:\n",
    "        print(\"Final info:\", info)\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.cla()\n",
    "test_a2c_env.unwrapped.render_all()\n",
    "plt.show()\n",
    "\n",
    "# Close the environment to free resources\n",
    "test_a2c_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748cc62-2919-48fd-9973-849095463dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322228fd-e029-43c6-8e6d-4a13202dd39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1516bbd-d262-47d6-86ef-b7bf6d510ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05ed82-f914-4ac5-87b0-faea0b6fde1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
